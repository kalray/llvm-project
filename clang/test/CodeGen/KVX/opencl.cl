// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// REQUIRES: kvx
// RUN: %clang_cc1 -triple kvx-cos-kalray -S -disable-llvm-passes -emit-llvm -o - %s | FileCheck %s

typedef char __attribute__((ext_vector_type(2))) char2;
typedef char __attribute__((ext_vector_type(3))) char3;
typedef char __attribute__((ext_vector_type(4))) char4;
typedef char __attribute__((ext_vector_type(8))) char8;
typedef char __attribute__((ext_vector_type(16))) char16;

typedef short __attribute__((ext_vector_type(2))) short2;
typedef short __attribute__((ext_vector_type(3))) short3;
typedef short __attribute__((ext_vector_type(4))) short4;
typedef short __attribute__((ext_vector_type(8))) short8;
typedef short __attribute__((ext_vector_type(16))) short16;

typedef int __attribute__((ext_vector_type(2))) int2;
typedef int __attribute__((ext_vector_type(3))) int3;
typedef int __attribute__((ext_vector_type(4))) int4;
typedef int __attribute__((ext_vector_type(8))) int8;
typedef int __attribute__((ext_vector_type(16))) int16;

typedef long __attribute__((ext_vector_type(2))) long2;
typedef long __attribute__((ext_vector_type(3))) long3;
typedef long __attribute__((ext_vector_type(4))) long4;
typedef long __attribute__((ext_vector_type(8))) long8;
typedef long __attribute__((ext_vector_type(16))) long16;

typedef half __attribute__((ext_vector_type(2))) half2;
typedef half __attribute__((ext_vector_type(3))) half3;
typedef half __attribute__((ext_vector_type(4))) half4;
typedef half __attribute__((ext_vector_type(8))) half8;
typedef half __attribute__((ext_vector_type(16))) half16;

typedef float __attribute__((ext_vector_type(2))) float2;
typedef float __attribute__((ext_vector_type(3))) float3;
typedef float __attribute__((ext_vector_type(4))) float4;
typedef float __attribute__((ext_vector_type(8))) float8;
typedef float __attribute__((ext_vector_type(16))) float16;

typedef double __attribute__((ext_vector_type(2))) double2;
typedef double __attribute__((ext_vector_type(3))) double3;
typedef double __attribute__((ext_vector_type(4))) double4;
typedef double __attribute__((ext_vector_type(8))) double8;
typedef double __attribute__((ext_vector_type(16))) double16;



// CHECK-LABEL: @local_memory_alignment_global(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    store volatile i8 0, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @local_memory_alignment_global.lds_i8, i64 0, i64 0), align 1, [[TBAA4:!tbaa !.*]]
// CHECK-NEXT:    store volatile <2 x i8> zeroinitializer, <2 x i8>* getelementptr inbounds ([4 x <2 x i8>], [4 x <2 x i8>]* @local_memory_alignment_global.lds_v2i8, i64 0, i64 0), align 2, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x i8> <i8 0, i8 0, i8 0, i8 undef>, <4 x i8>* bitcast ([4 x <3 x i8>]* @local_memory_alignment_global.lds_v3i8 to <4 x i8>*), align 4, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x i8> zeroinitializer, <4 x i8>* getelementptr inbounds ([4 x <4 x i8>], [4 x <4 x i8>]* @local_memory_alignment_global.lds_v4i8, i64 0, i64 0), align 4, [[TBAA4]]
// CHECK-NEXT:    store volatile <8 x i8> zeroinitializer, <8 x i8>* getelementptr inbounds ([4 x <8 x i8>], [4 x <8 x i8>]* @local_memory_alignment_global.lds_v8i8, i64 0, i64 0), align 8, [[TBAA4]]
// CHECK-NEXT:    store volatile <16 x i8> zeroinitializer, <16 x i8>* getelementptr inbounds ([4 x <16 x i8>], [4 x <16 x i8>]* @local_memory_alignment_global.lds_v16i8, i64 0, i64 0), align 16, [[TBAA4]]
// CHECK-NEXT:    store volatile i16 0, i16* getelementptr inbounds ([4 x i16], [4 x i16]* @local_memory_alignment_global.lds_i16, i64 0, i64 0), align 2, [[TBAA7:!tbaa !.*]]
// CHECK-NEXT:    store volatile <2 x i16> zeroinitializer, <2 x i16>* getelementptr inbounds ([4 x <2 x i16>], [4 x <2 x i16>]* @local_memory_alignment_global.lds_v2i16, i64 0, i64 0), align 4, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x i16> <i16 0, i16 0, i16 0, i16 undef>, <4 x i16>* bitcast ([4 x <3 x i16>]* @local_memory_alignment_global.lds_v3i16 to <4 x i16>*), align 8, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x i16> zeroinitializer, <4 x i16>* getelementptr inbounds ([4 x <4 x i16>], [4 x <4 x i16>]* @local_memory_alignment_global.lds_v4i16, i64 0, i64 0), align 8, [[TBAA4]]
// CHECK-NEXT:    store volatile <8 x i16> zeroinitializer, <8 x i16>* getelementptr inbounds ([4 x <8 x i16>], [4 x <8 x i16>]* @local_memory_alignment_global.lds_v8i16, i64 0, i64 0), align 16, [[TBAA4]]
// CHECK-NEXT:    store volatile <16 x i16> zeroinitializer, <16 x i16>* getelementptr inbounds ([4 x <16 x i16>], [4 x <16 x i16>]* @local_memory_alignment_global.lds_v16i16, i64 0, i64 0), align 32, [[TBAA4]]
// CHECK-NEXT:    store volatile i32 0, i32* getelementptr inbounds ([4 x i32], [4 x i32]* @local_memory_alignment_global.lds_i32, i64 0, i64 0), align 4, [[TBAA9:!tbaa !.*]]
// CHECK-NEXT:    store volatile <2 x i32> zeroinitializer, <2 x i32>* getelementptr inbounds ([4 x <2 x i32>], [4 x <2 x i32>]* @local_memory_alignment_global.lds_v2i32, i64 0, i64 0), align 8, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x i32> <i32 0, i32 0, i32 0, i32 undef>, <4 x i32>* bitcast ([4 x <3 x i32>]* @local_memory_alignment_global.lds_v3i32 to <4 x i32>*), align 16, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x i32> zeroinitializer, <4 x i32>* getelementptr inbounds ([4 x <4 x i32>], [4 x <4 x i32>]* @local_memory_alignment_global.lds_v4i32, i64 0, i64 0), align 16, [[TBAA4]]
// CHECK-NEXT:    store volatile <8 x i32> zeroinitializer, <8 x i32>* getelementptr inbounds ([4 x <8 x i32>], [4 x <8 x i32>]* @local_memory_alignment_global.lds_v8i32, i64 0, i64 0), align 32, [[TBAA4]]
// CHECK-NEXT:    store volatile <16 x i32> zeroinitializer, <16 x i32>* getelementptr inbounds ([4 x <16 x i32>], [4 x <16 x i32>]* @local_memory_alignment_global.lds_v16i32, i64 0, i64 0), align 64, [[TBAA4]]
// CHECK-NEXT:    store volatile i64 0, i64* getelementptr inbounds ([4 x i64], [4 x i64]* @local_memory_alignment_global.lds_i64, i64 0, i64 0), align 8, [[TBAA11:!tbaa !.*]]
// CHECK-NEXT:    store volatile <2 x i64> zeroinitializer, <2 x i64>* getelementptr inbounds ([4 x <2 x i64>], [4 x <2 x i64>]* @local_memory_alignment_global.lds_v2i64, i64 0, i64 0), align 16, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x i64> <i64 0, i64 0, i64 0, i64 undef>, <4 x i64>* bitcast ([4 x <3 x i64>]* @local_memory_alignment_global.lds_v3i64 to <4 x i64>*), align 32, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x i64> zeroinitializer, <4 x i64>* getelementptr inbounds ([4 x <4 x i64>], [4 x <4 x i64>]* @local_memory_alignment_global.lds_v4i64, i64 0, i64 0), align 32, [[TBAA4]]
// CHECK-NEXT:    store volatile <8 x i64> zeroinitializer, <8 x i64>* getelementptr inbounds ([4 x <8 x i64>], [4 x <8 x i64>]* @local_memory_alignment_global.lds_v8i64, i64 0, i64 0), align 64, [[TBAA4]]
// CHECK-NEXT:    store volatile <16 x i64> zeroinitializer, <16 x i64>* getelementptr inbounds ([4 x <16 x i64>], [4 x <16 x i64>]* @local_memory_alignment_global.lds_v16i64, i64 0, i64 0), align 128, [[TBAA4]]
// CHECK-NEXT:    store volatile half 0xH0000, half* getelementptr inbounds ([4 x half], [4 x half]* @local_memory_alignment_global.lds_f16, i64 0, i64 0), align 2, [[TBAA13:!tbaa !.*]]
// CHECK-NEXT:    store volatile <2 x half> zeroinitializer, <2 x half>* getelementptr inbounds ([4 x <2 x half>], [4 x <2 x half>]* @local_memory_alignment_global.lds_v2f16, i64 0, i64 0), align 4, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x half> <half 0xH0000, half 0xH0000, half 0xH0000, half undef>, <4 x half>* bitcast ([4 x <3 x half>]* @local_memory_alignment_global.lds_v3f16 to <4 x half>*), align 8, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x half> zeroinitializer, <4 x half>* getelementptr inbounds ([4 x <4 x half>], [4 x <4 x half>]* @local_memory_alignment_global.lds_v4f16, i64 0, i64 0), align 8, [[TBAA4]]
// CHECK-NEXT:    store volatile <8 x half> zeroinitializer, <8 x half>* getelementptr inbounds ([4 x <8 x half>], [4 x <8 x half>]* @local_memory_alignment_global.lds_v8f16, i64 0, i64 0), align 16, [[TBAA4]]
// CHECK-NEXT:    store volatile <16 x half> zeroinitializer, <16 x half>* getelementptr inbounds ([4 x <16 x half>], [4 x <16 x half>]* @local_memory_alignment_global.lds_v16f16, i64 0, i64 0), align 32, [[TBAA4]]
// CHECK-NEXT:    store volatile float 0.000000e+00, float* getelementptr inbounds ([4 x float], [4 x float]* @local_memory_alignment_global.lds_f32, i64 0, i64 0), align 4, [[TBAA15:!tbaa !.*]]
// CHECK-NEXT:    store volatile <2 x float> zeroinitializer, <2 x float>* getelementptr inbounds ([4 x <2 x float>], [4 x <2 x float>]* @local_memory_alignment_global.lds_v2f32, i64 0, i64 0), align 8, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x float> <float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float undef>, <4 x float>* bitcast ([4 x <3 x float>]* @local_memory_alignment_global.lds_v3f32 to <4 x float>*), align 16, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x float> zeroinitializer, <4 x float>* getelementptr inbounds ([4 x <4 x float>], [4 x <4 x float>]* @local_memory_alignment_global.lds_v4f32, i64 0, i64 0), align 16, [[TBAA4]]
// CHECK-NEXT:    store volatile <8 x float> zeroinitializer, <8 x float>* getelementptr inbounds ([4 x <8 x float>], [4 x <8 x float>]* @local_memory_alignment_global.lds_v8f32, i64 0, i64 0), align 32, [[TBAA4]]
// CHECK-NEXT:    store volatile <16 x float> zeroinitializer, <16 x float>* getelementptr inbounds ([4 x <16 x float>], [4 x <16 x float>]* @local_memory_alignment_global.lds_v16f32, i64 0, i64 0), align 64, [[TBAA4]]
// CHECK-NEXT:    store volatile double 0.000000e+00, double* getelementptr inbounds ([4 x double], [4 x double]* @local_memory_alignment_global.lds_f64, i64 0, i64 0), align 8, [[TBAA17:!tbaa !.*]]
// CHECK-NEXT:    store volatile <2 x double> zeroinitializer, <2 x double>* getelementptr inbounds ([4 x <2 x double>], [4 x <2 x double>]* @local_memory_alignment_global.lds_v2f64, i64 0, i64 0), align 16, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x double> <double 0.000000e+00, double 0.000000e+00, double 0.000000e+00, double undef>, <4 x double>* bitcast ([4 x <3 x double>]* @local_memory_alignment_global.lds_v3f64 to <4 x double>*), align 32, [[TBAA4]]
// CHECK-NEXT:    store volatile <4 x double> zeroinitializer, <4 x double>* getelementptr inbounds ([4 x <4 x double>], [4 x <4 x double>]* @local_memory_alignment_global.lds_v4f64, i64 0, i64 0), align 32, [[TBAA4]]
// CHECK-NEXT:    store volatile <8 x double> zeroinitializer, <8 x double>* getelementptr inbounds ([4 x <8 x double>], [4 x <8 x double>]* @local_memory_alignment_global.lds_v8f64, i64 0, i64 0), align 64, [[TBAA4]]
// CHECK-NEXT:    store volatile <16 x double> zeroinitializer, <16 x double>* getelementptr inbounds ([4 x <16 x double>], [4 x <16 x double>]* @local_memory_alignment_global.lds_v16f64, i64 0, i64 0), align 128, [[TBAA4]]
// CHECK-NEXT:    ret void
//
kernel void local_memory_alignment_global()
{
  volatile local char lds_i8[4];
  volatile local char2 lds_v2i8[4];
  volatile local char3 lds_v3i8[4];
  volatile local char4 lds_v4i8[4];
  volatile local char8 lds_v8i8[4];
  volatile local char16 lds_v16i8[4];

  volatile local short lds_i16[4];
  volatile local short2 lds_v2i16[4];
  volatile local short3 lds_v3i16[4];
  volatile local short4 lds_v4i16[4];
  volatile local short8 lds_v8i16[4];
  volatile local short16 lds_v16i16[4];

  volatile local int lds_i32[4];
  volatile local int2 lds_v2i32[4];
  volatile local int3 lds_v3i32[4];
  volatile local int4 lds_v4i32[4];
  volatile local int8 lds_v8i32[4];
  volatile local int16 lds_v16i32[4];

  volatile local long lds_i64[4];
  volatile local long2 lds_v2i64[4];
  volatile local long3 lds_v3i64[4];
  volatile local long4 lds_v4i64[4];
  volatile local long8 lds_v8i64[4];
  volatile local long16 lds_v16i64[4];

  volatile local half lds_f16[4];
  volatile local half2 lds_v2f16[4];
  volatile local half3 lds_v3f16[4];
  volatile local half4 lds_v4f16[4];
  volatile local half8 lds_v8f16[4];
  volatile local half16 lds_v16f16[4];

  volatile local float lds_f32[4];
  volatile local float2 lds_v2f32[4];
  volatile local float3 lds_v3f32[4];
  volatile local float4 lds_v4f32[4];
  volatile local float8 lds_v8f32[4];
  volatile local float16 lds_v16f32[4];

  volatile local double lds_f64[4];
  volatile local double2 lds_v2f64[4];
  volatile local double3 lds_v3f64[4];
  volatile local double4 lds_v4f64[4];
  volatile local double8 lds_v8f64[4];
  volatile local double16 lds_v16f64[4];

  *lds_i8 = 0;
  *lds_v2i8 = 0;
  *lds_v3i8 = 0;
  *lds_v4i8 = 0;
  *lds_v8i8 = 0;
  *lds_v16i8 = 0;

  *lds_i16 = 0;
  *lds_v2i16 = 0;
  *lds_v3i16 = 0;
  *lds_v4i16 = 0;
  *lds_v8i16 = 0;
  *lds_v16i16 = 0;

  *lds_i32 = 0;
  *lds_v2i32 = 0;
  *lds_v3i32 = 0;
  *lds_v4i32 = 0;
  *lds_v8i32 = 0;
  *lds_v16i32 = 0;

  *lds_i64 = 0;
  *lds_v2i64 = 0;
  *lds_v3i64 = 0;
  *lds_v4i64 = 0;
  *lds_v8i64 = 0;
  *lds_v16i64 = 0;

  *lds_f16 = 0;
  *lds_v2f16 = 0;
  *lds_v3f16 = 0;
  *lds_v4f16 = 0;
  *lds_v8f16 = 0;
  *lds_v16f16 = 0;

  *lds_f32 = 0;
  *lds_v2f32 = 0;
  *lds_v3f32 = 0;
  *lds_v4f32 = 0;
  *lds_v8f32 = 0;
  *lds_v16f32 = 0;

  *lds_f64 = 0;
  *lds_v2f64 = 0;
  *lds_v3f64 = 0;
  *lds_v4f64 = 0;
  *lds_v8f64 = 0;
  *lds_v16f64 = 0;
}

// CHECK-LABEL: @local_memory_alignment_arg(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[LDS_I8_ADDR:%.*]] = alloca i8*, align 8
// CHECK-NEXT:    [[LDS_V2I8_ADDR:%.*]] = alloca <2 x i8>*, align 8
// CHECK-NEXT:    [[LDS_V3I8_ADDR:%.*]] = alloca <3 x i8>*, align 8
// CHECK-NEXT:    [[LDS_V4I8_ADDR:%.*]] = alloca <4 x i8>*, align 8
// CHECK-NEXT:    [[LDS_V8I8_ADDR:%.*]] = alloca <8 x i8>*, align 8
// CHECK-NEXT:    [[LDS_V16I8_ADDR:%.*]] = alloca <16 x i8>*, align 8
// CHECK-NEXT:    [[LDS_I16_ADDR:%.*]] = alloca i16*, align 8
// CHECK-NEXT:    [[LDS_V2I16_ADDR:%.*]] = alloca <2 x i16>*, align 8
// CHECK-NEXT:    [[LDS_V3I16_ADDR:%.*]] = alloca <3 x i16>*, align 8
// CHECK-NEXT:    [[LDS_V4I16_ADDR:%.*]] = alloca <4 x i16>*, align 8
// CHECK-NEXT:    [[LDS_V8I16_ADDR:%.*]] = alloca <8 x i16>*, align 8
// CHECK-NEXT:    [[LDS_V16I16_ADDR:%.*]] = alloca <16 x i16>*, align 8
// CHECK-NEXT:    [[LDS_I32_ADDR:%.*]] = alloca i32*, align 8
// CHECK-NEXT:    [[LDS_V2I32_ADDR:%.*]] = alloca <2 x i32>*, align 8
// CHECK-NEXT:    [[LDS_V3I32_ADDR:%.*]] = alloca <3 x i32>*, align 8
// CHECK-NEXT:    [[LDS_V4I32_ADDR:%.*]] = alloca <4 x i32>*, align 8
// CHECK-NEXT:    [[LDS_V8I32_ADDR:%.*]] = alloca <8 x i32>*, align 8
// CHECK-NEXT:    [[LDS_V16I32_ADDR:%.*]] = alloca <16 x i32>*, align 8
// CHECK-NEXT:    [[LDS_I64_ADDR:%.*]] = alloca i64*, align 8
// CHECK-NEXT:    [[LDS_V2I64_ADDR:%.*]] = alloca <2 x i64>*, align 8
// CHECK-NEXT:    [[LDS_V3I64_ADDR:%.*]] = alloca <3 x i64>*, align 8
// CHECK-NEXT:    [[LDS_V4I64_ADDR:%.*]] = alloca <4 x i64>*, align 8
// CHECK-NEXT:    [[LDS_V8I64_ADDR:%.*]] = alloca <8 x i64>*, align 8
// CHECK-NEXT:    [[LDS_V16I64_ADDR:%.*]] = alloca <16 x i64>*, align 8
// CHECK-NEXT:    [[LDS_F16_ADDR:%.*]] = alloca half*, align 8
// CHECK-NEXT:    [[LDS_V2F16_ADDR:%.*]] = alloca <2 x half>*, align 8
// CHECK-NEXT:    [[LDS_V3F16_ADDR:%.*]] = alloca <3 x half>*, align 8
// CHECK-NEXT:    [[LDS_V4F16_ADDR:%.*]] = alloca <4 x half>*, align 8
// CHECK-NEXT:    [[LDS_V8F16_ADDR:%.*]] = alloca <8 x half>*, align 8
// CHECK-NEXT:    [[LDS_V16F16_ADDR:%.*]] = alloca <16 x half>*, align 8
// CHECK-NEXT:    [[LDS_F32_ADDR:%.*]] = alloca float*, align 8
// CHECK-NEXT:    [[LDS_V2F32_ADDR:%.*]] = alloca <2 x float>*, align 8
// CHECK-NEXT:    [[LDS_V3F32_ADDR:%.*]] = alloca <3 x float>*, align 8
// CHECK-NEXT:    [[LDS_V4F32_ADDR:%.*]] = alloca <4 x float>*, align 8
// CHECK-NEXT:    [[LDS_V8F32_ADDR:%.*]] = alloca <8 x float>*, align 8
// CHECK-NEXT:    [[LDS_V16F32_ADDR:%.*]] = alloca <16 x float>*, align 8
// CHECK-NEXT:    [[LDS_F64_ADDR:%.*]] = alloca double*, align 8
// CHECK-NEXT:    [[LDS_V2F64_ADDR:%.*]] = alloca <2 x double>*, align 8
// CHECK-NEXT:    [[LDS_V3F64_ADDR:%.*]] = alloca <3 x double>*, align 8
// CHECK-NEXT:    [[LDS_V4F64_ADDR:%.*]] = alloca <4 x double>*, align 8
// CHECK-NEXT:    [[LDS_V8F64_ADDR:%.*]] = alloca <8 x double>*, align 8
// CHECK-NEXT:    [[LDS_V16F64_ADDR:%.*]] = alloca <16 x double>*, align 8
// CHECK-NEXT:    store i8* [[LDS_I8:%.*]], i8** [[LDS_I8_ADDR]], align 8, [[TBAA24:!tbaa !.*]]
// CHECK-NEXT:    store <2 x i8>* [[LDS_V2I8:%.*]], <2 x i8>** [[LDS_V2I8_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <3 x i8>* [[LDS_V3I8:%.*]], <3 x i8>** [[LDS_V3I8_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <4 x i8>* [[LDS_V4I8:%.*]], <4 x i8>** [[LDS_V4I8_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <8 x i8>* [[LDS_V8I8:%.*]], <8 x i8>** [[LDS_V8I8_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <16 x i8>* [[LDS_V16I8:%.*]], <16 x i8>** [[LDS_V16I8_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store i16* [[LDS_I16:%.*]], i16** [[LDS_I16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <2 x i16>* [[LDS_V2I16:%.*]], <2 x i16>** [[LDS_V2I16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <3 x i16>* [[LDS_V3I16:%.*]], <3 x i16>** [[LDS_V3I16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <4 x i16>* [[LDS_V4I16:%.*]], <4 x i16>** [[LDS_V4I16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <8 x i16>* [[LDS_V8I16:%.*]], <8 x i16>** [[LDS_V8I16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <16 x i16>* [[LDS_V16I16:%.*]], <16 x i16>** [[LDS_V16I16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store i32* [[LDS_I32:%.*]], i32** [[LDS_I32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <2 x i32>* [[LDS_V2I32:%.*]], <2 x i32>** [[LDS_V2I32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <3 x i32>* [[LDS_V3I32:%.*]], <3 x i32>** [[LDS_V3I32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <4 x i32>* [[LDS_V4I32:%.*]], <4 x i32>** [[LDS_V4I32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <8 x i32>* [[LDS_V8I32:%.*]], <8 x i32>** [[LDS_V8I32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <16 x i32>* [[LDS_V16I32:%.*]], <16 x i32>** [[LDS_V16I32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store i64* [[LDS_I64:%.*]], i64** [[LDS_I64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <2 x i64>* [[LDS_V2I64:%.*]], <2 x i64>** [[LDS_V2I64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <3 x i64>* [[LDS_V3I64:%.*]], <3 x i64>** [[LDS_V3I64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <4 x i64>* [[LDS_V4I64:%.*]], <4 x i64>** [[LDS_V4I64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <8 x i64>* [[LDS_V8I64:%.*]], <8 x i64>** [[LDS_V8I64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <16 x i64>* [[LDS_V16I64:%.*]], <16 x i64>** [[LDS_V16I64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store half* [[LDS_F16:%.*]], half** [[LDS_F16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <2 x half>* [[LDS_V2F16:%.*]], <2 x half>** [[LDS_V2F16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <3 x half>* [[LDS_V3F16:%.*]], <3 x half>** [[LDS_V3F16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <4 x half>* [[LDS_V4F16:%.*]], <4 x half>** [[LDS_V4F16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <8 x half>* [[LDS_V8F16:%.*]], <8 x half>** [[LDS_V8F16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <16 x half>* [[LDS_V16F16:%.*]], <16 x half>** [[LDS_V16F16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store float* [[LDS_F32:%.*]], float** [[LDS_F32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <2 x float>* [[LDS_V2F32:%.*]], <2 x float>** [[LDS_V2F32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <3 x float>* [[LDS_V3F32:%.*]], <3 x float>** [[LDS_V3F32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <4 x float>* [[LDS_V4F32:%.*]], <4 x float>** [[LDS_V4F32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <8 x float>* [[LDS_V8F32:%.*]], <8 x float>** [[LDS_V8F32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <16 x float>* [[LDS_V16F32:%.*]], <16 x float>** [[LDS_V16F32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store double* [[LDS_F64:%.*]], double** [[LDS_F64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <2 x double>* [[LDS_V2F64:%.*]], <2 x double>** [[LDS_V2F64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <3 x double>* [[LDS_V3F64:%.*]], <3 x double>** [[LDS_V3F64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <4 x double>* [[LDS_V4F64:%.*]], <4 x double>** [[LDS_V4F64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <8 x double>* [[LDS_V8F64:%.*]], <8 x double>** [[LDS_V8F64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store <16 x double>* [[LDS_V16F64:%.*]], <16 x double>** [[LDS_V16F64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    [[TMP0:%.*]] = load i8*, i8** [[LDS_I8_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile i8 0, i8* [[TMP0]], align 1, [[TBAA4]]
// CHECK-NEXT:    [[TMP1:%.*]] = load <2 x i8>*, <2 x i8>** [[LDS_V2I8_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <2 x i8> zeroinitializer, <2 x i8>* [[TMP1]], align 2, [[TBAA4]]
// CHECK-NEXT:    [[TMP2:%.*]] = load <3 x i8>*, <3 x i8>** [[LDS_V3I8_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    [[STORETMP:%.*]] = bitcast <3 x i8>* [[TMP2]] to <4 x i8>*
// CHECK-NEXT:    store volatile <4 x i8> <i8 0, i8 0, i8 0, i8 undef>, <4 x i8>* [[STORETMP]], align 4, [[TBAA4]]
// CHECK-NEXT:    [[TMP3:%.*]] = load <4 x i8>*, <4 x i8>** [[LDS_V4I8_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <4 x i8> zeroinitializer, <4 x i8>* [[TMP3]], align 4, [[TBAA4]]
// CHECK-NEXT:    [[TMP4:%.*]] = load <8 x i8>*, <8 x i8>** [[LDS_V8I8_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <8 x i8> zeroinitializer, <8 x i8>* [[TMP4]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[TMP5:%.*]] = load <16 x i8>*, <16 x i8>** [[LDS_V16I8_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <16 x i8> zeroinitializer, <16 x i8>* [[TMP5]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[TMP6:%.*]] = load i16*, i16** [[LDS_I16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile i16 0, i16* [[TMP6]], align 2, [[TBAA7]]
// CHECK-NEXT:    [[TMP7:%.*]] = load <2 x i16>*, <2 x i16>** [[LDS_V2I16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <2 x i16> zeroinitializer, <2 x i16>* [[TMP7]], align 4, [[TBAA4]]
// CHECK-NEXT:    [[TMP8:%.*]] = load <3 x i16>*, <3 x i16>** [[LDS_V3I16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    [[STORETMP1:%.*]] = bitcast <3 x i16>* [[TMP8]] to <4 x i16>*
// CHECK-NEXT:    store volatile <4 x i16> <i16 0, i16 0, i16 0, i16 undef>, <4 x i16>* [[STORETMP1]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[TMP9:%.*]] = load <4 x i16>*, <4 x i16>** [[LDS_V4I16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <4 x i16> zeroinitializer, <4 x i16>* [[TMP9]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[TMP10:%.*]] = load <8 x i16>*, <8 x i16>** [[LDS_V8I16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <8 x i16> zeroinitializer, <8 x i16>* [[TMP10]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[TMP11:%.*]] = load <16 x i16>*, <16 x i16>** [[LDS_V16I16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <16 x i16> zeroinitializer, <16 x i16>* [[TMP11]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[TMP12:%.*]] = load i32*, i32** [[LDS_I32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile i32 0, i32* [[TMP12]], align 4, [[TBAA9]]
// CHECK-NEXT:    [[TMP13:%.*]] = load <2 x i32>*, <2 x i32>** [[LDS_V2I32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <2 x i32> zeroinitializer, <2 x i32>* [[TMP13]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[TMP14:%.*]] = load <3 x i32>*, <3 x i32>** [[LDS_V3I32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    [[STORETMP2:%.*]] = bitcast <3 x i32>* [[TMP14]] to <4 x i32>*
// CHECK-NEXT:    store volatile <4 x i32> <i32 0, i32 0, i32 0, i32 undef>, <4 x i32>* [[STORETMP2]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[TMP15:%.*]] = load <4 x i32>*, <4 x i32>** [[LDS_V4I32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <4 x i32> zeroinitializer, <4 x i32>* [[TMP15]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[TMP16:%.*]] = load <8 x i32>*, <8 x i32>** [[LDS_V8I32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <8 x i32> zeroinitializer, <8 x i32>* [[TMP16]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[TMP17:%.*]] = load <16 x i32>*, <16 x i32>** [[LDS_V16I32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <16 x i32> zeroinitializer, <16 x i32>* [[TMP17]], align 64, [[TBAA4]]
// CHECK-NEXT:    [[TMP18:%.*]] = load i64*, i64** [[LDS_I64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile i64 0, i64* [[TMP18]], align 8, [[TBAA11]]
// CHECK-NEXT:    [[TMP19:%.*]] = load <2 x i64>*, <2 x i64>** [[LDS_V2I64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <2 x i64> zeroinitializer, <2 x i64>* [[TMP19]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[TMP20:%.*]] = load <3 x i64>*, <3 x i64>** [[LDS_V3I64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    [[STORETMP3:%.*]] = bitcast <3 x i64>* [[TMP20]] to <4 x i64>*
// CHECK-NEXT:    store volatile <4 x i64> <i64 0, i64 0, i64 0, i64 undef>, <4 x i64>* [[STORETMP3]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[TMP21:%.*]] = load <4 x i64>*, <4 x i64>** [[LDS_V4I64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <4 x i64> zeroinitializer, <4 x i64>* [[TMP21]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[TMP22:%.*]] = load <8 x i64>*, <8 x i64>** [[LDS_V8I64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <8 x i64> zeroinitializer, <8 x i64>* [[TMP22]], align 64, [[TBAA4]]
// CHECK-NEXT:    [[TMP23:%.*]] = load <16 x i64>*, <16 x i64>** [[LDS_V16I64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <16 x i64> zeroinitializer, <16 x i64>* [[TMP23]], align 128, [[TBAA4]]
// CHECK-NEXT:    [[TMP24:%.*]] = load half*, half** [[LDS_F16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile half 0xH0000, half* [[TMP24]], align 2, [[TBAA13]]
// CHECK-NEXT:    [[TMP25:%.*]] = load <2 x half>*, <2 x half>** [[LDS_V2F16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <2 x half> zeroinitializer, <2 x half>* [[TMP25]], align 4, [[TBAA4]]
// CHECK-NEXT:    [[TMP26:%.*]] = load <3 x half>*, <3 x half>** [[LDS_V3F16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    [[STORETMP4:%.*]] = bitcast <3 x half>* [[TMP26]] to <4 x half>*
// CHECK-NEXT:    store volatile <4 x half> <half 0xH0000, half 0xH0000, half 0xH0000, half undef>, <4 x half>* [[STORETMP4]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[TMP27:%.*]] = load <4 x half>*, <4 x half>** [[LDS_V4F16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <4 x half> zeroinitializer, <4 x half>* [[TMP27]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[TMP28:%.*]] = load <8 x half>*, <8 x half>** [[LDS_V8F16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <8 x half> zeroinitializer, <8 x half>* [[TMP28]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[TMP29:%.*]] = load <16 x half>*, <16 x half>** [[LDS_V16F16_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <16 x half> zeroinitializer, <16 x half>* [[TMP29]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[TMP30:%.*]] = load float*, float** [[LDS_F32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile float 0.000000e+00, float* [[TMP30]], align 4, [[TBAA15]]
// CHECK-NEXT:    [[TMP31:%.*]] = load <2 x float>*, <2 x float>** [[LDS_V2F32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <2 x float> zeroinitializer, <2 x float>* [[TMP31]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[TMP32:%.*]] = load <3 x float>*, <3 x float>** [[LDS_V3F32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    [[STORETMP5:%.*]] = bitcast <3 x float>* [[TMP32]] to <4 x float>*
// CHECK-NEXT:    store volatile <4 x float> <float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float undef>, <4 x float>* [[STORETMP5]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[TMP33:%.*]] = load <4 x float>*, <4 x float>** [[LDS_V4F32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <4 x float> zeroinitializer, <4 x float>* [[TMP33]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[TMP34:%.*]] = load <8 x float>*, <8 x float>** [[LDS_V8F32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <8 x float> zeroinitializer, <8 x float>* [[TMP34]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[TMP35:%.*]] = load <16 x float>*, <16 x float>** [[LDS_V16F32_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <16 x float> zeroinitializer, <16 x float>* [[TMP35]], align 64, [[TBAA4]]
// CHECK-NEXT:    [[TMP36:%.*]] = load double*, double** [[LDS_F64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile double 0.000000e+00, double* [[TMP36]], align 8, [[TBAA17]]
// CHECK-NEXT:    [[TMP37:%.*]] = load <2 x double>*, <2 x double>** [[LDS_V2F64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <2 x double> zeroinitializer, <2 x double>* [[TMP37]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[TMP38:%.*]] = load <3 x double>*, <3 x double>** [[LDS_V3F64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    [[STORETMP6:%.*]] = bitcast <3 x double>* [[TMP38]] to <4 x double>*
// CHECK-NEXT:    store volatile <4 x double> <double 0.000000e+00, double 0.000000e+00, double 0.000000e+00, double undef>, <4 x double>* [[STORETMP6]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[TMP39:%.*]] = load <4 x double>*, <4 x double>** [[LDS_V4F64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <4 x double> zeroinitializer, <4 x double>* [[TMP39]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[TMP40:%.*]] = load <8 x double>*, <8 x double>** [[LDS_V8F64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <8 x double> zeroinitializer, <8 x double>* [[TMP40]], align 64, [[TBAA4]]
// CHECK-NEXT:    [[TMP41:%.*]] = load <16 x double>*, <16 x double>** [[LDS_V16F64_ADDR]], align 8, [[TBAA24]]
// CHECK-NEXT:    store volatile <16 x double> zeroinitializer, <16 x double>* [[TMP41]], align 128, [[TBAA4]]
// CHECK-NEXT:    ret void
//
kernel void local_memory_alignment_arg(
  volatile local char* lds_i8,
  volatile local char2* lds_v2i8,
  volatile local char3* lds_v3i8,
  volatile local char4* lds_v4i8,
  volatile local char8* lds_v8i8,
  volatile local char16* lds_v16i8,

  volatile local short* lds_i16,
  volatile local short2* lds_v2i16,
  volatile local short3* lds_v3i16,
  volatile local short4* lds_v4i16,
  volatile local short8* lds_v8i16,
  volatile local short16* lds_v16i16,

  volatile local int* lds_i32,
  volatile local int2* lds_v2i32,
  volatile local int3* lds_v3i32,
  volatile local int4* lds_v4i32,
  volatile local int8* lds_v8i32,
  volatile local int16* lds_v16i32,

  volatile local long* lds_i64,
  volatile local long2* lds_v2i64,
  volatile local long3* lds_v3i64,
  volatile local long4* lds_v4i64,
  volatile local long8* lds_v8i64,
  volatile local long16* lds_v16i64,

  volatile local half* lds_f16,
  volatile local half2* lds_v2f16,
  volatile local half3* lds_v3f16,
  volatile local half4* lds_v4f16,
  volatile local half8* lds_v8f16,
  volatile local half16* lds_v16f16,

  volatile local float* lds_f32,
  volatile local float2* lds_v2f32,
  volatile local float3* lds_v3f32,
  volatile local float4* lds_v4f32,
  volatile local float8* lds_v8f32,
  volatile local float16* lds_v16f32,

  volatile local double* lds_f64,
  volatile local double2* lds_v2f64,
  volatile local double3* lds_v3f64,
  volatile local double4* lds_v4f64,
  volatile local double8* lds_v8f64,
  volatile local double16* lds_v16f64)
{
  *lds_i8 = 0;
  *lds_v2i8 = 0;
  *lds_v3i8 = 0;
  *lds_v4i8 = 0;
  *lds_v8i8 = 0;
  *lds_v16i8 = 0;

  *lds_i16 = 0;
  *lds_v2i16 = 0;
  *lds_v3i16 = 0;
  *lds_v4i16 = 0;
  *lds_v8i16 = 0;
  *lds_v16i16 = 0;

  *lds_i32 = 0;
  *lds_v2i32 = 0;
  *lds_v3i32 = 0;
  *lds_v4i32 = 0;
  *lds_v8i32 = 0;
  *lds_v16i32 = 0;

  *lds_i64 = 0;
  *lds_v2i64 = 0;
  *lds_v3i64 = 0;
  *lds_v4i64 = 0;
  *lds_v8i64 = 0;
  *lds_v16i64 = 0;

  *lds_f16 = 0;
  *lds_v2f16 = 0;
  *lds_v3f16 = 0;
  *lds_v4f16 = 0;
  *lds_v8f16 = 0;
  *lds_v16f16 = 0;

  *lds_f32 = 0;
  *lds_v2f32 = 0;
  *lds_v3f32 = 0;
  *lds_v4f32 = 0;
  *lds_v8f32 = 0;
  *lds_v16f32 = 0;

  *lds_f64 = 0;
  *lds_v2f64 = 0;
  *lds_v3f64 = 0;
  *lds_v4f64 = 0;
  *lds_v8f64 = 0;
  *lds_v16f64 = 0;
}


// CHECK-LABEL: @private_memory_alignment_alloca(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[PRIVATE_I8:%.*]] = alloca [4 x i8], align 1
// CHECK-NEXT:    [[PRIVATE_V2I8:%.*]] = alloca [4 x <2 x i8>], align 2
// CHECK-NEXT:    [[PRIVATE_V3I8:%.*]] = alloca [4 x <3 x i8>], align 4
// CHECK-NEXT:    [[PRIVATE_V4I8:%.*]] = alloca [4 x <4 x i8>], align 4
// CHECK-NEXT:    [[PRIVATE_V8I8:%.*]] = alloca [4 x <8 x i8>], align 8
// CHECK-NEXT:    [[PRIVATE_V16I8:%.*]] = alloca [4 x <16 x i8>], align 16
// CHECK-NEXT:    [[PRIVATE_I16:%.*]] = alloca [4 x i16], align 2
// CHECK-NEXT:    [[PRIVATE_V2I16:%.*]] = alloca [4 x <2 x i16>], align 4
// CHECK-NEXT:    [[PRIVATE_V3I16:%.*]] = alloca [4 x <3 x i16>], align 8
// CHECK-NEXT:    [[PRIVATE_V4I16:%.*]] = alloca [4 x <4 x i16>], align 8
// CHECK-NEXT:    [[PRIVATE_V8I16:%.*]] = alloca [4 x <8 x i16>], align 16
// CHECK-NEXT:    [[PRIVATE_V16I16:%.*]] = alloca [4 x <16 x i16>], align 32
// CHECK-NEXT:    [[PRIVATE_I32:%.*]] = alloca [4 x i32], align 4
// CHECK-NEXT:    [[PRIVATE_V2I32:%.*]] = alloca [4 x <2 x i32>], align 8
// CHECK-NEXT:    [[PRIVATE_V3I32:%.*]] = alloca [4 x <3 x i32>], align 16
// CHECK-NEXT:    [[PRIVATE_V4I32:%.*]] = alloca [4 x <4 x i32>], align 16
// CHECK-NEXT:    [[PRIVATE_V8I32:%.*]] = alloca [4 x <8 x i32>], align 32
// CHECK-NEXT:    [[PRIVATE_V16I32:%.*]] = alloca [4 x <16 x i32>], align 64
// CHECK-NEXT:    [[PRIVATE_I64:%.*]] = alloca [4 x i64], align 8
// CHECK-NEXT:    [[PRIVATE_V2I64:%.*]] = alloca [4 x <2 x i64>], align 16
// CHECK-NEXT:    [[PRIVATE_V3I64:%.*]] = alloca [4 x <3 x i64>], align 32
// CHECK-NEXT:    [[PRIVATE_V4I64:%.*]] = alloca [4 x <4 x i64>], align 32
// CHECK-NEXT:    [[PRIVATE_V8I64:%.*]] = alloca [4 x <8 x i64>], align 64
// CHECK-NEXT:    [[PRIVATE_V16I64:%.*]] = alloca [4 x <16 x i64>], align 128
// CHECK-NEXT:    [[PRIVATE_F16:%.*]] = alloca [4 x half], align 2
// CHECK-NEXT:    [[PRIVATE_V2F16:%.*]] = alloca [4 x <2 x half>], align 4
// CHECK-NEXT:    [[PRIVATE_V3F16:%.*]] = alloca [4 x <3 x half>], align 8
// CHECK-NEXT:    [[PRIVATE_V4F16:%.*]] = alloca [4 x <4 x half>], align 8
// CHECK-NEXT:    [[PRIVATE_V8F16:%.*]] = alloca [4 x <8 x half>], align 16
// CHECK-NEXT:    [[PRIVATE_V16F16:%.*]] = alloca [4 x <16 x half>], align 32
// CHECK-NEXT:    [[PRIVATE_F32:%.*]] = alloca [4 x float], align 4
// CHECK-NEXT:    [[PRIVATE_V2F32:%.*]] = alloca [4 x <2 x float>], align 8
// CHECK-NEXT:    [[PRIVATE_V3F32:%.*]] = alloca [4 x <3 x float>], align 16
// CHECK-NEXT:    [[PRIVATE_V4F32:%.*]] = alloca [4 x <4 x float>], align 16
// CHECK-NEXT:    [[PRIVATE_V8F32:%.*]] = alloca [4 x <8 x float>], align 32
// CHECK-NEXT:    [[PRIVATE_V16F32:%.*]] = alloca [4 x <16 x float>], align 64
// CHECK-NEXT:    [[PRIVATE_F64:%.*]] = alloca [4 x double], align 8
// CHECK-NEXT:    [[PRIVATE_V2F64:%.*]] = alloca [4 x <2 x double>], align 16
// CHECK-NEXT:    [[PRIVATE_V3F64:%.*]] = alloca [4 x <3 x double>], align 32
// CHECK-NEXT:    [[PRIVATE_V4F64:%.*]] = alloca [4 x <4 x double>], align 32
// CHECK-NEXT:    [[PRIVATE_V8F64:%.*]] = alloca [4 x <8 x double>], align 64
// CHECK-NEXT:    [[PRIVATE_V16F64:%.*]] = alloca [4 x <16 x double>], align 128
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast [4 x i8]* [[PRIVATE_I8]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 4, i8* [[TMP0]]) [[ATTR2:#.*]]
// CHECK-NEXT:    [[TMP1:%.*]] = bitcast [4 x <2 x i8>]* [[PRIVATE_V2I8]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 8, i8* [[TMP1]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP2:%.*]] = bitcast [4 x <3 x i8>]* [[PRIVATE_V3I8]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 16, i8* [[TMP2]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP3:%.*]] = bitcast [4 x <4 x i8>]* [[PRIVATE_V4I8]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 16, i8* [[TMP3]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP4:%.*]] = bitcast [4 x <8 x i8>]* [[PRIVATE_V8I8]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 32, i8* [[TMP4]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP5:%.*]] = bitcast [4 x <16 x i8>]* [[PRIVATE_V16I8]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 64, i8* [[TMP5]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP6:%.*]] = bitcast [4 x i16]* [[PRIVATE_I16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 8, i8* [[TMP6]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP7:%.*]] = bitcast [4 x <2 x i16>]* [[PRIVATE_V2I16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 16, i8* [[TMP7]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP8:%.*]] = bitcast [4 x <3 x i16>]* [[PRIVATE_V3I16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 32, i8* [[TMP8]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP9:%.*]] = bitcast [4 x <4 x i16>]* [[PRIVATE_V4I16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 32, i8* [[TMP9]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP10:%.*]] = bitcast [4 x <8 x i16>]* [[PRIVATE_V8I16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 64, i8* [[TMP10]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP11:%.*]] = bitcast [4 x <16 x i16>]* [[PRIVATE_V16I16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 128, i8* [[TMP11]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP12:%.*]] = bitcast [4 x i32]* [[PRIVATE_I32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 16, i8* [[TMP12]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP13:%.*]] = bitcast [4 x <2 x i32>]* [[PRIVATE_V2I32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 32, i8* [[TMP13]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP14:%.*]] = bitcast [4 x <3 x i32>]* [[PRIVATE_V3I32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 64, i8* [[TMP14]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP15:%.*]] = bitcast [4 x <4 x i32>]* [[PRIVATE_V4I32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 64, i8* [[TMP15]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP16:%.*]] = bitcast [4 x <8 x i32>]* [[PRIVATE_V8I32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 128, i8* [[TMP16]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP17:%.*]] = bitcast [4 x <16 x i32>]* [[PRIVATE_V16I32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 256, i8* [[TMP17]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP18:%.*]] = bitcast [4 x i64]* [[PRIVATE_I64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 32, i8* [[TMP18]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP19:%.*]] = bitcast [4 x <2 x i64>]* [[PRIVATE_V2I64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 64, i8* [[TMP19]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP20:%.*]] = bitcast [4 x <3 x i64>]* [[PRIVATE_V3I64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 128, i8* [[TMP20]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP21:%.*]] = bitcast [4 x <4 x i64>]* [[PRIVATE_V4I64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 128, i8* [[TMP21]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP22:%.*]] = bitcast [4 x <8 x i64>]* [[PRIVATE_V8I64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 256, i8* [[TMP22]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP23:%.*]] = bitcast [4 x <16 x i64>]* [[PRIVATE_V16I64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 512, i8* [[TMP23]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP24:%.*]] = bitcast [4 x half]* [[PRIVATE_F16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 8, i8* [[TMP24]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP25:%.*]] = bitcast [4 x <2 x half>]* [[PRIVATE_V2F16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 16, i8* [[TMP25]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP26:%.*]] = bitcast [4 x <3 x half>]* [[PRIVATE_V3F16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 32, i8* [[TMP26]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP27:%.*]] = bitcast [4 x <4 x half>]* [[PRIVATE_V4F16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 32, i8* [[TMP27]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP28:%.*]] = bitcast [4 x <8 x half>]* [[PRIVATE_V8F16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 64, i8* [[TMP28]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP29:%.*]] = bitcast [4 x <16 x half>]* [[PRIVATE_V16F16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 128, i8* [[TMP29]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP30:%.*]] = bitcast [4 x float]* [[PRIVATE_F32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 16, i8* [[TMP30]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP31:%.*]] = bitcast [4 x <2 x float>]* [[PRIVATE_V2F32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 32, i8* [[TMP31]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP32:%.*]] = bitcast [4 x <3 x float>]* [[PRIVATE_V3F32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 64, i8* [[TMP32]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP33:%.*]] = bitcast [4 x <4 x float>]* [[PRIVATE_V4F32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 64, i8* [[TMP33]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP34:%.*]] = bitcast [4 x <8 x float>]* [[PRIVATE_V8F32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 128, i8* [[TMP34]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP35:%.*]] = bitcast [4 x <16 x float>]* [[PRIVATE_V16F32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 256, i8* [[TMP35]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP36:%.*]] = bitcast [4 x double]* [[PRIVATE_F64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 32, i8* [[TMP36]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP37:%.*]] = bitcast [4 x <2 x double>]* [[PRIVATE_V2F64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 64, i8* [[TMP37]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP38:%.*]] = bitcast [4 x <3 x double>]* [[PRIVATE_V3F64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 128, i8* [[TMP38]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP39:%.*]] = bitcast [4 x <4 x double>]* [[PRIVATE_V4F64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 128, i8* [[TMP39]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP40:%.*]] = bitcast [4 x <8 x double>]* [[PRIVATE_V8F64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 256, i8* [[TMP40]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP41:%.*]] = bitcast [4 x <16 x double>]* [[PRIVATE_V16F64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 512, i8* [[TMP41]]) [[ATTR2]]
// CHECK-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [4 x i8], [4 x i8]* [[PRIVATE_I8]], i64 0, i64 0
// CHECK-NEXT:    store volatile i8 0, i8* [[ARRAYDECAY]], align 1, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY1:%.*]] = getelementptr inbounds [4 x <2 x i8>], [4 x <2 x i8>]* [[PRIVATE_V2I8]], i64 0, i64 0
// CHECK-NEXT:    store volatile <2 x i8> zeroinitializer, <2 x i8>* [[ARRAYDECAY1]], align 2, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY2:%.*]] = getelementptr inbounds [4 x <3 x i8>], [4 x <3 x i8>]* [[PRIVATE_V3I8]], i64 0, i64 0
// CHECK-NEXT:    [[STORETMP:%.*]] = bitcast <3 x i8>* [[ARRAYDECAY2]] to <4 x i8>*
// CHECK-NEXT:    store volatile <4 x i8> <i8 0, i8 0, i8 0, i8 undef>, <4 x i8>* [[STORETMP]], align 4, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY3:%.*]] = getelementptr inbounds [4 x <4 x i8>], [4 x <4 x i8>]* [[PRIVATE_V4I8]], i64 0, i64 0
// CHECK-NEXT:    store volatile <4 x i8> zeroinitializer, <4 x i8>* [[ARRAYDECAY3]], align 4, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY4:%.*]] = getelementptr inbounds [4 x <8 x i8>], [4 x <8 x i8>]* [[PRIVATE_V8I8]], i64 0, i64 0
// CHECK-NEXT:    store volatile <8 x i8> zeroinitializer, <8 x i8>* [[ARRAYDECAY4]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY5:%.*]] = getelementptr inbounds [4 x <16 x i8>], [4 x <16 x i8>]* [[PRIVATE_V16I8]], i64 0, i64 0
// CHECK-NEXT:    store volatile <16 x i8> zeroinitializer, <16 x i8>* [[ARRAYDECAY5]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY6:%.*]] = getelementptr inbounds [4 x i16], [4 x i16]* [[PRIVATE_I16]], i64 0, i64 0
// CHECK-NEXT:    store volatile i16 0, i16* [[ARRAYDECAY6]], align 2, [[TBAA7]]
// CHECK-NEXT:    [[ARRAYDECAY7:%.*]] = getelementptr inbounds [4 x <2 x i16>], [4 x <2 x i16>]* [[PRIVATE_V2I16]], i64 0, i64 0
// CHECK-NEXT:    store volatile <2 x i16> zeroinitializer, <2 x i16>* [[ARRAYDECAY7]], align 4, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY8:%.*]] = getelementptr inbounds [4 x <3 x i16>], [4 x <3 x i16>]* [[PRIVATE_V3I16]], i64 0, i64 0
// CHECK-NEXT:    [[STORETMP9:%.*]] = bitcast <3 x i16>* [[ARRAYDECAY8]] to <4 x i16>*
// CHECK-NEXT:    store volatile <4 x i16> <i16 0, i16 0, i16 0, i16 undef>, <4 x i16>* [[STORETMP9]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY10:%.*]] = getelementptr inbounds [4 x <4 x i16>], [4 x <4 x i16>]* [[PRIVATE_V4I16]], i64 0, i64 0
// CHECK-NEXT:    store volatile <4 x i16> zeroinitializer, <4 x i16>* [[ARRAYDECAY10]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY11:%.*]] = getelementptr inbounds [4 x <8 x i16>], [4 x <8 x i16>]* [[PRIVATE_V8I16]], i64 0, i64 0
// CHECK-NEXT:    store volatile <8 x i16> zeroinitializer, <8 x i16>* [[ARRAYDECAY11]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY12:%.*]] = getelementptr inbounds [4 x <16 x i16>], [4 x <16 x i16>]* [[PRIVATE_V16I16]], i64 0, i64 0
// CHECK-NEXT:    store volatile <16 x i16> zeroinitializer, <16 x i16>* [[ARRAYDECAY12]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY13:%.*]] = getelementptr inbounds [4 x i32], [4 x i32]* [[PRIVATE_I32]], i64 0, i64 0
// CHECK-NEXT:    store volatile i32 0, i32* [[ARRAYDECAY13]], align 4, [[TBAA9]]
// CHECK-NEXT:    [[ARRAYDECAY14:%.*]] = getelementptr inbounds [4 x <2 x i32>], [4 x <2 x i32>]* [[PRIVATE_V2I32]], i64 0, i64 0
// CHECK-NEXT:    store volatile <2 x i32> zeroinitializer, <2 x i32>* [[ARRAYDECAY14]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY15:%.*]] = getelementptr inbounds [4 x <3 x i32>], [4 x <3 x i32>]* [[PRIVATE_V3I32]], i64 0, i64 0
// CHECK-NEXT:    [[STORETMP16:%.*]] = bitcast <3 x i32>* [[ARRAYDECAY15]] to <4 x i32>*
// CHECK-NEXT:    store volatile <4 x i32> <i32 0, i32 0, i32 0, i32 undef>, <4 x i32>* [[STORETMP16]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY17:%.*]] = getelementptr inbounds [4 x <4 x i32>], [4 x <4 x i32>]* [[PRIVATE_V4I32]], i64 0, i64 0
// CHECK-NEXT:    store volatile <4 x i32> zeroinitializer, <4 x i32>* [[ARRAYDECAY17]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY18:%.*]] = getelementptr inbounds [4 x <8 x i32>], [4 x <8 x i32>]* [[PRIVATE_V8I32]], i64 0, i64 0
// CHECK-NEXT:    store volatile <8 x i32> zeroinitializer, <8 x i32>* [[ARRAYDECAY18]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY19:%.*]] = getelementptr inbounds [4 x <16 x i32>], [4 x <16 x i32>]* [[PRIVATE_V16I32]], i64 0, i64 0
// CHECK-NEXT:    store volatile <16 x i32> zeroinitializer, <16 x i32>* [[ARRAYDECAY19]], align 64, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY20:%.*]] = getelementptr inbounds [4 x i64], [4 x i64]* [[PRIVATE_I64]], i64 0, i64 0
// CHECK-NEXT:    store volatile i64 0, i64* [[ARRAYDECAY20]], align 8, [[TBAA11]]
// CHECK-NEXT:    [[ARRAYDECAY21:%.*]] = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* [[PRIVATE_V2I64]], i64 0, i64 0
// CHECK-NEXT:    store volatile <2 x i64> zeroinitializer, <2 x i64>* [[ARRAYDECAY21]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY22:%.*]] = getelementptr inbounds [4 x <3 x i64>], [4 x <3 x i64>]* [[PRIVATE_V3I64]], i64 0, i64 0
// CHECK-NEXT:    [[STORETMP23:%.*]] = bitcast <3 x i64>* [[ARRAYDECAY22]] to <4 x i64>*
// CHECK-NEXT:    store volatile <4 x i64> <i64 0, i64 0, i64 0, i64 undef>, <4 x i64>* [[STORETMP23]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY24:%.*]] = getelementptr inbounds [4 x <4 x i64>], [4 x <4 x i64>]* [[PRIVATE_V4I64]], i64 0, i64 0
// CHECK-NEXT:    store volatile <4 x i64> zeroinitializer, <4 x i64>* [[ARRAYDECAY24]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY25:%.*]] = getelementptr inbounds [4 x <8 x i64>], [4 x <8 x i64>]* [[PRIVATE_V8I64]], i64 0, i64 0
// CHECK-NEXT:    store volatile <8 x i64> zeroinitializer, <8 x i64>* [[ARRAYDECAY25]], align 64, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY26:%.*]] = getelementptr inbounds [4 x <16 x i64>], [4 x <16 x i64>]* [[PRIVATE_V16I64]], i64 0, i64 0
// CHECK-NEXT:    store volatile <16 x i64> zeroinitializer, <16 x i64>* [[ARRAYDECAY26]], align 128, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY27:%.*]] = getelementptr inbounds [4 x half], [4 x half]* [[PRIVATE_F16]], i64 0, i64 0
// CHECK-NEXT:    store volatile half 0xH0000, half* [[ARRAYDECAY27]], align 2, [[TBAA13]]
// CHECK-NEXT:    [[ARRAYDECAY28:%.*]] = getelementptr inbounds [4 x <2 x half>], [4 x <2 x half>]* [[PRIVATE_V2F16]], i64 0, i64 0
// CHECK-NEXT:    store volatile <2 x half> zeroinitializer, <2 x half>* [[ARRAYDECAY28]], align 4, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY29:%.*]] = getelementptr inbounds [4 x <3 x half>], [4 x <3 x half>]* [[PRIVATE_V3F16]], i64 0, i64 0
// CHECK-NEXT:    [[STORETMP30:%.*]] = bitcast <3 x half>* [[ARRAYDECAY29]] to <4 x half>*
// CHECK-NEXT:    store volatile <4 x half> <half 0xH0000, half 0xH0000, half 0xH0000, half undef>, <4 x half>* [[STORETMP30]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY31:%.*]] = getelementptr inbounds [4 x <4 x half>], [4 x <4 x half>]* [[PRIVATE_V4F16]], i64 0, i64 0
// CHECK-NEXT:    store volatile <4 x half> zeroinitializer, <4 x half>* [[ARRAYDECAY31]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY32:%.*]] = getelementptr inbounds [4 x <8 x half>], [4 x <8 x half>]* [[PRIVATE_V8F16]], i64 0, i64 0
// CHECK-NEXT:    store volatile <8 x half> zeroinitializer, <8 x half>* [[ARRAYDECAY32]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY33:%.*]] = getelementptr inbounds [4 x <16 x half>], [4 x <16 x half>]* [[PRIVATE_V16F16]], i64 0, i64 0
// CHECK-NEXT:    store volatile <16 x half> zeroinitializer, <16 x half>* [[ARRAYDECAY33]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY34:%.*]] = getelementptr inbounds [4 x float], [4 x float]* [[PRIVATE_F32]], i64 0, i64 0
// CHECK-NEXT:    store volatile float 0.000000e+00, float* [[ARRAYDECAY34]], align 4, [[TBAA15]]
// CHECK-NEXT:    [[ARRAYDECAY35:%.*]] = getelementptr inbounds [4 x <2 x float>], [4 x <2 x float>]* [[PRIVATE_V2F32]], i64 0, i64 0
// CHECK-NEXT:    store volatile <2 x float> zeroinitializer, <2 x float>* [[ARRAYDECAY35]], align 8, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY36:%.*]] = getelementptr inbounds [4 x <3 x float>], [4 x <3 x float>]* [[PRIVATE_V3F32]], i64 0, i64 0
// CHECK-NEXT:    [[STORETMP37:%.*]] = bitcast <3 x float>* [[ARRAYDECAY36]] to <4 x float>*
// CHECK-NEXT:    store volatile <4 x float> <float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float undef>, <4 x float>* [[STORETMP37]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY38:%.*]] = getelementptr inbounds [4 x <4 x float>], [4 x <4 x float>]* [[PRIVATE_V4F32]], i64 0, i64 0
// CHECK-NEXT:    store volatile <4 x float> zeroinitializer, <4 x float>* [[ARRAYDECAY38]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY39:%.*]] = getelementptr inbounds [4 x <8 x float>], [4 x <8 x float>]* [[PRIVATE_V8F32]], i64 0, i64 0
// CHECK-NEXT:    store volatile <8 x float> zeroinitializer, <8 x float>* [[ARRAYDECAY39]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY40:%.*]] = getelementptr inbounds [4 x <16 x float>], [4 x <16 x float>]* [[PRIVATE_V16F32]], i64 0, i64 0
// CHECK-NEXT:    store volatile <16 x float> zeroinitializer, <16 x float>* [[ARRAYDECAY40]], align 64, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY41:%.*]] = getelementptr inbounds [4 x double], [4 x double]* [[PRIVATE_F64]], i64 0, i64 0
// CHECK-NEXT:    store volatile double 0.000000e+00, double* [[ARRAYDECAY41]], align 8, [[TBAA17]]
// CHECK-NEXT:    [[ARRAYDECAY42:%.*]] = getelementptr inbounds [4 x <2 x double>], [4 x <2 x double>]* [[PRIVATE_V2F64]], i64 0, i64 0
// CHECK-NEXT:    store volatile <2 x double> zeroinitializer, <2 x double>* [[ARRAYDECAY42]], align 16, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY43:%.*]] = getelementptr inbounds [4 x <3 x double>], [4 x <3 x double>]* [[PRIVATE_V3F64]], i64 0, i64 0
// CHECK-NEXT:    [[STORETMP44:%.*]] = bitcast <3 x double>* [[ARRAYDECAY43]] to <4 x double>*
// CHECK-NEXT:    store volatile <4 x double> <double 0.000000e+00, double 0.000000e+00, double 0.000000e+00, double undef>, <4 x double>* [[STORETMP44]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY45:%.*]] = getelementptr inbounds [4 x <4 x double>], [4 x <4 x double>]* [[PRIVATE_V4F64]], i64 0, i64 0
// CHECK-NEXT:    store volatile <4 x double> zeroinitializer, <4 x double>* [[ARRAYDECAY45]], align 32, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY46:%.*]] = getelementptr inbounds [4 x <8 x double>], [4 x <8 x double>]* [[PRIVATE_V8F64]], i64 0, i64 0
// CHECK-NEXT:    store volatile <8 x double> zeroinitializer, <8 x double>* [[ARRAYDECAY46]], align 64, [[TBAA4]]
// CHECK-NEXT:    [[ARRAYDECAY47:%.*]] = getelementptr inbounds [4 x <16 x double>], [4 x <16 x double>]* [[PRIVATE_V16F64]], i64 0, i64 0
// CHECK-NEXT:    store volatile <16 x double> zeroinitializer, <16 x double>* [[ARRAYDECAY47]], align 128, [[TBAA4]]
// CHECK-NEXT:    [[TMP42:%.*]] = bitcast [4 x <16 x double>]* [[PRIVATE_V16F64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 512, i8* [[TMP42]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP43:%.*]] = bitcast [4 x <8 x double>]* [[PRIVATE_V8F64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 256, i8* [[TMP43]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP44:%.*]] = bitcast [4 x <4 x double>]* [[PRIVATE_V4F64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 128, i8* [[TMP44]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP45:%.*]] = bitcast [4 x <3 x double>]* [[PRIVATE_V3F64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 128, i8* [[TMP45]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP46:%.*]] = bitcast [4 x <2 x double>]* [[PRIVATE_V2F64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 64, i8* [[TMP46]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP47:%.*]] = bitcast [4 x double]* [[PRIVATE_F64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 32, i8* [[TMP47]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP48:%.*]] = bitcast [4 x <16 x float>]* [[PRIVATE_V16F32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 256, i8* [[TMP48]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP49:%.*]] = bitcast [4 x <8 x float>]* [[PRIVATE_V8F32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 128, i8* [[TMP49]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP50:%.*]] = bitcast [4 x <4 x float>]* [[PRIVATE_V4F32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 64, i8* [[TMP50]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP51:%.*]] = bitcast [4 x <3 x float>]* [[PRIVATE_V3F32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 64, i8* [[TMP51]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP52:%.*]] = bitcast [4 x <2 x float>]* [[PRIVATE_V2F32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 32, i8* [[TMP52]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP53:%.*]] = bitcast [4 x float]* [[PRIVATE_F32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 16, i8* [[TMP53]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP54:%.*]] = bitcast [4 x <16 x half>]* [[PRIVATE_V16F16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 128, i8* [[TMP54]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP55:%.*]] = bitcast [4 x <8 x half>]* [[PRIVATE_V8F16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 64, i8* [[TMP55]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP56:%.*]] = bitcast [4 x <4 x half>]* [[PRIVATE_V4F16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 32, i8* [[TMP56]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP57:%.*]] = bitcast [4 x <3 x half>]* [[PRIVATE_V3F16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 32, i8* [[TMP57]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP58:%.*]] = bitcast [4 x <2 x half>]* [[PRIVATE_V2F16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 16, i8* [[TMP58]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP59:%.*]] = bitcast [4 x half]* [[PRIVATE_F16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 8, i8* [[TMP59]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP60:%.*]] = bitcast [4 x <16 x i64>]* [[PRIVATE_V16I64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 512, i8* [[TMP60]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP61:%.*]] = bitcast [4 x <8 x i64>]* [[PRIVATE_V8I64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 256, i8* [[TMP61]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP62:%.*]] = bitcast [4 x <4 x i64>]* [[PRIVATE_V4I64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 128, i8* [[TMP62]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP63:%.*]] = bitcast [4 x <3 x i64>]* [[PRIVATE_V3I64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 128, i8* [[TMP63]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP64:%.*]] = bitcast [4 x <2 x i64>]* [[PRIVATE_V2I64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 64, i8* [[TMP64]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP65:%.*]] = bitcast [4 x i64]* [[PRIVATE_I64]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 32, i8* [[TMP65]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP66:%.*]] = bitcast [4 x <16 x i32>]* [[PRIVATE_V16I32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 256, i8* [[TMP66]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP67:%.*]] = bitcast [4 x <8 x i32>]* [[PRIVATE_V8I32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 128, i8* [[TMP67]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP68:%.*]] = bitcast [4 x <4 x i32>]* [[PRIVATE_V4I32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 64, i8* [[TMP68]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP69:%.*]] = bitcast [4 x <3 x i32>]* [[PRIVATE_V3I32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 64, i8* [[TMP69]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP70:%.*]] = bitcast [4 x <2 x i32>]* [[PRIVATE_V2I32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 32, i8* [[TMP70]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP71:%.*]] = bitcast [4 x i32]* [[PRIVATE_I32]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 16, i8* [[TMP71]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP72:%.*]] = bitcast [4 x <16 x i16>]* [[PRIVATE_V16I16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 128, i8* [[TMP72]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP73:%.*]] = bitcast [4 x <8 x i16>]* [[PRIVATE_V8I16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 64, i8* [[TMP73]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP74:%.*]] = bitcast [4 x <4 x i16>]* [[PRIVATE_V4I16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 32, i8* [[TMP74]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP75:%.*]] = bitcast [4 x <3 x i16>]* [[PRIVATE_V3I16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 32, i8* [[TMP75]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP76:%.*]] = bitcast [4 x <2 x i16>]* [[PRIVATE_V2I16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 16, i8* [[TMP76]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP77:%.*]] = bitcast [4 x i16]* [[PRIVATE_I16]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 8, i8* [[TMP77]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP78:%.*]] = bitcast [4 x <16 x i8>]* [[PRIVATE_V16I8]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 64, i8* [[TMP78]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP79:%.*]] = bitcast [4 x <8 x i8>]* [[PRIVATE_V8I8]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 32, i8* [[TMP79]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP80:%.*]] = bitcast [4 x <4 x i8>]* [[PRIVATE_V4I8]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 16, i8* [[TMP80]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP81:%.*]] = bitcast [4 x <3 x i8>]* [[PRIVATE_V3I8]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 16, i8* [[TMP81]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP82:%.*]] = bitcast [4 x <2 x i8>]* [[PRIVATE_V2I8]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 8, i8* [[TMP82]]) [[ATTR2]]
// CHECK-NEXT:    [[TMP83:%.*]] = bitcast [4 x i8]* [[PRIVATE_I8]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 4, i8* [[TMP83]]) [[ATTR2]]
// CHECK-NEXT:    ret void
//
kernel void private_memory_alignment_alloca()
{
  volatile private char private_i8[4];
  volatile private char2 private_v2i8[4];
  volatile private char3 private_v3i8[4];
  volatile private char4 private_v4i8[4];
  volatile private char8 private_v8i8[4];
  volatile private char16 private_v16i8[4];

  volatile private short private_i16[4];
  volatile private short2 private_v2i16[4];
  volatile private short3 private_v3i16[4];
  volatile private short4 private_v4i16[4];
  volatile private short8 private_v8i16[4];
  volatile private short16 private_v16i16[4];

  volatile private int private_i32[4];
  volatile private int2 private_v2i32[4];
  volatile private int3 private_v3i32[4];
  volatile private int4 private_v4i32[4];
  volatile private int8 private_v8i32[4];
  volatile private int16 private_v16i32[4];

  volatile private long private_i64[4];
  volatile private long2 private_v2i64[4];
  volatile private long3 private_v3i64[4];
  volatile private long4 private_v4i64[4];
  volatile private long8 private_v8i64[4];
  volatile private long16 private_v16i64[4];

  volatile private half private_f16[4];
  volatile private half2 private_v2f16[4];
  volatile private half3 private_v3f16[4];
  volatile private half4 private_v4f16[4];
  volatile private half8 private_v8f16[4];
  volatile private half16 private_v16f16[4];

  volatile private float private_f32[4];
  volatile private float2 private_v2f32[4];
  volatile private float3 private_v3f32[4];
  volatile private float4 private_v4f32[4];
  volatile private float8 private_v8f32[4];
  volatile private float16 private_v16f32[4];

  volatile private double private_f64[4];
  volatile private double2 private_v2f64[4];
  volatile private double3 private_v3f64[4];
  volatile private double4 private_v4f64[4];
  volatile private double8 private_v8f64[4];
  volatile private double16 private_v16f64[4];

  *private_i8 = 0;
  *private_v2i8 = 0;
  *private_v3i8 = 0;
  *private_v4i8 = 0;
  *private_v8i8 = 0;
  *private_v16i8 = 0;

  *private_i16 = 0;
  *private_v2i16 = 0;
  *private_v3i16 = 0;
  *private_v4i16 = 0;
  *private_v8i16 = 0;
  *private_v16i16 = 0;

  *private_i32 = 0;
  *private_v2i32 = 0;
  *private_v3i32 = 0;
  *private_v4i32 = 0;
  *private_v8i32 = 0;
  *private_v16i32 = 0;

  *private_i64 = 0;
  *private_v2i64 = 0;
  *private_v3i64 = 0;
  *private_v4i64 = 0;
  *private_v8i64 = 0;
  *private_v16i64 = 0;

  *private_f16 = 0;
  *private_v2f16 = 0;
  *private_v3f16 = 0;
  *private_v4f16 = 0;
  *private_v8f16 = 0;
  *private_v16f16 = 0;

  *private_f32 = 0;
  *private_v2f32 = 0;
  *private_v3f32 = 0;
  *private_v4f32 = 0;
  *private_v8f32 = 0;
  *private_v16f32 = 0;

  *private_f64 = 0;
  *private_v2f64 = 0;
  *private_v3f64 = 0;
  *private_v4f64 = 0;
  *private_v8f64 = 0;
  *private_v16f64 = 0;
}
