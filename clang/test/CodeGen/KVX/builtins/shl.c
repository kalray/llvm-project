// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -target-cpu kv3-1 -triple kvx-kalray-cos -S -O2 -emit-llvm -o - %s | FileCheck %s
// RUN: %clang_cc1 -target-cpu kv3-2 -triple kvx-kalray-cos -S -O2 -emit-llvm -o - %s | FileCheck %s

#include "vector-types.h"

// CHECK-LABEL: @shld(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[V:%.*]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    ret i64 [[TMP0]]
//
long shld (long v, unsigned sht) { return __builtin_kvx_shld(v, sht, ""); }

// CHECK-LABEL: @shld_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[V:%.*]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    ret i64 [[TMP0]]
//
long shld_s (long v, unsigned sht) { return __builtin_kvx_shld(v, sht, ".s"); }

// CHECK-LABEL: @shld_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[V:%.*]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    ret i64 [[TMP0]]
//
long shld_us (long v, unsigned sht) { return __builtin_kvx_shld(v, sht, ".us"); }

// CHECK-LABEL: @shld_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[V:%.*]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    ret i64 [[TMP0]]
//
long shld_r (long v, unsigned sht) { return __builtin_kvx_shld(v, sht, ".r"); }

// CHECK-LABEL: @shldp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP3]], i32 [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> poison, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i64> [[TMP6]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP7]]
//
v2i64 shldp (v2i64 v, v2u32 sht) { return __builtin_kvx_shldp(v, sht, ""); }

// CHECK-LABEL: @shldp_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[TMP1]], i32 1)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP3]], i32 [[TMP4]], i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> poison, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i64> [[TMP6]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP7]]
//
v2i64 shldp_s (v2i64 v, v2u32 sht) { return __builtin_kvx_shldp(v, sht, ".s"); }

// CHECK-LABEL: @shldp_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[TMP1]], i32 2)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP3]], i32 [[TMP4]], i32 2)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> poison, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i64> [[TMP6]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP7]]
//
v2i64 shldp_us (v2i64 v, v2u32 sht) { return __builtin_kvx_shldp(v, sht, ".us"); }

// CHECK-LABEL: @shldp_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[TMP1]], i32 3)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP3]], i32 [[TMP4]], i32 3)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> poison, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i64> [[TMP6]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP7]]
//
v2i64 shldp_r (v2i64 v, v2u32 sht) { return __builtin_kvx_shldp(v, sht, ".r"); }

// CHECK-LABEL: @shldps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP2]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> poison, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i64> [[TMP4]], i64 [[TMP3]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP5]]
//
v2i64 shldps (v2i64 v, unsigned sht) { return __builtin_kvx_shldps(v, sht, ""); }

// CHECK-LABEL: @shldps_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP2]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> poison, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i64> [[TMP4]], i64 [[TMP3]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP5]]
//
v2i64 shldps_s (v2i64 v, unsigned sht) { return __builtin_kvx_shldps(v, sht, ".s"); }

// CHECK-LABEL: @shldps_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP2]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> poison, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i64> [[TMP4]], i64 [[TMP3]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP5]]
//
v2i64 shldps_us (v2i64 v, unsigned sht) { return __builtin_kvx_shldps(v, sht, ".us"); }

// CHECK-LABEL: @shldps_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP2]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> poison, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i64> [[TMP4]], i64 [[TMP3]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP5]]
//
v2i64 shldps_r (v2i64 v, unsigned sht) { return __builtin_kvx_shldps(v, sht, ".r"); }

// CHECK-LABEL: @shldq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP3]], i32 [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x i32> [[SHT]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP6]], i32 [[TMP7]], i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x i32> [[SHT]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP9]], i32 [[TMP10]], i32 0)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i64> poison, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP13:%.*]] = insertelement <4 x i64> [[TMP12]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP14:%.*]] = insertelement <4 x i64> [[TMP13]], i64 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i64> [[TMP14]], i64 [[TMP11]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP15]]
//
v4i64 shldq (v4i64 v, v4u32 sht) { return __builtin_kvx_shldq(v, sht, ""); }

// CHECK-LABEL: @shldq_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[TMP1]], i32 1)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP3]], i32 [[TMP4]], i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x i32> [[SHT]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP6]], i32 [[TMP7]], i32 1)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x i32> [[SHT]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP9]], i32 [[TMP10]], i32 1)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i64> poison, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP13:%.*]] = insertelement <4 x i64> [[TMP12]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP14:%.*]] = insertelement <4 x i64> [[TMP13]], i64 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i64> [[TMP14]], i64 [[TMP11]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP15]]
//
v4i64 shldq_s (v4i64 v, v4u32 sht) { return __builtin_kvx_shldq(v, sht, ".s"); }

// CHECK-LABEL: @shldq_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[TMP1]], i32 2)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP3]], i32 [[TMP4]], i32 2)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x i32> [[SHT]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP6]], i32 [[TMP7]], i32 2)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x i32> [[SHT]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP9]], i32 [[TMP10]], i32 2)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i64> poison, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP13:%.*]] = insertelement <4 x i64> [[TMP12]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP14:%.*]] = insertelement <4 x i64> [[TMP13]], i64 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i64> [[TMP14]], i64 [[TMP11]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP15]]
//
v4i64 shldq_us (v4i64 v, v4u32 sht) { return __builtin_kvx_shldq(v, sht, ".us"); }

// CHECK-LABEL: @shldq_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[TMP1]], i32 3)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP3]], i32 [[TMP4]], i32 3)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x i32> [[SHT]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP6]], i32 [[TMP7]], i32 3)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x i32> [[SHT]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP9]], i32 [[TMP10]], i32 3)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i64> poison, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP13:%.*]] = insertelement <4 x i64> [[TMP12]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP14:%.*]] = insertelement <4 x i64> [[TMP13]], i64 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i64> [[TMP14]], i64 [[TMP11]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP15]]
//
v4i64 shldq_r (v4i64 v, v4u32 sht) { return __builtin_kvx_shldq(v, sht, ".r"); }

// CHECK-LABEL: @shldqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP2]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i64> [[V]], i64 2
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP4]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V]], i64 3
// CHECK-NEXT:    [[TMP7:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP6]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x i64> poison, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> [[TMP8]], i64 [[TMP3]], i64 1
// CHECK-NEXT:    [[TMP10:%.*]] = insertelement <4 x i64> [[TMP9]], i64 [[TMP5]], i64 2
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP10]], i64 [[TMP7]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP11]]
//
v4i64 shldqs (v4i64 v, unsigned sht) { return __builtin_kvx_shldqs(v, sht, ""); }

// CHECK-LABEL: @shldqs_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP2]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i64> [[V]], i64 2
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP4]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V]], i64 3
// CHECK-NEXT:    [[TMP7:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP6]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x i64> poison, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> [[TMP8]], i64 [[TMP3]], i64 1
// CHECK-NEXT:    [[TMP10:%.*]] = insertelement <4 x i64> [[TMP9]], i64 [[TMP5]], i64 2
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP10]], i64 [[TMP7]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP11]]
//
v4i64 shldqs_s (v4i64 v, unsigned sht) { return __builtin_kvx_shldqs(v, sht, ".s"); }

// CHECK-LABEL: @shldqs_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP2]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i64> [[V]], i64 2
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP4]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V]], i64 3
// CHECK-NEXT:    [[TMP7:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP6]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x i64> poison, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> [[TMP8]], i64 [[TMP3]], i64 1
// CHECK-NEXT:    [[TMP10:%.*]] = insertelement <4 x i64> [[TMP9]], i64 [[TMP5]], i64 2
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP10]], i64 [[TMP7]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP11]]
//
v4i64 shldqs_us (v4i64 v, unsigned sht) { return __builtin_kvx_shldqs(v, sht, ".us"); }

// CHECK-LABEL: @shldqs_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP0]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP2]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i64> [[V]], i64 2
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP4]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V]], i64 3
// CHECK-NEXT:    [[TMP7:%.*]] = tail call i64 @llvm.kvx.shl.i64(i64 [[TMP6]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x i64> poison, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> [[TMP8]], i64 [[TMP3]], i64 1
// CHECK-NEXT:    [[TMP10:%.*]] = insertelement <4 x i64> [[TMP9]], i64 [[TMP5]], i64 2
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP10]], i64 [[TMP7]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP11]]
//
v4i64 shldqs_r (v4i64 v, unsigned sht) { return __builtin_kvx_shldqs(v, sht, ".r"); }

// CHECK-LABEL: @shlhos(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[V:%.*]], <8 x i16> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP0]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i16> [[V]], <8 x i16> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP2]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP4]]
//
v8i16 shlhos (v8i16 v, unsigned sht) { return __builtin_kvx_shlhos(v, sht, ""); }

// CHECK-LABEL: @shlhos_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[V:%.*]], <8 x i16> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP0]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i16> [[V]], <8 x i16> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP2]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP4]]
//
v8i16 shlhos_s (v8i16 v, unsigned sht) { return __builtin_kvx_shlhos(v, sht, ".s"); }

// CHECK-LABEL: @shlhos_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[V:%.*]], <8 x i16> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP0]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i16> [[V]], <8 x i16> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP2]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP4]]
//
v8i16 shlhos_us (v8i16 v, unsigned sht) { return __builtin_kvx_shlhos(v, sht, ".us"); }

// CHECK-LABEL: @shlhos_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[V:%.*]], <8 x i16> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP0]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i16> [[V]], <8 x i16> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP2]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP4]]
//
v8i16 shlhos_r (v8i16 v, unsigned sht) { return __builtin_kvx_shlhos(v, sht, ".r"); }

// CHECK-LABEL: @shlhps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i16> @llvm.kvx.shl.v2i16(<2 x i16> [[V:%.*]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x i16> [[TMP0]]
//
v2i16 shlhps (v2i16 v, unsigned sht) { return __builtin_kvx_shlhps(v, sht, ""); }

// CHECK-LABEL: @shlhps_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i16> @llvm.kvx.shl.v2i16(<2 x i16> [[V:%.*]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    ret <2 x i16> [[TMP0]]
//
v2i16 shlhps_s (v2i16 v, unsigned sht) { return __builtin_kvx_shlhps(v, sht, ".s"); }

// CHECK-LABEL: @shlhps_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i16> @llvm.kvx.shl.v2i16(<2 x i16> [[V:%.*]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    ret <2 x i16> [[TMP0]]
//
v2i16 shlhps_us (v2i16 v, unsigned sht) { return __builtin_kvx_shlhps(v, sht, ".us"); }

// CHECK-LABEL: @shlhps_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i16> @llvm.kvx.shl.v2i16(<2 x i16> [[V:%.*]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    ret <2 x i16> [[TMP0]]
//
v2i16 shlhps_r (v2i16 v, unsigned sht) { return __builtin_kvx_shlhps(v, sht, ".r"); }

// CHECK-LABEL: @shlhqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[V:%.*]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 shlhqs (v4i16 v, unsigned sht) { return __builtin_kvx_shlhqs(v, sht, ""); }

// CHECK-LABEL: @shlhqs_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[V:%.*]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 shlhqs_s (v4i16 v, unsigned sht) { return __builtin_kvx_shlhqs(v, sht, ".s"); }

// CHECK-LABEL: @shlhqs_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[V:%.*]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 shlhqs_us (v4i16 v, unsigned sht) { return __builtin_kvx_shlhqs(v, sht, ".us"); }

// CHECK-LABEL: @shlhqs_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[V:%.*]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 shlhqs_r (v4i16 v, unsigned sht) { return __builtin_kvx_shlhqs(v, sht, ".r"); }

// CHECK-LABEL: @shlhxs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[V:%.*]], <16 x i16> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP0]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i16> [[V]], <16 x i16> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP2]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[V]], <16 x i16> poison, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP4]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <16 x i16> [[V]], <16 x i16> poison, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP6]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <4 x i16> [[TMP5]], <4 x i16> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <8 x i16> [[TMP8]], <8 x i16> [[TMP9]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    ret <16 x i16> [[TMP10]]
//
v16i16 shlhxs (v16i16 v, unsigned sht) { return __builtin_kvx_shlhxs(v, sht, ""); }

// CHECK-LABEL: @shlhxs_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[V:%.*]], <16 x i16> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP0]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i16> [[V]], <16 x i16> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP2]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[V]], <16 x i16> poison, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP4]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <16 x i16> [[V]], <16 x i16> poison, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP6]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <4 x i16> [[TMP5]], <4 x i16> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <8 x i16> [[TMP8]], <8 x i16> [[TMP9]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    ret <16 x i16> [[TMP10]]
//
v16i16 shlhxs_s (v16i16 v, unsigned sht) { return __builtin_kvx_shlhxs(v, sht, ".s"); }

// CHECK-LABEL: @shlhxs_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[V:%.*]], <16 x i16> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP0]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i16> [[V]], <16 x i16> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP2]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[V]], <16 x i16> poison, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP4]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <16 x i16> [[V]], <16 x i16> poison, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP6]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <4 x i16> [[TMP5]], <4 x i16> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <8 x i16> [[TMP8]], <8 x i16> [[TMP9]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    ret <16 x i16> [[TMP10]]
//
v16i16 shlhxs_us (v16i16 v, unsigned sht) { return __builtin_kvx_shlhxs(v, sht, ".us"); }

// CHECK-LABEL: @shlhxs_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[V:%.*]], <16 x i16> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP0]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i16> [[V]], <16 x i16> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP2]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[V]], <16 x i16> poison, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP4]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <16 x i16> [[V]], <16 x i16> poison, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x i16> @llvm.kvx.shl.v4i16(<4 x i16> [[TMP6]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <4 x i16> [[TMP5]], <4 x i16> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <8 x i16> [[TMP8]], <8 x i16> [[TMP9]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    ret <16 x i16> [[TMP10]]
//
v16i16 shlhxs_r (v16i16 v, unsigned sht) { return __builtin_kvx_shlhxs(v, sht, ".r"); }

// CHECK-LABEL: @shlw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[V:%.*]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    ret i32 [[TMP0]]
//
int shlw (int v, unsigned sht) { return __builtin_kvx_shlw(v, sht, ""); }

// CHECK-LABEL: @shlw_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[V:%.*]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    ret i32 [[TMP0]]
//
int shlw_s (int v, unsigned sht) { return __builtin_kvx_shlw(v, sht, ".s"); }

// CHECK-LABEL: @shlw_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[V:%.*]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    ret i32 [[TMP0]]
//
int shlw_us (int v, unsigned sht) { return __builtin_kvx_shlw(v, sht, ".us"); }

// CHECK-LABEL: @shlw_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[V:%.*]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    ret i32 [[TMP0]]
//
int shlw_r (int v, unsigned sht) { return __builtin_kvx_shlw(v, sht, ".r"); }

// CHECK-LABEL: @shlwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <8 x i32> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <8 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP0]], i32 [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <8 x i32> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <8 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP3]], i32 [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <8 x i32> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <8 x i32> [[SHT]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP6]], i32 [[TMP7]], i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <8 x i32> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <8 x i32> [[SHT]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP9]], i32 [[TMP10]], i32 0)
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <8 x i32> [[V]], i64 4
// CHECK-NEXT:    [[TMP13:%.*]] = extractelement <8 x i32> [[SHT]], i64 4
// CHECK-NEXT:    [[TMP14:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP12]], i32 [[TMP13]], i32 0)
// CHECK-NEXT:    [[TMP15:%.*]] = extractelement <8 x i32> [[V]], i64 5
// CHECK-NEXT:    [[TMP16:%.*]] = extractelement <8 x i32> [[SHT]], i64 5
// CHECK-NEXT:    [[TMP17:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP15]], i32 [[TMP16]], i32 0)
// CHECK-NEXT:    [[TMP18:%.*]] = extractelement <8 x i32> [[V]], i64 6
// CHECK-NEXT:    [[TMP19:%.*]] = extractelement <8 x i32> [[SHT]], i64 6
// CHECK-NEXT:    [[TMP20:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP18]], i32 [[TMP19]], i32 0)
// CHECK-NEXT:    [[TMP21:%.*]] = extractelement <8 x i32> [[V]], i64 7
// CHECK-NEXT:    [[TMP22:%.*]] = extractelement <8 x i32> [[SHT]], i64 7
// CHECK-NEXT:    [[TMP23:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP21]], i32 [[TMP22]], i32 0)
// CHECK-NEXT:    [[TMP24:%.*]] = insertelement <8 x i32> poison, i32 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP25:%.*]] = insertelement <8 x i32> [[TMP24]], i32 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP26:%.*]] = insertelement <8 x i32> [[TMP25]], i32 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP27:%.*]] = insertelement <8 x i32> [[TMP26]], i32 [[TMP11]], i64 3
// CHECK-NEXT:    [[TMP28:%.*]] = insertelement <8 x i32> [[TMP27]], i32 [[TMP14]], i64 4
// CHECK-NEXT:    [[TMP29:%.*]] = insertelement <8 x i32> [[TMP28]], i32 [[TMP17]], i64 5
// CHECK-NEXT:    [[TMP30:%.*]] = insertelement <8 x i32> [[TMP29]], i32 [[TMP20]], i64 6
// CHECK-NEXT:    [[TMP31:%.*]] = insertelement <8 x i32> [[TMP30]], i32 [[TMP23]], i64 7
// CHECK-NEXT:    ret <8 x i32> [[TMP31]]
//
v8i32 shlwo (v8i32 v, v8u32 sht) { return __builtin_kvx_shlwo(v, sht, ""); }

// CHECK-LABEL: @shlwo_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <8 x i32> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <8 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP0]], i32 [[TMP1]], i32 1)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <8 x i32> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <8 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP3]], i32 [[TMP4]], i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <8 x i32> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <8 x i32> [[SHT]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP6]], i32 [[TMP7]], i32 1)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <8 x i32> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <8 x i32> [[SHT]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP9]], i32 [[TMP10]], i32 1)
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <8 x i32> [[V]], i64 4
// CHECK-NEXT:    [[TMP13:%.*]] = extractelement <8 x i32> [[SHT]], i64 4
// CHECK-NEXT:    [[TMP14:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP12]], i32 [[TMP13]], i32 1)
// CHECK-NEXT:    [[TMP15:%.*]] = extractelement <8 x i32> [[V]], i64 5
// CHECK-NEXT:    [[TMP16:%.*]] = extractelement <8 x i32> [[SHT]], i64 5
// CHECK-NEXT:    [[TMP17:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP15]], i32 [[TMP16]], i32 1)
// CHECK-NEXT:    [[TMP18:%.*]] = extractelement <8 x i32> [[V]], i64 6
// CHECK-NEXT:    [[TMP19:%.*]] = extractelement <8 x i32> [[SHT]], i64 6
// CHECK-NEXT:    [[TMP20:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP18]], i32 [[TMP19]], i32 1)
// CHECK-NEXT:    [[TMP21:%.*]] = extractelement <8 x i32> [[V]], i64 7
// CHECK-NEXT:    [[TMP22:%.*]] = extractelement <8 x i32> [[SHT]], i64 7
// CHECK-NEXT:    [[TMP23:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP21]], i32 [[TMP22]], i32 1)
// CHECK-NEXT:    [[TMP24:%.*]] = insertelement <8 x i32> poison, i32 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP25:%.*]] = insertelement <8 x i32> [[TMP24]], i32 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP26:%.*]] = insertelement <8 x i32> [[TMP25]], i32 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP27:%.*]] = insertelement <8 x i32> [[TMP26]], i32 [[TMP11]], i64 3
// CHECK-NEXT:    [[TMP28:%.*]] = insertelement <8 x i32> [[TMP27]], i32 [[TMP14]], i64 4
// CHECK-NEXT:    [[TMP29:%.*]] = insertelement <8 x i32> [[TMP28]], i32 [[TMP17]], i64 5
// CHECK-NEXT:    [[TMP30:%.*]] = insertelement <8 x i32> [[TMP29]], i32 [[TMP20]], i64 6
// CHECK-NEXT:    [[TMP31:%.*]] = insertelement <8 x i32> [[TMP30]], i32 [[TMP23]], i64 7
// CHECK-NEXT:    ret <8 x i32> [[TMP31]]
//
v8i32 shlwo_s (v8i32 v, v8u32 sht) { return __builtin_kvx_shlwo(v, sht, ".s"); }

// CHECK-LABEL: @shlwo_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <8 x i32> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <8 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP0]], i32 [[TMP1]], i32 2)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <8 x i32> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <8 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP3]], i32 [[TMP4]], i32 2)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <8 x i32> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <8 x i32> [[SHT]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP6]], i32 [[TMP7]], i32 2)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <8 x i32> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <8 x i32> [[SHT]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP9]], i32 [[TMP10]], i32 2)
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <8 x i32> [[V]], i64 4
// CHECK-NEXT:    [[TMP13:%.*]] = extractelement <8 x i32> [[SHT]], i64 4
// CHECK-NEXT:    [[TMP14:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP12]], i32 [[TMP13]], i32 2)
// CHECK-NEXT:    [[TMP15:%.*]] = extractelement <8 x i32> [[V]], i64 5
// CHECK-NEXT:    [[TMP16:%.*]] = extractelement <8 x i32> [[SHT]], i64 5
// CHECK-NEXT:    [[TMP17:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP15]], i32 [[TMP16]], i32 2)
// CHECK-NEXT:    [[TMP18:%.*]] = extractelement <8 x i32> [[V]], i64 6
// CHECK-NEXT:    [[TMP19:%.*]] = extractelement <8 x i32> [[SHT]], i64 6
// CHECK-NEXT:    [[TMP20:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP18]], i32 [[TMP19]], i32 2)
// CHECK-NEXT:    [[TMP21:%.*]] = extractelement <8 x i32> [[V]], i64 7
// CHECK-NEXT:    [[TMP22:%.*]] = extractelement <8 x i32> [[SHT]], i64 7
// CHECK-NEXT:    [[TMP23:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP21]], i32 [[TMP22]], i32 2)
// CHECK-NEXT:    [[TMP24:%.*]] = insertelement <8 x i32> poison, i32 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP25:%.*]] = insertelement <8 x i32> [[TMP24]], i32 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP26:%.*]] = insertelement <8 x i32> [[TMP25]], i32 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP27:%.*]] = insertelement <8 x i32> [[TMP26]], i32 [[TMP11]], i64 3
// CHECK-NEXT:    [[TMP28:%.*]] = insertelement <8 x i32> [[TMP27]], i32 [[TMP14]], i64 4
// CHECK-NEXT:    [[TMP29:%.*]] = insertelement <8 x i32> [[TMP28]], i32 [[TMP17]], i64 5
// CHECK-NEXT:    [[TMP30:%.*]] = insertelement <8 x i32> [[TMP29]], i32 [[TMP20]], i64 6
// CHECK-NEXT:    [[TMP31:%.*]] = insertelement <8 x i32> [[TMP30]], i32 [[TMP23]], i64 7
// CHECK-NEXT:    ret <8 x i32> [[TMP31]]
//
v8i32 shlwo_us (v8i32 v, v8u32 sht) { return __builtin_kvx_shlwo(v, sht, ".us"); }

// CHECK-LABEL: @shlwo_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <8 x i32> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <8 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP0]], i32 [[TMP1]], i32 3)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <8 x i32> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <8 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP3]], i32 [[TMP4]], i32 3)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <8 x i32> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <8 x i32> [[SHT]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP6]], i32 [[TMP7]], i32 3)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <8 x i32> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <8 x i32> [[SHT]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP9]], i32 [[TMP10]], i32 3)
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <8 x i32> [[V]], i64 4
// CHECK-NEXT:    [[TMP13:%.*]] = extractelement <8 x i32> [[SHT]], i64 4
// CHECK-NEXT:    [[TMP14:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP12]], i32 [[TMP13]], i32 3)
// CHECK-NEXT:    [[TMP15:%.*]] = extractelement <8 x i32> [[V]], i64 5
// CHECK-NEXT:    [[TMP16:%.*]] = extractelement <8 x i32> [[SHT]], i64 5
// CHECK-NEXT:    [[TMP17:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP15]], i32 [[TMP16]], i32 3)
// CHECK-NEXT:    [[TMP18:%.*]] = extractelement <8 x i32> [[V]], i64 6
// CHECK-NEXT:    [[TMP19:%.*]] = extractelement <8 x i32> [[SHT]], i64 6
// CHECK-NEXT:    [[TMP20:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP18]], i32 [[TMP19]], i32 3)
// CHECK-NEXT:    [[TMP21:%.*]] = extractelement <8 x i32> [[V]], i64 7
// CHECK-NEXT:    [[TMP22:%.*]] = extractelement <8 x i32> [[SHT]], i64 7
// CHECK-NEXT:    [[TMP23:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP21]], i32 [[TMP22]], i32 3)
// CHECK-NEXT:    [[TMP24:%.*]] = insertelement <8 x i32> poison, i32 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP25:%.*]] = insertelement <8 x i32> [[TMP24]], i32 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP26:%.*]] = insertelement <8 x i32> [[TMP25]], i32 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP27:%.*]] = insertelement <8 x i32> [[TMP26]], i32 [[TMP11]], i64 3
// CHECK-NEXT:    [[TMP28:%.*]] = insertelement <8 x i32> [[TMP27]], i32 [[TMP14]], i64 4
// CHECK-NEXT:    [[TMP29:%.*]] = insertelement <8 x i32> [[TMP28]], i32 [[TMP17]], i64 5
// CHECK-NEXT:    [[TMP30:%.*]] = insertelement <8 x i32> [[TMP29]], i32 [[TMP20]], i64 6
// CHECK-NEXT:    [[TMP31:%.*]] = insertelement <8 x i32> [[TMP30]], i32 [[TMP23]], i64 7
// CHECK-NEXT:    ret <8 x i32> [[TMP31]]
//
v8i32 shlwo_r (v8i32 v, v8u32 sht) { return __builtin_kvx_shlwo(v, sht, ".r"); }

// CHECK-LABEL: @shlwos(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[V:%.*]], <8 x i32> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP0]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP2]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> poison, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP4]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> poison, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP6]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <2 x i32> [[TMP5]], <2 x i32> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i32> [[TMP8]], <4 x i32> [[TMP9]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i32> [[TMP10]]
//
v8i32 shlwos (v8i32 v, unsigned sht) { return __builtin_kvx_shlwos(v, sht, ""); }

// CHECK-LABEL: @shlwos_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[V:%.*]], <8 x i32> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP0]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP2]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> poison, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP4]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> poison, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP6]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <2 x i32> [[TMP5]], <2 x i32> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i32> [[TMP8]], <4 x i32> [[TMP9]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i32> [[TMP10]]
//
v8i32 shlwos_s (v8i32 v, unsigned sht) { return __builtin_kvx_shlwos(v, sht, ".s"); }

// CHECK-LABEL: @shlwos_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[V:%.*]], <8 x i32> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP0]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP2]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> poison, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP4]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> poison, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP6]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <2 x i32> [[TMP5]], <2 x i32> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i32> [[TMP8]], <4 x i32> [[TMP9]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i32> [[TMP10]]
//
v8i32 shlwos_us (v8i32 v, unsigned sht) { return __builtin_kvx_shlwos(v, sht, ".us"); }

// CHECK-LABEL: @shlwos_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[V:%.*]], <8 x i32> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP0]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP2]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> poison, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP4]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> poison, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP6]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <2 x i32> [[TMP5]], <2 x i32> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i32> [[TMP8]], <4 x i32> [[TMP9]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i32> [[TMP10]]
//
v8i32 shlwos_r (v8i32 v, unsigned sht) { return __builtin_kvx_shlwos(v, sht, ".r"); }

// CHECK-LABEL: @shlwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i32> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP0]], i32 [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i32> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP3]], i32 [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> poison, i32 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i32> [[TMP6]], i32 [[TMP5]], i64 1
// CHECK-NEXT:    ret <2 x i32> [[TMP7]]
//
v2i32 shlwp (v2i32 v, v2u32 sht) { return __builtin_kvx_shlwp(v, sht, ""); }

// CHECK-LABEL: @shlwp_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i32> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP0]], i32 [[TMP1]], i32 1)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i32> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP3]], i32 [[TMP4]], i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> poison, i32 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i32> [[TMP6]], i32 [[TMP5]], i64 1
// CHECK-NEXT:    ret <2 x i32> [[TMP7]]
//
v2i32 shlwp_s (v2i32 v, v2u32 sht) { return __builtin_kvx_shlwp(v, sht, ".s"); }

// CHECK-LABEL: @shlwp_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i32> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP0]], i32 [[TMP1]], i32 2)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i32> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP3]], i32 [[TMP4]], i32 2)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> poison, i32 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i32> [[TMP6]], i32 [[TMP5]], i64 1
// CHECK-NEXT:    ret <2 x i32> [[TMP7]]
//
v2i32 shlwp_us (v2i32 v, v2u32 sht) { return __builtin_kvx_shlwp(v, sht, ".us"); }

// CHECK-LABEL: @shlwp_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i32> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP0]], i32 [[TMP1]], i32 3)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i32> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP3]], i32 [[TMP4]], i32 3)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> poison, i32 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i32> [[TMP6]], i32 [[TMP5]], i64 1
// CHECK-NEXT:    ret <2 x i32> [[TMP7]]
//
v2i32 shlwp_r (v2i32 v, v2u32 sht) { return __builtin_kvx_shlwp(v, sht, ".r"); }

// CHECK-LABEL: @shlwps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[V:%.*]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 shlwps (v2i32 v, unsigned sht) { return __builtin_kvx_shlwps(v, sht, ""); }

// CHECK-LABEL: @shlwps_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[V:%.*]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 shlwps_s (v2i32 v, unsigned sht) { return __builtin_kvx_shlwps(v, sht, ".s"); }

// CHECK-LABEL: @shlwps_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[V:%.*]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 shlwps_us (v2i32 v, unsigned sht) { return __builtin_kvx_shlwps(v, sht, ".us"); }

// CHECK-LABEL: @shlwps_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[V:%.*]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 shlwps_r (v2i32 v, unsigned sht) { return __builtin_kvx_shlwps(v, sht, ".r"); }

// CHECK-LABEL: @shlwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i32> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP0]], i32 [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i32> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP3]], i32 [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i32> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x i32> [[SHT]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP6]], i32 [[TMP7]], i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i32> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x i32> [[SHT]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP9]], i32 [[TMP10]], i32 0)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i32> poison, i32 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP13:%.*]] = insertelement <4 x i32> [[TMP12]], i32 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP14:%.*]] = insertelement <4 x i32> [[TMP13]], i32 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i32> [[TMP14]], i32 [[TMP11]], i64 3
// CHECK-NEXT:    ret <4 x i32> [[TMP15]]
//
v4i32 shlwq (v4i32 v, v4u32 sht) { return __builtin_kvx_shlwq(v, sht, ""); }

// CHECK-LABEL: @shlwq_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i32> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP0]], i32 [[TMP1]], i32 1)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i32> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP3]], i32 [[TMP4]], i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i32> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x i32> [[SHT]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP6]], i32 [[TMP7]], i32 1)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i32> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x i32> [[SHT]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP9]], i32 [[TMP10]], i32 1)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i32> poison, i32 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP13:%.*]] = insertelement <4 x i32> [[TMP12]], i32 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP14:%.*]] = insertelement <4 x i32> [[TMP13]], i32 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i32> [[TMP14]], i32 [[TMP11]], i64 3
// CHECK-NEXT:    ret <4 x i32> [[TMP15]]
//
v4i32 shlwq_s (v4i32 v, v4u32 sht) { return __builtin_kvx_shlwq(v, sht, ".s"); }

// CHECK-LABEL: @shlwq_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i32> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP0]], i32 [[TMP1]], i32 2)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i32> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP3]], i32 [[TMP4]], i32 2)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i32> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x i32> [[SHT]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP6]], i32 [[TMP7]], i32 2)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i32> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x i32> [[SHT]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP9]], i32 [[TMP10]], i32 2)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i32> poison, i32 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP13:%.*]] = insertelement <4 x i32> [[TMP12]], i32 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP14:%.*]] = insertelement <4 x i32> [[TMP13]], i32 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i32> [[TMP14]], i32 [[TMP11]], i64 3
// CHECK-NEXT:    ret <4 x i32> [[TMP15]]
//
v4i32 shlwq_us (v4i32 v, v4u32 sht) { return __builtin_kvx_shlwq(v, sht, ".us"); }

// CHECK-LABEL: @shlwq_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i32> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i32> [[SHT:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP0]], i32 [[TMP1]], i32 3)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i32> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i32> [[SHT]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP3]], i32 [[TMP4]], i32 3)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i32> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x i32> [[SHT]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP6]], i32 [[TMP7]], i32 3)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i32> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x i32> [[SHT]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i32 @llvm.kvx.shl.i32(i32 [[TMP9]], i32 [[TMP10]], i32 3)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i32> poison, i32 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP13:%.*]] = insertelement <4 x i32> [[TMP12]], i32 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP14:%.*]] = insertelement <4 x i32> [[TMP13]], i32 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i32> [[TMP14]], i32 [[TMP11]], i64 3
// CHECK-NEXT:    ret <4 x i32> [[TMP15]]
//
v4i32 shlwq_r (v4i32 v, v4u32 sht) { return __builtin_kvx_shlwq(v, sht, ".r"); }

// CHECK-LABEL: @shlwqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[V:%.*]], <4 x i32> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP0]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[V]], <4 x i32> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP2]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4i32 shlwqs (v4i32 v, unsigned sht) { return __builtin_kvx_shlwqs(v, sht, ""); }

// CHECK-LABEL: @shlwqs_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[V:%.*]], <4 x i32> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP0]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[V]], <4 x i32> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP2]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4i32 shlwqs_s (v4i32 v, unsigned sht) { return __builtin_kvx_shlwqs(v, sht, ".s"); }

// CHECK-LABEL: @shlwqs_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[V:%.*]], <4 x i32> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP0]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[V]], <4 x i32> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP2]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4i32 shlwqs_us (v4i32 v, unsigned sht) { return __builtin_kvx_shlwqs(v, sht, ".us"); }

// CHECK-LABEL: @shlwqs_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[V:%.*]], <4 x i32> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP0]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[V]], <4 x i32> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.shl.v2i32(<2 x i32> [[TMP2]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4i32 shlwqs_r (v4i32 v, unsigned sht) { return __builtin_kvx_shlwqs(v, sht, ".r"); }

// CHECK-LABEL: @shlbos(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[V:%.*]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    ret <8 x i8> [[TMP0]]
//
v8i8 shlbos (v8i8 v, unsigned sht) { return __builtin_kvx_shlbos(v, sht, ""); }

// CHECK-LABEL: @shlbos_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[V:%.*]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    ret <8 x i8> [[TMP0]]
//
v8i8 shlbos_s (v8i8 v, unsigned sht) { return __builtin_kvx_shlbos(v, sht, ".s"); }

// CHECK-LABEL: @shlbos_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[V:%.*]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    ret <8 x i8> [[TMP0]]
//
v8i8 shlbos_us (v8i8 v, unsigned sht) { return __builtin_kvx_shlbos(v, sht, ".us"); }

// CHECK-LABEL: @shlbos_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[V:%.*]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    ret <8 x i8> [[TMP0]]
//
v8i8 shlbos_r (v8i8 v, unsigned sht) { return __builtin_kvx_shlbos(v, sht, ".r"); }


// CHECK-LABEL: @shlbps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i8> @llvm.kvx.shl.v2i8(<2 x i8> [[V:%.*]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x i8> [[TMP0]]
//
v2i8 shlbps (v2i8 v, unsigned sht) { return __builtin_kvx_shlbps(v, sht, ""); }

// CHECK-LABEL: @shlbps_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i8> @llvm.kvx.shl.v2i8(<2 x i8> [[V:%.*]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    ret <2 x i8> [[TMP0]]
//
v2i8 shlbps_s (v2i8 v, unsigned sht) { return __builtin_kvx_shlbps(v, sht, ".s"); }

// CHECK-LABEL: @shlbps_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i8> @llvm.kvx.shl.v2i8(<2 x i8> [[V:%.*]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    ret <2 x i8> [[TMP0]]
//
v2i8 shlbps_us (v2i8 v, unsigned sht) { return __builtin_kvx_shlbps(v, sht, ".us"); }

// CHECK-LABEL: @shlbps_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i8> @llvm.kvx.shl.v2i8(<2 x i8> [[V:%.*]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    ret <2 x i8> [[TMP0]]
//
v2i8 shlbps_r (v2i8 v, unsigned sht) { return __builtin_kvx_shlbps(v, sht, ".r"); }

// CHECK-LABEL: @shlbqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i8> @llvm.kvx.shl.v4i8(<4 x i8> [[V:%.*]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x i8> [[TMP0]]
//
v4i8 shlbqs (v4i8 v, unsigned sht) { return __builtin_kvx_shlbqs(v, sht, ""); }

// CHECK-LABEL: @shlbqs_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i8> @llvm.kvx.shl.v4i8(<4 x i8> [[V:%.*]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    ret <4 x i8> [[TMP0]]
//
v4i8 shlbqs_s (v4i8 v, unsigned sht) { return __builtin_kvx_shlbqs(v, sht, ".s"); }

// CHECK-LABEL: @shlbqs_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i8> @llvm.kvx.shl.v4i8(<4 x i8> [[V:%.*]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    ret <4 x i8> [[TMP0]]
//
v4i8 shlbqs_us (v4i8 v, unsigned sht) { return __builtin_kvx_shlbqs(v, sht, ".us"); }

// CHECK-LABEL: @shlbqs_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i8> @llvm.kvx.shl.v4i8(<4 x i8> [[V:%.*]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    ret <4 x i8> [[TMP0]]
//
v4i8 shlbqs_r (v4i8 v, unsigned sht) { return __builtin_kvx_shlbqs(v, sht, ".r"); }

// CHECK-LABEL: @shlbvs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <32 x i8> [[V:%.*]], <32 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP0]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <32 x i8> [[V]], <32 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP2]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <32 x i8> [[V]], <32 x i8> poison, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP4]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <32 x i8> [[V]], <32 x i8> poison, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP6]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i8> [[TMP1]], <8 x i8> [[TMP3]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i8> [[TMP5]], <8 x i8> [[TMP7]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <16 x i8> [[TMP8]], <16 x i8> [[TMP9]], <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
// CHECK-NEXT:    ret <32 x i8> [[TMP10]]
//
v32i8 shlbvs (v32i8 v, unsigned sht) { return __builtin_kvx_shlbvs(v, sht, ""); }

// CHECK-LABEL: @shlbvs_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <32 x i8> [[V:%.*]], <32 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP0]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <32 x i8> [[V]], <32 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP2]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <32 x i8> [[V]], <32 x i8> poison, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP4]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <32 x i8> [[V]], <32 x i8> poison, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP6]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i8> [[TMP1]], <8 x i8> [[TMP3]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i8> [[TMP5]], <8 x i8> [[TMP7]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <16 x i8> [[TMP8]], <16 x i8> [[TMP9]], <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
// CHECK-NEXT:    ret <32 x i8> [[TMP10]]
//
v32i8 shlbvs_s (v32i8 v, unsigned sht) { return __builtin_kvx_shlbvs(v, sht, ".s"); }

// CHECK-LABEL: @shlbvs_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <32 x i8> [[V:%.*]], <32 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP0]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <32 x i8> [[V]], <32 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP2]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <32 x i8> [[V]], <32 x i8> poison, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP4]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <32 x i8> [[V]], <32 x i8> poison, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP6]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i8> [[TMP1]], <8 x i8> [[TMP3]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i8> [[TMP5]], <8 x i8> [[TMP7]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <16 x i8> [[TMP8]], <16 x i8> [[TMP9]], <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
// CHECK-NEXT:    ret <32 x i8> [[TMP10]]
//
v32i8 shlbvs_us (v32i8 v, unsigned sht) { return __builtin_kvx_shlbvs(v, sht, ".us"); }

// CHECK-LABEL: @shlbvs_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <32 x i8> [[V:%.*]], <32 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP0]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <32 x i8> [[V]], <32 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP2]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <32 x i8> [[V]], <32 x i8> poison, <8 x i32> <i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP4]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <32 x i8> [[V]], <32 x i8> poison, <8 x i32> <i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP6]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i8> [[TMP1]], <8 x i8> [[TMP3]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i8> [[TMP5]], <8 x i8> [[TMP7]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <16 x i8> [[TMP8]], <16 x i8> [[TMP9]], <32 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
// CHECK-NEXT:    ret <32 x i8> [[TMP10]]
//
v32i8 shlbvs_r (v32i8 v, unsigned sht) { return __builtin_kvx_shlbvs(v, sht, ".r"); }

// CHECK-LABEL: @shlbxs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i8> [[V:%.*]], <16 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP0]], i32 [[SHT:%.*]], i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i8> [[V]], <16 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP2]], i32 [[SHT]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i8> [[TMP1]], <8 x i8> [[TMP3]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    ret <16 x i8> [[TMP4]]
//
v16i8 shlbxs (v16i8 v, unsigned sht) { return __builtin_kvx_shlbxs(v, sht, ""); }

// CHECK-LABEL: @shlbxs_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i8> [[V:%.*]], <16 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP0]], i32 [[SHT:%.*]], i32 1)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i8> [[V]], <16 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP2]], i32 [[SHT]], i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i8> [[TMP1]], <8 x i8> [[TMP3]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    ret <16 x i8> [[TMP4]]
//
v16i8 shlbxs_s (v16i8 v, unsigned sht) { return __builtin_kvx_shlbxs(v, sht, ".s"); }

// CHECK-LABEL: @shlbxs_us(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i8> [[V:%.*]], <16 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP0]], i32 [[SHT:%.*]], i32 2)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i8> [[V]], <16 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP2]], i32 [[SHT]], i32 2)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i8> [[TMP1]], <8 x i8> [[TMP3]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    ret <16 x i8> [[TMP4]]
//
v16i8 shlbxs_us (v16i8 v, unsigned sht) { return __builtin_kvx_shlbxs(v, sht, ".us"); }

// CHECK-LABEL: @shlbxs_r(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i8> [[V:%.*]], <16 x i8> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP0]], i32 [[SHT:%.*]], i32 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i8> [[V]], <16 x i8> poison, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <8 x i8> @llvm.kvx.shl.v8i8(<8 x i8> [[TMP2]], i32 [[SHT]], i32 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i8> [[TMP1]], <8 x i8> [[TMP3]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    ret <16 x i8> [[TMP4]]
//
v16i8 shlbxs_r (v16i8 v, unsigned sht) { return __builtin_kvx_shlbxs(v, sht, ".r"); }
