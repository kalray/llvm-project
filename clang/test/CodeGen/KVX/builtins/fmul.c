// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple kvx-kalray-cos -S -O2 -emit-llvm -o - %s | FileCheck %s
#include "vector-types.h"

// CHECK-LABEL: @fmuld(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call double @llvm.kvx.fmul.f64(double [[V1:%.*]], double [[V2:%.*]], i32 3, i32 0)
// CHECK-NEXT:    ret double [[TMP0]]
//
double fmuld(double v1, double v2) { return __builtin_kvx_fmuld(v1, v2, ".rz"); }
// CHECK-LABEL: @fmuldp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x double> [[V1:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x double> [[V2:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call double @llvm.kvx.fmul.f64(double [[TMP0]], double [[TMP1]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x double> [[V1]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x double> [[V2]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call double @llvm.kvx.fmul.f64(double [[TMP3]], double [[TMP4]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x double> undef, double [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x double> [[TMP6]], double [[TMP5]], i64 1
// CHECK-NEXT:    ret <2 x double> [[TMP7]]
//
v2f64 fmuldp(v2f64 v1, v2f64 v2) { return __builtin_kvx_fmuldp(v1, v2, ".rn"); }
// CHECK-LABEL: @fmuldq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x double> [[V1:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x double> [[V2:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call double @llvm.kvx.fmul.f64(double [[TMP0]], double [[TMP1]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x double> [[V1]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x double> [[V2]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call double @llvm.kvx.fmul.f64(double [[TMP3]], double [[TMP4]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x double> [[V1]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x double> [[V2]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call double @llvm.kvx.fmul.f64(double [[TMP6]], double [[TMP7]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x double> [[V1]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x double> [[V2]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call double @llvm.kvx.fmul.f64(double [[TMP9]], double [[TMP10]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x double> undef, double [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP13:%.*]] = insertelement <4 x double> [[TMP12]], double [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP14:%.*]] = insertelement <4 x double> [[TMP13]], double [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x double> [[TMP14]], double [[TMP11]], i64 3
// CHECK-NEXT:    ret <4 x double> [[TMP15]]
//
v4f64 fmuldq(v4f64 v1, v4f64 v2) { return __builtin_kvx_fmuldq(v1, v2, ".rn"); }
// CHECK-LABEL: @fmulh(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call half @llvm.kvx.fmul.f16(half [[A:%.*]], half [[B:%.*]], i32 1, i32 1)
// CHECK-NEXT:    ret half [[TMP0]]
//
half fmulh(half a, half b) { return __builtin_kvx_fmulh(a, b, ".ru.s"); }
//
//

// CHECK-LABEL: @fmulhp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x half> @llvm.kvx.fmul.v2f16(<2 x half> [[V1:%.*]], <2 x half> [[V2:%.*]], i32 1, i32 1)
// CHECK-NEXT:    ret <2 x half> [[TMP0]]
//
v2f16 fmulhp(v2f16 v1, v2f16 v2) { return __builtin_kvx_fmulhp(v1, v2, ".ru.s"); }

// CHECK-LABEL: @fmulhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x half> @llvm.kvx.fmul.v4f16(<4 x half> [[V1:%.*]], <4 x half> [[V2:%.*]], i32 1, i32 1)
// CHECK-NEXT:    ret <4 x half> [[TMP0]]
//
v4f16 fmulhq(v4f16 v1, v4f16 v2) { return __builtin_kvx_fmulhq(v1, v2, ".ru.s"); }
// CHECK-LABEL: @fmulw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call float @llvm.kvx.fmul.f32(float [[V1:%.*]], float [[V2:%.*]], i32 3, i32 0)
// CHECK-NEXT:    ret float [[TMP0]]
//
float fmulw(float v1, float v2) { return __builtin_kvx_fmulw(v1, v2, ".rz"); }
// CHECK-LABEL: @fmulwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fmul.v2f32(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fmulwp(v2f32 v1, v2f32 v2) { return __builtin_kvx_fmulwp(v1, v2, ".rn"); }
