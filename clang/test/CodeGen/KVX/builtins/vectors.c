// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple kvx-kalray-cos -emit-llvm %s -O2 -o - | FileCheck %s
typedef int __attribute__((__vector_size__(8))) v2i32;
typedef short __attribute__((__vector_size__(4 * sizeof(short)))) v4i16;
typedef short __attribute__((__vector_size__(8 * sizeof(short)))) v8i16;
typedef short __attribute__((__vector_size__(16 * sizeof(short)))) v16i16;
typedef int __attribute__((__vector_size__(2 * sizeof(int)))) v2i32;
typedef int __attribute__((__vector_size__(4 * sizeof(int)))) v4i32;
typedef int __attribute__((__vector_size__(8 * sizeof(int)))) v8i32;
typedef long __attribute__((__vector_size__(2 * sizeof(long)))) v2i64;
typedef long __attribute__((__vector_size__(4 * sizeof(long)))) v4i64;

typedef unsigned int __attribute__((__vector_size__(8))) v2u32;
typedef unsigned short __attribute__((__vector_size__(4 * sizeof(short))))
v4u16;
typedef unsigned short __attribute__((__vector_size__(8 * sizeof(short))))
v8u16;
typedef unsigned short __attribute__((__vector_size__(16 * sizeof(short))))
v16u16;
typedef unsigned int __attribute__((__vector_size__(2 * sizeof(int)))) v2u32;
typedef unsigned int __attribute__((__vector_size__(4 * sizeof(int)))) v4u32;
typedef unsigned int __attribute__((__vector_size__(8 * sizeof(int)))) v8u32;
typedef unsigned long __attribute__((__vector_size__(2 * sizeof(long)))) v2u64;
typedef unsigned long __attribute__((__vector_size__(4 * sizeof(long)))) v4u64;

typedef float __attribute__((__vector_size__(2 * sizeof(float)))) v2f32;
typedef float __attribute__((__vector_size__(4 * sizeof(float)))) v4f32;
typedef float __attribute__((__vector_size__(8 * sizeof(float)))) v8f32;

typedef double __attribute__((__vector_size__(2 * sizeof(double)))) v2f64;
typedef double __attribute__((__vector_size__(4 * sizeof(double)))) v4f64;


// CHECK-LABEL: @avghq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 avghq(v4i16 a, v4i16 b) { return __builtin_kvx_avghq(a, b, ""); }

// CHECK-LABEL: @avgho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8i16 avgho(v8i16 a, v8i16 b) { return __builtin_kvx_avgho(a, b, ""); }

// CHECK-LABEL: @avghx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16i16 avghx(v16i16 a, v16i16 b) {
  return __builtin_kvx_avghx(a, b, "");
}

// CHECK-LABEL: @avgwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 avgwp(v2i32 a, v2i32 b) { return __builtin_kvx_avgwp(a, b, ""); }

// CHECK-LABEL: @avgwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4i32 avgwq(v4i32 a, v4i32 b) { return __builtin_kvx_avgwq(a, b, ""); }

// CHECK-LABEL: @avgwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8i32 avgwo(v8i32 a, v8i32 b) { return __builtin_kvx_avgwo(a, b, ""); }

// CHECK-LABEL: @avguhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4u16 avguhq(v4u16 a, v4u16 b) { return __builtin_kvx_avghq(a, b, ".u"); }

// CHECK-LABEL: @avguho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8u16 avguho(v8u16 a, v8i16 b) { return __builtin_kvx_avgho(a, b, ".u"); }

// CHECK-LABEL: @avguhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16u16 avguhx(v16u16 a, v16u16 b) { return __builtin_kvx_avghx(a, b, ".u"); }

// CHECK-LABEL: @avguwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2u32 avguwp(v2u32 a, v2u32 b) { return __builtin_kvx_avgwp(a, b, ".u"); }

// CHECK-LABEL: @avguwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4u32 avguwq(v4u32 a, v4u32 b) { return __builtin_kvx_avgwq(a, b, ".u"); }

// CHECK-LABEL: @avguwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8u32 avguwo(v8u32 a, v8u32 b) { return __builtin_kvx_avgwo(a, b, ".u"); }

// CHECK-LABEL: @avgrhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 avgrhq(v4i16 a, v4i16 b) { return __builtin_kvx_avghq(a, b, ".r"); }

// CHECK-LABEL: @avgrho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8i16 avgrho(v8i16 a, v8i16 b) { return __builtin_kvx_avgho(a, b, ".r"); }

// CHECK-LABEL: @avgrhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16i16 avgrhx(v16i16 a, v16i16 b) { return __builtin_kvx_avghx(a, b, ".r"); }

// CHECK-LABEL: @avgrwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 avgrwp(v2i32 a, v2i32 b) { return __builtin_kvx_avgwp(a, b, ".r"); }

// CHECK-LABEL: @avgrwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4i32 avgrwq(v4i32 a, v4i32 b) { return __builtin_kvx_avgwq(a, b, ".r"); }

// CHECK-LABEL: @avgrwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8i32 avgrwo(v8i32 a, v8i32 b) { return __builtin_kvx_avgwo(a, b, ".r"); }

// CHECK-LABEL: @avgruhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4u16 avgruhq(v4u16 a, v4u16 b) { return __builtin_kvx_avghq(a, b, ".ru"); }

// CHECK-LABEL: @avgruho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8u16 avgruho(v8u16 a, v8u16 b) { return __builtin_kvx_avgho(a, b, ".ru"); }

// CHECK-LABEL: @avgruhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16u16 avgruhx(v16u16 a, v16u16 b) { return __builtin_kvx_avghx(a, b, ".ru"); }

// CHECK-LABEL: @avgruwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2u32 avgruwp(v2u32 a, v2u32 b) { return __builtin_kvx_avgwp(a, b, ".ru"); }

// CHECK-LABEL: @avgruwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4u32 avgruwq(v4u32 a, v4u32 b) { return __builtin_kvx_avgwq(a, b, ".ru"); }

// CHECK-LABEL: @avgruwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8u32 avgruwo(v8u32 a, v8u32 b) { return __builtin_kvx_avgwo(a, b, ".ru"); }

/**
 * TODO: reintroduce addshq to addsdqs tests once saturation modifier is
 * supported in integer add builtins
 */

// v4i16 addshq(v4i16 a, v4i16 b) { return __builtin_kvx_addshq(a, b); }

// v8i16 addsho(v8i16 a, v8i16 b) { return __builtin_kvx_addsho(a, b); }

// v16i16 addshx(v16i16 a, v16i16 b) {
//   return __builtin_kvx_addshx(a, b);
// }

// v2i32 addswp(v2i32 a, v2i32 b) { return __builtin_kvx_addswp(a, b); }

// v4i32 addswq(v4i32 a, v4i32 b) { return __builtin_kvx_addswq(a, b); }

// v8i32 addswo(v8i32 a, v8i32 b) { return __builtin_kvx_addswo(a, b); }

// v2i64 addsdp(v2i64 a, v2i64 b) { return __builtin_kvx_addsdp(a, b); }

// v4i64 addsdq(v4i64 a, v4i64 b) { return __builtin_kvx_addsdq(a, b); }

// v4i16 addshqs(v4i16 a, short b) {
//   return __builtin_kvx_addshqs(a, b);
// }

// v8i16 addshos(v8i16 a, short b) {
//   return __builtin_kvx_addshos(a, b);
// }

// v16i16 addshxs(v16i16 a, short b) {
//   return __builtin_kvx_addshxs(a, b);
// }

// v2i32 addswps(v2i32 a, int b) { return __builtin_kvx_addswps(a, b); }

// v4i32 addswqs(v4i32 a, int b) { return __builtin_kvx_addswqs(a, b); }

// v8i32 addswos(v8i32 a, int b) { return __builtin_kvx_addswos(a, b); }

// v2i64 addsdps(v2i64 a, long b) {
//   return __builtin_kvx_addsdps(a, b);
// }

// v4i64 addsdqs(v4i64 a, long b) {
//   return __builtin_kvx_addsdqs(a, b);
// }

/**
 * TODO: reintroduce sbfshq to sbfsdqs tests once saturation modifier is
 * supported in integer sub builtins
 */

// v4i16 sbfshq(v4i16 a, v4i16 b) { return __builtin_kvx_sbfshq(a, b); }

// v8i16 sbfsho(v8i16 a, v8i16 b) { return __builtin_kvx_sbfsho(a, b); }

// v16i16 sbfshx(v16i16 a, v16i16 b) {
//   return __builtin_kvx_sbfshx(a, b);
// }

// v2i32 sbfswp(v2i32 a, v2i32 b) { return __builtin_kvx_sbfswp(a, b); }

// v4i32 sbfswq(v4i32 a, v4i32 b) { return __builtin_kvx_sbfswq(a, b); }

// v8i32 sbfswo(v8i32 a, v8i32 b) { return __builtin_kvx_sbfswo(a, b); }

// v2i64 sbfsdp(v2i64 a, v2i64 b) { return __builtin_kvx_sbfsdp(a, b); }

// v4i64 sbfsdq(v4i64 a, v4i64 b) { return __builtin_kvx_sbfsdq(a, b); }

// v4i16 sbfshqs(v4i16 a, short b) {
//   return __builtin_kvx_sbfshqs(a, b);
// }

// v8i16 sbfshos(v8i16 a, short b) {
//   return __builtin_kvx_sbfshos(a, b);
// }

// v16i16 sbfshxs(v16i16 a, short b) {
//   return __builtin_kvx_sbfshxs(a, b);
// }

// v2i32 sbfswps(v2i32 a, int b) { return __builtin_kvx_sbfswps(a, b); }

// v4i32 sbfswqs(v4i32 a, int b) { return __builtin_kvx_sbfswqs(a, b); }

// v8i32 sbfswos(v8i32 a, int b) { return __builtin_kvx_sbfswos(a, b); }

// v2i64 sbfsdps(v2i64 a, long b) {
//   return __builtin_kvx_sbfsdps(a, b);
// }

// v4i64 sbfsdqs(v4i64 a, long b) {
//   return __builtin_kvx_sbfsdqs(a, b);
// }

// CHECK-LABEL: @floatdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP0]], i64 63, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP3]], i64 63, i32 0, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = bitcast <2 x double> [[TMP5]] to <2 x i64>
// CHECK-NEXT:    ret <2 x i64> [[TMP6]]
//
v2i64 floatdp(v2i64 a) { return  __builtin_kvx_floatdp(a, 63, ".rn"); }
