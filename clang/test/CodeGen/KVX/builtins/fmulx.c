// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple kvx-kalray-cos -S -O2 -emit-llvm -o - %s | FileCheck %s
#include "vector-types.h"
// RUN: %clang_cc1 -triple kvx-kalray-cos -S -O2 -emit-llvm -o - %s | FileCheck %s
#include "vector-types.h"

// CHECK-LABEL: @fmulxhw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call float @llvm.kvx.fmulx.f32(half [[A:%.*]], half [[B:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret float [[TMP0]]
//
float fmulxhw(half a, half b) { return __builtin_kvx_fmulxhw(a, b, ".s"); }

// CHECK-LABEL: @fmulxhwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x half> [[A:%.*]], <8 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x half> [[B:%.*]], <8 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fmulx.v4f32(<4 x half> [[TMP0]], <4 x half> [[TMP1]], i32 7, i32 1)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x half> [[A]], <8 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x half> [[B]], <8 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fmulx.v4f32(<4 x half> [[TMP3]], <4 x half> [[TMP4]], i32 7, i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
v8f32 fmulxhwo(v8f16 a, v8f16 b) { return __builtin_kvx_fmulxhwo(a, b, ".s"); }

// CHECK-LABEL: @fmulxhwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fmulx.v2f32(<2 x half> [[A:%.*]], <2 x half> [[B:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fmulxhwp(v2f16 a, v2f16 b) { return __builtin_kvx_fmulxhwp(a, b, ".s"); }

// CHECK-LABEL: @fmulxhwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fmulx.v4f32(<4 x half> [[A:%.*]], <4 x half> [[B:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fmulxhwq(v4f16 a, v4f16 b) { return __builtin_kvx_fmulxhwq(a, b, ".s"); }

// CHECK-LABEL: @fmulxwd(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call double @llvm.kvx.fmulx.f64(float [[A:%.*]], float [[B:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret double [[TMP0]]
//
double fmulxwd(float a, float b) { return __builtin_kvx_fmulxwd(a, b, ".s"); }

// CHECK-LABEL: @fmulxwdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fmulx.v2f64(<2 x float> [[A:%.*]], <2 x float> [[B:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 fmulxwdp(v2f32 a, v2f32 b) { return __builtin_kvx_fmulxwdp(a, b, ".s"); }

// CHECK-LABEL: @fmulxwdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[A:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x float> [[B:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fmulx.v2f64(<2 x float> [[TMP0]], <2 x float> [[TMP1]], i32 7, i32 1)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x float> [[A]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x float> [[B]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fmulx.v2f64(<2 x float> [[TMP3]], <2 x float> [[TMP4]], i32 7, i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
v4f64 fmulxwdq(v4f32 a, v4f32 b) { return __builtin_kvx_fmulxwdq(a, b, ".s"); }
