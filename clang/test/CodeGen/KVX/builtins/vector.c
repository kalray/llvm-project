// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple kvx-kalray-cos -S -O2 -emit-llvm -o - %s | FileCheck %s

#include "vector-types.h"

// CHECK-LABEL: @fmulhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x half> @llvm.kvx.fmulhq(<4 x half> [[V1:%.*]], <4 x half> [[V2:%.*]], i32 1, i32 1)
// CHECK-NEXT:    ret <4 x half> [[TMP0]]
//
v4f16 fmulhq(v4f16 v1, v4f16 v2) {
  return __builtin_kvx_fmulhq(v1, v2, ".ru.s");
}

// CHECK-LABEL: @fmulho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x half> [[V1:%.*]], <8 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x half> [[V2:%.*]], <8 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x half> @llvm.kvx.fmulhq(<4 x half> [[TMP0]], <4 x half> [[TMP1]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x half> [[V1]], <8 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x half> [[V2]], <8 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x half> @llvm.kvx.fmulhq(<4 x half> [[TMP3]], <4 x half> [[TMP4]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x half> [[TMP2]], <4 x half> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x half> [[TMP6]]
//
v8f16 fmulho(v8f16 v1, v8f16 v2) {
  return __builtin_kvx_fmulho(v1, v2, ".ru.s");
}

// CHECK-LABEL: @fmulhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x half> [[V1:%.*]], <16 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x half> [[V2:%.*]], <16 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x half> @llvm.kvx.fmulhq(<4 x half> [[TMP0]], <4 x half> [[TMP1]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x half> [[V1]], <16 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x half> [[V2]], <16 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x half> @llvm.kvx.fmulhq(<4 x half> [[TMP3]], <4 x half> [[TMP4]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x half> [[TMP2]], <4 x half> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x half> [[V1]], <16 x half> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x half> [[V2]], <16 x half> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x half> @llvm.kvx.fmulhq(<4 x half> [[TMP7]], <4 x half> [[TMP8]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x half> [[TMP9]], <4 x half> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x half> [[TMP6]], <16 x half> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x half> [[V1]], <16 x half> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x half> [[V2]], <16 x half> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x half> @llvm.kvx.fmulhq(<4 x half> [[TMP12]], <4 x half> [[TMP13]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x half> [[TMP14]], <4 x half> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x half> [[TMP11]], <16 x half> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x half> [[TMP16]]
//
v16f16 fmulhx(v16f16 v1, v16f16 v2) {
  return __builtin_kvx_fmulhx(v1, v2, ".ru.s");
}

// CHECK-LABEL: @fmulwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fmulwp(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fmulwp(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_fmulwp(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fmulwq(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fmulwq(v4f32 v1, v4f32 v2) {
  return __builtin_kvx_fmulwq(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fmulwq(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fmulwq(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
v8f32 fmulwo(v8f32 v1, v8f32 v2) {
  return __builtin_kvx_fmulwo(v1, v2, ".rn");
}

// CHECK-LABEL: @fmuldp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fmuldp(<2 x double> [[V1:%.*]], <2 x double> [[V2:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 fmuldp(v2f64 v1, v2f64 v2) {
  return __builtin_kvx_fmuldp(v1, v2, ".rn");
}

// CHECK-LABEL: @fmuldq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V1:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[V2:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fmuldp(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[V1]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[V2]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fmuldp(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
v4f64 fmuldq(v4f64 v1, v4f64 v2) {
  return __builtin_kvx_fmuldq(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulwc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fmulwc(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], i32 0, i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fmulwc(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_fmulwc(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulwcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fmulwcp(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], i32 0, i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fmulwcp(v4f32 v1, v4f32 v2) {
  return __builtin_kvx_fmulwcp(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulwcq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fmulwcp(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0, i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fmulwcp(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0, i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
v8f32 fmulwcq(v8f32 v1, v8f32 v2) {
  return __builtin_kvx_fmulwcq(v1, v2, ".rn");
}

// CHECK-LABEL: @fmm212w(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fmm212w(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fmm212w(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_fmm212w(v1, v2, ".rn");
}

// CHECK-LABEL: @fmma212w(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fmma212w(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], <4 x float> [[V3:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fmma212w(v2f32 v1, v2f32 v2, v4f32 v3) {
  return __builtin_kvx_fmma212w(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @fmms212w(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fmms212w(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], <4 x float> [[V3:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fmms212w(v2f32 v1, v2f32 v2, v4f32 v3) {
  return __builtin_kvx_fmms212w(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmahq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x half> @llvm.kvx.ffmahq(<4 x half> [[V1:%.*]], <4 x half> [[V2:%.*]], <4 x half> [[V3:%.*]], i32 1, i32 1)
// CHECK-NEXT:    ret <4 x half> [[TMP0]]
//
v4f16 ffmahq(v4f16 v1, v4f16 v2, v4f16 v3) {
  return __builtin_kvx_ffmahq(v1, v2, v3, ".ru.s");
}

// CHECK-LABEL: @ffmaho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x half> [[V1:%.*]], <8 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x half> [[V2:%.*]], <8 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x half> [[V3:%.*]], <8 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x half> @llvm.kvx.ffmahq(<4 x half> [[TMP0]], <4 x half> [[TMP1]], <4 x half> [[TMP2]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x half> [[V1]], <8 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x half> [[V2]], <8 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x half> [[V3]], <8 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x half> @llvm.kvx.ffmahq(<4 x half> [[TMP4]], <4 x half> [[TMP5]], <4 x half> [[TMP6]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x half> [[TMP3]], <4 x half> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x half> [[TMP8]]
//
v8f16 ffmaho(v8f16 v1, v8f16 v2, v8f16 v3) {
  return __builtin_kvx_ffmaho(v1, v2, v3, ".ru.s");
}

// CHECK-LABEL: @ffmahx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x half> [[V1:%.*]], <16 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x half> [[V2:%.*]], <16 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x half> [[V3:%.*]], <16 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x half> @llvm.kvx.ffmahq(<4 x half> [[TMP0]], <4 x half> [[TMP1]], <4 x half> [[TMP2]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x half> [[V1]], <16 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <16 x half> [[V2]], <16 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <16 x half> [[V3]], <16 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x half> @llvm.kvx.ffmahq(<4 x half> [[TMP4]], <4 x half> [[TMP5]], <4 x half> [[TMP6]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x half> [[TMP3]], <4 x half> [[TMP7]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <16 x half> [[V1]], <16 x half> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <16 x half> [[V2]], <16 x half> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x half> [[V3]], <16 x half> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP12:%.*]] = tail call <4 x half> @llvm.kvx.ffmahq(<4 x half> [[TMP9]], <4 x half> [[TMP10]], <4 x half> [[TMP11]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <4 x half> [[TMP12]], <4 x half> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP14:%.*]] = shufflevector <16 x half> [[TMP8]], <16 x half> [[TMP13]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <16 x half> [[V1]], <16 x half> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x half> [[V2]], <16 x half> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP17:%.*]] = shufflevector <16 x half> [[V3]], <16 x half> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP18:%.*]] = tail call <4 x half> @llvm.kvx.ffmahq(<4 x half> [[TMP15]], <4 x half> [[TMP16]], <4 x half> [[TMP17]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP19:%.*]] = shufflevector <4 x half> [[TMP18]], <4 x half> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP20:%.*]] = shufflevector <16 x half> [[TMP14]], <16 x half> [[TMP19]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x half> [[TMP20]]
//
v16f16 ffmahx(v16f16 v1, v16f16 v2, v16f16 v3) {
  return __builtin_kvx_ffmahx(v1, v2, v3, ".ru.s");
}

// CHECK-LABEL: @ffmawp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.ffmawp(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], <2 x float> [[V3:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 ffmawp(v2f32 v1, v2f32 v2, v2f32 v3) {
  return __builtin_kvx_ffmawp(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmawq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.ffmawq(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], <4 x float> [[V3:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 ffmawq(v4f32 v1, v4f32 v2, v4f32 v3) {
  return __builtin_kvx_ffmawq(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmawo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V3:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x float> @llvm.kvx.ffmawq(<4 x float> [[TMP0]], <4 x float> [[TMP1]], <4 x float> [[TMP2]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x float> [[V3]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x float> @llvm.kvx.ffmawq(<4 x float> [[TMP4]], <4 x float> [[TMP5]], <4 x float> [[TMP6]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x float> [[TMP3]], <4 x float> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP8]]
//
v8f32 ffmawo(v8f32 v1, v8f32 v2, v8f32 v3) {
  return __builtin_kvx_ffmawo(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmadp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.ffmadp(<2 x double> [[V1:%.*]], <2 x double> [[V2:%.*]], <2 x double> [[V3:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 ffmadp(v2f64 v1, v2f64 v2, v2f64 v3) {
  return __builtin_kvx_ffmadp(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmadq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V1:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[V2:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x double> [[V3:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x double> @llvm.kvx.ffmadp(<2 x double> [[TMP0]], <2 x double> [[TMP1]], <2 x double> [[TMP2]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[V1]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <4 x double> [[V2]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x double> [[V3]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x double> @llvm.kvx.ffmadp(<2 x double> [[TMP4]], <2 x double> [[TMP5]], <2 x double> [[TMP6]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x double> [[TMP3]], <2 x double> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP8]]
//
v4f64 ffmadq(v4f64 v1, v4f64 v2, v4f64 v3) {
  return __builtin_kvx_ffmadq(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmswp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.ffmswp(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], <2 x float> [[V3:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 ffmswp(v2f32 v1, v2f32 v2, v2f32 v3) {
  return __builtin_kvx_ffmswp(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmswq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.ffmswq(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], <4 x float> [[V3:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 ffmswq(v4f32 v1, v4f32 v2, v4f32 v3) {
  return __builtin_kvx_ffmswq(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmswo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V3:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x float> @llvm.kvx.ffmswq(<4 x float> [[TMP0]], <4 x float> [[TMP1]], <4 x float> [[TMP2]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x float> [[V3]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x float> @llvm.kvx.ffmswq(<4 x float> [[TMP4]], <4 x float> [[TMP5]], <4 x float> [[TMP6]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x float> [[TMP3]], <4 x float> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP8]]
//
v8f32 ffmswo(v8f32 v1, v8f32 v2, v8f32 v3) {
  return __builtin_kvx_ffmswo(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmsdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.ffmsdp(<2 x double> [[V1:%.*]], <2 x double> [[V2:%.*]], <2 x double> [[V3:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 ffmsdp(v2f64 v1, v2f64 v2, v2f64 v3) {
  return __builtin_kvx_ffmsdp(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmsdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V1:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[V2:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x double> [[V3:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x double> @llvm.kvx.ffmsdp(<2 x double> [[TMP0]], <2 x double> [[TMP1]], <2 x double> [[TMP2]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[V1]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <4 x double> [[V2]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x double> [[V3]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x double> @llvm.kvx.ffmsdp(<2 x double> [[TMP4]], <2 x double> [[TMP5]], <2 x double> [[TMP6]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x double> [[TMP3]], <2 x double> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP8]]
//
v4f64 ffmsdq(v4f64 v1, v4f64 v2, v4f64 v3) {
  return __builtin_kvx_ffmsdq(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @floatwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[V:%.*]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 floatwp(v2i32 v) {
  return __builtin_kvx_floatwp(v, 3, ".rn");
}

// CHECK-LABEL: @floatwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[V:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP0]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[V]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP2]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x float> [[TMP4]]
//
v4f32 floatwq(v4i32 v) {
  return __builtin_kvx_floatwq(v, 3, ".rn");
}

// CHECK-LABEL: @floatwq_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[V:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP0]], i64 3, i32 0, i32 1)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[V]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP2]], i64 3, i32 0, i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x float> [[TMP4]]
//
v4f32 floatwq_s(v4i32 v) {
  return __builtin_kvx_floatwq(v, 3, ".rn.s");
}

// CHECK-LABEL: @floatwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[V:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP0]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP2]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP5]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x float> [[TMP6]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x float> [[TMP4]], <8 x float> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP9]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x float> [[TMP10]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x float> [[TMP8]], <8 x float> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x float> [[TMP12]]
//
v8f32 floatwo(v8i32 v) {
  return __builtin_kvx_floatwo(v, 3, ".rn");
}

// CHECK-LABEL: @floatdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP0]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP3]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    ret <2 x double> [[TMP5]]
//
v2f64 floatdp(v2i64 v) {
  return __builtin_kvx_floatdp(v, 3, ".rn");
}

// CHECK-LABEL: @floatdp_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP0]], i64 3, i32 0, i32 1)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP3]], i64 3, i32 0, i32 1)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    ret <2 x double> [[TMP5]]
//
v2f64 floatdp_s(v2i64 v) {
  return __builtin_kvx_floatdp(v, 3, ".rn.s");
}

// CHECK-LABEL: @floatdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP0]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <4 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP3]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <4 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP6]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x double> [[TMP5]], double [[TMP7]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP9]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x double> [[TMP8]], double [[TMP10]], i64 3
// CHECK-NEXT:    ret <4 x double> [[TMP11]]
//
v4f64 floatdq(v4i64 v) {
  return __builtin_kvx_floatdq(v, 3, ".rn");
}

// CHECK-LABEL: @floatuwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[V:%.*]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 floatuwp(v2u32 v) {
  return __builtin_kvx_floatuwp(v, 3, ".rn");
}

// CHECK-LABEL: @floatuwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[V:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[TMP0]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[V]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[TMP2]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x float> [[TMP4]]
//
v4f32 floatuwq(v4u32 v) {
  return __builtin_kvx_floatuwq(v, 3, ".rn");
}

// CHECK-LABEL: @floatuwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[V:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[TMP0]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[TMP2]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[TMP5]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x float> [[TMP6]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x float> [[TMP4]], <8 x float> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[TMP9]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x float> [[TMP10]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x float> [[TMP8]], <8 x float> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x float> [[TMP12]]
//
v8f32 floatuwo(v8u32 v) {
  return __builtin_kvx_floatuwo(v, 3, ".rn");
}

// CHECK-LABEL: @floatudp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.floatud(i64 [[TMP0]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.floatud(i64 [[TMP3]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    ret <2 x double> [[TMP5]]
//
v2f64 floatudp(v2u64 v) {
  return __builtin_kvx_floatudp(v, 3, ".rn");
}

// CHECK-LABEL: @floatudq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.floatud(i64 [[TMP0]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <4 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.floatud(i64 [[TMP3]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <4 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = tail call double @llvm.kvx.floatud(i64 [[TMP6]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x double> [[TMP5]], double [[TMP7]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = tail call double @llvm.kvx.floatud(i64 [[TMP9]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x double> [[TMP8]], double [[TMP10]], i64 3
// CHECK-NEXT:    ret <4 x double> [[TMP11]]
//
v4f64 floatudq(v4u64 v) {
  return __builtin_kvx_floatudq(v, 3, ".rn");
}

// CHECK-LABEL: @fixedwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[V:%.*]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 fixedwp(v2f32 v) {
  return __builtin_kvx_fixedwp(v, 3, ".rn");
}

// CHECK-LABEL: @fixedwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[V:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP0]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x float> [[V]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP2]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4i32 fixedwq(v4f32 v) {
  return __builtin_kvx_fixedwq(v, 3, ".rn");
}

// CHECK-LABEL: @fixedwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP0]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP2]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP5]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x i32> [[TMP6]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[TMP4]], <8 x i32> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP9]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x i32> [[TMP10]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[TMP8]], <8 x i32> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP12]]
//
v8i32 fixedwo(v8f32 v) {
  return __builtin_kvx_fixedwo(v, 3, ".rn");
}

// CHECK-LABEL: @fixeddp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <2 x i64> [[V:%.*]] to <2 x double>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x double> [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP1]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x double> [[TMP0]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP4]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = bitcast <2 x i64> [[TMP6]] to <2 x double>
// CHECK-NEXT:    ret <2 x double> [[TMP7]]
//
v2f64 fixeddp(v2i64 v) {
  return __builtin_kvx_fixeddp(v, 3, ".rn");
}

// CHECK-LABEL: @fixeddq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <4 x i64> [[V:%.*]] to <4 x double>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x double> [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP1]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <4 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x double> [[TMP0]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP4]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <4 x i64> [[TMP3]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x double> [[TMP0]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP7]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> [[TMP6]], i64 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x double> [[TMP0]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP10]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i64> [[TMP9]], i64 [[TMP11]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = bitcast <4 x i64> [[TMP12]] to <4 x double>
// CHECK-NEXT:    ret <4 x double> [[TMP13]]
//
v4f64 fixeddq(v4i64 v) {
  return __builtin_kvx_fixeddq(v, 3, ".rn");
}

// CHECK-LABEL: @fixeduwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[V:%.*]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2u32 fixeduwp(v2f32 v) {
  return __builtin_kvx_fixeduwp(v, 3, ".rn");
}

// CHECK-LABEL: @fixeduwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[V:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP0]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x float> [[V]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP2]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4u32 fixeduwq(v4f32 v) {
  return __builtin_kvx_fixeduwq(v, 3, ".rn");
}

// CHECK-LABEL: @fixeduwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP0]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP2]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP5]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x i32> [[TMP6]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[TMP4]], <8 x i32> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP9]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x i32> [[TMP10]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[TMP8]], <8 x i32> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP12]]
//
v8u32 fixeduwo(v8f32 v) {
  return __builtin_kvx_fixeduwo(v, 3, ".rn");
}

// CHECK-LABEL: @fixedudp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <2 x i64> [[V:%.*]] to <2 x double>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x double> [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP1]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x double> [[TMP0]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP4]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = bitcast <2 x i64> [[TMP6]] to <2 x double>
// CHECK-NEXT:    ret <2 x double> [[TMP7]]
//
v2f64 fixedudp(v2u64 v) {
  return __builtin_kvx_fixedudp(v, 3, ".rn");
}

// CHECK-LABEL: @fixedudq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <4 x i64> [[V:%.*]] to <4 x double>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x double> [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP1]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <4 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x double> [[TMP0]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP4]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <4 x i64> [[TMP3]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x double> [[TMP0]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP7]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> [[TMP6]], i64 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x double> [[TMP0]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP10]], i64 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i64> [[TMP9]], i64 [[TMP11]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = bitcast <4 x i64> [[TMP12]] to <4 x double>
// CHECK-NEXT:    ret <4 x double> [[TMP13]]
//
v4f64 fixedudq(v4u64 v) {
  return __builtin_kvx_fixedudq(v, 3, ".rn");
}

// CHECK-LABEL: @fnarrowwhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x half> @llvm.kvx.fnarrowwhq(<4 x float> [[V:%.*]], i32 1, i32 1)
// CHECK-NEXT:    ret <4 x half> [[TMP0]]
//
v4f16 fnarrowwhq(v4f32 v) {
  return __builtin_kvx_fnarrowwhq(v, ".ru.s");
}

// CHECK-LABEL: @fnarrowwho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x half> @llvm.kvx.fnarrowwhq(<4 x float> [[TMP0]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x half> @llvm.kvx.fnarrowwhq(<4 x float> [[TMP2]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x half> [[TMP1]], <4 x half> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x half> [[TMP4]]
//
v8f16 fnarrowwho(v8f32 v) {
  return __builtin_kvx_fnarrowwho(v, ".ru.s");
}

// CHECK-LABEL: @fnarrowdwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fnarrowdwp(<2 x double> [[V:%.*]], i32 1, i32 1)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fnarrowdwp(v2f64 v){
  return __builtin_kvx_fnarrowdwp(v, ".ru.s");
}

// CHECK-LABEL: @fnarrowdwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.fnarrowdwp(<2 x double> [[TMP0]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x double> [[V]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.fnarrowdwp(<2 x double> [[TMP2]], i32 1, i32 1)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x float> [[TMP4]]
//
v4f32 fnarrowdwq(v4f64 v){
  return __builtin_kvx_fnarrowdwq(v, ".ru.s");
}
