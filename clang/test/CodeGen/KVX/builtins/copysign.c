// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple kvx-kalray-cos -target-cpu kv3-1 -O1 -emit-llvm -o - %s | FileCheck %s
// RUN: %clang_cc1 -triple kvx-kalray-cos -target-cpu kv3-2 -O1 -emit-llvm -o - %s | FileCheck %s

#include "vector-types.h"

// CHECK-LABEL: @copysignd(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call double @llvm.copysign.f64(double [[LHS:%.*]], double [[RHS:%.*]])
// CHECK-NEXT:    ret double [[TMP0]]
//
double copysignd(double lhs, double rhs) {
  return __builtin_kvx_copysignd(lhs, rhs);
}

// CHECK-LABEL: @copysignw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call float @llvm.copysign.f32(float [[LHS:%.*]], float [[RHS:%.*]])
// CHECK-NEXT:    ret float [[TMP0]]
//
float copysignw(float lhs, float rhs) {
  return __builtin_kvx_copysignw(lhs, rhs);
}

// CHECK-LABEL: @copysignh(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call half @llvm.copysign.f16(half [[LHS:%.*]], half [[RHS:%.*]])
// CHECK-NEXT:    ret half [[TMP0]]
//
_Float16 copysignh(_Float16 lhs, _Float16 rhs) {
  return __builtin_kvx_copysignh(lhs, rhs);
}

// CHECK-LABEL: @copysignhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x half> @llvm.copysign.v4f16(<4 x half> [[LHS:%.*]], <4 x half> [[RHS:%.*]])
// CHECK-NEXT:    ret <4 x half> [[TMP0]]
//
v4f16 copysignhq(v4f16 lhs, v4f16 rhs) {
  return __builtin_kvx_copysignhq(lhs, rhs);
}

// CHECK-LABEL: @copysignhp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x half> @llvm.copysign.v2f16(<2 x half> [[LHS:%.*]], <2 x half> [[RHS:%.*]])
// CHECK-NEXT:    ret <2 x half> [[TMP0]]
//
v2f16 copysignhp(v2f16 lhs, v2f16 rhs) {
  return __builtin_kvx_copysignhp(lhs, rhs);
}

// CHECK-LABEL: @copysignwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.copysign.v2f32(<2 x float> [[LHS:%.*]], <2 x float> [[RHS:%.*]])
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 copysignwp(v2f32 lhs, v2f32 rhs) {
  return __builtin_kvx_copysignwp(lhs, rhs);
}

// CHECK-LABEL: @copysigndp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x double> [[LHS:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x double> [[RHS:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call double @llvm.copysign.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x double> [[LHS]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x double> [[RHS]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call double @llvm.copysign.f64(double [[TMP3]], double [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x double> poison, double [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x double> [[TMP6]], double [[TMP5]], i64 1
// CHECK-NEXT:    ret <2 x double> [[TMP7]]
//
v2f64 copysigndp(v2f64 lhs, v2f64 rhs) {
  return __builtin_kvx_copysigndp(lhs, rhs);
}

// CHECK-LABEL: @copysigndq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x double> [[LHS:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x double> [[RHS:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call double @llvm.copysign.f64(double [[TMP0]], double [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x double> [[LHS]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x double> [[RHS]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call double @llvm.copysign.f64(double [[TMP3]], double [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x double> [[LHS]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x double> [[RHS]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call double @llvm.copysign.f64(double [[TMP6]], double [[TMP7]])
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x double> [[LHS]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x double> [[RHS]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call double @llvm.copysign.f64(double [[TMP9]], double [[TMP10]])
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x double> poison, double [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP13:%.*]] = insertelement <4 x double> [[TMP12]], double [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP14:%.*]] = insertelement <4 x double> [[TMP13]], double [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x double> [[TMP14]], double [[TMP11]], i64 3
// CHECK-NEXT:    ret <4 x double> [[TMP15]]
//
v4f64 copysigndq(v4f64 lhs, v4f64 rhs) {
  return __builtin_kvx_copysigndq(lhs, rhs);
}

// CHECK-LABEL: @copysignho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <8 x half> @llvm.copysign.v8f16(<8 x half> [[LHS:%.*]], <8 x half> [[RHS:%.*]])
// CHECK-NEXT:    ret <8 x half> [[TMP0]]
//
v8f16 copysignho(v8f16 lhs, v8f16 rhs) {
  return __builtin_kvx_copysignho(lhs, rhs);
}

// CHECK-LABEL: @copysignhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <16 x half> @llvm.copysign.v16f16(<16 x half> [[LHS:%.*]], <16 x half> [[RHS:%.*]])
// CHECK-NEXT:    ret <16 x half> [[TMP0]]
//
v16f16 copysignhx(v16f16 lhs, v16f16 rhs) {
  return __builtin_kvx_copysignhx(lhs, rhs);
}

// CHECK-LABEL: @copysignwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <8 x float> @llvm.copysign.v8f32(<8 x float> [[LHS:%.*]], <8 x float> [[RHS:%.*]])
// CHECK-NEXT:    ret <8 x float> [[TMP0]]
//
v8f32 copysignwo(v8f32 lhs, v8f32 rhs) {
  return __builtin_kvx_copysignwo(lhs, rhs);
}

// CHECK-LABEL: @copysignwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.copysign.v4f32(<4 x float> [[LHS:%.*]], <4 x float> [[RHS:%.*]])
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 copysignwq(v4f32 lhs, v4f32 rhs) {
  return __builtin_kvx_copysignwq(lhs, rhs);
}
