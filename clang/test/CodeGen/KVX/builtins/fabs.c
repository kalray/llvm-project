// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple kvx-kalray-cos -target-cpu kv3-1 -S -O2 -emit-llvm -o - %s | FileCheck %s
// RUN: %clang_cc1 -triple kvx-kalray-cos -target-cpu kv3-2 -S -O2 -emit-llvm -o - %s | FileCheck %s

#include "vector-types.h"

// CHECK-LABEL: @fabsw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call float @llvm.fabs.f32(float [[V:%.*]])
// CHECK-NEXT:    ret float [[TMP0]]
//
float fabsw(float v) {
  return __builtin_kvx_fabsw(v);
}

// CHECK-LABEL: @fabsd(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call double @llvm.fabs.f64(double [[V:%.*]])
// CHECK-NEXT:    ret double [[TMP0]]
//
double fabsd(double v) {
  return __builtin_kvx_fabsd(v);
}

// CHECK-LABEL: @fabsh(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call half @llvm.fabs.f16(half [[V:%.*]])
// CHECK-NEXT:    ret half [[TMP0]]
//
_Float16 fabsh(_Float16 v) {
  return __builtin_kvx_fabsh(v);
}

// CHECK-LABEL: @fabsho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x half> [[V:%.*]], <8 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x half> @llvm.fabs.v4f16(<4 x half> [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x half> [[V]], <8 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x half> @llvm.fabs.v4f16(<4 x half> [[TMP2]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x half> [[TMP1]], <4 x half> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x half> [[TMP4]]
//
v8f16 fabsho(v8f16 v) {
  return __builtin_kvx_fabsho(v);
}

// CHECK-LABEL: @fabshp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x half> @llvm.fabs.v2f16(<2 x half> [[V:%.*]])
// CHECK-NEXT:    ret <2 x half> [[TMP0]]
//
v2f16 fabshp(v2f16 v) {
  return __builtin_kvx_fabshp(v);
}

// CHECK-LABEL: @fabshq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x half> @llvm.fabs.v4f16(<4 x half> [[V:%.*]])
// CHECK-NEXT:    ret <4 x half> [[TMP0]]
//
v4f16 fabshq(v4f16 v) {
  return __builtin_kvx_fabshq(v);
}

// CHECK-LABEL: @fabshx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x half> [[V:%.*]], <16 x half> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x half> @llvm.fabs.v4f16(<4 x half> [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x half> [[V]], <16 x half> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x half> @llvm.fabs.v4f16(<4 x half> [[TMP2]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x half> [[V]], <16 x half> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x half> @llvm.fabs.v4f16(<4 x half> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <16 x half> [[V]], <16 x half> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x half> @llvm.fabs.v4f16(<4 x half> [[TMP6]])
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x half> [[TMP1]], <4 x half> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <4 x half> [[TMP5]], <4 x half> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <8 x half> [[TMP8]], <8 x half> [[TMP9]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    ret <16 x half> [[TMP10]]
//
v16f16 fabshx(v16f16 v) {
  return __builtin_kvx_fabshx(v);
}

// CHECK-LABEL: @fabswp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.fabs.v2f32(<2 x float> [[V:%.*]])
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fabswp(v2f32 v) {
  return __builtin_kvx_fabswp(v);
}

// CHECK-LABEL: @fabswq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[V:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.fabs.v2f32(<2 x float> [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x float> [[V]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.fabs.v2f32(<2 x float> [[TMP2]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x float> [[TMP4]]
//
v4f32 fabswq(v4f32 v) {
  return __builtin_kvx_fabswq(v);
}

// CHECK-LABEL: @fabswo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.fabs.v2f32(<2 x float> [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.fabs.v2f32(<2 x float> [[TMP2]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x float> @llvm.fabs.v2f32(<2 x float> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x float> @llvm.fabs.v2f32(<2 x float> [[TMP6]])
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <2 x float> [[TMP5]], <2 x float> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x float> [[TMP8]], <4 x float> [[TMP9]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP10]]
//
v8f32 fabswo(v8f32 v) {
  return __builtin_kvx_fabswo(v);
}

// CHECK-LABEL: @fabsdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x double> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.fabs.f64(double [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x double> [[V]], i64 1
// CHECK-NEXT:    [[TMP3:%.*]] = tail call double @llvm.fabs.f64(double [[TMP2]])
// CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x double> undef, double [[TMP1]], i32 0
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x double> [[TMP4]], double [[TMP3]], i32 1
// CHECK-NEXT:    ret <2 x double> [[TMP5]]
//
v2f64 fabsdp(v2f64 v) {
  return __builtin_kvx_fabsdp(v);
}

// CHECK-LABEL: @fabsdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x double> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.fabs.f64(double [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x double> [[V]], i64 1
// CHECK-NEXT:    [[TMP3:%.*]] = tail call double @llvm.fabs.f64(double [[TMP2]])
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x double> [[V]], i64 2
// CHECK-NEXT:    [[TMP5:%.*]] = tail call double @llvm.fabs.f64(double [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x double> [[V]], i64 3
// CHECK-NEXT:    [[TMP7:%.*]] = tail call double @llvm.fabs.f64(double [[TMP6]])
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x double> undef, double [[TMP1]], i32 0
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x double> [[TMP8]], double [[TMP3]], i32 1
// CHECK-NEXT:    [[TMP10:%.*]] = insertelement <4 x double> [[TMP9]], double [[TMP5]], i32 2
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x double> [[TMP10]], double [[TMP7]], i32 3
// CHECK-NEXT:    ret <4 x double> [[TMP11]]
//
v4f64 fabsdq(v4f64 v) {
  return __builtin_kvx_fabsdq(v);
}
