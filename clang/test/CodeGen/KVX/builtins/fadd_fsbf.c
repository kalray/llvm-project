// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple kvx-kalray-cos -S -O2 -emit-llvm -o - %s | FileCheck %s

#include <kvx_builtins.h>

#define half _Float16

// CHECK-LABEL: @faddd(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call double @llvm.kvx.fadd.f64(double [[LHS:%.*]], double [[RHS:%.*]], i32 3, i32 0)
// CHECK-NEXT:    ret double [[TMP0]]
//
double faddd(double lhs, double rhs) {  return __builtin_kvx_faddd(lhs, rhs, ".rz");}

// CHECK-LABEL: @fadddc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.faddc.v2f64(<2 x double> [[LHS:%.*]], <2 x double> [[RHS:%.*]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
__kvx_v2df fadddc(__kvx_v2df lhs, __kvx_v2df rhs) {  return __builtin_kvx_fadddc(lhs, rhs, ".c.rn");}

// CHECK-LABEL: @fadddcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[LHS:%.*]], <4 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[RHS:%.*]], <4 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.faddc.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[LHS]], <4 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[RHS]], <4 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.faddc.v2f64(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
__kvx_v4df fadddcp(__kvx_v4df lhs, __kvx_v4df rhs) {  return __builtin_kvx_fadddcp(lhs, rhs, ".c.rn");}

// CHECK-LABEL: @fadddcq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[LHS:%.*]] = load <8 x double>, ptr [[TMP0:%.*]], align 32, !tbaa [[TBAA2:![0-9]+]]
// CHECK-NEXT:    [[RHS:%.*]] = load <8 x double>, ptr [[TMP1:%.*]], align 32, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x double> [[LHS]], <8 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x double> [[RHS]], <8 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP4:%.*]] = tail call <2 x double> @llvm.kvx.faddc.v2f64(<2 x double> [[TMP2]], <2 x double> [[TMP3]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x double> [[LHS]], <8 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x double> [[RHS]], <8 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x double> @llvm.kvx.faddc.v2f64(<2 x double> [[TMP5]], <2 x double> [[TMP6]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x double> [[TMP4]], <2 x double> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[SHUFFLE8:%.*]] = shufflevector <8 x double> [[LHS]], <8 x double> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <4 x double> [[SHUFFLE8]], <4 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[SHUFFLE10:%.*]] = shufflevector <8 x double> [[RHS]], <8 x double> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x double> [[SHUFFLE10]], <4 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP11:%.*]] = tail call <2 x double> @llvm.kvx.faddc.v2f64(<2 x double> [[TMP9]], <2 x double> [[TMP10]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <4 x double> [[SHUFFLE8]], <4 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <4 x double> [[SHUFFLE10]], <4 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x double> @llvm.kvx.faddc.v2f64(<2 x double> [[TMP12]], <2 x double> [[TMP13]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x double> [[TMP11]], <2 x double> [[TMP14]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[SHUFFLE16:%.*]] = shufflevector <4 x double> [[TMP8]], <4 x double> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    store <8 x double> [[SHUFFLE16]], ptr [[AGG_RESULT:%.*]], align 32, !tbaa [[TBAA2]]
// CHECK-NEXT:    ret void
//
__kvx_v8df fadddcq(__kvx_v8df lhs, __kvx_v8df rhs) {  return __builtin_kvx_fadddcq(lhs, rhs, ".c.rn");}

// __kvx_v8df fadddcq(__kvx_v8df lhs, __kvx_v8df rhs) {  return __builtin_kvx_fadddcq(lhs, rhs, ".c.rn");}

// CHECK-LABEL: @fadddp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fadd.v2f64(<2 x double> [[LHS:%.*]], <2 x double> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
__kvx_v2df fadddp(__kvx_v2df lhs, __kvx_v2df rhs) {  return __builtin_kvx_fadddp(lhs, rhs, ".rn");}

// CHECK-LABEL: @fadddq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[LHS:%.*]], <4 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[RHS:%.*]], <4 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fadd.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[LHS]], <4 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[RHS]], <4 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fadd.v2f64(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
__kvx_v4df fadddq(__kvx_v4df lhs, __kvx_v4df rhs) {  return __builtin_kvx_fadddq(lhs, rhs, ".rn");}

// CHECK-LABEL: @faddh(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call half @llvm.kvx.fadd.f16(half [[LHS:%.*]], half [[RHS:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret half [[TMP0]]
//
half faddh(half lhs, half rhs) {  return __builtin_kvx_faddh(lhs, rhs, ".s");}

// CHECK-LABEL: @faddhp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x half> @llvm.kvx.fadd.v2f16(<2 x half> [[LHS:%.*]], <2 x half> [[RHS:%.*]], i32 3, i32 1)
// CHECK-NEXT:    ret <2 x half> [[TMP0]]
//
__kvx_v2hf faddhp(__kvx_v2hf lhs, __kvx_v2hf rhs) {  return __builtin_kvx_faddhp(lhs, rhs, ".rz.s");}

// CHECK-LABEL: @faddhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x half> @llvm.kvx.fadd.v4f16(<4 x half> [[LHS:%.*]], <4 x half> [[RHS:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret <4 x half> [[TMP0]]
//
__kvx_v4hf faddhq(__kvx_v4hf lhs, __kvx_v4hf rhs) {  return __builtin_kvx_faddhq(lhs, rhs, ".s");}

// CHECK-LABEL: @faddw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call float @llvm.kvx.fadd.f32(float [[LHS:%.*]], float [[RHS:%.*]], i32 3, i32 0)
// CHECK-NEXT:    ret float [[TMP0]]
//
float faddw(float lhs, float rhs) {  return __builtin_kvx_faddw(lhs, rhs, ".rz");}

// CHECK-LABEL: @faddwc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.faddc.v2f32(<2 x float> [[LHS:%.*]], <2 x float> [[RHS:%.*]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
__kvx_v2sf faddwc(__kvx_v2sf lhs, __kvx_v2sf rhs) {  return __builtin_kvx_faddwc(lhs, rhs, ".c.rn");}

// CHECK-LABEL: @faddwcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.faddc.v4f32(<4 x float> [[LHS:%.*]], <4 x float> [[RHS:%.*]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
__kvx_v4sf faddwcp(__kvx_v4sf lhs, __kvx_v4sf rhs) {  return __builtin_kvx_faddwcp(lhs, rhs, ".c.rn");}

// CHECK-LABEL: @faddwcq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[LHS:%.*]], <8 x float> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[RHS:%.*]], <8 x float> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.faddc.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[LHS]], <8 x float> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[RHS]], <8 x float> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.faddc.v4f32(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
__kvx_v8sf faddwcq(__kvx_v8sf lhs, __kvx_v8sf rhs) {  return __builtin_kvx_faddwcq(lhs, rhs, ".c.rn");}

// CHECK-LABEL: @faddwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[LHS:%.*]], <8 x float> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[RHS:%.*]], <8 x float> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fadd.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[LHS]], <8 x float> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[RHS]], <8 x float> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fadd.v4f32(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
__kvx_v8sf faddwo(__kvx_v8sf lhs, __kvx_v8sf rhs) {  return __builtin_kvx_faddwo(lhs, rhs, ".rn");}

// CHECK-LABEL: @faddwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fadd.v2f32(<2 x float> [[LHS:%.*]], <2 x float> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
__kvx_v2sf faddwp(__kvx_v2sf lhs, __kvx_v2sf rhs) {  return __builtin_kvx_faddwp(lhs, rhs, ".rn");}

// CHECK-LABEL: @faddwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fadd.v4f32(<4 x float> [[LHS:%.*]], <4 x float> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
__kvx_v4sf faddwq(__kvx_v4sf lhs, __kvx_v4sf rhs) {  return __builtin_kvx_faddwq(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfd(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call double @llvm.kvx.fsbf.f64(double [[LHS:%.*]], double [[RHS:%.*]], i32 3, i32 0)
// CHECK-NEXT:    ret double [[TMP0]]
//
double fsbfd(double lhs, double rhs) {  return __builtin_kvx_fsbfd(lhs, rhs, ".rz");}

// CHECK-LABEL: @fsbfdc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fsbfc.v2f64(<2 x double> [[LHS:%.*]], <2 x double> [[RHS:%.*]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
__kvx_v2df fsbfdc(__kvx_v2df lhs, __kvx_v2df rhs) {  return __builtin_kvx_fsbfdc(lhs, rhs, ".c.rn");}

// CHECK-LABEL: @fsbfdcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[LHS:%.*]], <4 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[RHS:%.*]], <4 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fsbfc.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[LHS]], <4 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[RHS]], <4 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fsbfc.v2f64(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
__kvx_v4df fsbfdcp(__kvx_v4df lhs, __kvx_v4df rhs) {  return __builtin_kvx_fsbfdcp(lhs, rhs, ".c.rn");}

// CHECK-LABEL: @fsbfdcq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[LHS:%.*]] = load <8 x double>, ptr [[TMP0:%.*]], align 32, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[RHS:%.*]] = load <8 x double>, ptr [[TMP1:%.*]], align 32, !tbaa [[TBAA2]]
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x double> [[LHS]], <8 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x double> [[RHS]], <8 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP4:%.*]] = tail call <2 x double> @llvm.kvx.fsbfc.v2f64(<2 x double> [[TMP2]], <2 x double> [[TMP3]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x double> [[LHS]], <8 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x double> [[RHS]], <8 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x double> @llvm.kvx.fsbfc.v2f64(<2 x double> [[TMP5]], <2 x double> [[TMP6]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x double> [[TMP4]], <2 x double> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[SHUFFLE8:%.*]] = shufflevector <8 x double> [[LHS]], <8 x double> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <4 x double> [[SHUFFLE8]], <4 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[SHUFFLE10:%.*]] = shufflevector <8 x double> [[RHS]], <8 x double> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x double> [[SHUFFLE10]], <4 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP11:%.*]] = tail call <2 x double> @llvm.kvx.fsbfc.v2f64(<2 x double> [[TMP9]], <2 x double> [[TMP10]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <4 x double> [[SHUFFLE8]], <4 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <4 x double> [[SHUFFLE10]], <4 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x double> @llvm.kvx.fsbfc.v2f64(<2 x double> [[TMP12]], <2 x double> [[TMP13]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x double> [[TMP11]], <2 x double> [[TMP14]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[SHUFFLE16:%.*]] = shufflevector <4 x double> [[TMP8]], <4 x double> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    store <8 x double> [[SHUFFLE16]], ptr [[AGG_RESULT:%.*]], align 32, !tbaa [[TBAA2]]
// CHECK-NEXT:    ret void
//
__kvx_v8df fsbfdcq(__kvx_v8df lhs, __kvx_v8df rhs) {  return __builtin_kvx_fsbfdcq(lhs, rhs, ".c.rn");}

// CHECK-LABEL: @fsbfdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fsbf.v2f64(<2 x double> [[LHS:%.*]], <2 x double> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
__kvx_v2df fsbfdp(__kvx_v2df lhs, __kvx_v2df rhs) {  return __builtin_kvx_fsbfdp(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfdc2(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fsbfc.v2f64(<2 x double> [[LHS:%.*]], <2 x double> [[RHS:%.*]], i32 0, i32 0, i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
__kvx_v2df fsbfdc2(__kvx_v2df lhs, __kvx_v2df rhs) {  return __builtin_kvx_fsbfdc(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[LHS:%.*]], <4 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[RHS:%.*]], <4 x double> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fsbf.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[LHS]], <4 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[RHS]], <4 x double> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fsbf.v2f64(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
__kvx_v4df fsbfdq(__kvx_v4df lhs, __kvx_v4df rhs) {  return __builtin_kvx_fsbfdq(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfh(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call half @llvm.kvx.fsbf.f16(half [[LHS:%.*]], half [[RHS:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret half [[TMP0]]
//
half fsbfh(half lhs, half rhs) {  return __builtin_kvx_fsbfh(lhs, rhs, ".s");}

// CHECK-LABEL: @fsbfhp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x half> @llvm.kvx.fsbf.v2f16(<2 x half> [[LHS:%.*]], <2 x half> [[RHS:%.*]], i32 3, i32 1)
// CHECK-NEXT:    ret <2 x half> [[TMP0]]
//
__kvx_v2hf fsbfhp(__kvx_v2hf lhs, __kvx_v2hf rhs) {  return __builtin_kvx_fsbfhp(lhs, rhs, ".rz.s");}

// CHECK-LABEL: @fsbfhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x half> @llvm.kvx.fsbf.v4f16(<4 x half> [[LHS:%.*]], <4 x half> [[RHS:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret <4 x half> [[TMP0]]
//
__kvx_v4hf fsbfhq(__kvx_v4hf lhs, __kvx_v4hf rhs) {  return __builtin_kvx_fsbfhq(lhs, rhs, ".s");}

// CHECK-LABEL: @fsbfw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call float @llvm.kvx.fsbf.f32(float [[LHS:%.*]], float [[RHS:%.*]], i32 3, i32 0)
// CHECK-NEXT:    ret float [[TMP0]]
//
float fsbfw(float lhs, float rhs) {  return __builtin_kvx_fsbfw(lhs, rhs, ".rz");}

// CHECK-LABEL: @fsbfwc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fsbfc.v2f32(<2 x float> [[LHS:%.*]], <2 x float> [[RHS:%.*]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
__kvx_v2sf fsbfwc(__kvx_v2sf lhs, __kvx_v2sf rhs) {  return __builtin_kvx_fsbfwc(lhs, rhs, ".c.rn");}

// CHECK-LABEL: @fsbfwcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fsbfc.v4f32(<4 x float> [[LHS:%.*]], <4 x float> [[RHS:%.*]], i32 1, i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
__kvx_v4sf fsbfwcp(__kvx_v4sf lhs, __kvx_v4sf rhs) {  return __builtin_kvx_fsbfwcp(lhs, rhs, ".c.rn");}

// CHECK-LABEL: @fsbfwcq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[LHS:%.*]], <8 x float> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[RHS:%.*]], <8 x float> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fsbfc.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 1, i32 0, i32 1)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[LHS]], <8 x float> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[RHS]], <8 x float> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fsbfc.v4f32(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 1, i32 0, i32 1)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
__kvx_v8sf fsbfwcq(__kvx_v8sf lhs, __kvx_v8sf rhs) {  return __builtin_kvx_fsbfwcq(lhs, rhs, ".c.rn.s");}

// CHECK-LABEL: @fsbfwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[LHS:%.*]], <8 x float> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[RHS:%.*]], <8 x float> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fsbf.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[LHS]], <8 x float> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[RHS]], <8 x float> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fsbf.v4f32(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
__kvx_v8sf fsbfwo(__kvx_v8sf lhs, __kvx_v8sf rhs) {  return __builtin_kvx_fsbfwo(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fsbf.v2f32(<2 x float> [[LHS:%.*]], <2 x float> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
__kvx_v2sf fsbfwp(__kvx_v2sf lhs, __kvx_v2sf rhs) {  return __builtin_kvx_fsbfwp(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fsbf.v4f32(<4 x float> [[LHS:%.*]], <4 x float> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
__kvx_v4sf fsbfwq(__kvx_v4sf lhs, __kvx_v4sf rhs) {  return __builtin_kvx_fsbfwq(lhs, rhs, ".rn");}
