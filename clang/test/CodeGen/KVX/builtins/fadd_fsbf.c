// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple kvx-kalray-cos -S -O2 -emit-llvm -o - %s | FileCheck %s

#include "vector-types.h"
// CHECK-LABEL: @faddd(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call double @llvm.kvx.fadd.f64(double [[LHS:%.*]], double [[RHS:%.*]], i32 3, i32 0)
// CHECK-NEXT:    ret double [[TMP0]]
//
double faddd(double lhs, double rhs) {  return __builtin_kvx_faddd(lhs, rhs, ".rz");}

// CHECK-LABEL: @fadddc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.faddc.v2f64(<2 x double> [[LHS:%.*]], <2 x double> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 fadddc(v2f64 lhs, v2f64 rhs) {  return __builtin_kvx_fadddc(lhs, rhs, ".rn");}

// CHECK-LABEL: @fadddp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fadd.v2f64(<2 x double> [[LHS:%.*]], <2 x double> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 fadddp(v2f64 lhs, v2f64 rhs) {  return __builtin_kvx_fadddp(lhs, rhs, ".rn");}

// CHECK-LABEL: @fadddq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[LHS:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[RHS:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fadd.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[LHS]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[RHS]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fadd.v2f64(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
v4f64 fadddq(v4f64 lhs, v4f64 rhs) {  return __builtin_kvx_fadddq(lhs, rhs, ".rn");}

// CHECK-LABEL: @faddh(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call half @llvm.kvx.fadd.f16(half [[LHS:%.*]], half [[RHS:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret half [[TMP0]]
//
half faddh(half lhs, half rhs) {  return __builtin_kvx_faddh(lhs, rhs, ".s");}

// CHECK-LABEL: @faddhp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x half> @llvm.kvx.fadd.v2f16(<2 x half> [[LHS:%.*]], <2 x half> [[RHS:%.*]], i32 3, i32 1)
// CHECK-NEXT:    ret <2 x half> [[TMP0]]
//
v2f16 faddhp(v2f16 lhs, v2f16 rhs) {  return __builtin_kvx_faddhp(lhs, rhs, ".rz.s");}

// CHECK-LABEL: @faddhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x half> @llvm.kvx.fadd.v4f16(<4 x half> [[LHS:%.*]], <4 x half> [[RHS:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret <4 x half> [[TMP0]]
//
v4f16 faddhq(v4f16 lhs, v4f16 rhs) {  return __builtin_kvx_faddhq(lhs, rhs, ".s");}

// CHECK-LABEL: @faddw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call float @llvm.kvx.fadd.f32(float [[LHS:%.*]], float [[RHS:%.*]], i32 3, i32 0)
// CHECK-NEXT:    ret float [[TMP0]]
//
float faddw(float lhs, float rhs) {  return __builtin_kvx_faddw(lhs, rhs, ".rz");}

// CHECK-LABEL: @faddwc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.faddc.v2f32(<2 x float> [[LHS:%.*]], <2 x float> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 faddwc(v2f32 lhs, v2f32 rhs) {  return __builtin_kvx_faddwc(lhs, rhs, ".rn");}

// CHECK-LABEL: @faddwcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.faddc.v4f32(<4 x float> [[LHS:%.*]], <4 x float> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 faddwcp(v4f32 lhs, v4f32 rhs) {  return __builtin_kvx_faddwcp(lhs, rhs, ".rn");}

// CHECK-LABEL: @faddwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[LHS:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[RHS:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fadd.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[LHS]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[RHS]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fadd.v4f32(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
v8f32 faddwo(v8f32 lhs, v8f32 rhs) {  return __builtin_kvx_faddwo(lhs, rhs, ".rn");}

// CHECK-LABEL: @faddwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fadd.v2f32(<2 x float> [[LHS:%.*]], <2 x float> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 faddwp(v2f32 lhs, v2f32 rhs) {  return __builtin_kvx_faddwp(lhs, rhs, ".rn");}

// CHECK-LABEL: @faddwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fadd.v4f32(<4 x float> [[LHS:%.*]], <4 x float> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 faddwq(v4f32 lhs, v4f32 rhs) {  return __builtin_kvx_faddwq(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfd(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call double @llvm.kvx.fsbf.f64(double [[LHS:%.*]], double [[RHS:%.*]], i32 3, i32 0)
// CHECK-NEXT:    ret double [[TMP0]]
//
double fsbfd(double lhs, double rhs) {  return __builtin_kvx_fsbfd(lhs, rhs, ".rz");}

// CHECK-LABEL: @fsbfdc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fsbfc.v2f64(<2 x double> [[LHS:%.*]], <2 x double> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 fsbfdc(v2f64 lhs, v2f64 rhs) {  return __builtin_kvx_fsbfdc(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fsbf.v2f64(<2 x double> [[LHS:%.*]], <2 x double> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 fsbfdp(v2f64 lhs, v2f64 rhs) {  return __builtin_kvx_fsbfdp(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[LHS:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[RHS:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fsbf.v2f64(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[LHS]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[RHS]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fsbf.v2f64(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
v4f64 fsbfdq(v4f64 lhs, v4f64 rhs) {  return __builtin_kvx_fsbfdq(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfh(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call half @llvm.kvx.fsbf.f16(half [[LHS:%.*]], half [[RHS:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret half [[TMP0]]
//
half fsbfh(half lhs, half rhs) {  return __builtin_kvx_fsbfh(lhs, rhs, ".s");}

// CHECK-LABEL: @fsbfhp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x half> @llvm.kvx.fsbf.v2f16(<2 x half> [[LHS:%.*]], <2 x half> [[RHS:%.*]], i32 3, i32 1)
// CHECK-NEXT:    ret <2 x half> [[TMP0]]
//
v2f16 fsbfhp(v2f16 lhs, v2f16 rhs) {  return __builtin_kvx_fsbfhp(lhs, rhs, ".rz.s");}

// CHECK-LABEL: @fsbfhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x half> @llvm.kvx.fsbf.v4f16(<4 x half> [[LHS:%.*]], <4 x half> [[RHS:%.*]], i32 7, i32 1)
// CHECK-NEXT:    ret <4 x half> [[TMP0]]
//
v4f16 fsbfhq(v4f16 lhs, v4f16 rhs) {  return __builtin_kvx_fsbfhq(lhs, rhs, ".s");}

// CHECK-LABEL: @fsbfw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call float @llvm.kvx.fsbf.f32(float [[LHS:%.*]], float [[RHS:%.*]], i32 3, i32 0)
// CHECK-NEXT:    ret float [[TMP0]]
//
float fsbfw(float lhs, float rhs) {  return __builtin_kvx_fsbfw(lhs, rhs, ".rz");}

// CHECK-LABEL: @fsbfwc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fsbfc.v2f32(<2 x float> [[LHS:%.*]], <2 x float> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fsbfwc(v2f32 lhs, v2f32 rhs) {  return __builtin_kvx_fsbfwc(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfwcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fsbfc.v4f32(<4 x float> [[LHS:%.*]], <4 x float> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fsbfwcp(v4f32 lhs, v4f32 rhs) {  return __builtin_kvx_fsbfwcp(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[LHS:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[RHS:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fsbf.v4f32(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[LHS]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[RHS]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fsbf.v4f32(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
v8f32 fsbfwo(v8f32 lhs, v8f32 rhs) {  return __builtin_kvx_fsbfwo(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fsbf.v2f32(<2 x float> [[LHS:%.*]], <2 x float> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fsbfwp(v2f32 lhs, v2f32 rhs) {  return __builtin_kvx_fsbfwp(lhs, rhs, ".rn");}

// CHECK-LABEL: @fsbfwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fsbf.v4f32(<4 x float> [[LHS:%.*]], <4 x float> [[RHS:%.*]], i32 0, i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fsbfwq(v4f32 lhs, v4f32 rhs) {  return __builtin_kvx_fsbfwq(lhs, rhs, ".rn");}
