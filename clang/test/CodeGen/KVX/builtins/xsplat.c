// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -O2 -triple kvx-kalray-cos -S -emit-llvm -target-cpu kv3-1 -o - -x c %s | FileCheck %s
// RUN: %clang_cc1 -O2 -triple kvx-kalray-cos -S -emit-llvm -target-cpu kv3-2 -o - -x c %s | FileCheck %s

// CHECK-LABEL: @xsplat256rr(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <256 x i1> @llvm.kvx.xsplat.v256i1(i64 [[C:%.*]])
// CHECK-NEXT:    store <256 x i1> [[TMP0]], <256 x i1>* [[V:%.*]], align 32, [[TBAA2:!tbaa !.*]]
// CHECK-NEXT:    ret void
//
void xsplat256rr(__kvx_x256 *v, long c) {
  *v = __builtin_kvx_xsplatd256(c);
}

// CHECK-LABEL: @xsplat256ri16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <256 x i1> @llvm.kvx.xsplat.v256i1(i64 32767)
// CHECK-NEXT:    store <256 x i1> [[TMP0]], <256 x i1>* [[V:%.*]], align 32, [[TBAA2]]
// CHECK-NEXT:    ret void
//
void xsplat256ri16(__kvx_x256 *v, long c) {
  *v = __builtin_kvx_xsplatd256(32767UL);
}

// CHECK-LABEL: @xsplat256ri37(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <256 x i1> @llvm.kvx.xsplat.v256i1(i64 32768)
// CHECK-NEXT:    store <256 x i1> [[TMP0]], <256 x i1>* [[V:%.*]], align 32, [[TBAA2]]
// CHECK-NEXT:    ret void
//
void xsplat256ri37(__kvx_x256 *v, long c) {
  *v = __builtin_kvx_xsplatd256(32768UL);
}

// CHECK-LABEL: @xsplat256ri64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <256 x i1> @llvm.kvx.xsplat.v256i1(i64 8796093022208)
// CHECK-NEXT:    store <256 x i1> [[TMP0]], <256 x i1>* [[V:%.*]], align 32, [[TBAA2]]
// CHECK-NEXT:    ret void
//
void xsplat256ri64(__kvx_x256 *v, long c) {
  *v = __builtin_kvx_xsplatd256(8796093022208UL);
}

// CHECK-LABEL: @xsplat512rr(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <512 x i1> @llvm.kvx.xsplat.v512i1(i64 [[C:%.*]])
// CHECK-NEXT:    store <512 x i1> [[TMP0]], <512 x i1>* [[V:%.*]], align 32, [[TBAA6:!tbaa !.*]]
// CHECK-NEXT:    ret void
//
void xsplat512rr(__kvx_x512 *v, long c) {
  *v = __builtin_kvx_xsplatd512(c);
}

// CHECK-LABEL: @xsplat512ri16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <512 x i1> @llvm.kvx.xsplat.v512i1(i64 32767)
// CHECK-NEXT:    store <512 x i1> [[TMP0]], <512 x i1>* [[V:%.*]], align 32, [[TBAA6]]
// CHECK-NEXT:    ret void
//
void xsplat512ri16(__kvx_x512 *v, long c) {
  *v = __builtin_kvx_xsplatd512(32767UL);
}

// CHECK-LABEL: @xsplat512ri37(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <512 x i1> @llvm.kvx.xsplat.v512i1(i64 32768)
// CHECK-NEXT:    store <512 x i1> [[TMP0]], <512 x i1>* [[V:%.*]], align 32, [[TBAA6]]
// CHECK-NEXT:    ret void
//
void xsplat512ri37(__kvx_x512 *v, long c) {
  *v = __builtin_kvx_xsplatd512(32768UL);
}

// CHECK-LABEL: @xsplat512ri64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <512 x i1> @llvm.kvx.xsplat.v512i1(i64 8796093022208)
// CHECK-NEXT:    store <512 x i1> [[TMP0]], <512 x i1>* [[V:%.*]], align 32, [[TBAA6]]
// CHECK-NEXT:    ret void
//
void xsplat512ri64(__kvx_x512 *v, long c) {
  *v = __builtin_kvx_xsplatd512(8796093022208UL);
}

// CHECK-LABEL: @xsplat1024rr(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <1024 x i1> @llvm.kvx.xsplat.v1024i1(i64 [[C:%.*]])
// CHECK-NEXT:    store <1024 x i1> [[TMP0]], <1024 x i1>* [[V:%.*]], align 32, [[TBAA8:!tbaa !.*]]
// CHECK-NEXT:    ret void
//
void xsplat1024rr(__kvx_x1024 *v, long c) {
  *v = __builtin_kvx_xsplatd1024(c);
}

// CHECK-LABEL: @xsplat1024ri16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <1024 x i1> @llvm.kvx.xsplat.v1024i1(i64 32767)
// CHECK-NEXT:    store <1024 x i1> [[TMP0]], <1024 x i1>* [[V:%.*]], align 32, [[TBAA8]]
// CHECK-NEXT:    ret void
//
void xsplat1024ri16(__kvx_x1024 *v, long c) {
  *v = __builtin_kvx_xsplatd1024(32767UL);
}

// CHECK-LABEL: @xsplat1024ri37(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <1024 x i1> @llvm.kvx.xsplat.v1024i1(i64 32768)
// CHECK-NEXT:    store <1024 x i1> [[TMP0]], <1024 x i1>* [[V:%.*]], align 32, [[TBAA8]]
// CHECK-NEXT:    ret void
//
void xsplat1024ri37(__kvx_x1024 *v, long c) {
  *v = __builtin_kvx_xsplatd1024(32768UL);
}

// CHECK-LABEL: @xsplat1024ri64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <1024 x i1> @llvm.kvx.xsplat.v1024i1(i64 8796093022208)
// CHECK-NEXT:    store <1024 x i1> [[TMP0]], <1024 x i1>* [[V:%.*]], align 32, [[TBAA8]]
// CHECK-NEXT:    ret void
//
void xsplat1024ri64(__kvx_x1024 *v, long c) {
  *v = __builtin_kvx_xsplatd1024(8796093022208UL);
}

// CHECK-LABEL: @xsplat2048rr(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2048 x i1> @llvm.kvx.xsplat.v2048i1(i64 [[C:%.*]])
// CHECK-NEXT:    store <2048 x i1> [[TMP0]], <2048 x i1>* [[V:%.*]], align 32, [[TBAA10:!tbaa !.*]]
// CHECK-NEXT:    ret void
//
void xsplat2048rr(__kvx_x2048 *v, long c) {
  *v = __builtin_kvx_xsplatd2048(c);
}

// CHECK-LABEL: @xsplat2048ri16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2048 x i1> @llvm.kvx.xsplat.v2048i1(i64 32767)
// CHECK-NEXT:    store <2048 x i1> [[TMP0]], <2048 x i1>* [[V:%.*]], align 32, [[TBAA10]]
// CHECK-NEXT:    ret void
//
void xsplat2048ri16(__kvx_x2048 *v, long c) {
  *v = __builtin_kvx_xsplatd2048(32767UL);
}

// CHECK-LABEL: @xsplat2048ri37(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2048 x i1> @llvm.kvx.xsplat.v2048i1(i64 32768)
// CHECK-NEXT:    store <2048 x i1> [[TMP0]], <2048 x i1>* [[V:%.*]], align 32, [[TBAA10]]
// CHECK-NEXT:    ret void
//
void xsplat2048ri37(__kvx_x2048 *v, long c) {
  *v = __builtin_kvx_xsplatd2048(32768UL);
}

// CHECK-LABEL: @xsplat2048ri64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2048 x i1> @llvm.kvx.xsplat.v2048i1(i64 8796093022208)
// CHECK-NEXT:    store <2048 x i1> [[TMP0]], <2048 x i1>* [[V:%.*]], align 32, [[TBAA10]]
// CHECK-NEXT:    ret void
//
void xsplat2048ri64(__kvx_x2048 *v, long c) {
  *v = __builtin_kvx_xsplatd2048(8796093022208UL);
}

// CHECK-LABEL: @xsplat4096rr(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4096 x i1> @llvm.kvx.xsplat.v4096i1(i64 [[C:%.*]])
// CHECK-NEXT:    store <4096 x i1> [[TMP0]], <4096 x i1>* [[V:%.*]], align 32, [[TBAA12:!tbaa !.*]]
// CHECK-NEXT:    ret void
//
void xsplat4096rr(__kvx_x4096 *v, long c) {
  *v = __builtin_kvx_xsplatd4096(c);
}

// CHECK-LABEL: @xsplat4096ri16(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4096 x i1> @llvm.kvx.xsplat.v4096i1(i64 32767)
// CHECK-NEXT:    store <4096 x i1> [[TMP0]], <4096 x i1>* [[V:%.*]], align 32, [[TBAA12]]
// CHECK-NEXT:    ret void
//
void xsplat4096ri16(__kvx_x4096 *v, long c) {
  *v = __builtin_kvx_xsplatd4096(32767UL);
}

// CHECK-LABEL: @xsplat4096ri37(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4096 x i1> @llvm.kvx.xsplat.v4096i1(i64 32768)
// CHECK-NEXT:    store <4096 x i1> [[TMP0]], <4096 x i1>* [[V:%.*]], align 32, [[TBAA12]]
// CHECK-NEXT:    ret void
//
void xsplat4096ri37(__kvx_x4096 *v, long c) {
  *v = __builtin_kvx_xsplatd4096(32768UL);
}

// CHECK-LABEL: @xsplat4096ri64(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4096 x i1> @llvm.kvx.xsplat.v4096i1(i64 8796093022208)
// CHECK-NEXT:    store <4096 x i1> [[TMP0]], <4096 x i1>* [[V:%.*]], align 32, [[TBAA12]]
// CHECK-NEXT:    ret void
//
void xsplat4096ri64(__kvx_x4096 *v, long c) {
  *v = __builtin_kvx_xsplatd4096(8796093022208UL);
}
