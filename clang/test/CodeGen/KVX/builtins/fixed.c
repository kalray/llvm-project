// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple kvx-kalray-cos -S -O2 -emit-llvm -o - %s | FileCheck %s
#include "vector-types.h"

// CHECK-LABEL: @fixedw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.fixedw(float [[X:%.*]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    ret i32 [[TMP0]]
//
int fixedw(float x) {
  return __builtin_kvx_fixedw(x, 3, ".rn");
}

// CHECK-LABEL: @fixedd(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[X:%.*]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    ret i64 [[TMP0]]
//
long fixedd(double x) {
  return __builtin_kvx_fixedd(x, 3, ".rn");
}

// CHECK-LABEL: @fixedw_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.fixedw(float [[X:%.*]], i32 3, i32 0, i32 1)
// CHECK-NEXT:    ret i32 [[TMP0]]
//
int fixedw_s(float x) {
  return __builtin_kvx_fixedw(x, 3, ".rn.s");
}

// CHECK-LABEL: @fixedd_s(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[X:%.*]], i32 3, i32 0, i32 1)
// CHECK-NEXT:    ret i64 [[TMP0]]
//
long fixedd_s(double x) {
  return __builtin_kvx_fixedd(x, 3, ".rn.s");
}

// CHECK-LABEL: @fixedw_s_only(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.fixedw(float [[X:%.*]], i32 3, i32 7, i32 1)
// CHECK-NEXT:    ret i32 [[TMP0]]
//
int fixedw_s_only(float x) {
  return __builtin_kvx_fixedw(x, 3, ".s");
}

// CHECK-LABEL: @fixedd_s_only(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[X:%.*]], i32 3, i32 7, i32 1)
// CHECK-NEXT:    ret i64 [[TMP0]]
//
long fixedd_s_only(double x) {
  return __builtin_kvx_fixedd(x, 3, ".s");
}

// CHECK-LABEL: @fixeduw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.fixeduw(float [[X:%.*]], i32 3, i32 3, i32 0)
// CHECK-NEXT:    ret i32 [[TMP0]]
//
unsigned int fixeduw(float x) {
  return __builtin_kvx_fixeduw(x, 3, ".rz");
}

// CHECK-LABEL: @fixedud(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[X:%.*]], i32 3, i32 3, i32 0)
// CHECK-NEXT:    ret i64 [[TMP0]]
//
unsigned long fixedud(double x) {
  return __builtin_kvx_fixedud(x, 3, ".rz");
}

// CHECK-LABEL: @fixeddp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <2 x i64> [[V:%.*]] to <2 x double>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x double> [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP1]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x double> [[TMP0]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP3]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> [[TMP5]], i64 [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = bitcast <2 x i64> [[TMP6]] to <2 x double>
// CHECK-NEXT:    ret <2 x double> [[TMP7]]
//
v2f64 fixeddp(v2i64 v) { return __builtin_kvx_fixeddp(v, 3, ".rn"); }

// CHECK-LABEL: @fixeddq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <4 x i64> [[V:%.*]] to <4 x double>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x double> [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP1]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x double> [[TMP0]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP3]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <4 x double> [[TMP0]], i64 2
// CHECK-NEXT:    [[TMP6:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP5]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x double> [[TMP0]], i64 3
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP7]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP10:%.*]] = insertelement <4 x i64> [[TMP9]], i64 [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP10]], i64 [[TMP6]], i64 2
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i64> [[TMP11]], i64 [[TMP8]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = bitcast <4 x i64> [[TMP12]] to <4 x double>
// CHECK-NEXT:    ret <4 x double> [[TMP13]]
//
v4f64 fixeddq(v4i64 v) { return __builtin_kvx_fixeddq(v, 3, ".rn"); }

// CHECK-LABEL: @fixedudp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <2 x i64> [[V:%.*]] to <2 x double>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x double> [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP1]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x double> [[TMP0]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP3]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> [[TMP5]], i64 [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = bitcast <2 x i64> [[TMP6]] to <2 x double>
// CHECK-NEXT:    ret <2 x double> [[TMP7]]
//
v2f64 fixedudp(v2u64 v) { return __builtin_kvx_fixedudp(v, 3, ".rn"); }

// CHECK-LABEL: @fixedudq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <4 x i64> [[V:%.*]] to <4 x double>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x double> [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP1]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x double> [[TMP0]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP3]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <4 x double> [[TMP0]], i64 2
// CHECK-NEXT:    [[TMP6:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP5]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x double> [[TMP0]], i64 3
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP7]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP10:%.*]] = insertelement <4 x i64> [[TMP9]], i64 [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP10]], i64 [[TMP6]], i64 2
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i64> [[TMP11]], i64 [[TMP8]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = bitcast <4 x i64> [[TMP12]] to <4 x double>
// CHECK-NEXT:    ret <4 x double> [[TMP13]]
//
v4f64 fixedudq(v4u64 v) { return __builtin_kvx_fixedudq(v, 3, ".rn"); }

// CHECK-LABEL: @fixeduwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V:%.*]], <8 x float> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP0]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V]], <8 x float> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP2]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V]], <8 x float> poison, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP4]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x float> [[V]], <8 x float> poison, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP6]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <2 x i32> [[TMP5]], <2 x i32> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i32> [[TMP8]], <4 x i32> [[TMP9]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i32> [[TMP10]]
//
v8u32 fixeduwo(v8f32 v) { return __builtin_kvx_fixeduwo(v, 3, ".rn"); }

// CHECK-LABEL: @fixeduwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[V:%.*]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2u32 fixeduwp(v2f32 v) { return __builtin_kvx_fixeduwp(v, 3, ".rn"); }

// CHECK-LABEL: @fixeduwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[V:%.*]], <4 x float> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP0]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x float> [[V]], <4 x float> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP2]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4u32 fixeduwq(v4f32 v) { return __builtin_kvx_fixeduwq(v, 3, ".rn"); }

// CHECK-LABEL: @fixedwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V:%.*]], <8 x float> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP0]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V]], <8 x float> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP2]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V]], <8 x float> poison, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP4]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x float> [[V]], <8 x float> poison, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP6]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <2 x i32> [[TMP5]], <2 x i32> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i32> [[TMP8]], <4 x i32> [[TMP9]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i32> [[TMP10]]
//
v8i32 fixedwo(v8f32 v) { return __builtin_kvx_fixedwo(v, 3, ".rn"); }

// CHECK-LABEL: @fixedwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[V:%.*]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 fixedwp(v2f32 v) { return __builtin_kvx_fixedwp(v, 3, ".rn"); }

// CHECK-LABEL: @fixedwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[V:%.*]], <4 x float> poison, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP0]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x float> [[V]], <4 x float> poison, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP2]], i32 3, i32 0, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4i32 fixedwq(v4f32 v) { return __builtin_kvx_fixedwq(v, 3, ".rn"); }
