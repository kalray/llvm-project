// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple kvx-kalray-cos -emit-llvm %s -O2 -o - | FileCheck %s
typedef int __attribute__((__vector_size__(8))) v2i32;
typedef signed char __attribute__((__vector_size__(4 * sizeof(signed char)))) v4i8;
typedef signed char __attribute__((__vector_size__(8 * sizeof(signed char)))) v8i8;
typedef signed char __attribute__((__vector_size__(16 * sizeof(signed char)))) v16i8;
typedef signed char __attribute__((__vector_size__(32 * sizeof(signed char)))) v32i8;

typedef short __attribute__((__vector_size__(4 * sizeof(short)))) v4i16;
typedef short __attribute__((__vector_size__(8 * sizeof(short)))) v8i16;
typedef short __attribute__((__vector_size__(16 * sizeof(short)))) v16i16;

typedef int __attribute__((__vector_size__(2 * sizeof(int)))) v2i32;
typedef int __attribute__((__vector_size__(4 * sizeof(int)))) v4i32;
typedef int __attribute__((__vector_size__(8 * sizeof(int)))) v8i32;
typedef long __attribute__((__vector_size__(2 * sizeof(long)))) v2i64;
typedef long __attribute__((__vector_size__(4 * sizeof(long)))) v4i64;

typedef unsigned int __attribute__((__vector_size__(8))) v2u32;
typedef unsigned short __attribute__((__vector_size__(4 * sizeof(short))))
v4u16;
typedef unsigned short __attribute__((__vector_size__(8 * sizeof(short))))
v8u16;
typedef unsigned short __attribute__((__vector_size__(16 * sizeof(short))))
v16u16;
typedef unsigned int __attribute__((__vector_size__(2 * sizeof(int)))) v2u32;
typedef unsigned int __attribute__((__vector_size__(4 * sizeof(int)))) v4u32;
typedef unsigned int __attribute__((__vector_size__(8 * sizeof(int)))) v8u32;
typedef unsigned long __attribute__((__vector_size__(2 * sizeof(long)))) v2u64;
typedef unsigned long __attribute__((__vector_size__(4 * sizeof(long)))) v4u64;

typedef float __attribute__((__vector_size__(2 * sizeof(float)))) v2f32;
typedef float __attribute__((__vector_size__(4 * sizeof(float)))) v4f32;
typedef float __attribute__((__vector_size__(8 * sizeof(float)))) v8f32;

typedef double __attribute__((__vector_size__(2 * sizeof(double)))) v2f64;
typedef double __attribute__((__vector_size__(4 * sizeof(double)))) v4f64;

// CHECK-LABEL: @negbo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub <8 x i8> zeroinitializer, [[A:%.*]]
// CHECK-NEXT:    ret <8 x i8> [[NEG]]
//
v8i8 negbo(v8i8 a) {
  return __builtin_kvx_negbo(a, "");
}

// CHECK-LABEL: @negbos(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call <8 x i8> @llvm.ssub.sat.v8i8(<8 x i8> zeroinitializer, <8 x i8> [[A:%.*]])
// CHECK-NEXT:    ret <8 x i8> [[NEG_SAT]]
//
v8i8 negbos(v8i8 a) {
  return __builtin_kvx_negbo(a, ".s");
}

// CHECK-LABEL: @negbx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub <16 x i8> zeroinitializer, [[A:%.*]]
// CHECK-NEXT:    ret <16 x i8> [[NEG]]
//
v16i8 negbx(v16i8 a) {
  return __builtin_kvx_negbx(a, "");
}

// CHECK-LABEL: @negbxs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call <16 x i8> @llvm.ssub.sat.v16i8(<16 x i8> zeroinitializer, <16 x i8> [[A:%.*]])
// CHECK-NEXT:    ret <16 x i8> [[NEG_SAT]]
//
v16i8 negbxs(v16i8 a) {
  return __builtin_kvx_negbx(a, ".s");
}

// CHECK-LABEL: @negbv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub <32 x i8> zeroinitializer, [[A:%.*]]
// CHECK-NEXT:    ret <32 x i8> [[NEG]]
//
v32i8 negbv(v32i8 a) {
  return __builtin_kvx_negbv(a, "");
}

// CHECK-LABEL: @negbvs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call <32 x i8> @llvm.ssub.sat.v32i8(<32 x i8> zeroinitializer, <32 x i8> [[A:%.*]])
// CHECK-NEXT:    ret <32 x i8> [[NEG_SAT]]
//
v32i8 negbvs(v32i8 a) {
  return __builtin_kvx_negbv(a, ".s");
}

// CHECK-LABEL: @neghq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub <4 x i16> zeroinitializer, [[A:%.*]]
// CHECK-NEXT:    ret <4 x i16> [[NEG]]
//
v4i16 neghq(v4i16 a) {
  return __builtin_kvx_neghq(a, "");
}

// CHECK-LABEL: @neghqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call <4 x i16> @llvm.ssub.sat.v4i16(<4 x i16> zeroinitializer, <4 x i16> [[A:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[NEG_SAT]]
//
v4i16 neghqs(v4i16 a) {
  return __builtin_kvx_neghq(a, ".s");
}

// CHECK-LABEL: @negho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub <8 x i16> zeroinitializer, [[A:%.*]]
// CHECK-NEXT:    ret <8 x i16> [[NEG]]
//
v8i16 negho(v8i16 a) {
  return __builtin_kvx_negho(a, "");
}

// CHECK-LABEL: @neghos(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> [[A:%.*]])
// CHECK-NEXT:    ret <8 x i16> [[NEG_SAT]]
//
v8i16 neghos(v8i16 a) {
  return __builtin_kvx_negho(a, ".s");
}

// CHECK-LABEL: @neghx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub <16 x i16> zeroinitializer, [[A:%.*]]
// CHECK-NEXT:    ret <16 x i16> [[NEG]]
//
v16i16 neghx(v16i16 a) {
  return __builtin_kvx_neghx(a, "");
}

// CHECK-LABEL: @neghxs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call <16 x i16> @llvm.ssub.sat.v16i16(<16 x i16> zeroinitializer, <16 x i16> [[A:%.*]])
// CHECK-NEXT:    ret <16 x i16> [[NEG_SAT]]
//
v16i16 neghxs(v16i16 a) {
  return __builtin_kvx_neghx(a, ".s");
}

// CHECK-LABEL: @negw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub i32 0, [[A:%.*]]
// CHECK-NEXT:    ret i32 [[NEG]]
//
int negw(int a) {
  return __builtin_kvx_negw(a, "");
}

// CHECK-LABEL: @negws(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call i32 @llvm.ssub.sat.i32(i32 0, i32 [[A:%.*]])
// CHECK-NEXT:    ret i32 [[NEG_SAT]]
//
int negws(int a) {
  return __builtin_kvx_negw(a, ".s");
}

// CHECK-LABEL: @negwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub <2 x i32> zeroinitializer, [[A:%.*]]
// CHECK-NEXT:    ret <2 x i32> [[NEG]]
//
v2i32 negwp(v2i32 a) {
  return __builtin_kvx_negwp(a, "");
}

// CHECK-LABEL: @negwps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call <2 x i32> @llvm.ssub.sat.v2i32(<2 x i32> zeroinitializer, <2 x i32> [[A:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[NEG_SAT]]
//
v2i32 negwps(v2i32 a) {
  return __builtin_kvx_negwp(a, ".s");
}

// CHECK-LABEL: @negwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub <4 x i32> zeroinitializer, [[A:%.*]]
// CHECK-NEXT:    ret <4 x i32> [[NEG]]
//
v4i32 negwq(v4i32 a) {
  return __builtin_kvx_negwq(a, "");
}

// CHECK-LABEL: @negwqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call <4 x i32> @llvm.ssub.sat.v4i32(<4 x i32> zeroinitializer, <4 x i32> [[A:%.*]])
// CHECK-NEXT:    ret <4 x i32> [[NEG_SAT]]
//
v4i32 negwqs(v4i32 a) {
  return __builtin_kvx_negwq(a, ".s");
}

// CHECK-LABEL: @negwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub <8 x i32> zeroinitializer, [[A:%.*]]
// CHECK-NEXT:    ret <8 x i32> [[NEG]]
//
v8i32 negwo(v8i32 a) {
  return __builtin_kvx_negwo(a, "");
}

// CHECK-LABEL: @negwos(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call <8 x i32> @llvm.ssub.sat.v8i32(<8 x i32> zeroinitializer, <8 x i32> [[A:%.*]])
// CHECK-NEXT:    ret <8 x i32> [[NEG_SAT]]
//
v8i32 negwos(v8i32 a) {
  return __builtin_kvx_negwo(a, ".s");
}

// CHECK-LABEL: @negd(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub i64 0, [[A:%.*]]
// CHECK-NEXT:    ret i64 [[NEG]]
//
long negd(long a) {
  return __builtin_kvx_negd(a, "");
}

// CHECK-LABEL: @negds(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call i64 @llvm.ssub.sat.i64(i64 0, i64 [[A:%.*]])
// CHECK-NEXT:    ret i64 [[NEG_SAT]]
//
long negds(long a) {
  return __builtin_kvx_negd(a, ".s");
}

// CHECK-LABEL: @negdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub <2 x i64> zeroinitializer, [[A:%.*]]
// CHECK-NEXT:    ret <2 x i64> [[NEG]]
//
v2i64 negdp(v2i64 a) {
  return __builtin_kvx_negdp(a, "");
}

// CHECK-LABEL: @negdps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call <2 x i64> @llvm.ssub.sat.v2i64(<2 x i64> zeroinitializer, <2 x i64> [[A:%.*]])
// CHECK-NEXT:    ret <2 x i64> [[NEG_SAT]]
//
v2i64 negdps(v2i64 a) {
  return __builtin_kvx_negdp(a, ".s");
}

// CHECK-LABEL: @negdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG:%.*]] = sub <4 x i64> zeroinitializer, [[A:%.*]]
// CHECK-NEXT:    ret <4 x i64> [[NEG]]
//
v4i64 negdq(v4i64 a) {
  return __builtin_kvx_negdq(a, "");
}

// CHECK-LABEL: @negdqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[NEG_SAT:%.*]] = tail call <4 x i64> @llvm.ssub.sat.v4i64(<4 x i64> zeroinitializer, <4 x i64> [[A:%.*]])
// CHECK-NEXT:    ret <4 x i64> [[NEG_SAT]]
//
v4i64 negdqs(v4i64 a) {
  return __builtin_kvx_negdq(a, ".s");
}
