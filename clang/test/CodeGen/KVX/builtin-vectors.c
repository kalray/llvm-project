// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple kvx-kalray-cos -emit-llvm %s -O2 -o - | FileCheck %s
typedef int __attribute__((__vector_size__(8))) v2i32;
typedef short __attribute__((__vector_size__(4 * sizeof(short)))) v4i16;
typedef short __attribute__((__vector_size__(8 * sizeof(short)))) v8i16;
typedef short __attribute__((__vector_size__(16 * sizeof(short)))) v16i16;
typedef int __attribute__((__vector_size__(2 * sizeof(int)))) v2i32;
typedef int __attribute__((__vector_size__(4 * sizeof(int)))) v4i32;
typedef int __attribute__((__vector_size__(8 * sizeof(int)))) v8i32;
typedef long __attribute__((__vector_size__(2 * sizeof(long)))) v2i64;
typedef long __attribute__((__vector_size__(4 * sizeof(long)))) v4i64;

typedef unsigned int __attribute__((__vector_size__(8))) v2u32;
typedef unsigned short __attribute__((__vector_size__(4 * sizeof(short))))
v4u16;
typedef unsigned short __attribute__((__vector_size__(8 * sizeof(short))))
v8u16;
typedef unsigned short __attribute__((__vector_size__(16 * sizeof(short))))
v16u16;
typedef unsigned int __attribute__((__vector_size__(2 * sizeof(int)))) v2u32;
typedef unsigned int __attribute__((__vector_size__(4 * sizeof(int)))) v4u32;
typedef unsigned int __attribute__((__vector_size__(8 * sizeof(int)))) v8u32;
typedef unsigned long __attribute__((__vector_size__(2 * sizeof(long)))) v2u64;
typedef unsigned long __attribute__((__vector_size__(4 * sizeof(long)))) v4u64;

typedef float __attribute__((__vector_size__(2 * sizeof(float)))) v2f32;
typedef float __attribute__((__vector_size__(4 * sizeof(float)))) v4f32;
typedef float __attribute__((__vector_size__(8 * sizeof(float)))) v8f32;

typedef double __attribute__((__vector_size__(2 * sizeof(double)))) v2f64;
typedef double __attribute__((__vector_size__(4 * sizeof(double)))) v4f64;

// CHECK-LABEL: @abdhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.abdhq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 abdhq(v4i16 a, v4i16 b) { return __builtin_kvx_abdhq(a, b); }

// CHECK-LABEL: @abdho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.abdhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.abdhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8i16 abdho(v8i16 a, v8i16 b) { return  __builtin_kvx_abdho(a, b); }

// CHECK-LABEL: @abdhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.abdhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.abdhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.abdhq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.abdhq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16i16 abdhx(v16i16 a, v16i16 b) {
  return __builtin_kvx_abdhx(a, b);
}

// CHECK-LABEL: @abdwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.abdwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 abdwp(v2i32 a, v2i32 b) { return __builtin_kvx_abdwp(a, b); }

// CHECK-LABEL: @abdwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.abdwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.abdwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4i32 abdwq(v4i32 a, v4i32 b) { return __builtin_kvx_abdwq(a, b); }

// CHECK-LABEL: @abdwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.abdwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.abdwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.abdwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.abdwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8i32 abdwo(v8i32 a, v8i32 b) { return __builtin_kvx_abdwo(a, b); }

// CHECK-LABEL: @abddp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[B:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.abdd(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x i64> [[B]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call i64 @llvm.kvx.abdd(i64 [[TMP4]], i64 [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP6]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP7]]
//
v2i64 abddp(v2i64 a, v2i64 b) { return  __builtin_kvx_abddp(a, b); }

// CHECK-LABEL: @abddq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i64> [[B:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.abdd(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <4 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <4 x i64> [[B]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call i64 @llvm.kvx.abdd(i64 [[TMP4]], i64 [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <4 x i64> [[TMP3]], i64 [[TMP6]], i64 1
// CHECK-NEXT:    [[TMP8:%.*]] = extractelement <4 x i64> [[A]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[B]], i64 2
// CHECK-NEXT:    [[TMP10:%.*]] = tail call i64 @llvm.kvx.abdd(i64 [[TMP8]], i64 [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP7]], i64 [[TMP10]], i64 2
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <4 x i64> [[A]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = extractelement <4 x i64> [[B]], i64 3
// CHECK-NEXT:    [[TMP14:%.*]] = tail call i64 @llvm.kvx.abdd(i64 [[TMP12]], i64 [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i64> [[TMP11]], i64 [[TMP14]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP15]]
//
v4i64 abddq(v4i64 a, v4i64 b) { return __builtin_kvx_abddq(a, b); }

// CHECK-LABEL: @avghq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 avghq(v4i16 a, v4i16 b) { return __builtin_kvx_avghq(a, b, ""); }

// CHECK-LABEL: @avgho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8i16 avgho(v8i16 a, v8i16 b) { return __builtin_kvx_avgho(a, b, ""); }

// CHECK-LABEL: @avghx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.avghq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16i16 avghx(v16i16 a, v16i16 b) {
  return __builtin_kvx_avghx(a, b, "");
}

// CHECK-LABEL: @avgwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 avgwp(v2i32 a, v2i32 b) { return __builtin_kvx_avgwp(a, b, ""); }

// CHECK-LABEL: @avgwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4i32 avgwq(v4i32 a, v4i32 b) { return __builtin_kvx_avgwq(a, b, ""); }

// CHECK-LABEL: @avgwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.avgwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8i32 avgwo(v8i32 a, v8i32 b) { return __builtin_kvx_avgwo(a, b, ""); }

// CHECK-LABEL: @avguhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4u16 avguhq(v4u16 a, v4u16 b) { return __builtin_kvx_avghq(a, b, ".u"); }

// CHECK-LABEL: @avguho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8u16 avguho(v8u16 a, v8i16 b) { return __builtin_kvx_avgho(a, b, ".u"); }

// CHECK-LABEL: @avguhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.avguhq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16u16 avguhx(v16u16 a, v16u16 b) { return __builtin_kvx_avghx(a, b, ".u"); }

// CHECK-LABEL: @avguwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2u32 avguwp(v2u32 a, v2u32 b) { return __builtin_kvx_avgwp(a, b, ".u"); }

// CHECK-LABEL: @avguwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4u32 avguwq(v4u32 a, v4u32 b) { return __builtin_kvx_avgwq(a, b, ".u"); }

// CHECK-LABEL: @avguwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.avguwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8u32 avguwo(v8u32 a, v8u32 b) { return __builtin_kvx_avgwo(a, b, ".u"); }

// CHECK-LABEL: @avgrhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 avgrhq(v4i16 a, v4i16 b) { return __builtin_kvx_avghq(a, b, ".r"); }

// CHECK-LABEL: @avgrho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8i16 avgrho(v8i16 a, v8i16 b) { return __builtin_kvx_avgho(a, b, ".r"); }

// CHECK-LABEL: @avgrhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.avgrhq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16i16 avgrhx(v16i16 a, v16i16 b) { return __builtin_kvx_avghx(a, b, ".r"); }

// CHECK-LABEL: @avgrwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 avgrwp(v2i32 a, v2i32 b) { return __builtin_kvx_avgwp(a, b, ".r"); }

// CHECK-LABEL: @avgrwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4i32 avgrwq(v4i32 a, v4i32 b) { return __builtin_kvx_avgwq(a, b, ".r"); }

// CHECK-LABEL: @avgrwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.avgrwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8i32 avgrwo(v8i32 a, v8i32 b) { return __builtin_kvx_avgwo(a, b, ".r"); }

// CHECK-LABEL: @avgruhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4u16 avgruhq(v4u16 a, v4u16 b) { return __builtin_kvx_avghq(a, b, ".ru"); }

// CHECK-LABEL: @avgruho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8u16 avgruho(v8u16 a, v8u16 b) { return __builtin_kvx_avgho(a, b, ".ru"); }

// CHECK-LABEL: @avgruhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.avgruhq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16u16 avgruhx(v16u16 a, v16u16 b) { return __builtin_kvx_avghx(a, b, ".ru"); }

// CHECK-LABEL: @avgruwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2u32 avgruwp(v2u32 a, v2u32 b) { return __builtin_kvx_avgwp(a, b, ".ru"); }

// CHECK-LABEL: @avgruwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4u32 avgruwq(v4u32 a, v4u32 b) { return __builtin_kvx_avgwq(a, b, ".ru"); }

// CHECK-LABEL: @avgruwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.avgruwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8u32 avgruwo(v8u32 a, v8u32 b) { return __builtin_kvx_avgwo(a, b, ".ru"); }

/**
 * TODO: reintroduce addshq to addsdqs tests once saturation modifier is
 * supported in integer add builtins
 */

// v4i16 addshq(v4i16 a, v4i16 b) { return __builtin_kvx_addshq(a, b); }

// v8i16 addsho(v8i16 a, v8i16 b) { return __builtin_kvx_addsho(a, b); }

// v16i16 addshx(v16i16 a, v16i16 b) {
//   return __builtin_kvx_addshx(a, b);
// }

// v2i32 addswp(v2i32 a, v2i32 b) { return __builtin_kvx_addswp(a, b); }

// v4i32 addswq(v4i32 a, v4i32 b) { return __builtin_kvx_addswq(a, b); }

// v8i32 addswo(v8i32 a, v8i32 b) { return __builtin_kvx_addswo(a, b); }

// v2i64 addsdp(v2i64 a, v2i64 b) { return __builtin_kvx_addsdp(a, b); }

// v4i64 addsdq(v4i64 a, v4i64 b) { return __builtin_kvx_addsdq(a, b); }

// v4i16 addshqs(v4i16 a, short b) {
//   return __builtin_kvx_addshqs(a, b);
// }

// v8i16 addshos(v8i16 a, short b) {
//   return __builtin_kvx_addshos(a, b);
// }

// v16i16 addshxs(v16i16 a, short b) {
//   return __builtin_kvx_addshxs(a, b);
// }

// v2i32 addswps(v2i32 a, int b) { return __builtin_kvx_addswps(a, b); }

// v4i32 addswqs(v4i32 a, int b) { return __builtin_kvx_addswqs(a, b); }

// v8i32 addswos(v8i32 a, int b) { return __builtin_kvx_addswos(a, b); }

// v2i64 addsdps(v2i64 a, long b) {
//   return __builtin_kvx_addsdps(a, b);
// }

// v4i64 addsdqs(v4i64 a, long b) {
//   return __builtin_kvx_addsdqs(a, b);
// }

/**
 * TODO: reintroduce sbfshq to sbfsdqs tests once saturation modifier is
 * supported in integer sub builtins
 */

// v4i16 sbfshq(v4i16 a, v4i16 b) { return __builtin_kvx_sbfshq(a, b); }

// v8i16 sbfsho(v8i16 a, v8i16 b) { return __builtin_kvx_sbfsho(a, b); }

// v16i16 sbfshx(v16i16 a, v16i16 b) {
//   return __builtin_kvx_sbfshx(a, b);
// }

// v2i32 sbfswp(v2i32 a, v2i32 b) { return __builtin_kvx_sbfswp(a, b); }

// v4i32 sbfswq(v4i32 a, v4i32 b) { return __builtin_kvx_sbfswq(a, b); }

// v8i32 sbfswo(v8i32 a, v8i32 b) { return __builtin_kvx_sbfswo(a, b); }

// v2i64 sbfsdp(v2i64 a, v2i64 b) { return __builtin_kvx_sbfsdp(a, b); }

// v4i64 sbfsdq(v4i64 a, v4i64 b) { return __builtin_kvx_sbfsdq(a, b); }

// v4i16 sbfshqs(v4i16 a, short b) {
//   return __builtin_kvx_sbfshqs(a, b);
// }

// v8i16 sbfshos(v8i16 a, short b) {
//   return __builtin_kvx_sbfshos(a, b);
// }

// v16i16 sbfshxs(v16i16 a, short b) {
//   return __builtin_kvx_sbfshxs(a, b);
// }

// v2i32 sbfswps(v2i32 a, int b) { return __builtin_kvx_sbfswps(a, b); }

// v4i32 sbfswqs(v4i32 a, int b) { return __builtin_kvx_sbfswqs(a, b); }

// v8i32 sbfswos(v8i32 a, int b) { return __builtin_kvx_sbfswos(a, b); }

// v2i64 sbfsdps(v2i64 a, long b) {
//   return __builtin_kvx_sbfsdps(a, b);
// }

// v4i64 sbfsdqs(v4i64 a, long b) {
//   return __builtin_kvx_sbfsdqs(a, b);
// }

// CHECK-LABEL: @minw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.minw(i32 [[A:%.*]], i32 [[B:%.*]])
// CHECK-NEXT:    ret i32 [[TMP0]]
//
int minw(int a, int b) { return __builtin_kvx_minw(a, b); }

// CHECK-LABEL: @mind(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.mind(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-NEXT:    ret i64 [[TMP0]]
//
long mind(long a, long b) { return __builtin_kvx_mind(a, b); }

// CHECK-LABEL: @minhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.minhq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 minhq(v4i16 a, v4i16 b) { return __builtin_kvx_minhq(a, b); }

// CHECK-LABEL: @minho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.minhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.minhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8i16 minho(v8i16 a, v8i16 b) { return __builtin_kvx_minho(a, b); }

// CHECK-LABEL: @minhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.minhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.minhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.minhq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.minhq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16i16 minhx(v16i16 a, v16i16 b) {
  return __builtin_kvx_minhx(a, b);
}

// CHECK-LABEL: @minwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.minwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 minwp(v2i32 a, v2i32 b) { return __builtin_kvx_minwp(a, b); }

// CHECK-LABEL: @minwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.minwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.minwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4i32 minwq(v4i32 a, v4i32 b) { return __builtin_kvx_minwq(a, b); }

// CHECK-LABEL: @minwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.minwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.minwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.minwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.minwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8i32 minwo(v8i32 a, v8i32 b) { return __builtin_kvx_minwo(a, b); }

// CHECK-LABEL: @mindp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[B:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.mind(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x i64> [[B]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call i64 @llvm.kvx.mind(i64 [[TMP4]], i64 [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP6]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP7]]
//
v2i64 mindp(v2i64 a, v2i64 b) { return __builtin_kvx_mindp(a, b); }

// CHECK-LABEL: @mindq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i64> [[B:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.mind(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <4 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <4 x i64> [[B]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call i64 @llvm.kvx.mind(i64 [[TMP4]], i64 [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <4 x i64> [[TMP3]], i64 [[TMP6]], i64 1
// CHECK-NEXT:    [[TMP8:%.*]] = extractelement <4 x i64> [[A]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[B]], i64 2
// CHECK-NEXT:    [[TMP10:%.*]] = tail call i64 @llvm.kvx.mind(i64 [[TMP8]], i64 [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP7]], i64 [[TMP10]], i64 2
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <4 x i64> [[A]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = extractelement <4 x i64> [[B]], i64 3
// CHECK-NEXT:    [[TMP14:%.*]] = tail call i64 @llvm.kvx.mind(i64 [[TMP12]], i64 [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i64> [[TMP11]], i64 [[TMP14]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP15]]
//
v4i64 mindq(v4i64 a, v4i64 b) { return __builtin_kvx_mindq(a, b); }

// CHECK-LABEL: @maxw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.maxw(i32 [[A:%.*]], i32 [[B:%.*]])
// CHECK-NEXT:    ret i32 [[TMP0]]
//
int maxw(int a, int b) { return __builtin_kvx_maxw(a, b); }

// CHECK-LABEL: @maxd(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.maxd(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-NEXT:    ret i64 [[TMP0]]
//
long maxd(long a, long b) { return __builtin_kvx_maxd(a, b); }

// CHECK-LABEL: @maxhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.maxhq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 maxhq(v4i16 a, v4i16 b) { return __builtin_kvx_maxhq(a, b); }

// CHECK-LABEL: @maxho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.maxhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.maxhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8i16 maxho(v8i16 a, v8i16 b) { return __builtin_kvx_maxho(a, b); }

// CHECK-LABEL: @maxhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.maxhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.maxhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.maxhq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.maxhq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16i16 maxhx(v16i16 a, v16i16 b) {
  return __builtin_kvx_maxhx(a, b);
}

// CHECK-LABEL: @maxwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.maxwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 maxwp(v2i32 a, v2i32 b) { return __builtin_kvx_maxwp(a, b); }

// CHECK-LABEL: @maxwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.maxwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.maxwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4i32 maxwq(v4i32 a, v4i32 b) { return __builtin_kvx_maxwq(a, b); }

// CHECK-LABEL: @maxwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.maxwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.maxwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.maxwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.maxwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8i32 maxwo(v8i32 a, v8i32 b) { return __builtin_kvx_maxwo(a, b); }

// CHECK-LABEL: @maxdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[B:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.maxd(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x i64> [[B]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call i64 @llvm.kvx.maxd(i64 [[TMP4]], i64 [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP6]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP7]]
//
v2i64 maxdp(v2i64 a, v2i64 b) { return __builtin_kvx_maxdp(a, b); }

// CHECK-LABEL: @maxdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i64> [[B:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.maxd(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <4 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <4 x i64> [[B]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call i64 @llvm.kvx.maxd(i64 [[TMP4]], i64 [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <4 x i64> [[TMP3]], i64 [[TMP6]], i64 1
// CHECK-NEXT:    [[TMP8:%.*]] = extractelement <4 x i64> [[A]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[B]], i64 2
// CHECK-NEXT:    [[TMP10:%.*]] = tail call i64 @llvm.kvx.maxd(i64 [[TMP8]], i64 [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP7]], i64 [[TMP10]], i64 2
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <4 x i64> [[A]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = extractelement <4 x i64> [[B]], i64 3
// CHECK-NEXT:    [[TMP14:%.*]] = tail call i64 @llvm.kvx.maxd(i64 [[TMP12]], i64 [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i64> [[TMP11]], i64 [[TMP14]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP15]]
//
v4i64 maxdq(v4i64 a, v4i64 b) { return __builtin_kvx_maxdq(a, b); }

// CHECK-LABEL: @minuw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.minuw(i32 [[A:%.*]], i32 [[B:%.*]])
// CHECK-NEXT:    ret i32 [[TMP0]]
//
unsigned int minuw(unsigned int a, unsigned int b) {
  return __builtin_kvx_minuw(a, b);
}

// CHECK-LABEL: @minuw2(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.minuw(i32 [[A:%.*]], i32 5)
// CHECK-NEXT:    ret i32 [[TMP0]]
//
unsigned int minuw2(unsigned int a) {
  return __builtin_kvx_minuw(a, 5);
}

// CHECK-LABEL: @minud(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.minud(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-NEXT:    ret i64 [[TMP0]]
//
unsigned long minud(unsigned long a, unsigned long b) {
  return __builtin_kvx_minud(a, b);
}

// CHECK-LABEL: @minud2(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.minud(i64 [[A:%.*]], i64 5)
// CHECK-NEXT:    ret i64 [[TMP0]]
//
unsigned long minud2(unsigned long a) {
  return __builtin_kvx_minud(a, 5);
}

// CHECK-LABEL: @minuhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.minuhq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4u16 minuhq(v4u16 a, v4u16 b) { return __builtin_kvx_minuhq(a, b); }

// CHECK-LABEL: @minuho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.minuhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.minuhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8u16 minuho(v8u16 a, v8u16 b) { return __builtin_kvx_minuho(a, b); }

// CHECK-LABEL: @minuhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.minuhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.minuhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.minuhq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.minuhq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16u16 minuhx(v16u16 a, v16u16 b) {
  return __builtin_kvx_minuhx(a, b);
}

// CHECK-LABEL: @minuwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.minuwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2u32 minuwp(v2u32 a, v2u32 b) { return __builtin_kvx_minuwp(a, b); }

// CHECK-LABEL: @minuwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.minuwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.minuwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4u32 minuwq(v4u32 a, v4u32 b) { return __builtin_kvx_minuwq(a, b); }

// CHECK-LABEL: @minuwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.minuwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.minuwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.minuwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.minuwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8u32 minuwo(v8u32 a, v8u32 b) { return __builtin_kvx_minuwo(a, b); }

// CHECK-LABEL: @minudp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[B:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.minud(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x i64> [[B]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call i64 @llvm.kvx.minud(i64 [[TMP4]], i64 [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP6]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP7]]
//
v2u64 minudp(v2u64 a, v2u64 b) { return __builtin_kvx_minudp(a, b); }

// CHECK-LABEL: @minudq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i64> [[B:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.minud(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <4 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <4 x i64> [[B]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call i64 @llvm.kvx.minud(i64 [[TMP4]], i64 [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <4 x i64> [[TMP3]], i64 [[TMP6]], i64 1
// CHECK-NEXT:    [[TMP8:%.*]] = extractelement <4 x i64> [[A]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[B]], i64 2
// CHECK-NEXT:    [[TMP10:%.*]] = tail call i64 @llvm.kvx.minud(i64 [[TMP8]], i64 [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP7]], i64 [[TMP10]], i64 2
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <4 x i64> [[A]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = extractelement <4 x i64> [[B]], i64 3
// CHECK-NEXT:    [[TMP14:%.*]] = tail call i64 @llvm.kvx.minud(i64 [[TMP12]], i64 [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i64> [[TMP11]], i64 [[TMP14]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP15]]
//
v4u64 minudq(v4u64 a, v4u64 b) { return __builtin_kvx_minudq(a, b); }

// CHECK-LABEL: @maxuw(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @llvm.kvx.maxuw(i32 [[A:%.*]], i32 [[B:%.*]])
// CHECK-NEXT:    ret i32 [[TMP0]]
//
unsigned int maxuw(unsigned int a, unsigned int b) {
  return __builtin_kvx_maxuw(a, b);
}

// CHECK-LABEL: @maxud(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.kvx.maxud(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-NEXT:    ret i64 [[TMP0]]
//
unsigned long maxud(unsigned long a, unsigned long b) {
  return __builtin_kvx_maxud(a, b);
}

// CHECK-LABEL: @maxuhq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.maxuhq(<4 x i16> [[A:%.*]], <4 x i16> [[B:%.*]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4u16 maxuhq(v4u16 a, v4u16 b) { return __builtin_kvx_maxuhq(a, b); }

// CHECK-LABEL: @maxuho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[B:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.maxuhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[B]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.maxuhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP6]]
//
v8u16 maxuho(v8u16 a, v8u16 b) { return __builtin_kvx_maxuho(a, b); }

// CHECK-LABEL: @maxuhx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[B:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x i16> @llvm.kvx.maxuhq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x i16> @llvm.kvx.maxuhq(<4 x i16> [[TMP3]], <4 x i16> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i16> [[TMP2]], <4 x i16> [[TMP5]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <4 x i16> @llvm.kvx.maxuhq(<4 x i16> [[TMP7]], <4 x i16> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i16> [[TMP9]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[TMP6]], <16 x i16> [[TMP10]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <16 x i16> [[B]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <4 x i16> @llvm.kvx.maxuhq(<4 x i16> [[TMP12]], <4 x i16> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <4 x i16> [[TMP14]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[TMP11]], <16 x i16> [[TMP15]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP16]]
//
v16u16 maxuhx(v16u16 a, v16u16 b) {
  return __builtin_kvx_maxuhx(a, b);
}

// CHECK-LABEL: @maxuwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.maxuwp(<2 x i32> [[A:%.*]], <2 x i32> [[B:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2u32 maxuwp(v2u32 a, v2u32 b) { return __builtin_kvx_maxuwp(a, b); }

// CHECK-LABEL: @maxuwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[B:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.maxuwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[B]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.maxuwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP6]]
//
v4u32 maxuwq(v4u32 a, v4u32 b) { return __builtin_kvx_maxuwq(a, b); }

// CHECK-LABEL: @maxuwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[B:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.maxuwp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.maxuwp(<2 x i32> [[TMP3]], <2 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x i32> @llvm.kvx.maxuwp(<2 x i32> [[TMP7]], <2 x i32> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x i32> [[TMP9]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[TMP6]], <8 x i32> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x i32> [[B]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x i32> @llvm.kvx.maxuwp(<2 x i32> [[TMP12]], <2 x i32> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[TMP11]], <8 x i32> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP16]]
//
v8u32 maxuwo(v8u32 a, v8u32 b) { return __builtin_kvx_maxuwo(a, b); }

// CHECK-LABEL: @maxudp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[B:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.maxud(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x i64> [[B]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call i64 @llvm.kvx.maxud(i64 [[TMP4]], i64 [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP6]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP7]]
//
v2u64 maxudp(v2u64 a, v2u64 b) { return __builtin_kvx_maxudp(a, b); }

// CHECK-LABEL: @maxudq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i64> [[B:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.maxud(i64 [[TMP0]], i64 [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <4 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <4 x i64> [[B]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call i64 @llvm.kvx.maxud(i64 [[TMP4]], i64 [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <4 x i64> [[TMP3]], i64 [[TMP6]], i64 1
// CHECK-NEXT:    [[TMP8:%.*]] = extractelement <4 x i64> [[A]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[B]], i64 2
// CHECK-NEXT:    [[TMP10:%.*]] = tail call i64 @llvm.kvx.maxud(i64 [[TMP8]], i64 [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP7]], i64 [[TMP10]], i64 2
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <4 x i64> [[A]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = extractelement <4 x i64> [[B]], i64 3
// CHECK-NEXT:    [[TMP14:%.*]] = tail call i64 @llvm.kvx.maxud(i64 [[TMP12]], i64 [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x i64> [[TMP11]], i64 [[TMP14]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP15]]
//
v4u64 maxudq(v4u64 a, v4u64 b) { return __builtin_kvx_maxudq(a, b); }

// CHECK-LABEL: @shlhqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[A:%.*]], i64 [[CONV]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 shlhqs(v4i16 a, unsigned int b) {
  return __builtin_kvx_shlhqs(a, b);
}

// CHECK-LABEL: @shlhqsimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[A:%.*]], i64 3)
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 shlhqsimm(v4i16 a) { return __builtin_kvx_shlhqs(a, 3); }

// CHECK-LABEL: @shlhos(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[TMP0]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[TMP2]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP4]]
//
v8i16 shlhos(v8i16 a, unsigned int b) {
  return __builtin_kvx_shlhos(a, b);
}

// CHECK-LABEL: @shlhosimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[TMP0]], i64 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[TMP2]], i64 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP4]]
//
v8i16 shlhosimm(v8i16 a) { return __builtin_kvx_shlhos(a, 3); }

// CHECK-LABEL: @shlhxs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[C:%.*]] = alloca <16 x i16>, align 32
// CHECK-NEXT:    [[C_0_SROA_CAST:%.*]] = bitcast <16 x i16>* [[C]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull [[C_0_SROA_CAST]])
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[TMP0]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[TMP2]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[TMP5]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <4 x i16> [[TMP6]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[TMP4]], <16 x i16> [[TMP7]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[TMP9]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <4 x i16> [[TMP10]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[TMP8]], <16 x i16> [[TMP11]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    store volatile <16 x i16> [[TMP12]], <16 x i16>* [[C]], align 32, [[TBAA2:!tbaa !.*]]
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull [[C_0_SROA_CAST]])
// CHECK-NEXT:    ret void
//
void shlhxs(v16i16 a, unsigned int b) {
  volatile v16i16 c = __builtin_kvx_shlhxs(a, b);
}

// CHECK-LABEL: @shlhxsimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[C:%.*]] = alloca <16 x i16>, align 32
// CHECK-NEXT:    [[C_0_SROA_CAST:%.*]] = bitcast <16 x i16>* [[C]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull [[C_0_SROA_CAST]])
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[TMP0]], i64 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[TMP2]], i64 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[TMP5]], i64 3)
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <4 x i16> [[TMP6]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[TMP4]], <16 x i16> [[TMP7]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <4 x i16> @llvm.kvx.sllhqs(<4 x i16> [[TMP9]], i64 3)
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <4 x i16> [[TMP10]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[TMP8]], <16 x i16> [[TMP11]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    store volatile <16 x i16> [[TMP12]], <16 x i16>* [[C]], align 32, [[TBAA2]]
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull [[C_0_SROA_CAST]])
// CHECK-NEXT:    ret void
//
void shlhxsimm(v16i16 a) { volatile v16i16 c = __builtin_kvx_shlhxs(a, 3); }

// CHECK-LABEL: @shlwps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[C:%.*]] = alloca <2 x i32>, align 8
// CHECK-NEXT:    [[C_0_SROA_CAST:%.*]] = bitcast <2 x i32>* [[C]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull [[C_0_SROA_CAST]])
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[A:%.*]], i64 [[CONV]])
// CHECK-NEXT:    store volatile <2 x i32> [[TMP0]], <2 x i32>* [[C]], align 8, [[TBAA2]]
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull [[C_0_SROA_CAST]])
// CHECK-NEXT:    ret void
//
void shlwps(v2i32 a, unsigned int b) {
  volatile v2i32 c = __builtin_kvx_shlwps(a, b);
}

// CHECK-LABEL: @shlwpsimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[C:%.*]] = alloca <2 x i32>, align 8
// CHECK-NEXT:    [[C_0_SROA_CAST:%.*]] = bitcast <2 x i32>* [[C]] to i8*
// CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull [[C_0_SROA_CAST]])
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[A:%.*]], i64 3)
// CHECK-NEXT:    store volatile <2 x i32> [[TMP0]], <2 x i32>* [[C]], align 8, [[TBAA2]]
// CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull [[C_0_SROA_CAST]])
// CHECK-NEXT:    ret void
//
void shlwpsimm(v2i32 a) { volatile v2i32 c = __builtin_kvx_shlwps(a, 3); }

// CHECK-LABEL: @shlwqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[TMP0]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[TMP2]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4i32 shlwqs(v4i32 a, unsigned int b) {
  return __builtin_kvx_shlwqs(a, b);
}

// CHECK-LABEL: @shlwqsimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[TMP0]], i64 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[TMP2]], i64 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4i32 shlwqsimm(v4i32 a) { return __builtin_kvx_shlwqs(a, 3); }

// CHECK-LABEL: @shlwos(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[TMP0]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[TMP2]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[TMP5]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x i32> [[TMP6]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[TMP4]], <8 x i32> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[TMP9]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x i32> [[TMP10]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[TMP8]], <8 x i32> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP12]]
//
v8i32 shlwos(v8i32 a, unsigned int b) {
  return __builtin_kvx_shlwos(a, b);
}

// CHECK-LABEL: @shlwosimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[TMP0]], i64 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[TMP2]], i64 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[TMP5]], i64 3)
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x i32> [[TMP6]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[TMP4]], <8 x i32> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x i32> @llvm.kvx.sllwps(<2 x i32> [[TMP9]], i64 3)
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x i32> [[TMP10]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[TMP8]], <8 x i32> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP12]]
//
v8i32 shlwosimm(v8i32 a) { return __builtin_kvx_shlwos(a, 3); }

// CHECK-LABEL: @shldps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.slld(i64 [[TMP0]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x i64> undef, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.kvx.slld(i64 [[TMP3]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i64> [[TMP2]], i64 [[TMP4]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP5]]
//
v2i64 shldps(v2i64 a, unsigned int b) {
  return __builtin_kvx_shldps(a, b);
}

// CHECK-LABEL: @shldpsimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.slld(i64 [[TMP0]], i64 3)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x i64> undef, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.kvx.slld(i64 [[TMP3]], i64 3)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i64> [[TMP2]], i64 [[TMP4]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP5]]
//
v2i64 shldpsimm(v2i64 a) { return __builtin_kvx_shldps(a, 3); }

// CHECK-LABEL: @shldqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.slld(i64 [[TMP0]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <4 x i64> undef, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.kvx.slld(i64 [[TMP3]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <4 x i64> [[TMP2]], i64 [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[A]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = tail call i64 @llvm.kvx.slld(i64 [[TMP6]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x i64> [[TMP5]], i64 [[TMP7]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[A]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = tail call i64 @llvm.kvx.slld(i64 [[TMP9]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP8]], i64 [[TMP10]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP11]]
//
v4i64 shldqs(v4i64 a, unsigned int b) {
  return __builtin_kvx_shldqs(a, b);
}

// CHECK-LABEL: @shldqsimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.slld(i64 [[TMP0]], i64 3)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <4 x i64> undef, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.kvx.slld(i64 [[TMP3]], i64 3)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <4 x i64> [[TMP2]], i64 [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[A]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = tail call i64 @llvm.kvx.slld(i64 [[TMP6]], i64 3)
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x i64> [[TMP5]], i64 [[TMP7]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[A]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = tail call i64 @llvm.kvx.slld(i64 [[TMP9]], i64 3)
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP8]], i64 [[TMP10]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP11]]
//
v4i64 shldqsimm(v4i64 a) { return __builtin_kvx_shldqs(a, 3); }

/**
 * TODO Reintroduce slshqs - slsdqsimm once string modifier is there
 */

// v4i16 slshqs(v4i16 a, unsigned int b) {
//   return __builtin_kvx_slshqs(a, b);
// }

// v4i16 slshqsimm(v4i16 a) { return __builtin_kvx_slshqs(a, 3); }

// v8i16 slshos(v8i16 a, unsigned int b) {
//   return __builtin_kvx_slshos(a, b);
// }

// v8i16 slshosimm(v8i16 a) { return __builtin_kvx_slshos(a, 3); }

// v16i16 slshxs(v16i16 a, unsigned int b) {
//   return __builtin_kvx_slshxs(a, b);
// }

// v16i16 slshxsimm(v16i16 a) { return __builtin_kvx_slshxs(a, 3); }

// v2i32 slswps(v2i32 a, unsigned int b) {
//   return __builtin_kvx_slswps(a, b);
// }

// v2i32 slswpsimm(v2i32 a) { return __builtin_kvx_slswps(a, 3); }

// v4i32 slswqs(v4i32 a, unsigned int b) {
//   return __builtin_kvx_slswqs(a, b);
// }

// v4i32 slswqsimm(v4i32 a) { return __builtin_kvx_slswqs(a, 3); }

// v8i32 slswos(v8i32 a, unsigned int b) {
//   return __builtin_kvx_slswos(a, b);
// }

// v8i32 slswosimm(v8i32 a) { return __builtin_kvx_slswos(a, 3); }

// v2i64 slsdps(v2i64 a, unsigned int b) {
//   return __builtin_kvx_slsdps(a, b);
// }

// v2i64 slsdpsimm(v2i64 a) { return __builtin_kvx_slsdps(a, 3); }

// v4i64 slsdqs(v4i64 a, unsigned int b) {
//   return __builtin_kvx_slsdqs(a, b);
// }

// v4i64 slsdqsimm(v4i64 a) { return __builtin_kvx_slsdqs(a, 3); }

/**
 * TODO Reintroduce srahqs - sradqsimm once string modifier is there
 */

// v4i16 srahqs(v4i16 a, unsigned int b) {
//   return __builtin_kvx_srahqs(a, b);
// }

// v4i16 srahqsimm(v4i16 a) { return __builtin_kvx_srahqs(a, 3); }

// v8i16 srahos(v8i16 a, unsigned int b) {
//   return __builtin_kvx_srahos(a, b);
// }

// v8i16 srahosimm(v8i16 a) { return __builtin_kvx_srahos(a, 3); }

// void srahxs(v16i16 a, unsigned int b) {
//   volatile v16i16 c = __builtin_kvx_srahxs(a, b);
// }

// void srahxsimm(v16i16 a) { volatile v16i16 c = __builtin_kvx_srahxs(a, 3); }

// v2i32 srawps(v2i32 a, unsigned int b) {
//   return __builtin_kvx_srawps(a, b);
// }

// v2i32 srawpsimm(v2i32 a) { return __builtin_kvx_srawps(a, 3); }

// v4i32 srawqs(v4i32 a, unsigned int b) {
//   return __builtin_kvx_srawqs(a, b);
// }

// v4i32 srawqsimm(v4i32 a) { return __builtin_kvx_srawqs(a, 3); }

// v8i32 srawos(v8i32 a, unsigned int b) {
//   return __builtin_kvx_srawos(a, b);
// }

// v8i32 srawosimm(v8i32 a) { return __builtin_kvx_srawos(a, 3); }

// v2i64 sradps(v2i64 a, unsigned int b) {
//   return __builtin_kvx_sradps(a, b);
// }

// v2i64 sradpsimm(v2i64 a) { return __builtin_kvx_sradps(a, 3); }

// v4i64 sradqs(v4i64 a, unsigned int b) {
//   return __builtin_kvx_sradqs(a, b);
// }

// v4i64 sradqsimm(v4i64 a) { return __builtin_kvx_sradqs(a, 3); }

// CHECK-LABEL: @shrhqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[A:%.*]], i64 [[CONV]])
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 shrhqs(v4i16 a, unsigned int b) {
  return __builtin_kvx_shrhqs(a, b);
}

// CHECK-LABEL: @shrhqsimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[A:%.*]], i64 3)
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 shrhqsimm(v4i16 a) { return __builtin_kvx_shrhqs(a, 3); }

// CHECK-LABEL: @shrhos(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[TMP0]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[TMP2]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP4]]
//
v8i16 shrhos(v8i16 a, unsigned int b) {
  return __builtin_kvx_shrhos(a, b);
}

// CHECK-LABEL: @shrhosimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[A:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[TMP0]], i64 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i16> [[A]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[TMP2]], i64 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP4]]
//
v8i16 shrhosimm(v8i16 a) { return __builtin_kvx_shrhos(a, 3); }

// CHECK-LABEL: @shrhxs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[TMP0]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[TMP2]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[TMP5]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <4 x i16> [[TMP6]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[TMP4]], <16 x i16> [[TMP7]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[TMP9]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <4 x i16> [[TMP10]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[TMP8]], <16 x i16> [[TMP11]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP12]]
//
v16i16 shrhxs(v16i16 a, unsigned int b) {
  return __builtin_kvx_shrhxs(a, b);
}

// CHECK-LABEL: @shrhxsimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[A:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[TMP0]], i64 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[TMP2]], i64 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i16> [[TMP1]], <4 x i16> [[TMP3]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[TMP5]], i64 3)
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <4 x i16> [[TMP6]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <16 x i16> [[TMP4]], <16 x i16> [[TMP7]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <16 x i16> [[A]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <4 x i16> @llvm.kvx.srlhqs(<4 x i16> [[TMP9]], i64 3)
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <4 x i16> [[TMP10]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <16 x i16> [[TMP8]], <16 x i16> [[TMP11]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP12]]
//
v16i16 shrhxsimm(v16i16 a) { return __builtin_kvx_shrhxs(a, 3); }

// CHECK-LABEL: @shrwps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[A:%.*]], i64 [[CONV]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 shrwps(v2i32 a, unsigned int b) {
  return __builtin_kvx_shrwps(a, b);
}

// CHECK-LABEL: @shrwpsimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[A:%.*]], i64 3)
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 shrwpsimm(v2i32 a) { return __builtin_kvx_shrwps(a, 3); }

// CHECK-LABEL: @shrwqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[TMP0]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[TMP2]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4i32 shrwqs(v4i32 a, unsigned int b) {
  return __builtin_kvx_shrwqs(a, b);
}

// CHECK-LABEL: @shrwqsimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[A:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[TMP0]], i64 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[A]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[TMP2]], i64 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4i32 shrwqsimm(v4i32 a) { return __builtin_kvx_shrwqs(a, 3); }

// CHECK-LABEL: @shrwos(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[TMP0]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[TMP2]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[TMP5]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x i32> [[TMP6]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[TMP4]], <8 x i32> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[TMP9]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x i32> [[TMP10]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[TMP8]], <8 x i32> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP12]]
//
v8i32 shrwos(v8i32 a, unsigned int b) {
  return __builtin_kvx_shrwos(a, b);
}

// CHECK-LABEL: @shrwosimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[A:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[TMP0]], i64 3)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[TMP2]], i64 3)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[TMP5]], i64 3)
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x i32> [[TMP6]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[TMP4]], <8 x i32> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i32> [[A]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x i32> @llvm.kvx.srlwps(<2 x i32> [[TMP9]], i64 3)
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x i32> [[TMP10]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[TMP8]], <8 x i32> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP12]]
//
v8i32 shrwosimm(v8i32 a) { return __builtin_kvx_shrwos(a, 3); }

// CHECK-LABEL: @shrdps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.srld(i64 [[TMP0]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x i64> undef, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.kvx.srld(i64 [[TMP3]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i64> [[TMP2]], i64 [[TMP4]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP5]]
//
v2i64 shrdps(v2i64 a, unsigned int b) {
  return __builtin_kvx_shrdps(a, b);
}

// CHECK-LABEL: @shrdpsimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.srld(i64 [[TMP0]], i64 3)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x i64> undef, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.kvx.srld(i64 [[TMP3]], i64 3)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i64> [[TMP2]], i64 [[TMP4]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP5]]
//
v2i64 shrdpsimm(v2i64 a) { return __builtin_kvx_shrdps(a, 3); }

// CHECK-LABEL: @shrdqs(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.srld(i64 [[TMP0]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <4 x i64> undef, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.kvx.srld(i64 [[TMP3]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <4 x i64> [[TMP2]], i64 [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[A]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = tail call i64 @llvm.kvx.srld(i64 [[TMP6]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x i64> [[TMP5]], i64 [[TMP7]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[A]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = tail call i64 @llvm.kvx.srld(i64 [[TMP9]], i64 [[CONV]])
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP8]], i64 [[TMP10]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP11]]
//
v4i64 shrdqs(v4i64 a, unsigned int b) {
  return __builtin_kvx_shrdqs(a, b);
}

// CHECK-LABEL: @shrdqsimm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @llvm.kvx.srld(i64 [[TMP0]], i64 3)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <4 x i64> undef, i64 [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.kvx.srld(i64 [[TMP3]], i64 3)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <4 x i64> [[TMP2]], i64 [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[A]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = tail call i64 @llvm.kvx.srld(i64 [[TMP6]], i64 3)
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x i64> [[TMP5]], i64 [[TMP7]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[A]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = tail call i64 @llvm.kvx.srld(i64 [[TMP9]], i64 3)
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> [[TMP8]], i64 [[TMP10]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP11]]
//
v4i64 shrdqsimm(v4i64 a) { return __builtin_kvx_shrdqs(a, 3); }

/**
 * TODO Reintroduce srshqs - srsdqsimm once string modifier is there
 */

// v4i16 srshqs(v4i16 a, unsigned int b) {
//   return __builtin_kvx_srshqs(a, b);
// }

// v4i16 srshqsimm(v4i16 a) { return __builtin_kvx_srshqs(a, 3); }

// v8i16 srshos(v8i16 a, unsigned int b) {
//   return __builtin_kvx_srshos(a, b);
// }

// v8i16 srshosimm(v8i16 a) { return __builtin_kvx_srshos(a, 3); }

// v16i16 srshxs(v16i16 a, unsigned int b) {
//   return __builtin_kvx_srshxs(a, b);
// }

// v16i16 srshxsimm(v16i16 a) { return __builtin_kvx_srshxs(a, 3); }

// v2i32 srswps(v2i32 a, unsigned int b) {
//   return __builtin_kvx_srswps(a, b);
// }

// v2i32 srswpsimm(v2i32 a) { return __builtin_kvx_srswps(a, 3); }

// v4i32 srswqs(v4i32 a, unsigned int b) {
//   return __builtin_kvx_srswqs(a, b);
// }

// v4i32 srswqsimm(v4i32 a) { return __builtin_kvx_srswqs(a, 3); }

// v8i32 srswos(v8i32 a, unsigned int b) {
//   return __builtin_kvx_srswos(a, b);
// }

// v8i32 srswosimm(v8i32 a) { return __builtin_kvx_srswos(a, 3); }

// v2i64 srsdps(v2i64 a, unsigned int b) {
//   return __builtin_kvx_srsdps(a, b);
// }

// v2i64 srsdpsimm(v2i64 a) { return __builtin_kvx_srsdps(a, 3); }

// v4i64 srsdqs(v4i64 a, unsigned int b) {
//   return __builtin_kvx_srsdqs(a, b);
// }

// v4i64 srsdqsimm(v4i64 a) { return __builtin_kvx_shrdqs(a, 3); }

// CHECK-LABEL: @floatdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[A:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP0]], i64 63, i32 0, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[A]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP3]], i64 63, i32 0, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = bitcast <2 x double> [[TMP5]] to <2 x i64>
// CHECK-NEXT:    ret <2 x i64> [[TMP6]]
//
v2i64 floatdp(v2i64 a) { return  __builtin_kvx_floatdp(a, 63, ".rn"); }
