// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple kvx-kalray-cos -S -O2 -emit-llvm -o - %s | FileCheck %s

typedef int __attribute__((__vector_size__(8))) v2i32;
typedef short __attribute__((__vector_size__(4 * sizeof(short)))) v4i16;
typedef short __attribute__((__vector_size__(8 * sizeof(short)))) v8i16;
typedef short __attribute__((__vector_size__(16 * sizeof(short)))) v16i16;
typedef int __attribute__((__vector_size__(2 * sizeof(int)))) v2i32;
typedef int __attribute__((__vector_size__(4 * sizeof(int)))) v4i32;
typedef int __attribute__((__vector_size__(8 * sizeof(int)))) v8i32;
typedef long __attribute__((__vector_size__(2 * sizeof(long)))) v2i64;
typedef long __attribute__((__vector_size__(4 * sizeof(long)))) v4i64;

typedef unsigned int __attribute__((__vector_size__(2 * sizeof(unsigned int))))
v2u32;
typedef unsigned int __attribute__((__vector_size__(4 * sizeof(unsigned int))))
v4u32;
typedef unsigned int __attribute__((__vector_size__(8 * sizeof(unsigned int))))
v8u32;

typedef unsigned long
    __attribute__((__vector_size__(2 * sizeof(unsigned long)))) v2u64;
typedef unsigned long
    __attribute__((__vector_size__(4 * sizeof(unsigned long)))) v4u64;

typedef float __attribute__((__vector_size__(2 * sizeof(float)))) v2f32;
typedef float __attribute__((__vector_size__(4 * sizeof(float)))) v4f32;
typedef float __attribute__((__vector_size__(8 * sizeof(float)))) v8f32;

typedef double __attribute__((__vector_size__(2 * sizeof(double)))) v2f64;
typedef double __attribute__((__vector_size__(4 * sizeof(double)))) v4f64;

// CHECK-LABEL: @ctzwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.ctzwp(<2 x i32> [[V:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 ctzwp(v2i32 v) {
  return __builtin_kvx_ctzwp(v);
}

// CHECK-LABEL: @clzwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.clzwp(<2 x i32> [[V:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 clzwp(v2i32 v) {
  return __builtin_kvx_clzwp(v);
}

// CHECK-LABEL: @clswp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.clswp(<2 x i32> [[V:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 clswp(v2i32 v) {
  return __builtin_kvx_clswp(v);
}

// CHECK-LABEL: @cbswp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.cbswp(<2 x i32> [[V:%.*]])
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 cbswp(v2i32 v) {
  return __builtin_kvx_cbswp(v);
}

// CHECK-LABEL: @selecthq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x i16> @llvm.kvx.cmovehq(<4 x i16> [[V1:%.*]], <4 x i16> [[V2:%.*]], <4 x i16> [[C:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x i16> [[TMP0]]
//
v4i16 selecthq(v4i16 v1, v4i16 v2, v4i16 c) {
  return __builtin_kvx_selecthq(v1, v2, c, ".nez");
}

// CHECK-LABEL: @selectho(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i16> [[V1:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i16> [[V2:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i16> [[C:%.*]], <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.cmovehq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]], <4 x i16> [[TMP2]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i16> [[V1]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x i16> [[V2]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x i16> [[C]], <8 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x i16> @llvm.kvx.cmovehq(<4 x i16> [[TMP4]], <4 x i16> [[TMP5]], <4 x i16> [[TMP6]], i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x i16> [[TMP3]], <4 x i16> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x i16> [[TMP8]]
//
v8i16 selectho(v8i16 v1, v8i16 v2, v8i16 c) {
  return __builtin_kvx_selectho(v1, v2, c, ".nez");
}

// CHECK-LABEL: @selecthx(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <16 x i16> [[V1:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <16 x i16> [[V2:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <16 x i16> [[C:%.*]], <16 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x i16> @llvm.kvx.cmovehq(<4 x i16> [[TMP0]], <4 x i16> [[TMP1]], <4 x i16> [[TMP2]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <16 x i16> [[V1]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <16 x i16> [[V2]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <16 x i16> [[C]], <16 x i16> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x i16> @llvm.kvx.cmovehq(<4 x i16> [[TMP4]], <4 x i16> [[TMP5]], <4 x i16> [[TMP6]], i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x i16> [[TMP3]], <4 x i16> [[TMP7]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <16 x i16> [[V1]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <16 x i16> [[V2]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <16 x i16> [[C]], <16 x i16> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
// CHECK-NEXT:    [[TMP12:%.*]] = tail call <4 x i16> @llvm.kvx.cmovehq(<4 x i16> [[TMP9]], <4 x i16> [[TMP10]], <4 x i16> [[TMP11]], i32 0)
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <4 x i16> [[TMP12]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP14:%.*]] = shufflevector <16 x i16> [[TMP8]], <16 x i16> [[TMP13]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <16 x i16> [[V1]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <16 x i16> [[V2]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP17:%.*]] = shufflevector <16 x i16> [[C]], <16 x i16> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
// CHECK-NEXT:    [[TMP18:%.*]] = tail call <4 x i16> @llvm.kvx.cmovehq(<4 x i16> [[TMP15]], <4 x i16> [[TMP16]], <4 x i16> [[TMP17]], i32 0)
// CHECK-NEXT:    [[TMP19:%.*]] = shufflevector <4 x i16> [[TMP18]], <4 x i16> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP20:%.*]] = shufflevector <16 x i16> [[TMP14]], <16 x i16> [[TMP19]], <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 16, i32 17, i32 18, i32 19>
// CHECK-NEXT:    ret <16 x i16> [[TMP20]]
//
v16i16 selecthx(v16i16 v1, v16i16 v2, v16i16 c) {
  return __builtin_kvx_selecthx(v1, v2, c, ".nez");
}

// CHECK-LABEL: @selectwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[V1:%.*]], <2 x i32> [[V2:%.*]], <2 x i32> [[C:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 selectwp(v2i32 v1, v2i32 v2, v2i32 c) {
  return __builtin_kvx_selectwp(v1, v2, c, ".nez");
}

// CHECK-LABEL: @selectwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[V1:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x i32> [[V2:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[C:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]], <2 x i32> [[TMP2]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[V1]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <4 x i32> [[V2]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x i32> [[C]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP4]], <2 x i32> [[TMP5]], <2 x i32> [[TMP6]], i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x i32> [[TMP3]], <2 x i32> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP8]]
//
v4i32 selectwq(v4i32 v1, v4i32 v2, v4i32 c) {
  return __builtin_kvx_selectwq(v1, v2, c, ".nez");
}

// CHECK-LABEL: @selectwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[V1:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x i32> [[V2:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[C:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]], <2 x i32> [[TMP2]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[V1]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x i32> [[V2]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x i32> [[C]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP4]], <2 x i32> [[TMP5]], <2 x i32> [[TMP6]], i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x i32> [[TMP3]], <2 x i32> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i32> [[V1]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <8 x i32> [[V2]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[C]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP12:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP9]], <2 x i32> [[TMP10]], <2 x i32> [[TMP11]], i32 0)
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <2 x i32> [[TMP12]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP14:%.*]] = shufflevector <8 x i32> [[TMP8]], <8 x i32> [[TMP13]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <8 x i32> [[V1]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x i32> [[V2]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP17:%.*]] = shufflevector <8 x i32> [[C]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP18:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP15]], <2 x i32> [[TMP16]], <2 x i32> [[TMP17]], i32 0)
// CHECK-NEXT:    [[TMP19:%.*]] = shufflevector <2 x i32> [[TMP18]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP20:%.*]] = shufflevector <8 x i32> [[TMP14]], <8 x i32> [[TMP19]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP20]]
//
v8i32 selectwo(v8i32 v1, v8i32 v2, v8i32 c) {
  return __builtin_kvx_selectwo(v1, v2, c, ".nez");
}

// CHECK-LABEL: @selectdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V1:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[V2:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i64> [[C:%.*]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @llvm.kvx.cmoved(i64 [[TMP0]], i64 [[TMP1]], i64 [[TMP2]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> undef, i64 [[TMP3]], i64 0
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x i64> [[V1]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <2 x i64> [[V2]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <2 x i64> [[C]], i64 1
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.cmoved(i64 [[TMP5]], i64 [[TMP6]], i64 [[TMP7]], i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <2 x i64> [[TMP4]], i64 [[TMP8]], i64 1
// CHECK-NEXT:    ret <2 x i64> [[TMP9]]
//
v2i64 selectdp(v2i64 v1, v2i64 v2, v2i64 c) {
  return __builtin_kvx_selectdp(v1, v2, c, ".nez");
}

// CHECK-LABEL: @selectdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V1:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i64> [[V2:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i64> [[C:%.*]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @llvm.kvx.cmoved(i64 [[TMP0]], i64 [[TMP1]], i64 [[TMP2]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = insertelement <4 x i64> undef, i64 [[TMP3]], i64 0
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <4 x i64> [[V1]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V2]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x i64> [[C]], i64 1
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.cmoved(i64 [[TMP5]], i64 [[TMP6]], i64 [[TMP7]], i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> [[TMP4]], i64 [[TMP8]], i64 1
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x i64> [[V1]], i64 2
// CHECK-NEXT:    [[TMP11:%.*]] = extractelement <4 x i64> [[V2]], i64 2
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <4 x i64> [[C]], i64 2
// CHECK-NEXT:    [[TMP13:%.*]] = tail call i64 @llvm.kvx.cmoved(i64 [[TMP10]], i64 [[TMP11]], i64 [[TMP12]], i32 0)
// CHECK-NEXT:    [[TMP14:%.*]] = insertelement <4 x i64> [[TMP9]], i64 [[TMP13]], i64 2
// CHECK-NEXT:    [[TMP15:%.*]] = extractelement <4 x i64> [[V1]], i64 3
// CHECK-NEXT:    [[TMP16:%.*]] = extractelement <4 x i64> [[V2]], i64 3
// CHECK-NEXT:    [[TMP17:%.*]] = extractelement <4 x i64> [[C]], i64 3
// CHECK-NEXT:    [[TMP18:%.*]] = tail call i64 @llvm.kvx.cmoved(i64 [[TMP15]], i64 [[TMP16]], i64 [[TMP17]], i32 0)
// CHECK-NEXT:    [[TMP19:%.*]] = insertelement <4 x i64> [[TMP14]], i64 [[TMP18]], i64 3
// CHECK-NEXT:    ret <4 x i64> [[TMP19]]
//
v4i64 selectdq(v4i64 v1, v4i64 v2, v4i64 c) {
  return __builtin_kvx_selectdq(v1, v2, c, ".nez");
}

// CHECK-LABEL: @selectfwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <2 x float> [[V1:%.*]] to <2 x i32>
// CHECK-NEXT:    [[TMP1:%.*]] = bitcast <2 x float> [[V2:%.*]] to <2 x i32>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP0]], <2 x i32> [[TMP1]], <2 x i32> [[C:%.*]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = bitcast <2 x i32> [[TMP2]] to <2 x float>
// CHECK-NEXT:    ret <2 x float> [[TMP3]]
//
v2f32 selectfwp(v2f32 v1, v2f32 v2, v2i32 c) {
  return __builtin_kvx_selectfwp(v1, v2, c, ".nez");
}

// CHECK-LABEL: @selectfwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[V1:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x float> [[V2:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = bitcast <2 x float> [[TMP0]] to <2 x i32>
// CHECK-NEXT:    [[TMP3:%.*]] = bitcast <2 x float> [[TMP1]] to <2 x i32>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x i32> [[C:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP2]], <2 x i32> [[TMP3]], <2 x i32> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = bitcast <2 x i32> [[TMP5]] to <2 x float>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <4 x float> [[V1]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x float> [[V2]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP9:%.*]] = bitcast <2 x float> [[TMP7]] to <2 x i32>
// CHECK-NEXT:    [[TMP10:%.*]] = bitcast <2 x float> [[TMP8]] to <2 x i32>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <4 x i32> [[C]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP12:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP9]], <2 x i32> [[TMP10]], <2 x i32> [[TMP11]], i32 0)
// CHECK-NEXT:    [[TMP13:%.*]] = bitcast <2 x i32> [[TMP12]] to <2 x float>
// CHECK-NEXT:    [[TMP14:%.*]] = shufflevector <2 x float> [[TMP6]], <2 x float> [[TMP13]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x float> [[TMP14]]
//
v4f32 selectfwq(v4f32 v1, v4f32 v2, v4i32 c) {
  return __builtin_kvx_selectfwq(v1, v2, c, ".nez");
}

// CHECK-LABEL: @selectfwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = bitcast <2 x float> [[TMP0]] to <2 x i32>
// CHECK-NEXT:    [[TMP3:%.*]] = bitcast <2 x float> [[TMP1]] to <2 x i32>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x i32> [[C:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP2]], <2 x i32> [[TMP3]], <2 x i32> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = bitcast <2 x i32> [[TMP5]] to <2 x float>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP9:%.*]] = bitcast <2 x float> [[TMP7]] to <2 x i32>
// CHECK-NEXT:    [[TMP10:%.*]] = bitcast <2 x float> [[TMP8]] to <2 x i32>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x i32> [[C]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP12:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP9]], <2 x i32> [[TMP10]], <2 x i32> [[TMP11]], i32 0)
// CHECK-NEXT:    [[TMP13:%.*]] = bitcast <2 x i32> [[TMP12]] to <2 x float>
// CHECK-NEXT:    [[TMP14:%.*]] = shufflevector <2 x float> [[TMP6]], <2 x float> [[TMP13]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP17:%.*]] = bitcast <2 x float> [[TMP15]] to <2 x i32>
// CHECK-NEXT:    [[TMP18:%.*]] = bitcast <2 x float> [[TMP16]] to <2 x i32>
// CHECK-NEXT:    [[TMP19:%.*]] = shufflevector <8 x i32> [[C]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP20:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP17]], <2 x i32> [[TMP18]], <2 x i32> [[TMP19]], i32 0)
// CHECK-NEXT:    [[TMP21:%.*]] = bitcast <2 x i32> [[TMP20]] to <2 x float>
// CHECK-NEXT:    [[TMP22:%.*]] = shufflevector <2 x float> [[TMP21]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP23:%.*]] = shufflevector <8 x float> [[TMP14]], <8 x float> [[TMP22]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP24:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP25:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP26:%.*]] = bitcast <2 x float> [[TMP24]] to <2 x i32>
// CHECK-NEXT:    [[TMP27:%.*]] = bitcast <2 x float> [[TMP25]] to <2 x i32>
// CHECK-NEXT:    [[TMP28:%.*]] = shufflevector <8 x i32> [[C]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP29:%.*]] = tail call <2 x i32> @llvm.kvx.cmovewp(<2 x i32> [[TMP26]], <2 x i32> [[TMP27]], <2 x i32> [[TMP28]], i32 0)
// CHECK-NEXT:    [[TMP30:%.*]] = bitcast <2 x i32> [[TMP29]] to <2 x float>
// CHECK-NEXT:    [[TMP31:%.*]] = shufflevector <2 x float> [[TMP30]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP32:%.*]] = shufflevector <8 x float> [[TMP23]], <8 x float> [[TMP31]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x float> [[TMP32]]
//
v8f32 selectfwo(v8f32 v1, v8f32 v2, v8i32 c) {
  return __builtin_kvx_selectfwo(v1, v2, c, ".nez");
}

// CHECK-LABEL: @selectfdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[BC:%.*]] = bitcast <2 x double> [[V1:%.*]] to <2 x i64>
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[BC]], i64 0
// CHECK-NEXT:    [[BC1:%.*]] = bitcast <2 x double> [[V2:%.*]] to <2 x i64>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[BC1]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i64> [[C:%.*]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @llvm.kvx.cmoved(i64 [[TMP0]], i64 [[TMP1]], i64 [[TMP2]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> undef, i64 [[TMP3]], i64 0
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x i64> [[BC]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <2 x i64> [[BC1]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <2 x i64> [[C]], i64 1
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.cmoved(i64 [[TMP5]], i64 [[TMP6]], i64 [[TMP7]], i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <2 x i64> [[TMP4]], i64 [[TMP8]], i64 1
// CHECK-NEXT:    [[TMP10:%.*]] = bitcast <2 x i64> [[TMP9]] to <2 x double>
// CHECK-NEXT:    ret <2 x double> [[TMP10]]
//
v2f64 selectfdp(v2f64 v1, v2f64 v2, v2i64 c) {
  return __builtin_kvx_selectfdp(v1, v2, c, ".nez");
}

// CHECK-LABEL: @selectfdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[BC:%.*]] = bitcast <4 x double> [[V1:%.*]] to <4 x i64>
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[BC]], i64 0
// CHECK-NEXT:    [[BC1:%.*]] = bitcast <4 x double> [[V2:%.*]] to <4 x i64>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i64> [[BC1]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i64> [[C:%.*]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @llvm.kvx.cmoved(i64 [[TMP0]], i64 [[TMP1]], i64 [[TMP2]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = insertelement <4 x i64> undef, i64 [[TMP3]], i64 0
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <4 x i64> [[BC]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[BC1]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x i64> [[C]], i64 1
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.cmoved(i64 [[TMP5]], i64 [[TMP6]], i64 [[TMP7]], i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> [[TMP4]], i64 [[TMP8]], i64 1
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x i64> [[BC]], i64 2
// CHECK-NEXT:    [[TMP11:%.*]] = extractelement <4 x i64> [[BC1]], i64 2
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <4 x i64> [[C]], i64 2
// CHECK-NEXT:    [[TMP13:%.*]] = tail call i64 @llvm.kvx.cmoved(i64 [[TMP10]], i64 [[TMP11]], i64 [[TMP12]], i32 0)
// CHECK-NEXT:    [[TMP14:%.*]] = insertelement <4 x i64> [[TMP9]], i64 [[TMP13]], i64 2
// CHECK-NEXT:    [[TMP15:%.*]] = extractelement <4 x i64> [[BC]], i64 3
// CHECK-NEXT:    [[TMP16:%.*]] = extractelement <4 x i64> [[BC1]], i64 3
// CHECK-NEXT:    [[TMP17:%.*]] = extractelement <4 x i64> [[C]], i64 3
// CHECK-NEXT:    [[TMP18:%.*]] = tail call i64 @llvm.kvx.cmoved(i64 [[TMP15]], i64 [[TMP16]], i64 [[TMP17]], i32 0)
// CHECK-NEXT:    [[TMP19:%.*]] = insertelement <4 x i64> [[TMP14]], i64 [[TMP18]], i64 3
// CHECK-NEXT:    [[TMP20:%.*]] = bitcast <4 x i64> [[TMP19]] to <4 x double>
// CHECK-NEXT:    ret <4 x double> [[TMP20]]
//
v4f64 selectfdq(v4f64 v1, v4f64 v2, v4i64 c) {
  return __builtin_kvx_selectfdq(v1, v2, c, ".nez");
}

// CHECK-LABEL: @fabswp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fabswp(<2 x float> [[V:%.*]])
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fabswp(v2f32 v) {
  return __builtin_kvx_fabswp(v);
}

// CHECK-LABEL: @fabswq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[V:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.fabswp(<2 x float> [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x float> [[V]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.fabswp(<2 x float> [[TMP2]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x float> [[TMP4]]
//
v4f32 fabswq(v4f32 v) {
  return __builtin_kvx_fabswq(v);
}

// CHECK-LABEL: @fabswo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.fabswp(<2 x float> [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.fabswp(<2 x float> [[TMP2]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x float> @llvm.kvx.fabswp(<2 x float> [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x float> [[TMP6]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x float> [[TMP4]], <8 x float> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x float> @llvm.kvx.fabswp(<2 x float> [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x float> [[TMP10]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x float> [[TMP8]], <8 x float> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x float> [[TMP12]]
//
v8f32 fabswo(v8f32 v) {
  return __builtin_kvx_fabswo(v);
}

// CHECK-LABEL: @fabsdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x double> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.fabsd(double [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x double> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.fabsd(double [[TMP3]])
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    ret <2 x double> [[TMP5]]
//
v2f64 fabsdp(v2f64 v) {
  return __builtin_kvx_fabsdp(v);
}

// CHECK-LABEL: @fabsdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x double> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.fabsd(double [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <4 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x double> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.fabsd(double [[TMP3]])
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <4 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x double> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = tail call double @llvm.kvx.fabsd(double [[TMP6]])
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x double> [[TMP5]], double [[TMP7]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x double> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = tail call double @llvm.kvx.fabsd(double [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x double> [[TMP8]], double [[TMP10]], i64 3
// CHECK-NEXT:    ret <4 x double> [[TMP11]]
//
v4f64 fabsdq(v4f64 v) {
  return __builtin_kvx_fabsdq(v);
}

// CHECK-LABEL: @fnegwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fnegwp(<2 x float> [[V:%.*]])
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fnegwp(v2f32 v) {
  return __builtin_kvx_fnegwp(v);
}

// CHECK-LABEL: @fnegwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[V:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.fnegwp(<2 x float> [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x float> [[V]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.fnegwp(<2 x float> [[TMP2]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x float> [[TMP4]]
//
v4f32 fnegwq(v4f32 v) {
  return __builtin_kvx_fnegwq(v);
}

// CHECK-LABEL: @fnegwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.fnegwp(<2 x float> [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.fnegwp(<2 x float> [[TMP2]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x float> @llvm.kvx.fnegwp(<2 x float> [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x float> [[TMP6]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x float> [[TMP4]], <8 x float> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x float> @llvm.kvx.fnegwp(<2 x float> [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x float> [[TMP10]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x float> [[TMP8]], <8 x float> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x float> [[TMP12]]
//
v8f32 fnegwo(v8f32 v) {
  return __builtin_kvx_fnegwo(v);
}

// CHECK-LABEL: @fnegdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x double> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.fnegd(double [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x double> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.fnegd(double [[TMP3]])
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    ret <2 x double> [[TMP5]]
//
v2f64 fnegdp(v2f64 v) {
  return __builtin_kvx_fnegdp(v);
}

// CHECK-LABEL: @fnegdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x double> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.fnegd(double [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <4 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x double> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.fnegd(double [[TMP3]])
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <4 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x double> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = tail call double @llvm.kvx.fnegd(double [[TMP6]])
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x double> [[TMP5]], double [[TMP7]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x double> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = tail call double @llvm.kvx.fnegd(double [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x double> [[TMP8]], double [[TMP10]], i64 3
// CHECK-NEXT:    ret <4 x double> [[TMP11]]
//
v4f64 fnegdq(v4f64 v) {
  return __builtin_kvx_fnegdq(v);
}

// CHECK-LABEL: @fmaxwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fmaxwp(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]])
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fmaxwp(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_fmaxwp(v1, v2);
}

// CHECK-LABEL: @fmaxwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[V1:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.fmaxwp(<2 x float> [[TMP0]], <2 x float> [[TMP0]])
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x float> [[V1]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.fmaxwp(<2 x float> [[TMP2]], <2 x float> [[TMP2]])
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x float> [[TMP4]]
//
v4f32 fmaxwq(v4f32 v1, v4f32 v2) {
  return __builtin_kvx_fmaxwq(v1, v1);
}

// CHECK-LABEL: @fmaxwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x float> @llvm.kvx.fmaxwp(<2 x float> [[TMP0]], <2 x float> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x float> @llvm.kvx.fmaxwp(<2 x float> [[TMP3]], <2 x float> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x float> [[TMP2]], <2 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x float> @llvm.kvx.fmaxwp(<2 x float> [[TMP7]], <2 x float> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x float> [[TMP9]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x float> [[TMP6]], <8 x float> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x float> @llvm.kvx.fmaxwp(<2 x float> [[TMP12]], <2 x float> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x float> [[TMP14]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x float> [[TMP11]], <8 x float> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x float> [[TMP16]]
//
v8f32 fmaxwo(v8f32 v1, v8f32 v2) {
  return __builtin_kvx_fmaxwo(v1, v2);
}

// CHECK-LABEL: @fmaxdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x double> [[V1:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x double> [[V2:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call double @llvm.kvx.fmaxd(double [[TMP0]], double [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x double> undef, double [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x double> [[V1]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x double> [[V2]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call double @llvm.kvx.fmaxd(double [[TMP4]], double [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x double> [[TMP3]], double [[TMP6]], i64 1
// CHECK-NEXT:    ret <2 x double> [[TMP7]]
//
v2f64 fmaxdp(v2f64 v1, v2f64 v2) {
  return __builtin_kvx_fmaxdp(v1, v2);
}

// CHECK-LABEL: @fmaxdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x double> [[V1:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x double> [[V2:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call double @llvm.kvx.fmaxd(double [[TMP0]], double [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <4 x double> undef, double [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x double> [[V1]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <4 x double> [[V2]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call double @llvm.kvx.fmaxd(double [[TMP4]], double [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <4 x double> [[TMP3]], double [[TMP6]], i64 1
// CHECK-NEXT:    [[TMP8:%.*]] = extractelement <4 x double> [[V1]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x double> [[V2]], i64 2
// CHECK-NEXT:    [[TMP10:%.*]] = tail call double @llvm.kvx.fmaxd(double [[TMP8]], double [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x double> [[TMP7]], double [[TMP10]], i64 2
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <4 x double> [[V1]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = extractelement <4 x double> [[V2]], i64 3
// CHECK-NEXT:    [[TMP14:%.*]] = tail call double @llvm.kvx.fmaxd(double [[TMP12]], double [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x double> [[TMP11]], double [[TMP14]], i64 3
// CHECK-NEXT:    ret <4 x double> [[TMP15]]
//
v4f64 fmaxdq(v4f64 v1, v4f64 v2) {
  return __builtin_kvx_fmaxdq(v1, v2);
}

// CHECK-LABEL: @fminwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fminwp(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]])
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fminwp(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_fminwp(v1, v2);
}

// CHECK-LABEL: @fminwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[V1:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x float> [[V2:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x float> @llvm.kvx.fminwp(<2 x float> [[TMP0]], <2 x float> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x float> [[V1]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x float> [[V2]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x float> @llvm.kvx.fminwp(<2 x float> [[TMP3]], <2 x float> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x float> [[TMP2]], <2 x float> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x float> [[TMP6]]
//
v4f32 fminwq(v4f32 v1, v4f32 v2) {
  return __builtin_kvx_fminwq(v1, v2);
}

// CHECK-LABEL: @fminwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x float> @llvm.kvx.fminwp(<2 x float> [[TMP0]], <2 x float> [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x float> @llvm.kvx.fminwp(<2 x float> [[TMP3]], <2 x float> [[TMP4]])
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x float> [[TMP2]], <2 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP9:%.*]] = tail call <2 x float> @llvm.kvx.fminwp(<2 x float> [[TMP7]], <2 x float> [[TMP8]])
// CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <2 x float> [[TMP9]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <8 x float> [[TMP6]], <8 x float> [[TMP10]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP14:%.*]] = tail call <2 x float> @llvm.kvx.fminwp(<2 x float> [[TMP12]], <2 x float> [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = shufflevector <2 x float> [[TMP14]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <8 x float> [[TMP11]], <8 x float> [[TMP15]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x float> [[TMP16]]
//
v8f32 fminwo(v8f32 v1, v8f32 v2) {
  return __builtin_kvx_fminwo(v1, v2);
}

// CHECK-LABEL: @fmindp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x double> [[V1:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x double> [[V2:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call double @llvm.kvx.fmind(double [[TMP0]], double [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x double> undef, double [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x double> [[V1]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x double> [[V2]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call double @llvm.kvx.fmind(double [[TMP4]], double [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x double> [[TMP3]], double [[TMP6]], i64 1
// CHECK-NEXT:    ret <2 x double> [[TMP7]]
//
v2f64 fmindp(v2f64 v1, v2f64 v2) {
  return __builtin_kvx_fmindp(v1, v2);
}

// CHECK-LABEL: @fmindq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x double> [[V1:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x double> [[V2:%.*]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call double @llvm.kvx.fmind(double [[TMP0]], double [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <4 x double> undef, double [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x double> [[V1]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = extractelement <4 x double> [[V2]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = tail call double @llvm.kvx.fmind(double [[TMP4]], double [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = insertelement <4 x double> [[TMP3]], double [[TMP6]], i64 1
// CHECK-NEXT:    [[TMP8:%.*]] = extractelement <4 x double> [[V1]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x double> [[V2]], i64 2
// CHECK-NEXT:    [[TMP10:%.*]] = tail call double @llvm.kvx.fmind(double [[TMP8]], double [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x double> [[TMP7]], double [[TMP10]], i64 2
// CHECK-NEXT:    [[TMP12:%.*]] = extractelement <4 x double> [[V1]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = extractelement <4 x double> [[V2]], i64 3
// CHECK-NEXT:    [[TMP14:%.*]] = tail call double @llvm.kvx.fmind(double [[TMP12]], double [[TMP13]])
// CHECK-NEXT:    [[TMP15:%.*]] = insertelement <4 x double> [[TMP11]], double [[TMP14]], i64 3
// CHECK-NEXT:    ret <4 x double> [[TMP15]]
//
v4f64 fmindq(v4f64 v1, v4f64 v2) {
  return __builtin_kvx_fmindq(v1, v2);
}

// CHECK-LABEL: @faddwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.faddwp(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 faddwp(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_faddwp(v1, v2, ".rn");
}

// CHECK-LABEL: @faddwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.faddwq(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 faddwq(v4f32 v1, v4f32 v2) {
  return __builtin_kvx_faddwq(v1, v2, ".rn");
}

// CHECK-LABEL: @faddwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.faddwq(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.faddwq(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
v8f32 faddwo(v8f32 v1, v8f32 v2) {
  return __builtin_kvx_faddwo(v1, v2, ".rn");
}

// CHECK-LABEL: @fadddp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fadddp(<2 x double> [[V1:%.*]], <2 x double> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 fadddp(v2f64 v1, v2f64 v2) {
  return __builtin_kvx_fadddp(v1, v2, ".rn");
}

// CHECK-LABEL: @fadddq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V1:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[V2:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fadddp(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[V1]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[V2]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fadddp(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
v4f64 fadddq(v4f64 v1, v4f64 v2) {
  return __builtin_kvx_fadddq(v1, v2, ".rn");
}

// CHECK-LABEL: @faddcwc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.faddcwc(<2 x float> [[V1:%.*]], <2 x float> [[V1]], i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 faddcwc(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_faddcwc(v1, v1, ".rn");
}

// CHECK-LABEL: @faddcwcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.faddcwcp(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 faddcwcp(v4f32 v1, v4f32 v2) {
  return __builtin_kvx_faddcwcp(v1, v2, ".rn");
}

// CHECK-LABEL: @faddcwcq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.faddcwcp(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.faddcwcp(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
v8f32 faddcwcq(v8f32 v1, v8f32 v2) {
  return __builtin_kvx_faddcwcq(v1, v2, ".rn");
}

// CHECK-LABEL: @faddcdc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.faddcdc(<2 x double> [[V1:%.*]], <2 x double> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 faddcdc(v2f64 v1, v2f64 v2) {
  return __builtin_kvx_faddcdc(v1, v2, ".rn");
}

// CHECK-LABEL: @faddcdcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V1:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[V2:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.faddcdc(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[V1]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[V2]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.faddcdc(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
v4f64 faddcdcp(v4f64 v1, v4f64 v2) {
  return __builtin_kvx_faddcdcp(v1, v2, ".rn");
}

// CHECK-LABEL: @fsbfwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fsbfwp(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fsbfwp(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_fsbfwp(v1, v2, ".rn");
}

// CHECK-LABEL: @fsbfwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fsbfwq(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fsbfwq(v4f32 v1, v4f32 v2) {
  return __builtin_kvx_fsbfwq(v1, v2, ".rn");
}

// CHECK-LABEL: @fsbfwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fsbfwq(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fsbfwq(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
v8f32 fsbfwo(v8f32 v1, v8f32 v2) {
  return __builtin_kvx_fsbfwo(v1, v2, ".rn");
}

// CHECK-LABEL: @fsbfdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fsbfdp(<2 x double> [[V1:%.*]], <2 x double> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 fsbfdp(v2f64 v1, v2f64 v2) {
  return __builtin_kvx_fsbfdp(v1, v2, ".rn");
}

// CHECK-LABEL: @fsbfdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V1:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[V2:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fsbfdp(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[V1]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[V2]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fsbfdp(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
v4f64 fsbfdq(v4f64 v1, v4f64 v2) {
  return __builtin_kvx_fsbfdq(v1, v2, ".rn");
}

// CHECK-LABEL: @fsbfcwc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fsbfcwc(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fsbfcwc(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_fsbfcwc(v1, v2, ".rn");
}

// CHECK-LABEL: @fsbfcwcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fsbfcwcp(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fsbfcwcp(v4f32 v1, v4f32 v2) {
  return __builtin_kvx_fsbfcwcp(v1, v2, ".rn");
}

// CHECK-LABEL: @fsbfcwcq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fsbfcwcp(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fsbfcwcp(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
v8f32 fsbfcwcq(v8f32 v1, v8f32 v2) {
  return __builtin_kvx_fsbfcwcq(v1, v2, ".rn");
}

// CHECK-LABEL: @fsbfcdc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fsbfcdc(<2 x double> [[V1:%.*]], <2 x double> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 fsbfcdc(v2f64 v1, v2f64 v2) {
  return __builtin_kvx_fsbfcdc(v1, v2, ".rn");
}

// CHECK-LABEL: @fsbfcdcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V1:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[V2:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fsbfcdc(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[V1]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[V2]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fsbfcdc(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
v4f64 fsbfcdcp(v4f64 v1, v4f64 v2) {
  return __builtin_kvx_fsbfcdcp(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fmulwp(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fmulwp(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_fmulwp(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fmulwq(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fmulwq(v4f32 v1, v4f32 v2) {
  return __builtin_kvx_fmulwq(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fmulwq(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fmulwq(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
v8f32 fmulwo(v8f32 v1, v8f32 v2) {
  return __builtin_kvx_fmulwo(v1, v2, ".rn");
}

// CHECK-LABEL: @fmuldp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fmuldp(<2 x double> [[V1:%.*]], <2 x double> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 fmuldp(v2f64 v1, v2f64 v2) {
  return __builtin_kvx_fmuldp(v1, v2, ".rn");
}

// CHECK-LABEL: @fmuldq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V1:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[V2:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fmuldp(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[V1]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[V2]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fmuldp(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
v4f64 fmuldq(v4f64 v1, v4f64 v2) {
  return __builtin_kvx_fmuldq(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulwc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fmulwc(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fmulwc(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_fmulwc(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulwcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fmulwcp(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fmulwcp(v4f32 v1, v4f32 v2) {
  return __builtin_kvx_fmulwcp(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulwcq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fmulwcp(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fmulwcp(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
v8f32 fmulwcq(v8f32 v1, v8f32 v2) {
  return __builtin_kvx_fmulwcq(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulcwc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.fmulcwc(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 fmulcwc(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_fmulcwc(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulcwcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fmulcwcp(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fmulcwcp(v4f32 v1, v4f32 v2) {
  return __builtin_kvx_fmulcwcp(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulcwcq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <4 x float> @llvm.kvx.fmulcwcp(<4 x float> [[TMP0]], <4 x float> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <4 x float> @llvm.kvx.fmulcwcp(<4 x float> [[TMP3]], <4 x float> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x float> [[TMP2]], <4 x float> [[TMP5]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP6]]
//
v8f32 fmulcwcq(v8f32 v1, v8f32 v2) {
  return __builtin_kvx_fmulcwcq(v1, v2, ".rn");
}

// CHECK-LABEL: @fmuldc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fmuldc(<2 x double> [[V1:%.*]], <2 x double> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 fmuldc(v2f64 v1, v2f64 v2) {
  return __builtin_kvx_fmuldc(v1, v2, ".rn");
}

// CHECK-LABEL: @fmuldcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V1:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[V2:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fmuldc(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[V1]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[V2]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fmuldc(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
v4f64 fmuldcp(v4f64 v1, v4f64 v2) {
  return __builtin_kvx_fmuldcp(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulcdc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.fmulcdc(<2 x double> [[V1:%.*]], <2 x double> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 fmulcdc(v2f64 v1, v2f64 v2) {
  return __builtin_kvx_fmulcdc(v1, v2, ".rn");
}

// CHECK-LABEL: @fmulcdcp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V1:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[V2:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <2 x double> @llvm.kvx.fmulcdc(<2 x double> [[TMP0]], <2 x double> [[TMP1]], i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = shufflevector <4 x double> [[V1]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[V2]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = tail call <2 x double> @llvm.kvx.fmulcdc(<2 x double> [[TMP3]], <2 x double> [[TMP4]], i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <2 x double> [[TMP2]], <2 x double> [[TMP5]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP6]]
//
v4f64 fmulcdcp(v4f64 v1, v4f64 v2) {
  return __builtin_kvx_fmulcdcp(v1, v2, ".rn");
}

// CHECK-LABEL: @fmm212w(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fmm212w(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fmm212w(v2f32 v1, v2f32 v2) {
  return __builtin_kvx_fmm212w(v1, v2, ".rn");
}

// CHECK-LABEL: @fmma212w(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fmma212w(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], <4 x float> [[V3:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fmma212w(v2f32 v1, v2f32 v2, v4f32 v3) {
  return __builtin_kvx_fmma212w(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @fmms212w(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.fmms212w(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], <4 x float> [[V3:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 fmms212w(v2f32 v1, v2f32 v2, v4f32 v3) {
  return __builtin_kvx_fmms212w(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmawp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.ffmawp(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], <2 x float> [[V3:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 ffmawp(v2f32 v1, v2f32 v2, v2f32 v3) {
  return __builtin_kvx_ffmawp(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmawq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.ffmawq(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], <4 x float> [[V3:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 ffmawq(v4f32 v1, v4f32 v2, v4f32 v3) {
  return __builtin_kvx_ffmawq(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmawo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V3:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x float> @llvm.kvx.ffmawq(<4 x float> [[TMP0]], <4 x float> [[TMP1]], <4 x float> [[TMP2]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x float> [[V3]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x float> @llvm.kvx.ffmawq(<4 x float> [[TMP4]], <4 x float> [[TMP5]], <4 x float> [[TMP6]], i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x float> [[TMP3]], <4 x float> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP8]]
//
v8f32 ffmawo(v8f32 v1, v8f32 v2, v8f32 v3) {
  return __builtin_kvx_ffmawo(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmadp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.ffmadp(<2 x double> [[V1:%.*]], <2 x double> [[V2:%.*]], <2 x double> [[V3:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 ffmadp(v2f64 v1, v2f64 v2, v2f64 v3) {
  return __builtin_kvx_ffmadp(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmadq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V1:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[V2:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x double> [[V3:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x double> @llvm.kvx.ffmadp(<2 x double> [[TMP0]], <2 x double> [[TMP1]], <2 x double> [[TMP2]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[V1]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <4 x double> [[V2]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x double> [[V3]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x double> @llvm.kvx.ffmadp(<2 x double> [[TMP4]], <2 x double> [[TMP5]], <2 x double> [[TMP6]], i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x double> [[TMP3]], <2 x double> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP8]]
//
v4f64 ffmadq(v4f64 v1, v4f64 v2, v4f64 v3) {
  return __builtin_kvx_ffmadq(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmswp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.ffmswp(<2 x float> [[V1:%.*]], <2 x float> [[V2:%.*]], <2 x float> [[V3:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 ffmswp(v2f32 v1, v2f32 v2, v2f32 v3) {
  return __builtin_kvx_ffmswp(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmswq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <4 x float> @llvm.kvx.ffmswq(<4 x float> [[V1:%.*]], <4 x float> [[V2:%.*]], <4 x float> [[V3:%.*]], i32 0)
// CHECK-NEXT:    ret <4 x float> [[TMP0]]
//
v4f32 ffmswq(v4f32 v1, v4f32 v2, v4f32 v3) {
  return __builtin_kvx_ffmswq(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmswo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V1:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <8 x float> [[V2:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V3:%.*]], <8 x float> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <4 x float> @llvm.kvx.ffmswq(<4 x float> [[TMP0]], <4 x float> [[TMP1]], <4 x float> [[TMP2]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <8 x float> [[V1]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x float> [[V2]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <8 x float> [[V3]], <8 x float> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <4 x float> @llvm.kvx.ffmswq(<4 x float> [[TMP4]], <4 x float> [[TMP5]], <4 x float> [[TMP6]], i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <4 x float> [[TMP3]], <4 x float> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
// CHECK-NEXT:    ret <8 x float> [[TMP8]]
//
v8f32 ffmswo(v8f32 v1, v8f32 v2, v8f32 v3) {
  return __builtin_kvx_ffmswo(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmsdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x double> @llvm.kvx.ffmsdp(<2 x double> [[V1:%.*]], <2 x double> [[V2:%.*]], <2 x double> [[V3:%.*]], i32 0)
// CHECK-NEXT:    ret <2 x double> [[TMP0]]
//
v2f64 ffmsdp(v2f64 v1, v2f64 v2, v2f64 v3) {
  return __builtin_kvx_ffmsdp(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @ffmsdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[V1:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[V2:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x double> [[V3:%.*]], <4 x double> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x double> @llvm.kvx.ffmsdp(<2 x double> [[TMP0]], <2 x double> [[TMP1]], <2 x double> [[TMP2]], i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <4 x double> [[V1]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <4 x double> [[V2]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <4 x double> [[V3]], <4 x double> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP7:%.*]] = tail call <2 x double> @llvm.kvx.ffmsdp(<2 x double> [[TMP4]], <2 x double> [[TMP5]], <2 x double> [[TMP6]], i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <2 x double> [[TMP3]], <2 x double> [[TMP7]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x double> [[TMP8]]
//
v4f64 ffmsdq(v4f64 v1, v4f64 v2, v4f64 v3) {
  return __builtin_kvx_ffmsdq(v1, v2, v3, ".rn");
}

// CHECK-LABEL: @floatwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[V:%.*]], i64 3, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 floatwp(v2i32 v) {
  return __builtin_kvx_floatwp(v, 3, ".rn");
}

// CHECK-LABEL: @floatwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[V:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP0]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[V]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP2]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x float> [[TMP4]]
//
v4f32 floatwq(v4i32 v) {
  return __builtin_kvx_floatwq(v, 3, ".rn");
}

// CHECK-LABEL: @floatwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[V:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP0]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP2]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP5]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x float> [[TMP6]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x float> [[TMP4]], <8 x float> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x float> @llvm.kvx.floatwp(<2 x i32> [[TMP9]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x float> [[TMP10]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x float> [[TMP8]], <8 x float> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x float> [[TMP12]]
//
v8f32 floatwo(v8i32 v) {
  return __builtin_kvx_floatwo(v, 3, ".rn");
}

// CHECK-LABEL: @floatdp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP0]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP3]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    ret <2 x double> [[TMP5]]
//
v2f64 floatdp(v2i64 v) {
  return __builtin_kvx_floatdp(v, 3, ".rn");
}

// CHECK-LABEL: @floatdq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP0]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <4 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP3]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <4 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP6]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x double> [[TMP5]], double [[TMP7]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = tail call double @llvm.kvx.floatd(i64 [[TMP9]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x double> [[TMP8]], double [[TMP10]], i64 3
// CHECK-NEXT:    ret <4 x double> [[TMP11]]
//
v4f64 floatdq(v4i64 v) {
  return __builtin_kvx_floatdq(v, 3, ".rn");
}

// CHECK-LABEL: @floatuwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[V:%.*]], i64 3, i32 0)
// CHECK-NEXT:    ret <2 x float> [[TMP0]]
//
v2f32 floatuwp(v2u32 v) {
  return __builtin_kvx_floatuwp(v, 3, ".rn");
}

// CHECK-LABEL: @floatuwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x i32> [[V:%.*]], <4 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[TMP0]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x i32> [[V]], <4 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[TMP2]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x float> [[TMP4]]
//
v4f32 floatuwq(v4u32 v) {
  return __builtin_kvx_floatuwq(v, 3, ".rn");
}

// CHECK-LABEL: @floatuwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x i32> [[V:%.*]], <8 x i32> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[TMP0]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[TMP2]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x float> [[TMP1]], <2 x float> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[TMP5]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x float> [[TMP6]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x float> [[TMP4]], <8 x float> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x i32> [[V]], <8 x i32> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x float> @llvm.kvx.floatuwp(<2 x i32> [[TMP9]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x float> [[TMP10]], <2 x float> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x float> [[TMP8]], <8 x float> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x float> [[TMP12]]
//
v8f32 floatuwo(v8u32 v) {
  return __builtin_kvx_floatuwo(v, 3, ".rn");
}

// CHECK-LABEL: @floatudp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <2 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.floatud(i64 [[TMP0]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <2 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.floatud(i64 [[TMP3]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    ret <2 x double> [[TMP5]]
//
v2f64 floatudp(v2u64 v) {
  return __builtin_kvx_floatudp(v, 3, ".rn");
}

// CHECK-LABEL: @floatudq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = extractelement <4 x i64> [[V:%.*]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = tail call double @llvm.kvx.floatud(i64 [[TMP0]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = insertelement <4 x double> undef, double [[TMP1]], i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = extractelement <4 x i64> [[V]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call double @llvm.kvx.floatud(i64 [[TMP3]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP5:%.*]] = insertelement <4 x double> [[TMP2]], double [[TMP4]], i64 1
// CHECK-NEXT:    [[TMP6:%.*]] = extractelement <4 x i64> [[V]], i64 2
// CHECK-NEXT:    [[TMP7:%.*]] = tail call double @llvm.kvx.floatud(i64 [[TMP6]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP8:%.*]] = insertelement <4 x double> [[TMP5]], double [[TMP7]], i64 2
// CHECK-NEXT:    [[TMP9:%.*]] = extractelement <4 x i64> [[V]], i64 3
// CHECK-NEXT:    [[TMP10:%.*]] = tail call double @llvm.kvx.floatud(i64 [[TMP9]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x double> [[TMP8]], double [[TMP10]], i64 3
// CHECK-NEXT:    ret <4 x double> [[TMP11]]
//
v4f64 floatudq(v4u64 v) {
  return __builtin_kvx_floatudq(v, 3, ".rn");
}

// CHECK-LABEL: @fixedwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[V:%.*]], i64 3, i32 0)
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2i32 fixedwp(v2f32 v) {
  return __builtin_kvx_fixedwp(v, 3, ".rn");
}

// CHECK-LABEL: @fixedwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[V:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP0]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x float> [[V]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP2]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4i32 fixedwq(v4f32 v) {
  return __builtin_kvx_fixedwq(v, 3, ".rn");
}

// CHECK-LABEL: @fixedwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP0]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP2]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP5]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x i32> [[TMP6]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[TMP4]], <8 x i32> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x i32> @llvm.kvx.fixedwp(<2 x float> [[TMP9]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x i32> [[TMP10]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[TMP8]], <8 x i32> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP12]]
//
v8i32 fixedwo(v8f32 v) {
  return __builtin_kvx_fixedwo(v, 3, ".rn");
}

// CHECK-LABEL: @fixeddp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <2 x i64> [[V:%.*]] to <2 x double>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x double> [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP1]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x double> [[TMP0]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP4]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = bitcast <2 x i64> [[TMP6]] to <2 x double>
// CHECK-NEXT:    ret <2 x double> [[TMP7]]
//
v2f64 fixeddp(v2i64 v) {
  return __builtin_kvx_fixeddp(v, 3, ".rn");
}

// CHECK-LABEL: @fixeddq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <4 x i64> [[V:%.*]] to <4 x double>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x double> [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP1]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <4 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x double> [[TMP0]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP4]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <4 x i64> [[TMP3]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x double> [[TMP0]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP7]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> [[TMP6]], i64 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x double> [[TMP0]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i64 @llvm.kvx.fixedd(double [[TMP10]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i64> [[TMP9]], i64 [[TMP11]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = bitcast <4 x i64> [[TMP12]] to <4 x double>
// CHECK-NEXT:    ret <4 x double> [[TMP13]]
//
v4f64 fixeddq(v4i64 v) {
  return __builtin_kvx_fixeddq(v, 3, ".rn");
}

// CHECK-LABEL: @fixeduwp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[V:%.*]], i64 3, i32 0)
// CHECK-NEXT:    ret <2 x i32> [[TMP0]]
//
v2u32 fixeduwp(v2f32 v) {
  return __builtin_kvx_fixeduwp(v, 3, ".rn");
}

// CHECK-LABEL: @fixeduwq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x float> [[V:%.*]], <4 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP0]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <4 x float> [[V]], <4 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP2]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
// CHECK-NEXT:    ret <4 x i32> [[TMP4]]
//
v4u32 fixeduwq(v4f32 v) {
  return __builtin_kvx_fixeduwq(v, 3, ".rn");
}

// CHECK-LABEL: @fixeduwo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <8 x float> [[V:%.*]], <8 x float> undef, <2 x i32> <i32 0, i32 1>
// CHECK-NEXT:    [[TMP1:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP0]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP2:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 2, i32 3>
// CHECK-NEXT:    [[TMP3:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP2]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP1]], <2 x i32> [[TMP3]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 4, i32 5>
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP5]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <2 x i32> [[TMP6]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP8:%.*]] = shufflevector <8 x i32> [[TMP4]], <8 x i32> [[TMP7]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 8, i32 9, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <8 x float> [[V]], <8 x float> undef, <2 x i32> <i32 6, i32 7>
// CHECK-NEXT:    [[TMP10:%.*]] = tail call <2 x i32> @llvm.kvx.fixeduwp(<2 x float> [[TMP9]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x i32> [[TMP10]], <2 x i32> undef, <8 x i32> <i32 0, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
// CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <8 x i32> [[TMP8]], <8 x i32> [[TMP11]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 8, i32 9>
// CHECK-NEXT:    ret <8 x i32> [[TMP12]]
//
v8u32 fixeduwo(v8f32 v) {
  return __builtin_kvx_fixeduwo(v, 3, ".rn");
}

// CHECK-LABEL: @fixedudp(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <2 x i64> [[V:%.*]] to <2 x double>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x double> [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP1]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x double> [[TMP0]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP4]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = bitcast <2 x i64> [[TMP6]] to <2 x double>
// CHECK-NEXT:    ret <2 x double> [[TMP7]]
//
v2f64 fixedudp(v2u64 v) {
  return __builtin_kvx_fixedudp(v, 3, ".rn");
}

// CHECK-LABEL: @fixedudq(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast <4 x i64> [[V:%.*]] to <4 x double>
// CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x double> [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP1]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP3:%.*]] = insertelement <4 x i64> undef, i64 [[TMP2]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = extractelement <4 x double> [[TMP0]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP4]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP6:%.*]] = insertelement <4 x i64> [[TMP3]], i64 [[TMP5]], i64 1
// CHECK-NEXT:    [[TMP7:%.*]] = extractelement <4 x double> [[TMP0]], i64 2
// CHECK-NEXT:    [[TMP8:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP7]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> [[TMP6]], i64 [[TMP8]], i64 2
// CHECK-NEXT:    [[TMP10:%.*]] = extractelement <4 x double> [[TMP0]], i64 3
// CHECK-NEXT:    [[TMP11:%.*]] = tail call i64 @llvm.kvx.fixedud(double [[TMP10]], i64 3, i32 0)
// CHECK-NEXT:    [[TMP12:%.*]] = insertelement <4 x i64> [[TMP9]], i64 [[TMP11]], i64 3
// CHECK-NEXT:    [[TMP13:%.*]] = bitcast <4 x i64> [[TMP12]] to <4 x double>
// CHECK-NEXT:    ret <4 x double> [[TMP13]]
//
v4f64 fixedudq(v4u64 v) {
  return __builtin_kvx_fixedudq(v, 3, ".rn");
}
