; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O3 -mcpu=kv3-1 -o - %s | FileCheck %s -check-prefix=CV1
; RUN: llc -O3 -mcpu=kv3-2 -o - %s | FileCheck %s -check-prefix=CV2
; RUN: clang -march=kv3-1 -c -o /dev/null %s
; RUN: clang -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define void @fmm222_(ptr %p) {
; CV1-LABEL: fmm222_:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    lq $r2r3 = 0[$r0]
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    lq $r4r5 = 16[$r0]
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r1 = $r2, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    srld $r1 = $r5, 32
; CV1-NEXT:    insf $r2 = $r1, 63, 32
; CV1-NEXT:    insf $r4 = $r5, 63, 32
; CV1-NEXT:    srld $r6 = $r4, 32
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    srld $r1 = $r3, 32
; CV1-NEXT:    insf $r6 = $r1, 63, 32
; CV1-NEXT:    fdot2w $r8 = $r4, $r2
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fdot2w $r2 = $r6, $r2
; CV1-NEXT:    insf $r3 = $r1, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fdot2w $r9 = $r4, $r3
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fdot2w $r1 = $r6, $r3
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    insf $r8 = $r2, 63, 32
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    insf $r9 = $r1, 63, 32
; CV1-NEXT:    ;; # (end cycle 12)
; CV1-NEXT:    sq 32[$r0] = $r8r9
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 13)
;
; CV2-LABEL: fmm222_:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    lq $r2r3 = 0[$r0]
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    lq $r4r5 = 16[$r0]
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fmm222w $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 32[$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 7)
entry:
  %0 = load volatile <4 x float>, ptr %p
  %arrayidx1 = getelementptr inbounds <4 x float>, ptr %p, i64 1
  %1 = load volatile <4 x float>, ptr %arrayidx1
  %vecext = extractelement <4 x float> %0, i64 0
  %vecext2 = extractelement <4 x float> %1, i64 0
  %mul = fmul fast float %vecext2, %vecext
  %vecext3 = extractelement <4 x float> %0, i64 1
  %vecext4 = extractelement <4 x float> %1, i64 2
  %mul5 = fmul fast float %vecext4, %vecext3
  %add = fadd fast float %mul, %mul5
  %vecinit = insertelement <4 x float> undef, float %add, i64 0
  %vecext7 = extractelement <4 x float> %1, i64 1
  %mul8 = fmul fast float %vecext7, %vecext
  %vecext10 = extractelement <4 x float> %1, i64 3
  %mul11 = fmul fast float %vecext10, %vecext3
  %add12 = fadd fast float %mul8, %mul11
  %vecinit13 = insertelement <4 x float> %vecinit, float %add12, i64 1
  %vecext14 = extractelement <4 x float> %0, i64 2
  %mul16 = fmul fast float %vecext2, %vecext14
  %vecext17 = extractelement <4 x float> %0, i64 3
  %mul19 = fmul fast float %vecext4, %vecext17
  %add20 = fadd fast float %mul16, %mul19
  %vecinit21 = insertelement <4 x float> %vecinit13, float %add20, i64 2
  %mul24 = fmul fast float %vecext7, %vecext14
  %mul27 = fmul fast float %vecext10, %vecext17
  %add28 = fadd fast float %mul24, %mul27
  %vecinit29 = insertelement <4 x float> %vecinit21, float %add28, i64 3
  %arrayidx30 = getelementptr inbounds <4 x float>, ptr %p, i64 2
  store volatile <4 x float> %vecinit29, ptr %arrayidx30
  ret void
}

