; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O2 -o - %s | FileCheck %s --check-prefixes=CHECK,KV3_1
; RUN: llc -mcpu=kv3-2 -O2 -o - %s | FileCheck %s --check-prefixes=CHECK,KV3_2
target triple = "kvx-kalray-cos"

define half @add_f16_i(half %0) {
; KV3_1-LABEL: add_f16_i:
; KV3_1:       # %bb.0:
; KV3_1-NEXT:    zxhd $r0 = $r0
; KV3_1-NEXT:    ;;
; KV3_1-NEXT:    faddhq $r0 = $r0, 0x3800
; KV3_1-NEXT:    ret
; KV3_1-NEXT:    ;;
;
; KV3_2-LABEL: add_f16_i:
; KV3_2:       # %bb.0:
; KV3_2-NEXT:    zxhd $r0 = $r0
; KV3_2-NEXT:    make $r1 = 0x3800
; KV3_2-NEXT:    ;;
; KV3_2-NEXT:    faddhq $r0 = $r0, $r1
; KV3_2-NEXT:    ret
; KV3_2-NEXT:    ;;
  %2 = fadd half %0, 0.5
  ret half %2
}

define half @add_f16_f16(half %0, half %1) {
; CHECK-LABEL: add_f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    zxhd $r0 = $r0
; CHECK-NEXT:    zxhd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd half %0, %1
  ret half %3
}

define <2 x half> @add_v2f16_i(<2 x half> %0) {
; KV3_1-LABEL: add_v2f16_i:
; KV3_1:       # %bb.0:
; KV3_1-NEXT:    zxwd $r0 = $r0
; KV3_1-NEXT:    ;;
; KV3_1-NEXT:    faddhq $r0 = $r0, 0x3c003800
; KV3_1-NEXT:    ret
; KV3_1-NEXT:    ;;
;
; KV3_2-LABEL: add_v2f16_i:
; KV3_2:       # %bb.0:
; KV3_2-NEXT:    zxwd $r0 = $r0
; KV3_2-NEXT:    make $r1 = 0x3c003800
; KV3_2-NEXT:    ;;
; KV3_2-NEXT:    faddhq $r0 = $r0, $r1
; KV3_2-NEXT:    ret
; KV3_2-NEXT:    ;;
  %2 = fadd <2 x half> %0, <half 0.5, half 1.0>
  ret <2 x half> %2
}

define <2 x half> @add_v2f16_v2f16(<2 x half> %0, <2 x half> %1) {
; CHECK-LABEL: add_v2f16_v2f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    zxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd <2 x half> %0, %1
  ret <2 x half> %3
}

define <4 x half> @add_v4f16_i(<4 x half> %0) {
; KV3_1-LABEL: add_v4f16_i:
; KV3_1:       # %bb.0:
; KV3_1-NEXT:    faddhq $r0 = $r0, 0x3c0038003c003800
; KV3_1-NEXT:    ret
; KV3_1-NEXT:    ;;
;
; KV3_2-LABEL: add_v4f16_i:
; KV3_2:       # %bb.0:
; KV3_2-NEXT:    make $r1 = 0x3c0038003c003800
; KV3_2-NEXT:    ;;
; KV3_2-NEXT:    faddhq $r0 = $r0, $r1
; KV3_2-NEXT:    ret
; KV3_2-NEXT:    ;;
  %2 = fadd <4 x half> %0, <half 0.5, half 1.0, half 0.5, half 1.0>
  ret <4 x half> %2
}

define <4 x half> @add_v4f16_v4f16(<4 x half> %0, <4 x half> %1) {
; CHECK-LABEL: add_v4f16_v4f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    faddhq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd <4 x half> %0, %1
  ret <4 x half> %3
}


define float @add_f32_f32(float %0, float %1) {
; CHECK-LABEL: add_f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    faddw $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd float %0, %1
  ret float %3
}

define float @add_f32_ri(float %0) {
; KV3_1-LABEL: add_f32_ri:
; KV3_1:       # %bb.0:
; KV3_1-NEXT:    faddw $r0 = $r0, 0x3f000000
; KV3_1-NEXT:    ret
; KV3_1-NEXT:    ;;
;
; KV3_2-LABEL: add_f32_ri:
; KV3_2:       # %bb.0:
; KV3_2-NEXT:    make $r1 = 0x3f000000
; KV3_2-NEXT:    ;;
; KV3_2-NEXT:    faddw $r0 = $r0, $r1
; KV3_2-NEXT:    ret
; KV3_2-NEXT:    ;;
  %2 = fadd float %0, 0.5
  ret float %2
}

define <2 x float> @add_v2f32_v2f32(<2 x float> %0, <2 x float> %1) {
; CHECK-LABEL: add_v2f32_v2f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    faddwp $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd <2 x float> %0, %1
  ret <2 x float> %3
}

define <2 x float> @add_v2f32_imm(<2 x float> %0) {
; KV3_1-LABEL: add_v2f32_imm:
; KV3_1:       # %bb.0:
; KV3_1-NEXT:    faddwp $r0 = $r0, 0x400000003f800000
; KV3_1-NEXT:    ret
; KV3_1-NEXT:    ;;
;
; KV3_2-LABEL: add_v2f32_imm:
; KV3_2:       # %bb.0:
; KV3_2-NEXT:    make $r1 = 0x400000003f800000
; KV3_2-NEXT:    ;;
; KV3_2-NEXT:    faddwp $r0 = $r0, $r1
; KV3_2-NEXT:    ret
; KV3_2-NEXT:    ;;
  %2 = fadd <2 x float> %0, <float 1.0, float 2.0>
  ret <2 x float> %2
}

define <4 x float> @add_v4f32_v4f32(<4 x float> %0, <4 x float> %1) {
; CHECK-LABEL: add_v4f32_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    faddwq $r0r1 = $r0r1, $r2r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd <4 x float> %0, %1
  ret <4 x float> %3
}


define double @add_f64_f64(double %0, double %1) {
; CHECK-LABEL: add_f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    faddd $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd double %0, %1
  ret double %3
}

define <2 x double> @add_v2f64_v2f64(<2 x double> %0, <2 x double> %1) {
; CHECK-LABEL: add_v2f64_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fadddp $r0r1 = $r0r1, $r2r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd <2 x double> %0, %1
  ret <2 x double> %3
}

define <4 x double> @add_v4f64_v4f64(<4 x double> %0, <4 x double> %1) {
; CHECK-LABEL: add_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fadddp $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fadddp $r0r1 = $r0r1, $r4r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd <4 x double> %0, %1
  ret <4 x double> %3
}
