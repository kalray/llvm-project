; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O1 < %s | FileCheck %s
target triple = "kvx-kalray-cos"

%struct.Y = type { i64, i64 }

define %struct.Y @f(i64 %x.coerce0, i64 %x.coerce1, i64 %x.coerce2, i64 %x.coerce3, i64 %x.coerce4, i64 %x.coerce5, i64 %x.coerce6, i64 %x.coerce7, i64 %x.coerce8, i64 %x.coerce9, i64 %x.coerce10, i64 %x.coerce11, i64 %x.coerce12, i64 %x.coerce13) {
; CHECK-LABEL: f:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 32[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -32
; CHECK-NEXT:    sq 16[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -40
; CHECK-NEXT:    .cfi_offset 18, -48
; CHECK-NEXT:    ld $r15 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r18 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r19 = $r0, 10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 8[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 0[$r12] = $r15
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    call g
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r0 = $r0, 10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 72[$r12] = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r1 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r18r19 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 32[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    goto h
; CHECK-NEXT:    ;;
entry:
  %x.sroa.30 = alloca i64, align 8
  store i64 %x.coerce13, i64* %x.sroa.30, align 8
  %add = add nsw i64 %x.coerce0, 10
  %call = tail call %struct.Y @g(i64 %add, i64 %x.coerce1, i64 %x.coerce2, i64 %x.coerce3, i64 %x.coerce4, i64 %x.coerce5, i64 %x.coerce6, i64 %x.coerce7, i64 %x.coerce8, i64 %x.coerce9, i64 %x.coerce10, i64 %x.coerce11, i64 %x.coerce12, i64 %x.coerce13)
  %0 = extractvalue %struct.Y %call, 0
  %x.sroa.30.0.x.sroa.30.0.x.sroa.30.104. = load volatile i64, i64* %x.sroa.30, align 8
  %add2 = add nsw i64 %x.sroa.30.0.x.sroa.30.0.x.sroa.30.104., 10
  store volatile i64 %add2, i64* %x.sroa.30, align 8
  %conv = trunc i64 %add to i32
  %x.sroa.30.0.x.sroa.30.0.x.sroa.30.104.11 = load volatile i64, i64* %x.sroa.30, align 8
  %call5 = tail call %struct.Y (i32, ...) @h(i32 %conv, i64 %x.sroa.30.0.x.sroa.30.0.x.sroa.30.104.11, i64 %x.coerce1)
  ret %struct.Y %call5

}

declare %struct.Y @g(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64)

declare %struct.Y @h(i32, ...)
