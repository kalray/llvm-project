; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mcpu=kv3-1 -O2 -o - %s | FileCheck %s --check-prefixes=CHECK,KVXV1
; RUN: llc -mcpu=kv3-2 -O2 -o - %s | FileCheck %s --check-prefixes=CHECK,KVXV2
; RUN: clang -O2 -c -o /dev/null %s

; Assembly broken in CV2: T19960
; FIXME: clang -O2 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define i32 @sadd_sat32(i32 %a, i32 %b) {
; CHECK-LABEL: sadd_sat32:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addsw $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call i32 @llvm.sadd.sat.i32(i32 %b, i32 %a)
  ret i32 %0
}

define i32 @sadd_sat32_ri(i32 %a) {
; CHECK-LABEL: sadd_sat32_ri:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addsw $r0 = $r0, 0xcaca
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call i32 @llvm.sadd.sat.i32(i32 %a, i32 51914)
  ret i32 %0
}

; TODO: This could be addshq, but i16 is not legal.
define signext i16 @sadd_sat16(i16 signext %a, i16 signext %b) {
; CHECK-LABEL: sadd_sat16:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sllw $r0 = $r0, 16
; CHECK-NEXT:    sllw $r1 = $r1, 16
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    addsw $r0 = $r1, $r0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sraw $r0 = $r0, 16
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
entry:
  %0 = tail call i16 @llvm.sadd.sat.i16(i16 %b, i16 %a)
  ret i16 %0
}

define signext i8 @sadd_sat8(i8 signext %a, i8 signext %b) {
; CHECK-LABEL: sadd_sat8:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sllw $r0 = $r0, 24
; CHECK-NEXT:    sllw $r1 = $r1, 24
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    addsw $r0 = $r1, $r0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sraw $r0 = $r0, 24
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
entry:
  %0 = tail call i8 @llvm.sadd.sat.i8(i8 %b, i8 %a)
  ret i8 %0
}

define signext i64 @sadd_sat64(i64 signext %a, i64 signext %b) {
; CHECK-LABEL: sadd_sat64:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addsd $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call i64 @llvm.sadd.sat.i64(i64 %b, i64 %a)
  ret i64 %0
}

define signext i64 @sadd_sat64_ri10(i64 signext %a) {
; KVXV1-LABEL: sadd_sat64_ri10:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    addsd $r0 = $r0, -512
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 0)
;
; KVXV2-LABEL: sadd_sat64_ri10:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    make $r1 = -512
; KVXV2-NEXT:    ;; # (end cycle 0)
; KVXV2-NEXT:    addsd $r0 = $r0, $r1
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = tail call i64 @llvm.sadd.sat.i64(i64 %a, i64 -512)
  ret i64 %0
}

define signext i64 @sadd_sat64_ri37(i64 signext %a) {
; KVXV1-LABEL: sadd_sat64_ri37:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    addsd $r0 = $r0, 0x1fffffffff
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 0)
;
; KVXV2-LABEL: sadd_sat64_ri37:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    make $r1 = 0x1fffffffff
; KVXV2-NEXT:    ;; # (end cycle 0)
; KVXV2-NEXT:    addsd $r0 = $r0, $r1
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = tail call i64 @llvm.sadd.sat.i64(i64 %a, i64 137438953471)
  ret i64 %0
}

define signext i64 @sadd_sat64_ri64(i64 signext %a) {
; KVXV1-LABEL: sadd_sat64_ri64:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    addsd $r0 = $r0, 0x7fffffffffffffff
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 0)
;
; KVXV2-LABEL: sadd_sat64_ri64:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    make $r1 = 0x7fffffffffffffff
; KVXV2-NEXT:    ;; # (end cycle 0)
; KVXV2-NEXT:    addsd $r0 = $r0, $r1
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = tail call i64 @llvm.sadd.sat.i64(i64 %a, i64 9223372036854775807)
  ret i64 %0
}

define signext i64 @sadd_sat64_ri(i64 signext %a) {
; CHECK-LABEL: sadd_sat64_ri:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addsd $r0 = $r0, 0x51f41fff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call i64 @llvm.sadd.sat.i64(i64 1374953471, i64 %a)
  ret i64 %0
}

define signext i64 @sadd_sat64_not_ri(i64 signext %a) {
; KVXV1-LABEL: sadd_sat64_not_ri:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    addsd $r0 = $r0, 0xfffffffff5926c01
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 0)
;
; KVXV2-LABEL: sadd_sat64_not_ri:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    make $r1 = 0xfffffffff5926c01
; KVXV2-NEXT:    ;; # (end cycle 0)
; KVXV2-NEXT:    addsd $r0 = $r0, $r1
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = tail call i64 @llvm.sadd.sat.i64(i64 -174953471, i64 %a)
  ret i64 %0
}

define signext i64 @sadd_sat64_ri_at(i64 signext %a) {
; KVXV1-LABEL: sadd_sat64_ri_at:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    addsd $r0 = $r0, 0xdeadbeefdeadbeef
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 0)
;
; KVXV2-LABEL: sadd_sat64_ri_at:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    addsd.@ $r0 = $r0, 0xdeadbeef
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call i64 @llvm.sadd.sat.i64(i64 16045690984833335023, i64 %a)
  ret i64 %0
}

define <2 x i32> @sadd_satv2i32(<2 x i32> %a, <2 x i32> %b) {
; CHECK-LABEL: sadd_satv2i32:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addswp $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <2 x i32> @llvm.sadd.sat.v2i32(<2 x i32> %b, <2 x i32> %a)
  ret <2 x i32> %0
}

define <2 x i32> @sadd_satv2i32_ri_(<2 x i32> %a) {
; CHECK-LABEL: sadd_satv2i32_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addswp $r0 = $r0, 15
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <2 x i32> @llvm.sadd.sat.v2i32(<2 x i32> %a, <2 x i32> <i32 15, i32 0>)
  ret <2 x i32> %0
}

define <2 x i32> @sadd_satv2i32_ri_at(<2 x i32> %a) {
; CHECK-LABEL: sadd_satv2i32_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addswp.@ $r0 = $r0, 15
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <2 x i32> @llvm.sadd.sat.v2i32(<2 x i32> %a, <2 x i32> <i32 15, i32 15>)
  ret <2 x i32> %0
}

define <2 x i32> @sadd_satv2i32_rr(<2 x i32> %a) {
; CHECK-LABEL: sadd_satv2i32_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x1b58000002bc
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    addswp $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
entry:
  %0 = tail call <2 x i32> @llvm.sadd.sat.v2i32(<2 x i32> %a, <2 x i32> <i32 700, i32 7000>)
  ret <2 x i32> %0
}

define <2 x i16> @sadd_satv2i16(<2 x i16> %a, <2 x i16> %b) {
; CHECK-LABEL: sadd_satv2i16:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addshq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <2 x i16> @llvm.sadd.sat.v2i16(<2 x i16> %b, <2 x i16> %a)
  ret <2 x i16> %0
}

define <2 x i16> @sadd_satv2i16_ri(<2 x i16> %a) {
; CHECK-LABEL: sadd_satv2i16_ri:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addshq $r0 = $r0, 0x10001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <2 x i16> @llvm.sadd.sat.v2i16(<2 x i16> %a, <2 x i16> <i16 1, i16 1>)
  ret <2 x i16> %0
}

define <4 x i16> @sadd_satv4i16(<4 x i16> %a, <4 x i16> %b) {
; CHECK-LABEL: sadd_satv4i16:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addshq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <4 x i16> @llvm.sadd.sat.v4i16(<4 x i16> %b, <4 x i16> %a)
  ret <4 x i16> %0
}

define <4 x i16> @sadd_satv4i16_ri_(<4 x i16> %a) {
; CHECK-LABEL: sadd_satv4i16_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addshq $r0 = $r0, 0x9e8f618
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <4 x i16> @llvm.sadd.sat.v4i16(<4 x i16> %a, <4 x i16> <i16 63000, i16 -63000, i16 0, i16 0>)
  ret <4 x i16> %0
}

define <4 x i16> @sadd_satv4i16_ri_at(<4 x i16> %a) {
; CHECK-LABEL: sadd_satv4i16_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addshq.@ $r0 = $r0, 0x9e8f618
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <4 x i16> @llvm.sadd.sat.v4i16(<4 x i16> %a, <4 x i16> <i16 63000, i16 -63000, i16 63000, i16 -63000>)
  ret <4 x i16> %0
}

define <4 x i32> @sadd_satv4i32(<4 x i32> %a, <4 x i32> %b) {
; CHECK-LABEL: sadd_satv4i32:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addswp $r0 = $r2, $r0
; CHECK-NEXT:    addswp $r1 = $r3, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <4 x i32> @llvm.sadd.sat.v4i32(<4 x i32> %b, <4 x i32> %a)
  ret <4 x i32> %0
}

; TODO: Could be simply zxwx(addsw)
define i32 @sadd_sat32_trunc(i32 %a, i32 %b) {
; KVXV1-LABEL: sadd_sat32_trunc:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    sxwd $r1 = $r1
; KVXV1-NEXT:    ;; # (end cycle 0)
; KVXV1-NEXT:    addwd $r0 = $r0, $r1
; KVXV1-NEXT:    ;; # (end cycle 1)
; KVXV1-NEXT:    satdh $r0 = $r0
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 2)
;
; KVXV2-LABEL: sadd_sat32_trunc:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    sxwd $r1 = $r1
; KVXV2-NEXT:    ;; # (end cycle 0)
; KVXV2-NEXT:    addwd $r0 = $r0, $r1
; KVXV2-NEXT:    ;; # (end cycle 1)
; KVXV2-NEXT:    mind $r0 = $r0, 0x7fff
; KVXV2-NEXT:    ;; # (end cycle 2)
; KVXV2-NEXT:    maxd $r0 = $r0, 0xffffffffffff8000
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 3)
entry:
  %conv = sext i32 %a to i64
  %conv1 = sext i32 %b to i64
  %add = add nsw i64 %conv1, %conv
  %0 = icmp slt i64 %add, 32767
  %spec.store.select = select i1 %0, i64 %add, i64 32767
  %1 = icmp sgt i64 %spec.store.select, -32768
  %spec.store.select8 = select i1 %1, i64 %spec.store.select, i64 -32768
  %conv7 = trunc i64 %spec.store.select8 to i32
  ret i32 %conv7
}

define i32 @sadd_sat32_ext16(i32 %a, i16 %b) {
; CHECK-LABEL: sadd_sat32_ext16:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sxhd $r1 = $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    addsw $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
entry:
  %0 = sext i16 %b to i32
  %1 = tail call i32 @llvm.sadd.sat.i32(i32 %0, i32 %a)
  ret i32 %1
}

; TODO: Could be simply addsw
define i32 @sadd_sat32_zext(i32 %a, i32 %b) {
; CHECK-LABEL: sadd_sat32_zext:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    zxwd $r1 = $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    adduwd $r0 = $r0, $r1
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    minud $r0 = $r0, 0x7fffffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
entry:
  %conv = zext i32 %a to i64
  %conv1 = zext i32 %b to i64
  %add = add nuw nsw i64 %conv1, %conv
  %0 = icmp ult i64 %add, 2147483647
  %spec.store.select = select i1 %0, i64 %add, i64 2147483647
  %conv7 = trunc i64 %spec.store.select to i32
  ret i32 %conv7
}

define i64 @sadd_sat32_notrunc(i32 %a, i32 %b) {
; CHECK-LABEL: sadd_sat32_notrunc:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addsw $r0 = $r1, $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
entry:
  %0 = tail call i32 @llvm.sadd.sat.i32(i32 %b, i32 %a)
  %spec.store.select8 = sext i32 %0 to i64
  ret i64 %spec.store.select8
}

define <2 x i8> @sadd_satv2i8(<2 x i8> %a, <2 x i8> %b) {
; KVXV1-LABEL: sadd_satv2i8:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    zxbd $r0 = $r0
; KVXV1-NEXT:    zxbd $r1 = $r1
; KVXV1-NEXT:    extfz $r2 = $r0, 15, 8
; KVXV1-NEXT:    extfz $r3 = $r1, 15, 8
; KVXV1-NEXT:    ;; # (end cycle 0)
; KVXV1-NEXT:    sllw $r0 = $r0, 24
; KVXV1-NEXT:    sllw $r1 = $r1, 24
; KVXV1-NEXT:    sllw $r2 = $r2, 24
; KVXV1-NEXT:    sllw $r3 = $r3, 24
; KVXV1-NEXT:    ;; # (end cycle 1)
; KVXV1-NEXT:    addsw $r0 = $r1, $r0
; KVXV1-NEXT:    addsw $r2 = $r3, $r2
; KVXV1-NEXT:    ;; # (end cycle 2)
; KVXV1-NEXT:    sraw $r0 = $r0, 24
; KVXV1-NEXT:    sraw $r1 = $r2, 24
; KVXV1-NEXT:    ;; # (end cycle 3)
; KVXV1-NEXT:    insf $r0 = $r1, 15, 8
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 4)
;
; KVXV2-LABEL: sadd_satv2i8:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    addsbo $r0 = $r1, $r0
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <2 x i8> @llvm.sadd.sat.v2i8(<2 x i8> %b, <2 x i8> %a)
  ret <2 x i8> %0
}

define <2 x i8> @sadd_satv2i8_ri(<2 x i8> %a) {
; KVXV1-LABEL: sadd_satv2i8_ri:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    zxbd $r0 = $r0
; KVXV1-NEXT:    extfz $r1 = $r0, 15, 8
; KVXV1-NEXT:    ;; # (end cycle 0)
; KVXV1-NEXT:    sllw $r0 = $r0, 24
; KVXV1-NEXT:    sllw $r1 = $r1, 24
; KVXV1-NEXT:    ;; # (end cycle 1)
; KVXV1-NEXT:    addsw $r0 = $r0, 0x1000000
; KVXV1-NEXT:    addsw $r1 = $r1, 0x1000000
; KVXV1-NEXT:    ;; # (end cycle 2)
; KVXV1-NEXT:    sraw $r0 = $r0, 24
; KVXV1-NEXT:    sraw $r1 = $r1, 24
; KVXV1-NEXT:    ;; # (end cycle 3)
; KVXV1-NEXT:    insf $r0 = $r1, 15, 8
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 4)
;
; KVXV2-LABEL: sadd_satv2i8_ri:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    addsbo $r0 = $r0, 257
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <2 x i8> @llvm.sadd.sat.v2i8(<2 x i8> %a, <2 x i8> <i8 1, i8 1>)
  ret <2 x i8> %0
}

define <4 x i8> @sadd_satv4i8(<4 x i8> %a, <4 x i8> %b) {
; KVXV1-LABEL: sadd_satv4i8:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    srlw $r2 = $r0, 24
; KVXV1-NEXT:    srlw $r3 = $r1, 24
; KVXV1-NEXT:    extfz $r4 = $r0, 23, 16
; KVXV1-NEXT:    extfz $r5 = $r1, 23, 16
; KVXV1-NEXT:    ;; # (end cycle 0)
; KVXV1-NEXT:    sllw $r2 = $r2, 24
; KVXV1-NEXT:    sllw $r3 = $r3, 24
; KVXV1-NEXT:    sllw $r4 = $r4, 24
; KVXV1-NEXT:    sllw $r5 = $r5, 24
; KVXV1-NEXT:    ;; # (end cycle 1)
; KVXV1-NEXT:    addsw $r2 = $r3, $r2
; KVXV1-NEXT:    addsw $r3 = $r5, $r4
; KVXV1-NEXT:    ;; # (end cycle 2)
; KVXV1-NEXT:    zxbd $r0 = $r0
; KVXV1-NEXT:    zxbd $r1 = $r1
; KVXV1-NEXT:    extfz $r4 = $r0, 15, 8
; KVXV1-NEXT:    extfz $r5 = $r1, 15, 8
; KVXV1-NEXT:    ;; # (end cycle 3)
; KVXV1-NEXT:    sllw $r0 = $r0, 24
; KVXV1-NEXT:    sllw $r1 = $r1, 24
; KVXV1-NEXT:    sllw $r4 = $r4, 24
; KVXV1-NEXT:    sllw $r5 = $r5, 24
; KVXV1-NEXT:    ;; # (end cycle 4)
; KVXV1-NEXT:    addsw $r0 = $r1, $r0
; KVXV1-NEXT:    sraw $r1 = $r2, 24
; KVXV1-NEXT:    sraw $r2 = $r3, 24
; KVXV1-NEXT:    addsw $r4 = $r5, $r4
; KVXV1-NEXT:    ;; # (end cycle 5)
; KVXV1-NEXT:    sraw $r0 = $r0, 24
; KVXV1-NEXT:    insf $r2 = $r1, 15, 8
; KVXV1-NEXT:    sraw $r3 = $r4, 24
; KVXV1-NEXT:    ;; # (end cycle 6)
; KVXV1-NEXT:    insf $r0 = $r3, 15, 8
; KVXV1-NEXT:    ;; # (end cycle 7)
; KVXV1-NEXT:    insf $r0 = $r2, 31, 16
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 8)
;
; KVXV2-LABEL: sadd_satv4i8:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    addsbo $r0 = $r1, $r0
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <4 x i8> @llvm.sadd.sat.v4i8(<4 x i8> %b, <4 x i8> %a)
  ret <4 x i8> %0
}

define <4 x i8> @sadd_satv4i8_ri(<4 x i8> %a) {
; KVXV1-LABEL: sadd_satv4i8_ri:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    extfz $r0 = $r0, 15, 8
; KVXV1-NEXT:    extfz $r1 = $r0, 23, 16
; KVXV1-NEXT:    zxbd $r2 = $r0
; KVXV1-NEXT:    srlw $r3 = $r0, 24
; KVXV1-NEXT:    ;; # (end cycle 0)
; KVXV1-NEXT:    sllw $r1 = $r1, 24
; KVXV1-NEXT:    sllw $r2 = $r2, 24
; KVXV1-NEXT:    sxbd $r3 = $r3
; KVXV1-NEXT:    sxbd $r4 = $r0
; KVXV1-NEXT:    ;; # (end cycle 1)
; KVXV1-NEXT:    addsw $r1 = $r1, 0x80000000
; KVXV1-NEXT:    addsw $r2 = $r2, 0x7f000000
; KVXV1-NEXT:    ;; # (end cycle 2)
; KVXV1-NEXT:    sraw $r0 = $r2, 24
; KVXV1-NEXT:    sraw $r1 = $r1, 24
; KVXV1-NEXT:    ;; # (end cycle 3)
; KVXV1-NEXT:    insf $r0 = $r4, 15, 8
; KVXV1-NEXT:    insf $r1 = $r3, 15, 8
; KVXV1-NEXT:    ;; # (end cycle 4)
; KVXV1-NEXT:    insf $r0 = $r1, 31, 16
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 5)
;
; KVXV2-LABEL: sadd_satv4i8_ri:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    addsbo $r0 = $r0, 0x80007f
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <4 x i8> @llvm.sadd.sat.v4i8(<4 x i8> %a, <4 x i8> <i8 127, i8 0, i8 -128, i8 0>)
  ret <4 x i8> %0
}

define <8 x i8> @sadd_satv8i8(<8 x i8> %a, <8 x i8> %b) {
; KVXV1-LABEL: sadd_satv8i8:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; KVXV1-NEXT:    sbmm8 $r2 = $r0, 0x4000200004000100
; KVXV1-NEXT:    sbmm8 $r3 = $r1, 0x4000200004000100
; KVXV1-NEXT:    ;; # (end cycle 0)
; KVXV1-NEXT:    andd.@ $r1 = $r1, 0xff00ff00
; KVXV1-NEXT:    addshq $r2 = $r3, $r2
; KVXV1-NEXT:    ;; # (end cycle 1)
; KVXV1-NEXT:    addshq $r0 = $r1, $r0
; KVXV1-NEXT:    srlhqs $r1 = $r2, 8
; KVXV1-NEXT:    ;; # (end cycle 2)
; KVXV1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; KVXV1-NEXT:    ;; # (end cycle 3)
; KVXV1-NEXT:    ord $r0 = $r0, $r1
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 4)
;
; KVXV2-LABEL: sadd_satv8i8:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    addsbo $r0 = $r1, $r0
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <8 x i8> @llvm.sadd.sat.v8i8(<8 x i8> %b, <8 x i8> %a)
  ret <8 x i8> %0
}

define <8 x i8> @sadd_satv8i8_ri_(<8 x i8> %a) {
; KVXV1-LABEL: sadd_satv8i8_ri_:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; KVXV1-NEXT:    make $r1 = 0x80007f
; KVXV1-NEXT:    sbmm8 $r3 = $r0, 0x4000200004000100
; KVXV1-NEXT:    ;; # (end cycle 0)
; KVXV1-NEXT:    andd.@ $r1 = $r1, 0xff00ff00
; KVXV1-NEXT:    sbmm8 $r2 = $r1, 0x4000200004000100
; KVXV1-NEXT:    ;; # (end cycle 1)
; KVXV1-NEXT:    addshq $r0 = $r0, $r1
; KVXV1-NEXT:    addshq $r2 = $r3, $r2
; KVXV1-NEXT:    ;; # (end cycle 2)
; KVXV1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; KVXV1-NEXT:    srlhqs $r1 = $r2, 8
; KVXV1-NEXT:    ;; # (end cycle 3)
; KVXV1-NEXT:    ord $r0 = $r0, $r1
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 4)
;
; KVXV2-LABEL: sadd_satv8i8_ri_:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    addsbo $r0 = $r0, 0x80007f
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <8 x i8> @llvm.sadd.sat.v8i8(<8 x i8> %a, <8 x i8> <i8 127, i8 0, i8 -128, i8 0, i8 0, i8 0, i8 0, i8 0>)
  ret <8 x i8> %0
}

define <8 x i8> @sadd_satv8i8_ri_at(<8 x i8> %a) {
; KVXV1-LABEL: sadd_satv8i8_ri_at:
; KVXV1:       # %bb.0: # %entry
; KVXV1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; KVXV1-NEXT:    make $r1 = 0x80007f0080007f
; KVXV1-NEXT:    sbmm8 $r3 = $r0, 0x4000200004000100
; KVXV1-NEXT:    ;; # (end cycle 0)
; KVXV1-NEXT:    andd.@ $r1 = $r1, 0xff00ff00
; KVXV1-NEXT:    sbmm8 $r2 = $r1, 0x4000200004000100
; KVXV1-NEXT:    ;; # (end cycle 1)
; KVXV1-NEXT:    addshq $r0 = $r0, $r1
; KVXV1-NEXT:    addshq $r2 = $r3, $r2
; KVXV1-NEXT:    ;; # (end cycle 2)
; KVXV1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; KVXV1-NEXT:    srlhqs $r1 = $r2, 8
; KVXV1-NEXT:    ;; # (end cycle 3)
; KVXV1-NEXT:    ord $r0 = $r0, $r1
; KVXV1-NEXT:    ret
; KVXV1-NEXT:    ;; # (end cycle 4)
;
; KVXV2-LABEL: sadd_satv8i8_ri_at:
; KVXV2:       # %bb.0: # %entry
; KVXV2-NEXT:    addsbo.@ $r0 = $r0, 0x80007f
; KVXV2-NEXT:    ret
; KVXV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <8 x i8> @llvm.sadd.sat.v8i8(<8 x i8> %a, <8 x i8> <i8 127, i8 0, i8 -128, i8 0, i8 127, i8 0, i8 -128, i8 0>)
  ret <8 x i8> %0
}

declare void @use64(i64)
declare i32 @llvm.sadd.sat.i32(i32, i32)
declare i16 @llvm.sadd.sat.i16(i16, i16)
declare i8 @llvm.sadd.sat.i8(i8, i8)
declare i64 @llvm.sadd.sat.i64(i64, i64)
declare <4 x i32> @llvm.sadd.sat.v4i32(<4 x i32>, <4 x i32>)
declare <4 x i16> @llvm.sadd.sat.v4i16(<4 x i16>, <4 x i16>)
declare <2 x i16> @llvm.sadd.sat.v2i16(<2 x i16>, <2 x i16>)
declare <2 x i32> @llvm.sadd.sat.v2i32(<2 x i32>, <2 x i32>)
declare <2 x i8>  @llvm.sadd.sat.v2i8(<2 x i8>, <2 x i8>)
declare <4 x i8>  @llvm.sadd.sat.v4i8(<4 x i8>, <4 x i8>)
declare <8 x i8>  @llvm.sadd.sat.v8i8(<8 x i8>, <8 x i8>)
