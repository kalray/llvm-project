; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O3 -mcpu=kv3-2 -o - %s -mtriple=kvx-kalray-cos | FileCheck %s
; RUN: clang -O3 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define <4 x i64> @xmovefo256(ptr nocapture noundef readonly %a) {
; CHECK-LABEL: xmovefo256:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovefo $r0r1r2r3 = $a0
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = load <256 x i1>, ptr %a
  %1 = tail call <4 x i64> @llvm.kvx.xmovefo256(<256 x i1> %0)
  ret <4 x i64> %1
}

declare <4 x i64> @llvm.kvx.xmovefo256(<256 x i1>)

define <2 x i64> @xmovefq256_h0(ptr nocapture noundef readonly %a) {
; CHECK-LABEL: xmovefq256_h0:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovefq $r0r1 = $a0.lo
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = load <256 x i1>, ptr %a
  %1 = tail call <2 x i64> @llvm.kvx.xmovefq256(<256 x i1> %0, i32 0)
  ret <2 x i64> %1
}

declare <2 x i64> @llvm.kvx.xmovefq256(<256 x i1>, i32)

define <2 x i64> @xmovefq256_h1(ptr nocapture noundef readonly %a) {
; CHECK-LABEL: xmovefq256_h1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovefq $r0r1 = $a0.hi
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = load <256 x i1>, ptr %a
  %1 = tail call <2 x i64> @llvm.kvx.xmovefq256(<256 x i1> %0, i32 1)
  ret <2 x i64> %1
}

define i64 @xmovefd256_q0(ptr nocapture noundef readonly %a) {
; CHECK-LABEL: xmovefd256_q0:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovefd $r0 = $a0.x
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = load <256 x i1>, ptr %a
  %1 = tail call i64 @llvm.kvx.xmovefd256(<256 x i1> %0, i32 0)
  ret i64 %1
}

declare i64 @llvm.kvx.xmovefd256(<256 x i1>, i32)

define i64 @xmovefd256_q1(ptr nocapture noundef readonly %a) {
; CHECK-LABEL: xmovefd256_q1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovefd $r0 = $a0.y
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = load <256 x i1>, ptr %a
  %1 = tail call i64 @llvm.kvx.xmovefd256(<256 x i1> %0, i32 1)
  ret i64 %1
}

define i64 @xmovefd256_q2(ptr nocapture noundef readonly %a) {
; CHECK-LABEL: xmovefd256_q2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovefd $r0 = $a0.z
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = load <256 x i1>, ptr %a
  %1 = tail call i64 @llvm.kvx.xmovefd256(<256 x i1> %0, i32 2)
  ret i64 %1
}

define i64 @xmovefd256_q3(ptr nocapture noundef readonly %a) {
; CHECK-LABEL: xmovefd256_q3:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovefd $r0 = $a0.t
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = load <256 x i1>, ptr %a
  %1 = tail call i64 @llvm.kvx.xmovefd256(<256 x i1> %0, i32 3)
  ret i64 %1
}

define void @xmoveto256(ptr nocapture noundef writeonly %c, <4 x i64> noundef %a) {
; CHECK-LABEL: xmoveto256:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r4 = $r1
; CHECK-NEXT:    copyd $r5 = $r2
; CHECK-NEXT:    copyd $r6 = $r3
; CHECK-NEXT:    copyd $r7 = $r4
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovetq $a0.lo = $r4, $r5
; CHECK-NEXT:    xmovetq $a0.hi = $r6, $r7
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    xso 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 5)
entry:
  %0 = tail call <256 x i1> @llvm.kvx.xmoveto256(<4 x i64> %a)
  store <256 x i1> %0, ptr %c
  ret void
}

declare <256 x i1> @llvm.kvx.xmoveto256(<4 x i64>)

define void @xmovetq256_h0(ptr nocapture noundef %c, <2 x i64> noundef %a) {
; CHECK-LABEL: xmovetq256_h0:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    copyd $r2 = $r1
; CHECK-NEXT:    copyd $r3 = $r2
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovetq $a0.lo = $r2, $r3
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    xso 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 5)
entry:
  %0 = load <256 x i1>, ptr %c
  %1 = tail call <256 x i1> @llvm.kvx.xmovetq256(<256 x i1> %0, <2 x i64> %a, i32 0)
  store <256 x i1> %1, ptr %c
  ret void
}

declare <256 x i1> @llvm.kvx.xmovetq256(<256 x i1>, <2 x i64>, i32)

define void @xmovetq256_h1(ptr nocapture noundef %c, <2 x i64> noundef %a) {
; CHECK-LABEL: xmovetq256_h1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    copyd $r2 = $r1
; CHECK-NEXT:    copyd $r3 = $r2
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovetq $a0.hi = $r2, $r3
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    xso 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 5)
entry:
  %0 = load <256 x i1>, ptr %c
  %1 = tail call <256 x i1> @llvm.kvx.xmovetq256(<256 x i1> %0, <2 x i64> %a, i32 1)
  store <256 x i1> %1, ptr %c
  ret void
}

define void @xmovetd256_q0(ptr nocapture noundef %c, i64 noundef %a) {
; CHECK-LABEL: xmovetd256_q0:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovetd $a0.x = $r1
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    xso 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 5)
entry:
  %0 = load <256 x i1>, ptr %c
  %1 = tail call <256 x i1> @llvm.kvx.xmovetd256(<256 x i1> %0, i64 %a, i32 0)
  store <256 x i1> %1, ptr %c
  ret void
}

declare <256 x i1> @llvm.kvx.xmovetd256(<256 x i1>, i64, i32)

define void @xmovetd256_q1(ptr nocapture noundef %c, i64 noundef %a) {
; CHECK-LABEL: xmovetd256_q1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovetd $a0.y = $r1
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    xso 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 5)
entry:
  %0 = load <256 x i1>, ptr %c
  %1 = tail call <256 x i1> @llvm.kvx.xmovetd256(<256 x i1> %0, i64 %a, i32 1)
  store <256 x i1> %1, ptr %c
  ret void
}

define void @xmovetd256_q2(ptr nocapture noundef %c, i64 noundef %a) {
; CHECK-LABEL: xmovetd256_q2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovetd $a0.z = $r1
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    xso 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 5)
entry:
  %0 = load <256 x i1>, ptr %c
  %1 = tail call <256 x i1> @llvm.kvx.xmovetd256(<256 x i1> %0, i64 %a, i32 2)
  store <256 x i1> %1, ptr %c
  ret void
}

define void @xmovetd256_q3(ptr nocapture noundef %c, i64 noundef %a) {
; CHECK-LABEL: xmovetd256_q3:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    xlo $a0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    xmovetd $a0.t = $r1
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    xso 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 5)
entry:
  %0 = load <256 x i1>, ptr %c
  %1 = tail call <256 x i1> @llvm.kvx.xmovetd256(<256 x i1> %0, i64 %a, i32 3)
  store <256 x i1> %1, ptr %c
  ret void
}

