; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mcpu=kv3-1 -O2 -o - %s | FileCheck %s --check-prefix=CV1
; RUN: llc -mcpu=kv3-2 -O2 -o - %s | FileCheck %s --check-prefix=CV2

target triple = "kvx-kalray-cos"

define <3 x i8> @ashiftR_imm(<3 x i8> %a){
; CV1-LABEL: ashiftR_imm:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r1 = $r0, 23, 16
; CV1-NEXT:    extfz $r2 = $r0, 15, 8
; CV1-NEXT:    zxbd $r3 = $r0
; CV1-NEXT:    srlw $r4 = $r0, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r1 = $r1, 3
; CV1-NEXT:    sraw $r2 = $r2, 3
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r0 = $r3, 3
; CV1-NEXT:    insf $r1 = $r4, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r2, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r1, 31, 16
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: ashiftR_imm:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    srabos $r0 = $r0, 3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shr = ashr <3 x i8> %a, <i8 3, i8 3, i8 3>
  ret <3 x i8> %shr
}

define <3 x i8> @lshiftR_imm(<3 x i8> %a){
; CV1-LABEL: lshiftR_imm:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r1 = $r0, 23, 16
; CV1-NEXT:    extfz $r2 = $r0, 15, 8
; CV1-NEXT:    zxbd $r3 = $r0
; CV1-NEXT:    srlw $r4 = $r0, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    andw $r1 = $r1, 248
; CV1-NEXT:    andw $r2 = $r2, 248
; CV1-NEXT:    andw $r3 = $r3, 248
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r0 = $r3, 3
; CV1-NEXT:    srlw $r1 = $r1, 3
; CV1-NEXT:    srlw $r2 = $r2, 3
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r2, 15, 8
; CV1-NEXT:    insf $r1 = $r4, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r1, 31, 16
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: lshiftR_imm:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    srlbos $r0 = $r0, 3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shr = lshr <3 x i8> %a, <i8 3, i8 3, i8 3>
  ret <3 x i8> %shr
}

define <3 x i8> @shiftL_imm(<3 x i8> %a){
; CV1-LABEL: shiftL_imm:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r1 = $r0, 23, 16
; CV1-NEXT:    extfz $r2 = $r0, 15, 8
; CV1-NEXT:    zxbd $r3 = $r0
; CV1-NEXT:    srlw $r4 = $r0, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    sllw $r0 = $r3, 3
; CV1-NEXT:    sllw $r1 = $r1, 3
; CV1-NEXT:    sllw $r2 = $r2, 3
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r2, 15, 8
; CV1-NEXT:    insf $r1 = $r4, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r1, 31, 16
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: shiftL_imm:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    sllbos $r0 = $r0, 3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shl = shl <3 x i8> %a, <i8 3, i8 3, i8 3>
  ret <3 x i8> %shl
}

define <3 x i8> @ashiftR(<3 x i8> %a, i8 %c){
; CV1-LABEL: ashiftR:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    srlw $r0 = $r0, 24
; CV1-NEXT:    extfz $r2 = $r0, 15, 8
; CV1-NEXT:    zxbd $r3 = $r0
; CV1-NEXT:    extfz $r4 = $r0, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r2 = $r3, $r1
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    sraw $r5 = $r2, $r1
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r1 = $r4, $r1
; CV1-NEXT:    insf $r2 = $r5, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r1 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r2 = $r1, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: ashiftR:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    srabos $r0 = $r0, $r1
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %0 = insertelement <3 x i8> undef, i8 %c, i32 0
  %sh_prom = shufflevector <3 x i8> %0, <3 x i8> undef, <3 x i32> zeroinitializer
  %shr = ashr <3 x i8> %a, %sh_prom
  ret <3 x i8> %shr
}

define <3 x i8> @lshiftR(<3 x i8> %a, i8 %c){
; CV1-LABEL: lshiftR:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    srlw $r0 = $r0, 24
; CV1-NEXT:    extfz $r2 = $r0, 15, 8
; CV1-NEXT:    zxbd $r3 = $r0
; CV1-NEXT:    extfz $r4 = $r0, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r2 = $r2
; CV1-NEXT:    zxbd $r3 = $r3
; CV1-NEXT:    zxbd $r4 = $r4
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r1 = $r4, $r1
; CV1-NEXT:    srlw $r2 = $r3, $r1
; CV1-NEXT:    srlw $r5 = $r2, $r1
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r1 = $r0, 15, 8
; CV1-NEXT:    insf $r2 = $r5, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r2 = $r1, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: lshiftR:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    srlbos $r0 = $r0, $r1
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %0 = insertelement <3 x i8> undef, i8 %c, i32 0
  %sh_prom = shufflevector <3 x i8> %0, <3 x i8> undef, <3 x i32> zeroinitializer
  %shr = lshr <3 x i8> %a, %sh_prom
  ret <3 x i8> %shr
}

define <3 x i8> @shiftL(<3 x i8> %a, i8 %c){
; CV1-LABEL: shiftL:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    srlw $r0 = $r0, 24
; CV1-NEXT:    extfz $r2 = $r0, 15, 8
; CV1-NEXT:    zxbd $r3 = $r0
; CV1-NEXT:    extfz $r4 = $r0, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    sllw $r1 = $r4, $r1
; CV1-NEXT:    sllw $r2 = $r3, $r1
; CV1-NEXT:    sllw $r5 = $r2, $r1
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r1 = $r0, 15, 8
; CV1-NEXT:    insf $r2 = $r5, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r2 = $r1, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: shiftL:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    sllbos $r0 = $r0, $r1
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %0 = insertelement <3 x i8> undef, i8 %c, i32 0
  %sh_prom = shufflevector <3 x i8> %0, <3 x i8> undef, <3 x i32> zeroinitializer
  %shl = shl <3 x i8> %a, %sh_prom
  ret <3 x i8> %shl
}
define <3 x i8> @ashiftR_vec_imm(<3 x i8> %a){
; CV1-LABEL: ashiftR_vec_imm:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r1 = $r0, 23, 16
; CV1-NEXT:    extfz $r2 = $r0, 15, 8
; CV1-NEXT:    zxbd $r3 = $r0
; CV1-NEXT:    srlw $r4 = $r0, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r1 = $r1, 3
; CV1-NEXT:    sraw $r2 = $r2, 2
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r0 = $r3, 1
; CV1-NEXT:    insf $r1 = $r4, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r2, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r1, 31, 16
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: ashiftR_vec_imm:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    srabos $r1 = $r0, 1
; CV2-NEXT:    srabos $r2 = $r0, 2
; CV2-NEXT:    ;;
; CV2-NEXT:    srabos $r0 = $r0, 3
; CV2-NEXT:    insf $r2 = $r1, 7, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r0 = $r2, 15, 0
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shr = ashr <3 x i8> %a, <i8 1, i8 2, i8 3>
  ret <3 x i8> %shr
}

define <3 x i8> @lshiftR_imm_vec(<3 x i8> %a){
; CV1-LABEL: lshiftR_imm_vec:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r1 = $r0, 23, 16
; CV1-NEXT:    extfz $r2 = $r0, 15, 8
; CV1-NEXT:    zxbd $r3 = $r0
; CV1-NEXT:    srlw $r4 = $r0, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    andw $r1 = $r1, 248
; CV1-NEXT:    andw $r2 = $r2, 252
; CV1-NEXT:    andw $r3 = $r3, 248
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r0 = $r3, 3
; CV1-NEXT:    srlw $r1 = $r1, 3
; CV1-NEXT:    srlw $r2 = $r2, 2
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r2, 15, 8
; CV1-NEXT:    insf $r1 = $r4, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r1, 31, 16
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: lshiftR_imm_vec:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    srlbos $r0 = $r0, 2
; CV2-NEXT:    srlbos $r1 = $r0, 3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r0 = $r1, 7, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r1 = $r0, 15, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    copyd $r0 = $r1
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shr = lshr <3 x i8> %a, <i8 3, i8 2, i8 3>
  ret <3 x i8> %shr
}

define <3 x i8> @shiftL_imm_vec(<3 x i8> %a){
; CV1-LABEL: shiftL_imm_vec:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    srlw $r0 = $r0, 24
; CV1-NEXT:    extfz $r1 = $r0, 23, 16
; CV1-NEXT:    extfz $r2 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sllw $r1 = $r1, 3
; CV1-NEXT:    sllw $r2 = $r2, 3
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r2, 15, 8
; CV1-NEXT:    insf $r1 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r1, 31, 16
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: shiftL_imm_vec:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    sllbos $r0 = $r0, 3
; CV2-NEXT:    sllbos $r1 = $r0, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    copyd $r2 = $r0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r1, 7, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r0 = $r2, 15, 0
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shl = shl <3 x i8> %a, <i8 8, i8 3, i8 3>
  ret <3 x i8> %shl
}

define <3 x i8> @ashiftR_vec(<3 x i8> %a, <3 x i8> %c){
; CV1-LABEL: ashiftR_vec:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    srlw $r2 = $r0, 24
; CV1-NEXT:    extfz $r4 = $r0, 23, 16
; CV1-NEXT:    extfz $r6 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r1 = $r1
; CV1-NEXT:    extfz $r3 = $r1, 23, 16
; CV1-NEXT:    extfz $r5 = $r1, 15, 8
; CV1-NEXT:    srlw $r7 = $r1, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r0 = $r0
; CV1-NEXT:    sraw $r2 = $r2, $r7
; CV1-NEXT:    sraw $r3 = $r4, $r3
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r0 = $r0, $r1
; CV1-NEXT:    insf $r3 = $r2, 15, 8
; CV1-NEXT:    sraw $r4 = $r6, $r5
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r4, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r3, 31, 16
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: ashiftR_vec:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    extfz $r2 = $r1, 10, 8
; CV2-NEXT:    srabos $r3 = $r0, $r1
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r1 = $r1, 26, 24
; CV2-NEXT:    extfz $r4 = $r1, 18, 16
; CV2-NEXT:    ;;
; CV2-NEXT:    srabos $r2 = $r0, $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 7, 0
; CV2-NEXT:    srabos $r3 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    srabos $r0 = $r0, $r1
; CV2-NEXT:    insf $r3 = $r2, 15, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r0 = $r3, 23, 0
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shr = ashr <3 x i8> %a, %c
  ret <3 x i8> %shr
}

define <3 x i8> @lshiftR_vec(<3 x i8> %a, <3 x i8> %c){
; CV1-LABEL: lshiftR_vec:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    srlw $r2 = $r0, 24
; CV1-NEXT:    extfz $r3 = $r0, 23, 16
; CV1-NEXT:    extfz $r4 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r1 = $r1
; CV1-NEXT:    srlw $r5 = $r1, 24
; CV1-NEXT:    extfz $r6 = $r1, 23, 16
; CV1-NEXT:    extfz $r7 = $r1, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    zxbd $r2 = $r2
; CV1-NEXT:    zxbd $r3 = $r3
; CV1-NEXT:    zxbd $r4 = $r4
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r0 = $r0, $r1
; CV1-NEXT:    srlw $r2 = $r2, $r5
; CV1-NEXT:    srlw $r3 = $r3, $r6
; CV1-NEXT:    srlw $r4 = $r4, $r7
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r4, 15, 8
; CV1-NEXT:    insf $r3 = $r2, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r3, 31, 16
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: lshiftR_vec:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    extfz $r2 = $r1, 10, 8
; CV2-NEXT:    srlbos $r3 = $r0, $r1
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r1 = $r1, 26, 24
; CV2-NEXT:    extfz $r4 = $r1, 18, 16
; CV2-NEXT:    ;;
; CV2-NEXT:    srlbos $r2 = $r0, $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 7, 0
; CV2-NEXT:    srlbos $r3 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    srlbos $r0 = $r0, $r1
; CV2-NEXT:    insf $r3 = $r2, 15, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r0 = $r3, 23, 0
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shr = lshr <3 x i8> %a, %c
  ret <3 x i8> %shr
}

define <3 x i8> @shiftL_vec(<3 x i8> %a, <3 x i8> %c){
; CV1-LABEL: shiftL_vec:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    srlw $r2 = $r0, 24
; CV1-NEXT:    srlw $r3 = $r1, 24
; CV1-NEXT:    extfz $r4 = $r0, 23, 16
; CV1-NEXT:    extfz $r5 = $r1, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    zxbd $r1 = $r1
; CV1-NEXT:    extfz $r6 = $r0, 15, 8
; CV1-NEXT:    extfz $r7 = $r1, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sllw $r0 = $r0, $r1
; CV1-NEXT:    sllw $r2 = $r2, $r3
; CV1-NEXT:    sllw $r3 = $r4, $r5
; CV1-NEXT:    sllw $r4 = $r6, $r7
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r4, 15, 8
; CV1-NEXT:    insf $r3 = $r2, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r3, 31, 16
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: shiftL_vec:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    extfz $r2 = $r1, 10, 8
; CV2-NEXT:    sllbos $r3 = $r0, $r1
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r1 = $r1, 26, 24
; CV2-NEXT:    extfz $r4 = $r1, 18, 16
; CV2-NEXT:    ;;
; CV2-NEXT:    sllbos $r2 = $r0, $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 7, 0
; CV2-NEXT:    sllbos $r3 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    sllbos $r0 = $r0, $r1
; CV2-NEXT:    insf $r3 = $r2, 15, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r0 = $r3, 23, 0
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shl = shl <3 x i8> %a, %c
  ret <3 x i8> %shl
}
