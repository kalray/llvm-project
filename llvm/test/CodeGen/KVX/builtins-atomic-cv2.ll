; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mcpu=kv3-2 -o - %s -O2 | FileCheck %s --check-prefixes=CV2
; RUN: clang -march=kv3-2 -O2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define i32 @acswapw(i32* %0, i32 %1, i32 %2) {
; CV2-LABEL: acswapw:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r2 = $r1
; CV2-NEXT:    copyd $r3 = $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapw $r0, [$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast i32* %0 to i8*
  %5 = tail call i32 @llvm.kvx.acswapw(i8* %4, i32 %1, i32 %2, i32 1, i32 0)
  ret i32 %5
}

declare i32 @llvm.kvx.acswapw(i8*, i32, i32, i32, i32)

define i32 @acswapwv(i32* %0, i32 %1, i32 %2) {
; CV2-LABEL: acswapwv:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r2 = $r1
; CV2-NEXT:    copyd $r3 = $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapw.v $r0, [$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast i32* %0 to i8*
  %5 = tail call i32 @llvm.kvx.acswapw(i8* %4, i32 %1, i32 %2, i32 0, i32 0)
  ret i32 %5
}

define i32 @acswapws(i32* %0, i32 %1, i32 %2) {
; CV2-LABEL: acswapws:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r2 = $r1
; CV2-NEXT:    copyd $r3 = $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapw.s $r0, [$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast i32* %0 to i8*
  %5 = tail call i32 @llvm.kvx.acswapw(i8* %4, i32 %1, i32 %2, i32 1, i32 2)
  ret i32 %5
}

define i32 @acswapwvs(i32* %0, i32 %1, i32 %2) {
; CV2-LABEL: acswapwvs:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r2 = $r1
; CV2-NEXT:    copyd $r3 = $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapw.v.s $r0, [$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast i32* %0 to i8*
  %5 = tail call i32 @llvm.kvx.acswapw(i8* %4, i32 %1, i32 %2, i32 0, i32 2)
  ret i32 %5
}

define i32 @acswapwg(i32* %0, i32 %1, i32 %2) {
; CV2-LABEL: acswapwg:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r2 = $r1
; CV2-NEXT:    copyd $r3 = $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapw.g $r0, [$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast i32* %0 to i8*
  %5 = tail call i32 @llvm.kvx.acswapw(i8* %4, i32 %1, i32 %2, i32 1, i32 1)
  ret i32 %5
}

define i32 @acswapwvg(i32* %0, i32 %1, i32 %2) {
; CV2-LABEL: acswapwvg:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r2 = $r1
; CV2-NEXT:    copyd $r3 = $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapw.v.g $r0, [$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast i32* %0 to i8*
  %5 = tail call i32 @llvm.kvx.acswapw(i8* %4, i32 %1, i32 %2, i32 0, i32 1)
  ret i32 %5
}

define i64 @acswapd(i64* %0, i64 %1, i64 %2) {
; CV2-LABEL: acswapd:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r2 = $r1
; CV2-NEXT:    copyd $r3 = $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapd $r0, [$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast i64* %0 to i8*
  %5 = tail call i64 @llvm.kvx.acswapd(i8* %4, i64 %1, i64 %2, i32 1, i32 0)
  ret i64 %5
}

declare i64 @llvm.kvx.acswapd(i8*, i64, i64, i32, i32)

define i64 @acswapdv(i64* %0, i64 %1, i64 %2) {
; CV2-LABEL: acswapdv:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r2 = $r1
; CV2-NEXT:    copyd $r3 = $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapd.v $r0, [$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast i64* %0 to i8*
  %5 = tail call i64 @llvm.kvx.acswapd(i8* %4, i64 %1, i64 %2, i32 0, i32 0)
  ret i64 %5
}

define i64 @acswapds(i64* %0, i64 %1, i64 %2) {
; CV2-LABEL: acswapds:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r2 = $r1
; CV2-NEXT:    copyd $r3 = $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapd.s $r0, [$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast i64* %0 to i8*
  %5 = tail call i64 @llvm.kvx.acswapd(i8* %4, i64 %1, i64 %2, i32 1, i32 2)
  ret i64 %5
}

define i64 @acswapdvs(i64* %0, i64 %1, i64 %2) {
; CV2-LABEL: acswapdvs:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r2 = $r1
; CV2-NEXT:    copyd $r3 = $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapd.v.s $r0, [$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast i64* %0 to i8*
  %5 = tail call i64 @llvm.kvx.acswapd(i8* %4, i64 %1, i64 %2, i32 0, i32 2)
  ret i64 %5
}

define i64 @acswapdg(i64* %0, i64 %1, i64 %2) {
; CV2-LABEL: acswapdg:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r2 = $r1
; CV2-NEXT:    copyd $r3 = $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapd.g $r0, [$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast i64* %0 to i8*
  %5 = tail call i64 @llvm.kvx.acswapd(i8* %4, i64 %1, i64 %2, i32 1, i32 1)
  ret i64 %5
}

define i64 @acswapdvg(i64* %0, i64 %1, i64 %2) {
; CV2-LABEL: acswapdvg:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r2 = $r1
; CV2-NEXT:    copyd $r3 = $r2
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapd.v.g $r0, [$r0] = $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast i64* %0 to i8*
  %5 = tail call i64 @llvm.kvx.acswapd(i8* %4, i64 %1, i64 %2, i32 0, i32 1)
  ret i64 %5
}

define <2 x i64> @acswapq(<2 x i64>* %0, <2 x i64> %1, <2 x i64> %2) {
; CV2-LABEL: acswapq:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r4 = $r1
; CV2-NEXT:    copyd $r5 = $r2
; CV2-NEXT:    copyd $r6 = $r3
; CV2-NEXT:    copyd $r7 = $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapq $r0r1, [$r0] = $r4r5r6r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast <2 x i64>* %0 to i8*
  %5 = tail call <2 x i64> @llvm.kvx.acswapq(i8* %4, <2 x i64> %1, <2 x i64> %2, i32 1, i32 0)
  ret <2 x i64> %5
}

declare <2 x i64> @llvm.kvx.acswapq(i8*, <2 x i64>, <2 x i64>, i32, i32)

define <2 x i64> @acswapqv(<2 x i64>* %0, <2 x i64> %1, <2 x i64> %2) {
; CV2-LABEL: acswapqv:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r4 = $r1
; CV2-NEXT:    copyd $r5 = $r2
; CV2-NEXT:    copyd $r6 = $r3
; CV2-NEXT:    copyd $r7 = $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapq.v $r0r1, [$r0] = $r4r5r6r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast <2 x i64>* %0 to i8*
  %5 = tail call <2 x i64> @llvm.kvx.acswapq(i8* %4, <2 x i64> %1, <2 x i64> %2, i32 0, i32 0)
  ret <2 x i64> %5
}

define <2 x i64> @acswapqs(<2 x i64>* %0, <2 x i64> %1, <2 x i64> %2) {
; CV2-LABEL: acswapqs:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r4 = $r1
; CV2-NEXT:    copyd $r5 = $r2
; CV2-NEXT:    copyd $r6 = $r3
; CV2-NEXT:    copyd $r7 = $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapq.s $r0r1, [$r0] = $r4r5r6r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast <2 x i64>* %0 to i8*
  %5 = tail call <2 x i64> @llvm.kvx.acswapq(i8* %4, <2 x i64> %1, <2 x i64> %2, i32 1, i32 2)
  ret <2 x i64> %5
}

define <2 x i64> @acswapqvs(<2 x i64>* %0, <2 x i64> %1, <2 x i64> %2) {
; CV2-LABEL: acswapqvs:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r4 = $r1
; CV2-NEXT:    copyd $r5 = $r2
; CV2-NEXT:    copyd $r6 = $r3
; CV2-NEXT:    copyd $r7 = $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapq.v.s $r0r1, [$r0] = $r4r5r6r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast <2 x i64>* %0 to i8*
  %5 = tail call <2 x i64> @llvm.kvx.acswapq(i8* %4, <2 x i64> %1, <2 x i64> %2, i32 0, i32 2)
  ret <2 x i64> %5
}

define <2 x i64> @acswapqg(<2 x i64>* %0, <2 x i64> %1, <2 x i64> %2) {
; CV2-LABEL: acswapqg:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r4 = $r1
; CV2-NEXT:    copyd $r5 = $r2
; CV2-NEXT:    copyd $r6 = $r3
; CV2-NEXT:    copyd $r7 = $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapq.g $r0r1, [$r0] = $r4r5r6r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast <2 x i64>* %0 to i8*
  %5 = tail call <2 x i64> @llvm.kvx.acswapq(i8* %4, <2 x i64> %1, <2 x i64> %2, i32 1, i32 1)
  ret <2 x i64> %5
}

define <2 x i64> @acswapqvg(<2 x i64>* %0, <2 x i64> %1, <2 x i64> %2) {
; CV2-LABEL: acswapqvg:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r4 = $r1
; CV2-NEXT:    copyd $r5 = $r2
; CV2-NEXT:    copyd $r6 = $r3
; CV2-NEXT:    copyd $r7 = $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapq.v.g $r0r1, [$r0] = $r4r5r6r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = bitcast <2 x i64>* %0 to i8*
  %5 = tail call <2 x i64> @llvm.kvx.acswapq(i8* %4, <2 x i64> %1, <2 x i64> %2, i32 0, i32 1)
  ret <2 x i64> %5
}

define <2 x i64> @acswapqvgr(<2 x i64>* %0, <2 x i64> %1, <2 x i64> %2, i32 %3) {
; CV2-LABEL: acswapqvgr:
; CV2:       # %bb.0:
; CV2-NEXT:    sxwd $r4 = $r5
; CV2-NEXT:    copyd $r5 = $r2
; CV2-NEXT:    copyd $r6 = $r3
; CV2-NEXT:    copyd $r7 = $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    addx16d $r0 = $r4, $r0
; CV2-NEXT:    copyd $r4 = $r1
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapq.v.g $r0r1, [$r0] = $r4r5r6r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %5 = sext i32 %3 to i64
  %6 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %5
  %7 = bitcast <2 x i64>* %6 to i8*
  %8 = tail call <2 x i64> @llvm.kvx.acswapq(i8* %7, <2 x i64> %1, <2 x i64> %2, i32 0, i32 1)
  ret <2 x i64> %8
}

define <2 x i64> @acswapqvgri27(<2 x i64>* %0, <2 x i64> %1, <2 x i64> %2) {
; CV2-LABEL: acswapqvgri27:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r4 = $r1
; CV2-NEXT:    copyd $r5 = $r2
; CV2-NEXT:    copyd $r6 = $r3
; CV2-NEXT:    copyd $r7 = $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapq.v.g $r0r1, 240[$r0] = $r4r5r6r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %5 = bitcast <2 x i64>* %4 to i8*
  %6 = tail call <2 x i64> @llvm.kvx.acswapq(i8* nonnull %5, <2 x i64> %1, <2 x i64> %2, i32 0, i32 1)
  ret <2 x i64> %6
}

define <2 x i64> @acswapqvgri54(<2 x i64>* %0, <2 x i64> %1, <2 x i64> %2) {
; CV2-LABEL: acswapqvgri54:
; CV2:       # %bb.0:
; CV2-NEXT:    copyd $r4 = $r1
; CV2-NEXT:    copyd $r5 = $r2
; CV2-NEXT:    copyd $r6 = $r3
; CV2-NEXT:    copyd $r7 = $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    acswapq.v.g $r0r1, 0x1000000030[$r0] = $r4r5r6r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4294967299
  %5 = bitcast <2 x i64>* %4 to i8*
  %6 = tail call <2 x i64> @llvm.kvx.acswapq(i8* nonnull %5, <2 x i64> %1, <2 x i64> %2, i32 0, i32 1)
  ret <2 x i64> %6
}

