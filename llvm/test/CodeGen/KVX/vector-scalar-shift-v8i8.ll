; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mcpu=kv3-1 -O2 -o - %s | FileCheck %s --check-prefix=CV1
; RUN: llc -mcpu=kv3-2 -O2 -o - %s | FileCheck %s --check-prefix=CV2

target triple = "kvx-kalray-cos"

define <8 x i8> @ashiftR_imm(<8 x i8> %a){
; CV1-LABEL: ashiftR_imm:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r1 = $r0, 55, 48
; CV1-NEXT:    srld $r2 = $r0, 56
; CV1-NEXT:    extfz $r3 = $r0, 47, 40
; CV1-NEXT:    srlw $r7 = $r0, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r4 = $r0, 39, 32
; CV1-NEXT:    extfz $r5 = $r0, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    extfz $r6 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r2 = $r2, 3
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r1 = $r1, 3
; CV1-NEXT:    sraw $r3 = $r3, 3
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r0 = $r0
; CV1-NEXT:    sraw $r4 = $r4, 3
; CV1-NEXT:    sraw $r5 = $r5, 3
; CV1-NEXT:    sraw $r7 = $r7, 3
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r0 = $r0, 3
; CV1-NEXT:    insf $r1 = $r2, 15, 8
; CV1-NEXT:    insf $r4 = $r3, 15, 8
; CV1-NEXT:    sraw $r6 = $r6, 3
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r6, 15, 8
; CV1-NEXT:    insf $r5 = $r7, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r5, 31, 16
; CV1-NEXT:    insf $r4 = $r1, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: ashiftR_imm:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    srabos $r0 = $r0, 3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shr = ashr <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  ret <8 x i8> %shr
}

define <8 x i8> @lshiftR_imm(<8 x i8> %a){
; CV1-LABEL: lshiftR_imm:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    andd $r0 = $r0, 0xff00ff00ff00ff00
; CV1-NEXT:    andd $r1 = $r0, 0xff00ff00ff00ff
; CV1-NEXT:    make $r2 = 3
; CV1-NEXT:    ;;
; CV1-NEXT:    srld $r0 = $r0, $r2
; CV1-NEXT:    srld $r1 = $r1, $r2
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r0 = $r0, 0xff00ff00ff00ff00
; CV1-NEXT:    andd $r1 = $r1, 0xff00ff00ff00ff
; CV1-NEXT:    ;;
; CV1-NEXT:    ord $r0 = $r0, $r1
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: lshiftR_imm:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    srlbos $r0 = $r0, 3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shr = lshr <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  ret <8 x i8> %shr
}

define <8 x i8> @shiftL_imm(<8 x i8> %a){
; CV1-LABEL: shiftL_imm:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    andd $r0 = $r0, 0xff00ff00ff00ff00
; CV1-NEXT:    andd $r1 = $r0, 0xff00ff00ff00ff
; CV1-NEXT:    make $r2 = 3
; CV1-NEXT:    ;;
; CV1-NEXT:    slld $r0 = $r0, $r2
; CV1-NEXT:    slld $r1 = $r1, $r2
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r0 = $r0, 0xff00ff00ff00ff00
; CV1-NEXT:    andd $r1 = $r1, 0xff00ff00ff00ff
; CV1-NEXT:    ;;
; CV1-NEXT:    ord $r0 = $r0, $r1
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: shiftL_imm:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    sllbos $r0 = $r0, 3
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shl = shl <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  ret <8 x i8> %shl
}

define <8 x i8> @ashiftR(<8 x i8> %a, i32 %c){
; CV1-LABEL: ashiftR:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r2 = $r0, 55, 48
; CV1-NEXT:    srld $r3 = $r0, 56
; CV1-NEXT:    extfz $r4 = $r0, 47, 40
; CV1-NEXT:    srlw $r8 = $r0, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r5 = $r0, 39, 32
; CV1-NEXT:    extfz $r6 = $r0, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    extfz $r7 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r3 = $r3, $r1
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    sxbd $r8 = $r8
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r2 = $r2, $r1
; CV1-NEXT:    sraw $r4 = $r4, $r1
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r0 = $r0
; CV1-NEXT:    sraw $r5 = $r5, $r1
; CV1-NEXT:    sraw $r6 = $r6, $r1
; CV1-NEXT:    sraw $r8 = $r8, $r1
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r0 = $r0, $r1
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    sraw $r7 = $r7, $r1
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r7, 15, 8
; CV1-NEXT:    insf $r6 = $r8, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r6, 31, 16
; CV1-NEXT:    insf $r5 = $r2, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r5, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: ashiftR:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    srabos $r0 = $r0, $r1
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %0 = trunc i32 %c to i8
  %1 = insertelement <8 x i8> undef, i8 %0, i32 0
  %sh_prom = shufflevector <8 x i8> %1, <8 x i8> undef, <8 x i32> zeroinitializer
  %shr = ashr <8 x i8> %a, %sh_prom
  ret <8 x i8> %shr
}

define <8 x i8> @lshiftR(<8 x i8> %a, i32 %c){
; CV1-LABEL: lshiftR:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    andd $r0 = $r0, 0xff00ff00ff00ff00
; CV1-NEXT:    andd $r2 = $r0, 0xff00ff00ff00ff
; CV1-NEXT:    ;;
; CV1-NEXT:    srld $r0 = $r0, $r1
; CV1-NEXT:    srld $r2 = $r2, $r1
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r0 = $r0, 0xff00ff00ff00ff00
; CV1-NEXT:    andd $r1 = $r2, 0xff00ff00ff00ff
; CV1-NEXT:    ;;
; CV1-NEXT:    ord $r0 = $r0, $r1
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: lshiftR:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    srlbos $r0 = $r0, $r1
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %0 = trunc i32 %c to i8
  %1 = insertelement <8 x i8> undef, i8 %0, i32 0
  %sh_prom = shufflevector <8 x i8> %1, <8 x i8> undef, <8 x i32> zeroinitializer
  %shr = lshr <8 x i8> %a, %sh_prom
  ret <8 x i8> %shr
}

define <8 x i8> @shiftL(<8 x i8> %a, i32 %c){
; CV1-LABEL: shiftL:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    andd $r0 = $r0, 0xff00ff00ff00ff00
; CV1-NEXT:    andd $r2 = $r0, 0xff00ff00ff00ff
; CV1-NEXT:    ;;
; CV1-NEXT:    slld $r0 = $r0, $r1
; CV1-NEXT:    slld $r2 = $r2, $r1
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r0 = $r0, 0xff00ff00ff00ff00
; CV1-NEXT:    andd $r1 = $r2, 0xff00ff00ff00ff
; CV1-NEXT:    ;;
; CV1-NEXT:    ord $r0 = $r0, $r1
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: shiftL:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    sllbos $r0 = $r0, $r1
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %0 = trunc i32 %c to i8
  %1 = insertelement <8 x i8> undef, i8 %0, i32 0
  %sh_prom = shufflevector <8 x i8> %1, <8 x i8> undef, <8 x i32> zeroinitializer
  %shl = shl <8 x i8> %a, %sh_prom
  ret <8 x i8> %shl
}

define <8 x i8> @ashiftR_imm_vec(<8 x i8> %a){
; CV1-LABEL: ashiftR_imm_vec:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r1 = $r0, 55, 48
; CV1-NEXT:    srld $r2 = $r0, 56
; CV1-NEXT:    extfz $r3 = $r0, 47, 40
; CV1-NEXT:    srlw $r7 = $r0, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r4 = $r0, 39, 32
; CV1-NEXT:    extfz $r5 = $r0, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    extfz $r6 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r2 = $r2, 2
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r1 = $r1, 3
; CV1-NEXT:    sraw $r3 = $r3, 3
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r0 = $r0
; CV1-NEXT:    sraw $r4 = $r4, 4
; CV1-NEXT:    sraw $r5 = $r5, 3
; CV1-NEXT:    sraw $r7 = $r7, 2
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r0 = $r0, 4
; CV1-NEXT:    insf $r1 = $r2, 15, 8
; CV1-NEXT:    insf $r4 = $r3, 15, 8
; CV1-NEXT:    sraw $r6 = $r6, 3
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r6, 15, 8
; CV1-NEXT:    insf $r5 = $r7, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r5, 31, 16
; CV1-NEXT:    insf $r4 = $r1, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: ashiftR_imm_vec:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    make $r1 = 0x203030402030304
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r2 = $r1, 10, 8
; CV2-NEXT:    extfz $r4 = $r1, 18, 16
; CV2-NEXT:    ;;
; CV2-NEXT:    srabos $r2 = $r0, $r2
; CV2-NEXT:    srabos $r3 = $r0, $r1
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 7, 0
; CV2-NEXT:    srabos $r4 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r3 = $r1, 26, 24
; CV2-NEXT:    insf $r4 = $r2, 15, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r2 = $r1, 34, 32
; CV2-NEXT:    srabos $r3 = $r0, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r3 = $r4, 23, 0
; CV2-NEXT:    extfz $r4 = $r1, 42, 40
; CV2-NEXT:    ;;
; CV2-NEXT:    srabos $r2 = $r0, $r2
; CV2-NEXT:    srabos $r4 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 31, 0
; CV2-NEXT:    extfz $r3 = $r1, 50, 48
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r1 = $r1, 58, 56
; CV2-NEXT:    insf $r4 = $r2, 39, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    srabos $r0 = $r0, $r1
; CV2-NEXT:    srabos $r2 = $r0, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r4, 47, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r0 = $r2, 55, 0
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shr = ashr <8 x i8> %a, <i8 4, i8 3, i8 3, i8 2, i8 4, i8 3, i8 3, i8 2>
  ret <8 x i8> %shr
}

define <8 x i8> @lshiftR_imm_vec(<8 x i8> %a){
; CV1-LABEL: lshiftR_imm_vec:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r1 = $r0, 55, 48
; CV1-NEXT:    srld $r2 = $r0, 56
; CV1-NEXT:    extfz $r3 = $r0, 47, 40
; CV1-NEXT:    srlw $r5 = $r0, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r4 = $r0, 39, 32
; CV1-NEXT:    extfz $r6 = $r0, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    andw $r1 = $r1, 248
; CV1-NEXT:    andw $r2 = $r2, 252
; CV1-NEXT:    extfz $r7 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    andw $r3 = $r3, 248
; CV1-NEXT:    andw $r4 = $r4, 240
; CV1-NEXT:    andw $r5 = $r5, 240
; CV1-NEXT:    andw $r6 = $r6, 248
; CV1-NEXT:    ;;
; CV1-NEXT:    andw $r0 = $r0, 252
; CV1-NEXT:    srlw $r1 = $r1, 3
; CV1-NEXT:    srlw $r2 = $r2, 2
; CV1-NEXT:    andw $r7 = $r7, 254
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r3 = $r3, 3
; CV1-NEXT:    srlw $r4 = $r4, 4
; CV1-NEXT:    srlw $r5 = $r5, 4
; CV1-NEXT:    srlw $r6 = $r6, 3
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r0 = $r0, 2
; CV1-NEXT:    insf $r1 = $r2, 15, 8
; CV1-NEXT:    insf $r4 = $r3, 15, 8
; CV1-NEXT:    srlw $r7 = $r7, 1
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r7, 15, 8
; CV1-NEXT:    insf $r6 = $r5, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r6, 31, 16
; CV1-NEXT:    insf $r4 = $r1, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: lshiftR_imm_vec:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    make $r1 = 0x203030404030102
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r2 = $r1, 10, 8
; CV2-NEXT:    extfz $r4 = $r1, 18, 16
; CV2-NEXT:    ;;
; CV2-NEXT:    srlbos $r2 = $r0, $r2
; CV2-NEXT:    srlbos $r3 = $r0, $r1
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 7, 0
; CV2-NEXT:    srlbos $r4 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r3 = $r1, 26, 24
; CV2-NEXT:    insf $r4 = $r2, 15, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r2 = $r1, 34, 32
; CV2-NEXT:    srlbos $r3 = $r0, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r3 = $r4, 23, 0
; CV2-NEXT:    extfz $r4 = $r1, 42, 40
; CV2-NEXT:    ;;
; CV2-NEXT:    srlbos $r2 = $r0, $r2
; CV2-NEXT:    srlbos $r4 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 31, 0
; CV2-NEXT:    extfz $r3 = $r1, 50, 48
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r1 = $r1, 58, 56
; CV2-NEXT:    insf $r4 = $r2, 39, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    srlbos $r0 = $r0, $r1
; CV2-NEXT:    srlbos $r2 = $r0, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r4, 47, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r0 = $r2, 55, 0
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shr = lshr <8 x i8> %a, <i8 2, i8 1, i8 3, i8 4, i8 4, i8 3, i8 3, i8 2>
  ret <8 x i8> %shr
}

define <8 x i8> @shiftL_imm_vec(<8 x i8> %a){
; CV1-LABEL: shiftL_imm_vec:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r1 = $r0, 55, 48
; CV1-NEXT:    srld $r2 = $r0, 56
; CV1-NEXT:    extfz $r3 = $r0, 47, 40
; CV1-NEXT:    srlw $r5 = $r0, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r4 = $r0, 39, 32
; CV1-NEXT:    extfz $r6 = $r0, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    sllw $r1 = $r1, 3
; CV1-NEXT:    sllw $r2 = $r2, 2
; CV1-NEXT:    extfz $r7 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sllw $r3 = $r3, 3
; CV1-NEXT:    sllw $r4 = $r4, 4
; CV1-NEXT:    sllw $r5 = $r5, 5
; CV1-NEXT:    sllw $r6 = $r6, 3
; CV1-NEXT:    ;;
; CV1-NEXT:    sllw $r0 = $r0, 3
; CV1-NEXT:    insf $r1 = $r2, 15, 8
; CV1-NEXT:    insf $r4 = $r3, 15, 8
; CV1-NEXT:    sllw $r7 = $r7, 3
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r7, 15, 8
; CV1-NEXT:    insf $r6 = $r5, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r6, 31, 16
; CV1-NEXT:    insf $r4 = $r1, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: shiftL_imm_vec:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    make $r1 = 0x203030405030303
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r2 = $r1, 10, 8
; CV2-NEXT:    extfz $r4 = $r1, 18, 16
; CV2-NEXT:    ;;
; CV2-NEXT:    sllbos $r2 = $r0, $r2
; CV2-NEXT:    sllbos $r3 = $r0, $r1
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 7, 0
; CV2-NEXT:    sllbos $r4 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r3 = $r1, 26, 24
; CV2-NEXT:    insf $r4 = $r2, 15, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r2 = $r1, 34, 32
; CV2-NEXT:    sllbos $r3 = $r0, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r3 = $r4, 23, 0
; CV2-NEXT:    extfz $r4 = $r1, 42, 40
; CV2-NEXT:    ;;
; CV2-NEXT:    sllbos $r2 = $r0, $r2
; CV2-NEXT:    sllbos $r4 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 31, 0
; CV2-NEXT:    extfz $r3 = $r1, 50, 48
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r1 = $r1, 58, 56
; CV2-NEXT:    insf $r4 = $r2, 39, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    sllbos $r0 = $r0, $r1
; CV2-NEXT:    sllbos $r2 = $r0, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r4, 47, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r0 = $r2, 55, 0
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shl = shl <8 x i8> %a, <i8 3, i8 3, i8 3, i8 5, i8 4, i8 3, i8 3, i8 2>
  ret <8 x i8> %shl
}

define <8 x i8> @ashiftR_rr_vec(<8 x i8> %a, <8 x i8> %b){
; CV1-LABEL: ashiftR_rr_vec:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r3 = $r0, 55, 48
; CV1-NEXT:    extfz $r5 = $r0, 47, 40
; CV1-NEXT:    srld $r8 = $r0, 56
; CV1-NEXT:    srlw $r16 = $r0, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r7 = $r0, 39, 32
; CV1-NEXT:    extfz $r10 = $r0, 23, 16
; CV1-NEXT:    srld $r17 = $r1, 56
; CV1-NEXT:    srlw $r32 = $r1, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    sxbd $r8 = $r8
; CV1-NEXT:    extfz $r15 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r2 = $r1, 55, 48
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r4 = $r1, 47, 40
; CV1-NEXT:    extfz $r6 = $r1, 39, 32
; CV1-NEXT:    sraw $r8 = $r8, $r17
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r1 = $r1
; CV1-NEXT:    sraw $r2 = $r3, $r2
; CV1-NEXT:    extfz $r9 = $r1, 23, 16
; CV1-NEXT:    extfz $r11 = $r1, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r0 = $r0
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    sxbd $r16 = $r16
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r0 = $r0, $r1
; CV1-NEXT:    sraw $r3 = $r5, $r4
; CV1-NEXT:    sxbd $r10 = $r10
; CV1-NEXT:    sxbd $r15 = $r15
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r2 = $r8, 15, 8
; CV1-NEXT:    sraw $r4 = $r7, $r6
; CV1-NEXT:    sraw $r5 = $r16, $r32
; CV1-NEXT:    sraw $r6 = $r10, $r9
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r4 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r5, 15, 8
; CV1-NEXT:    sraw $r7 = $r15, $r11
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r7, 15, 8
; CV1-NEXT:    insf $r4 = $r2, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r6, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: ashiftR_rr_vec:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    extfz $r2 = $r1, 10, 8
; CV2-NEXT:    extfz $r4 = $r1, 18, 16
; CV2-NEXT:    ;;
; CV2-NEXT:    srabos $r2 = $r0, $r2
; CV2-NEXT:    srabos $r3 = $r0, $r1
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 7, 0
; CV2-NEXT:    srabos $r4 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r3 = $r1, 26, 24
; CV2-NEXT:    insf $r4 = $r2, 15, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r2 = $r1, 34, 32
; CV2-NEXT:    srabos $r3 = $r0, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r3 = $r4, 23, 0
; CV2-NEXT:    extfz $r4 = $r1, 42, 40
; CV2-NEXT:    ;;
; CV2-NEXT:    srabos $r2 = $r0, $r2
; CV2-NEXT:    srabos $r4 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 31, 0
; CV2-NEXT:    extfz $r3 = $r1, 50, 48
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r1 = $r1, 58, 56
; CV2-NEXT:    insf $r4 = $r2, 39, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    srabos $r0 = $r0, $r1
; CV2-NEXT:    srabos $r2 = $r0, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r4, 47, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r0 = $r2, 55, 0
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shr = ashr <8 x i8> %a, %b
  ret <8 x i8> %shr
}

define <8 x i8> @lshiftR_rr_vec(<8 x i8> %a, <8 x i8> %b){
; CV1-LABEL: lshiftR_rr_vec:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r3 = $r0, 55, 48
; CV1-NEXT:    extfz $r5 = $r0, 47, 40
; CV1-NEXT:    srld $r7 = $r0, 56
; CV1-NEXT:    srlw $r11 = $r0, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    srld $r6 = $r1, 56
; CV1-NEXT:    extfz $r9 = $r0, 39, 32
; CV1-NEXT:    srlw $r10 = $r1, 24
; CV1-NEXT:    extfz $r16 = $r0, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    extfz $r2 = $r1, 55, 48
; CV1-NEXT:    zxbd $r7 = $r7
; CV1-NEXT:    extfz $r32 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r3 = $r3
; CV1-NEXT:    extfz $r4 = $r1, 47, 40
; CV1-NEXT:    zxbd $r5 = $r5
; CV1-NEXT:    extfz $r8 = $r1, 39, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    zxbd $r1 = $r1
; CV1-NEXT:    extfz $r15 = $r1, 23, 16
; CV1-NEXT:    extfz $r17 = $r1, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r9 = $r9
; CV1-NEXT:    zxbd $r11 = $r11
; CV1-NEXT:    zxbd $r16 = $r16
; CV1-NEXT:    zxbd $r32 = $r32
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r0 = $r0, $r1
; CV1-NEXT:    srlw $r2 = $r3, $r2
; CV1-NEXT:    srlw $r3 = $r5, $r4
; CV1-NEXT:    srlw $r6 = $r7, $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r4 = $r9, $r8
; CV1-NEXT:    srlw $r5 = $r11, $r10
; CV1-NEXT:    srlw $r7 = $r16, $r15
; CV1-NEXT:    srlw $r8 = $r32, $r17
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r2 = $r6, 15, 8
; CV1-NEXT:    insf $r4 = $r3, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r8, 15, 8
; CV1-NEXT:    insf $r7 = $r5, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r7, 31, 16
; CV1-NEXT:    insf $r4 = $r2, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: lshiftR_rr_vec:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    extfz $r2 = $r1, 10, 8
; CV2-NEXT:    extfz $r4 = $r1, 18, 16
; CV2-NEXT:    ;;
; CV2-NEXT:    srlbos $r2 = $r0, $r2
; CV2-NEXT:    srlbos $r3 = $r0, $r1
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 7, 0
; CV2-NEXT:    srlbos $r4 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r3 = $r1, 26, 24
; CV2-NEXT:    insf $r4 = $r2, 15, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r2 = $r1, 34, 32
; CV2-NEXT:    srlbos $r3 = $r0, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r3 = $r4, 23, 0
; CV2-NEXT:    extfz $r4 = $r1, 42, 40
; CV2-NEXT:    ;;
; CV2-NEXT:    srlbos $r2 = $r0, $r2
; CV2-NEXT:    srlbos $r4 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 31, 0
; CV2-NEXT:    extfz $r3 = $r1, 50, 48
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r1 = $r1, 58, 56
; CV2-NEXT:    insf $r4 = $r2, 39, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    srlbos $r0 = $r0, $r1
; CV2-NEXT:    srlbos $r2 = $r0, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r4, 47, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r0 = $r2, 55, 0
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shr = lshr <8 x i8> %a, %b
  ret <8 x i8> %shr
}

define <8 x i8> @shiftL_rr_vec(<8 x i8> %a, <8 x i8> %b){
; CV1-LABEL: shiftL_rr_vec:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    extfz $r2 = $r0, 55, 48
; CV1-NEXT:    extfz $r3 = $r1, 55, 48
; CV1-NEXT:    srld $r6 = $r0, 56
; CV1-NEXT:    srld $r7 = $r1, 56
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r4 = $r0, 47, 40
; CV1-NEXT:    extfz $r5 = $r1, 47, 40
; CV1-NEXT:    srlw $r10 = $r0, 24
; CV1-NEXT:    srlw $r11 = $r1, 24
; CV1-NEXT:    ;;
; CV1-NEXT:    sllw $r2 = $r2, $r3
; CV1-NEXT:    sllw $r6 = $r6, $r7
; CV1-NEXT:    extfz $r8 = $r0, 39, 32
; CV1-NEXT:    extfz $r9 = $r1, 39, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    sllw $r3 = $r4, $r5
; CV1-NEXT:    sllw $r5 = $r10, $r11
; CV1-NEXT:    extfz $r15 = $r0, 23, 16
; CV1-NEXT:    extfz $r16 = $r1, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    zxbd $r1 = $r1
; CV1-NEXT:    extfz $r17 = $r0, 15, 8
; CV1-NEXT:    extfz $r32 = $r1, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r2 = $r6, 15, 8
; CV1-NEXT:    sllw $r4 = $r8, $r9
; CV1-NEXT:    sllw $r7 = $r15, $r16
; CV1-NEXT:    sllw $r8 = $r17, $r32
; CV1-NEXT:    ;;
; CV1-NEXT:    sllw $r0 = $r0, $r1
; CV1-NEXT:    insf $r4 = $r3, 15, 8
; CV1-NEXT:    insf $r7 = $r5, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r8, 15, 8
; CV1-NEXT:    insf $r4 = $r2, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r7, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: shiftL_rr_vec:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    extfz $r2 = $r1, 10, 8
; CV2-NEXT:    extfz $r4 = $r1, 18, 16
; CV2-NEXT:    ;;
; CV2-NEXT:    sllbos $r2 = $r0, $r2
; CV2-NEXT:    sllbos $r3 = $r0, $r1
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 7, 0
; CV2-NEXT:    sllbos $r4 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r3 = $r1, 26, 24
; CV2-NEXT:    insf $r4 = $r2, 15, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r2 = $r1, 34, 32
; CV2-NEXT:    sllbos $r3 = $r0, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r3 = $r4, 23, 0
; CV2-NEXT:    extfz $r4 = $r1, 42, 40
; CV2-NEXT:    ;;
; CV2-NEXT:    sllbos $r2 = $r0, $r2
; CV2-NEXT:    sllbos $r4 = $r0, $r4
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r3, 31, 0
; CV2-NEXT:    extfz $r3 = $r1, 50, 48
; CV2-NEXT:    ;;
; CV2-NEXT:    extfz $r1 = $r1, 58, 56
; CV2-NEXT:    insf $r4 = $r2, 39, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    sllbos $r0 = $r0, $r1
; CV2-NEXT:    sllbos $r2 = $r0, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r2 = $r4, 47, 0
; CV2-NEXT:    ;;
; CV2-NEXT:    insf $r0 = $r2, 55, 0
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
entry:
  %shl = shl <8 x i8> %a, %b
  ret <8 x i8> %shl
}
