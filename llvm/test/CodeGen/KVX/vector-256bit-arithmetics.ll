; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O2 -o - %s | FileCheck %s
target triple = "kvx-kalray-cos"

define <4 x double> @mul_v4f64_v4f64(<4 x double> %0, <4 x double> %1) {
; CHECK-LABEL: mul_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmuld $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fmul <4 x double> %0, %1
  ret <4 x double> %3
}

define <4 x double> @mul_v4f64_f64(<4 x double> %0, double %1) {
; CHECK-LABEL: mul_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmuld $r1 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r2 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x double> undef, double %1, i32 0
  %4 = shufflevector <4 x double> %3, <4 x double> undef, <4 x i32> zeroinitializer
  %5 = fmul <4 x double> %4, %0
  ret <4 x double> %5
}

define <4 x double> @div_v4f64_v4f64(<4 x double> %0, <4 x double> %1) {
; CHECK-LABEL: div_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 48[$r12] = $r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 25, -16
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -24
; CHECK-NEXT:    .cfi_offset 21, -32
; CHECK-NEXT:    .cfi_offset 22, -40
; CHECK-NEXT:    .cfi_offset 23, -48
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r19 = $r6
; CHECK-NEXT:    copyd $r20 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -56
; CHECK-NEXT:    .cfi_offset 19, -64
; CHECK-NEXT:    copyd $r21 = $r3
; CHECK-NEXT:    copyd $r22 = $r2
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r25
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r25 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fdiv <4 x double> %0, %1
  ret <4 x double> %3
}

define <4 x double> @div_v4f64_f64(<4 x double> %0, double %1) {
; CHECK-LABEL: div_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sq 40[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    .cfi_offset 25, -24
; CHECK-NEXT:    sd 32[$r12] = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 22, -32
; CHECK-NEXT:    sq 16[$r12] = $r20r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -40
; CHECK-NEXT:    .cfi_offset 21, -48
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r20 = $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -56
; CHECK-NEXT:    .cfi_offset 19, -64
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r25
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r20r21 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r22 = 32[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 40[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x double> undef, double %1, i32 0
  %4 = shufflevector <4 x double> %3, <4 x double> undef, <4 x i32> zeroinitializer
  %5 = fdiv <4 x double> %0, %4
  ret <4 x double> %5
}

define <4 x double> @add_v4f64_v4f64(<4 x double> %0, <4 x double> %1) {
; CHECK-LABEL: add_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fadddp $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fadddp $r0r1 = $r0r1, $r4r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd <4 x double> %0, %1
  ret <4 x double> %3
}

define <4 x double> @add_v4f64_f64(<4 x double> %0, double %1) {
; CHECK-LABEL: add_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    copyd $r6 = $r4
; CHECK-NEXT:    copyd $r7 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fadddp $r2r3 = $r6r7, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fadddp $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x double> undef, double %1, i32 0
  %4 = shufflevector <4 x double> %3, <4 x double> undef, <4 x i32> zeroinitializer
  %5 = fadd <4 x double> %4, %0
  ret <4 x double> %5
}

define <4 x double> @sub_v4f64_v4f64(<4 x double> %0, <4 x double> %1) {
; CHECK-LABEL: sub_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fsbfdp $r2r3 = $r6r7, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfdp $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fsub <4 x double> %0, %1
  ret <4 x double> %3
}

define <4 x double> @sub_v4f64_f64(<4 x double> %0, double %1) {
; CHECK-LABEL: sub_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    copyd $r6 = $r4
; CHECK-NEXT:    copyd $r7 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfdp $r2r3 = $r6r7, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfdp $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x double> undef, double %1, i32 0
  %4 = shufflevector <4 x double> %3, <4 x double> undef, <4 x i32> zeroinitializer
  %5 = fsub <4 x double> %0, %4
  ret <4 x double> %5
}

define <4 x double> @mul_add_v4f64_v4f64(<4 x double> %0, <4 x double> %1, <4 x double> %2) {
; CHECK-LABEL: mul_add_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmuld $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r3 = $r3, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fadddp $r2r3 = $r2r3, $r10r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fadddp $r0r1 = $r0r1, $r8r9
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = fmul <4 x double> %0, %1
  %5 = fadd <4 x double> %4, %2
  ret <4 x double> %5
}

define <4 x i64> @mul_v4i64_v4i64(<4 x i64> %0, <4 x i64> %1) {
; CHECK-LABEL: mul_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    muld $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = mul <4 x i64> %1, %0
  ret <4 x i64> %3
}

define <4 x i64> @mul_v4i64_i64(<4 x i64> %0, i64 %1) {
; CHECK-LABEL: mul_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    muld $r1 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r2 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x i64> undef, i64 %1, i32 0
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <4 x i32> zeroinitializer
  %5 = mul <4 x i64> %4, %0
  ret <4 x i64> %5
}

define <4 x i64> @div_v4i64_v4i64(<4 x i64> %0, <4 x i64> %1) {
; CHECK-LABEL: div_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 48[$r12] = $r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 25, -16
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -24
; CHECK-NEXT:    .cfi_offset 21, -32
; CHECK-NEXT:    .cfi_offset 22, -40
; CHECK-NEXT:    .cfi_offset 23, -48
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r19 = $r6
; CHECK-NEXT:    copyd $r20 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -56
; CHECK-NEXT:    .cfi_offset 19, -64
; CHECK-NEXT:    copyd $r21 = $r3
; CHECK-NEXT:    copyd $r22 = $r2
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r25
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r25 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sdiv <4 x i64> %0, %1
  ret <4 x i64> %3
}

define <4 x i64> @div_v4i64_i64(<4 x i64> %0, i64 %1) {
; CHECK-LABEL: div_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sq 40[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    .cfi_offset 25, -24
; CHECK-NEXT:    sd 32[$r12] = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 22, -32
; CHECK-NEXT:    sq 16[$r12] = $r20r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -40
; CHECK-NEXT:    .cfi_offset 21, -48
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r20 = $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -56
; CHECK-NEXT:    .cfi_offset 19, -64
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r25
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r20r21 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r22 = 32[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 40[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x i64> undef, i64 %1, i32 0
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <4 x i32> zeroinitializer
  %5 = sdiv <4 x i64> %0, %4
  ret <4 x i64> %5
}

define <4 x i64> @add_v4i64_v4i64(<4 x i64> %0, <4 x i64> %1) {
; CHECK-LABEL: add_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r1 = $r5, $r1
; CHECK-NEXT:    addd $r0 = $r4, $r0
; CHECK-NEXT:    addd $r2 = $r6, $r2
; CHECK-NEXT:    addd $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = add <4 x i64> %1, %0
  ret <4 x i64> %3
}

define <4 x i64> @add_v4i64_i64(<4 x i64> %0, i64 %1) {
; CHECK-LABEL: add_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r1 = $r4, $r1
; CHECK-NEXT:    addd $r0 = $r4, $r0
; CHECK-NEXT:    addd $r2 = $r4, $r2
; CHECK-NEXT:    addd $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x i64> undef, i64 %1, i32 0
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <4 x i32> zeroinitializer
  %5 = add <4 x i64> %4, %0
  ret <4 x i64> %5
}

define <4 x i64> @sub_v4i64_v4i64(<4 x i64> %0, <4 x i64> %1) {
; CHECK-LABEL: sub_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbfd $r1 = $r5, $r1
; CHECK-NEXT:    sbfd $r0 = $r4, $r0
; CHECK-NEXT:    sbfd $r2 = $r6, $r2
; CHECK-NEXT:    sbfd $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sub <4 x i64> %0, %1
  ret <4 x i64> %3
}

define <4 x i64> @sub_v4i64_i64(<4 x i64> %0, i64 %1) {
; CHECK-LABEL: sub_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbfd $r1 = $r4, $r1
; CHECK-NEXT:    sbfd $r0 = $r4, $r0
; CHECK-NEXT:    sbfd $r2 = $r4, $r2
; CHECK-NEXT:    sbfd $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x i64> undef, i64 %1, i32 0
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <4 x i32> zeroinitializer
  %5 = sub <4 x i64> %0, %4
  ret <4 x i64> %5
}

define <4 x i64> @mul_add_v4i64_v4i64(<4 x i64> %0, <4 x i64> %1, <4 x i64> %2) {
; CHECK-LABEL: mul_add_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    maddd $r8 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddd $r9 = $r5, $r1
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddd $r10 = $r6, $r2
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddd $r11 = $r7, $r3
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = mul <4 x i64> %1, %0
  %5 = add <4 x i64> %4, %2
  ret <4 x i64> %5
}

define <8 x float> @mul_vv8f32_v8f32(<8 x float> %0, <8 x float> %1) {
; CHECK-LABEL: mul_vv8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmulwp $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwp $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwp $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwp $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fmul <8 x float> %0, %1
  ret <8 x float> %3
}

define <8 x float> @mul_v8f32_f32(<8 x float> %0, float %1) {
; CHECK-LABEL: mul_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r4 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r2r3 = $r4r5, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x float> undef, float %1, i32 0
  %4 = shufflevector <8 x float> %3, <8 x float> undef, <8 x i32> zeroinitializer
  %5 = fmul <8 x float> %4, %0
  ret <8 x float> %5
}

define <8 x float> @div_v8f32_v8f32(<8 x float> %0, <8 x float> %1) {
; CHECK-LABEL: div_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 80[$r12] = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 26, -16
; CHECK-NEXT:    sq 64[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -24
; CHECK-NEXT:    .cfi_offset 25, -32
; CHECK-NEXT:    so 32[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -40
; CHECK-NEXT:    .cfi_offset 21, -48
; CHECK-NEXT:    .cfi_offset 22, -56
; CHECK-NEXT:    .cfi_offset 23, -64
; CHECK-NEXT:    sq 16[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r19 = $r6
; CHECK-NEXT:    copyd $r20 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -72
; CHECK-NEXT:    .cfi_offset 19, -80
; CHECK-NEXT:    copyd $r21 = $r4
; CHECK-NEXT:    copyd $r22 = $r3
; CHECK-NEXT:    copyd $r23 = $r2
; CHECK-NEXT:    copyd $r24 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    srad $r0 = $r22, 32
; CHECK-NEXT:    srad $r1 = $r18, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    srad $r0 = $r23, 32
; CHECK-NEXT:    srad $r1 = $r19, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    srad $r0 = $r24, 32
; CHECK-NEXT:    srad $r1 = $r20, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r25, 32
; CHECK-NEXT:    srad $r1 = $r21, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    copyd $r0 = $r25
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r23, 63, 32
; CHECK-NEXT:    insf $r19 = $r22, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r26, 63, 32
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    copyd $r2 = $r19
; CHECK-NEXT:    insf $r0 = $r24, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r18
; CHECK-NEXT:    lq $r18r19 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r26 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fdiv <8 x float> %0, %1
  ret <8 x float> %3
}

define <8 x float> @div_v8f32_f32(<8 x float> %0, float %1) {
; CHECK-LABEL: div_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 80[$r12] = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 26, -16
; CHECK-NEXT:    sq 64[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -24
; CHECK-NEXT:    .cfi_offset 25, -32
; CHECK-NEXT:    so 32[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -40
; CHECK-NEXT:    .cfi_offset 21, -48
; CHECK-NEXT:    .cfi_offset 22, -56
; CHECK-NEXT:    .cfi_offset 23, -64
; CHECK-NEXT:    sq 16[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r20 = $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -72
; CHECK-NEXT:    .cfi_offset 19, -80
; CHECK-NEXT:    copyd $r21 = $r1
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    srad $r0 = $r19, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    srad $r0 = $r20, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r21, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srad $r0 = $r22, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r25, 63, 32
; CHECK-NEXT:    insf $r20 = $r24, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r23, 63, 32
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r20
; CHECK-NEXT:    insf $r0 = $r26, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r19
; CHECK-NEXT:    lq $r18r19 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r26 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x float> undef, float %1, i32 0
  %4 = shufflevector <8 x float> %3, <8 x float> undef, <8 x i32> zeroinitializer
  %5 = fdiv <8 x float> %0, %4
  ret <8 x float> %5
}

define <8 x float> @add_v8f32_v8f32(<8 x float> %0, <8 x float> %1) {
; CHECK-LABEL: add_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    faddwp $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwp $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwp $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwp $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd <8 x float> %0, %1
  ret <8 x float> %3
}

define <8 x float> @add_v8f32_f32(<8 x float> %0, float %1) {
; CHECK-LABEL: add_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r4 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r2r3 = $r4r5, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x float> undef, float %1, i32 0
  %4 = shufflevector <8 x float> %3, <8 x float> undef, <8 x i32> zeroinitializer
  %5 = fadd <8 x float> %4, %0
  ret <8 x float> %5
}

define <8 x float> @sub_v8f32_v8f32(<8 x float> %0, <8 x float> %1) {
; CHECK-LABEL: sub_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fsbfwp $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfwp $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfwp $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfwp $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fsub <8 x float> %0, %1
  ret <8 x float> %3
}

define <8 x float> @sub_v8f32_f32(<8 x float> %0, float %1) {
; CHECK-LABEL: sub_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r4 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfwq $r2r3 = $r4r5, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x float> undef, float %1, i32 0
  %4 = shufflevector <8 x float> %3, <8 x float> undef, <8 x i32> zeroinitializer
  %5 = fsub <8 x float> %0, %4
  ret <8 x float> %5
}

define <8 x float> @mul_add_v8f32_v8f32(<8 x float> %0, <8 x float> %1, <8 x float> %2) {
; CHECK-LABEL: mul_add_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmulwq $r0r1 = $r0r1, $r4r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r2r3 = $r2r3, $r10r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r0r1 = $r0r1, $r8r9
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = fmul <8 x float> %0, %1
  %5 = fadd <8 x float> %4, %2
  ret <8 x float> %5
}

define <8 x i32> @mul_v8i32_v8i32(<8 x i32> %0, <8 x i32> %1) {
; CHECK-LABEL: mul_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mulwp $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulwp $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulwp $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulwp $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = mul <8 x i32> %1, %0
  ret <8 x i32> %3
}

define <8 x i32> @mul_v8i32_i32(<8 x i32> %0, i32 %1) {
; CHECK-LABEL: mul_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r4 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulwq $r2r3 = $r4r5, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x i32> undef, i32 %1, i32 0
  %4 = shufflevector <8 x i32> %3, <8 x i32> undef, <8 x i32> zeroinitializer
  %5 = mul <8 x i32> %4, %0
  ret <8 x i32> %5
}

define <8 x i32> @div_v8i32_v8i32(<8 x i32> %0, <8 x i32> %1) {
; CHECK-LABEL: div_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 80[$r12] = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 26, -16
; CHECK-NEXT:    sq 64[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -24
; CHECK-NEXT:    .cfi_offset 25, -32
; CHECK-NEXT:    so 32[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -40
; CHECK-NEXT:    .cfi_offset 21, -48
; CHECK-NEXT:    .cfi_offset 22, -56
; CHECK-NEXT:    .cfi_offset 23, -64
; CHECK-NEXT:    sq 16[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r19 = $r6
; CHECK-NEXT:    copyd $r20 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -72
; CHECK-NEXT:    .cfi_offset 19, -80
; CHECK-NEXT:    copyd $r21 = $r4
; CHECK-NEXT:    copyd $r22 = $r3
; CHECK-NEXT:    copyd $r23 = $r2
; CHECK-NEXT:    copyd $r24 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r18, 32
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    srad $r0 = $r22, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    sxwd $r0 = $r22
; CHECK-NEXT:    sxwd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r19, 32
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    srad $r0 = $r23, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    sxwd $r0 = $r23
; CHECK-NEXT:    sxwd $r1 = $r19
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r20, 32
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    srad $r0 = $r24, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    sxwd $r0 = $r24
; CHECK-NEXT:    sxwd $r1 = $r20
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r21, 32
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r25, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    sxwd $r0 = $r25
; CHECK-NEXT:    sxwd $r1 = $r21
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r23, 63, 32
; CHECK-NEXT:    insf $r19 = $r22, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r26, 63, 32
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    copyd $r2 = $r19
; CHECK-NEXT:    insf $r0 = $r24, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r18
; CHECK-NEXT:    lq $r18r19 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r26 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sdiv <8 x i32> %0, %1
  ret <8 x i32> %3
}

define <8 x i32> @div_v8i32_i32(<8 x i32> %0, i32 %1) {
; CHECK-LABEL: div_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 80[$r12] = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 26, -16
; CHECK-NEXT:    sq 64[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -24
; CHECK-NEXT:    .cfi_offset 25, -32
; CHECK-NEXT:    so 32[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -40
; CHECK-NEXT:    .cfi_offset 21, -48
; CHECK-NEXT:    .cfi_offset 22, -56
; CHECK-NEXT:    .cfi_offset 23, -64
; CHECK-NEXT:    sq 16[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -72
; CHECK-NEXT:    .cfi_offset 19, -80
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srad $r0 = $r18, 32
; CHECK-NEXT:    sxwd $r22 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    sxwd $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    srad $r0 = $r19, 32
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    sxwd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    srad $r0 = $r20, 32
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    sxwd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r21, 32
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    sxwd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r25, 63, 32
; CHECK-NEXT:    insf $r19 = $r24, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r23, 63, 32
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    copyd $r2 = $r19
; CHECK-NEXT:    insf $r0 = $r26, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r18
; CHECK-NEXT:    lq $r18r19 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r26 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x i32> undef, i32 %1, i32 0
  %4 = shufflevector <8 x i32> %3, <8 x i32> undef, <8 x i32> zeroinitializer
  %5 = sdiv <8 x i32> %0, %4
  ret <8 x i32> %5
}

define <8 x i32> @add_v8i32_v8i32(<8 x i32> %0, <8 x i32> %1) {
; CHECK-LABEL: add_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addwp $r0 = $r4, $r0
; CHECK-NEXT:    addwp $r1 = $r5, $r1
; CHECK-NEXT:    addwp $r2 = $r6, $r2
; CHECK-NEXT:    addwp $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = add <8 x i32> %1, %0
  ret <8 x i32> %3
}

define <8 x i32> @add_v8i32_i32(<8 x i32> %0, i32 %1) {
; CHECK-LABEL: add_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r4 = $r5
; CHECK-NEXT:    addwp $r3 = $r5, $r3
; CHECK-NEXT:    addwp $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addwp $r2 = $r4, $r2
; CHECK-NEXT:    addwp $r0 = $r4, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x i32> undef, i32 %1, i32 0
  %4 = shufflevector <8 x i32> %3, <8 x i32> undef, <8 x i32> zeroinitializer
  %5 = add <8 x i32> %4, %0
  ret <8 x i32> %5
}

define <8 x i32> @sub_v8i32_v8i32(<8 x i32> %0, <8 x i32> %1) {
; CHECK-LABEL: sub_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbfwp $r0 = $r4, $r0
; CHECK-NEXT:    sbfwp $r1 = $r5, $r1
; CHECK-NEXT:    sbfwp $r2 = $r6, $r2
; CHECK-NEXT:    sbfwp $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sub <8 x i32> %0, %1
  ret <8 x i32> %3
}

define <8 x i32> @sub_v8i32_i32(<8 x i32> %0, i32 %1) {
; CHECK-LABEL: sub_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r4 = $r5
; CHECK-NEXT:    sbfwp $r3 = $r5, $r3
; CHECK-NEXT:    sbfwp $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfwp $r2 = $r4, $r2
; CHECK-NEXT:    sbfwp $r0 = $r4, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x i32> undef, i32 %1, i32 0
  %4 = shufflevector <8 x i32> %3, <8 x i32> undef, <8 x i32> zeroinitializer
  %5 = sub <8 x i32> %0, %4
  ret <8 x i32> %5
}

define <8 x i32> @mul_add_v8i32_v8i32(<8 x i32> %0, <8 x i32> %1, <8 x i32> %2) {
; CHECK-LABEL: mul_add_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    maddwp $r8 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddwp $r11 = $r7, $r3
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddwp $r9 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddwp $r10 = $r6, $r2
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = mul <8 x i32> %1, %0
  %5 = add <8 x i32> %4, %2
  ret <8 x i32> %5
}

define <16 x half> @mul_vv16f16_v16f16(<16 x half> %0, <16 x half> %1) {
; CHECK-LABEL: mul_vv16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmulhq $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fmul <16 x half> %0, %1
  ret <16 x half> %3
}

define <16 x half> @mul_v16f16_f16(<16 x half> %0, half %1) {
; CHECK-LABEL: mul_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    insf $r4 = $r4, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r4, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r1 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r2 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x half> undef, half %1, i32 0
  %4 = shufflevector <16 x half> %3, <16 x half> undef, <16 x i32> zeroinitializer
  %5 = fmul <16 x half> %4, %0
  ret <16 x half> %5
}

define <16 x half> @div_v16f16_v16f16(<16 x half> %0, <16 x half> %1) {
; CHECK-LABEL: div_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 56[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    .cfi_offset 25, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 27, -40
; CHECK-NEXT:    so 24[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    .cfi_offset 21, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 23, -72
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r21 = $r6
; CHECK-NEXT:    copyd $r23 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -80
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    copyd $r20 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r22 = $r2
; CHECK-NEXT:    copyd $r24 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r0 = $r25, 48
; CHECK-NEXT:    srld $r1 = $r20, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r20, 32
; CHECK-NEXT:    fnarrowwh $r26 = $r0
; CHECK-NEXT:    srld $r0 = $r25, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r27 = $r0
; CHECK-NEXT:    srlw $r0 = $r25, 16
; CHECK-NEXT:    srlw $r1 = $r20, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r27 = $r26, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r26 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r20
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r20 = $r0
; CHECK-NEXT:    srld $r0 = $r24, 48
; CHECK-NEXT:    srld $r1 = $r23, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r26, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r20 = $r27, 63, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r23, 32
; CHECK-NEXT:    fnarrowwh $r25 = $r0
; CHECK-NEXT:    srld $r0 = $r24, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r26 = $r0
; CHECK-NEXT:    srlw $r0 = $r24, 16
; CHECK-NEXT:    srlw $r1 = $r23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r26 = $r25, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r25 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r23
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r23 = $r0
; CHECK-NEXT:    srld $r0 = $r22, 48
; CHECK-NEXT:    srld $r1 = $r21, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r25, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r23 = $r26, 63, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r21, 32
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    srld $r0 = $r22, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r25 = $r0
; CHECK-NEXT:    srlw $r0 = $r22, 16
; CHECK-NEXT:    srlw $r1 = $r21, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r25 = $r24, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r21
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r21 = $r0
; CHECK-NEXT:    srld $r0 = $r19, 48
; CHECK-NEXT:    srld $r1 = $r18, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r21 = $r25, 63, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r18, 32
; CHECK-NEXT:    fnarrowwh $r22 = $r0
; CHECK-NEXT:    srld $r0 = $r19, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    srlw $r0 = $r19, 16
; CHECK-NEXT:    srlw $r1 = $r18, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r22, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r22 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r23
; CHECK-NEXT:    copyd $r2 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r22, 31, 16
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 24[$r12]
; CHECK-NEXT:    insf $r3 = $r24, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fdiv <16 x half> %0, %1
  ret <16 x half> %3
}

define <16 x half> @div_v16f16_f16(<16 x half> %0, half %1) {
; CHECK-LABEL: div_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -24
; CHECK-NEXT:    .cfi_offset 21, -32
; CHECK-NEXT:    .cfi_offset 22, -40
; CHECK-NEXT:    .cfi_offset 23, -48
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r20 = $r2
; CHECK-NEXT:    copyd $r21 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -56
; CHECK-NEXT:    .cfi_offset 19, -64
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r0 = $r22, 48
; CHECK-NEXT:    fwidenlhw $r19 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r23 = $r0
; CHECK-NEXT:    srld $r0 = $r22, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    srlw $r0 = $r22, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r23 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r22 = $r0
; CHECK-NEXT:    srld $r0 = $r21, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r23, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r24, 63, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r23 = $r0
; CHECK-NEXT:    srld $r0 = $r21, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    srlw $r0 = $r21, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r23 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r21 = $r0
; CHECK-NEXT:    srld $r0 = $r20, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r23, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 63, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r23 = $r0
; CHECK-NEXT:    srld $r0 = $r20, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    srlw $r0 = $r20, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r23 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r20 = $r0
; CHECK-NEXT:    srld $r0 = $r18, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r23, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r24, 63, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r23 = $r0
; CHECK-NEXT:    srld $r0 = $r18, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    srlw $r0 = $r18, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r23 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r20
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r23, 31, 16
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    insf $r3 = $r24, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x half> undef, half %1, i32 0
  %4 = shufflevector <16 x half> %3, <16 x half> undef, <16 x i32> zeroinitializer
  %5 = fdiv <16 x half> %0, %4
  ret <16 x half> %5
}

define <16 x half> @add_v16f16_v16f16(<16 x half> %0, <16 x half> %1) {
; CHECK-LABEL: add_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    faddhq $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd <16 x half> %0, %1
  ret <16 x half> %3
}

define <16 x half> @add_v16f16_f16(<16 x half> %0, half %1) {
; CHECK-LABEL: add_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    insf $r4 = $r4, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r4, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r1 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r2 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x half> undef, half %1, i32 0
  %4 = shufflevector <16 x half> %3, <16 x half> undef, <16 x i32> zeroinitializer
  %5 = fadd <16 x half> %4, %0
  ret <16 x half> %5
}

define <16 x half> @sub_v16f16_v16f16(<16 x half> %0, <16 x half> %1) {
; CHECK-LABEL: sub_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fsbfhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fsub <16 x half> %0, %1
  ret <16 x half> %3
}

define <16 x half> @sub_v16f16_f16(<16 x half> %0, half %1) {
; CHECK-LABEL: sub_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    insf $r4 = $r4, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r4, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r1 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r2 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x half> undef, half %1, i32 0
  %4 = shufflevector <16 x half> %3, <16 x half> undef, <16 x i32> zeroinitializer
  %5 = fsub <16 x half> %0, %4
  ret <16 x half> %5
}

define <16 x half> @mul_add_v16f16_v16f16(<16 x half> %0, <16 x half> %1, <16 x half> %2) {
; CHECK-LABEL: mul_add_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmulhq $r3 = $r3, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r0 = $r0, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r1 = $r1, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r2 = $r2, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r3 = $r3, $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = fmul <16 x half> %0, %1
  %5 = fadd <16 x half> %4, %2
  ret <16 x half> %5
}

define <16 x i16> @mul_v16i16_v16i16(<16 x i16> %0, <16 x i16> %1) {
; CHECK-LABEL: mul_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mulhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = mul <16 x i16> %1, %0
  ret <16 x i16> %3
}

define <16 x i16> @mul_v16i16_i16(<16 x i16> %0, i16 %1) {
; CHECK-LABEL: mul_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbmm8 $r4 = $r4, 0x201020102010201
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r1 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r2 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x i16> undef, i16 %1, i32 0
  %4 = shufflevector <16 x i16> %3, <16 x i16> undef, <16 x i32> zeroinitializer
  %5 = mul <16 x i16> %4, %0
  ret <16 x i16> %5
}

define <16 x i16> @div_v16i16_v16i16(<16 x i16> %0, <16 x i16> %1) {
; CHECK-LABEL: div_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 56[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    .cfi_offset 25, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 27, -40
; CHECK-NEXT:    so 24[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    .cfi_offset 21, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 23, -72
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r21 = $r6
; CHECK-NEXT:    copyd $r22 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -80
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    copyd $r20 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r23 = $r2
; CHECK-NEXT:    copyd $r24 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r0 = $r25, 48
; CHECK-NEXT:    srad $r1 = $r20, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r20, 47, 32
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    extfs $r0 = $r25, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r27 = $r0
; CHECK-NEXT:    extfs $r0 = $r25, 31, 16
; CHECK-NEXT:    extfs $r1 = $r20, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r27 = $r26, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxhd $r1 = $r20
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    sxhd $r0 = $r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r24, 48
; CHECK-NEXT:    srad $r1 = $r22, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r26, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r20 = $r27, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r22, 47, 32
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    extfs $r0 = $r24, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    extfs $r0 = $r24, 31, 16
; CHECK-NEXT:    extfs $r1 = $r22, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r26 = $r25, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxhd $r1 = $r22
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    sxhd $r0 = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    srad $r0 = $r23, 48
; CHECK-NEXT:    srad $r1 = $r21, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r25, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r22 = $r26, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r21, 47, 32
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r23, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    extfs $r0 = $r23, 31, 16
; CHECK-NEXT:    extfs $r1 = $r21, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r25 = $r24, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxhd $r1 = $r21
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    sxhd $r0 = $r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srad $r0 = $r19, 48
; CHECK-NEXT:    srad $r1 = $r18, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r21 = $r25, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r18, 47, 32
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfs $r0 = $r19, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r19, 31, 16
; CHECK-NEXT:    extfs $r1 = $r18, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r23, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxhd $r1 = $r18
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    sxhd $r0 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    copyd $r2 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r23, 31, 16
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 24[$r12]
; CHECK-NEXT:    insf $r3 = $r24, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sdiv <16 x i16> %0, %1
  ret <16 x i16> %3
}

define <16 x i16> @div_v16i16_i16(<16 x i16> %0, i16 %1) {
; CHECK-LABEL: div_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -24
; CHECK-NEXT:    .cfi_offset 21, -32
; CHECK-NEXT:    .cfi_offset 22, -40
; CHECK-NEXT:    .cfi_offset 23, -48
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r20 = $r2
; CHECK-NEXT:    copyd $r21 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -56
; CHECK-NEXT:    .cfi_offset 19, -64
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    sxhd $r1 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r0 = $r22, 48
; CHECK-NEXT:    sxwd $r19 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfs $r0 = $r22, 47, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r22, 31, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    sxhd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    srad $r0 = $r21, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r23, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r24, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfs $r0 = $r21, 47, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r21, 31, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    sxhd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srad $r0 = $r20, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r23, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfs $r0 = $r20, 47, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r20, 31, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    sxhd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r18, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r23, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r24, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfs $r0 = $r18, 47, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r18, 31, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    sxhd $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r20
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r23, 31, 16
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    insf $r3 = $r24, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x i16> undef, i16 %1, i32 0
  %4 = shufflevector <16 x i16> %3, <16 x i16> undef, <16 x i32> zeroinitializer
  %5 = sdiv <16 x i16> %0, %4
  ret <16 x i16> %5
}

define <16 x i16> @add_v16i16_v16i16(<16 x i16> %0, <16 x i16> %1) {
; CHECK-LABEL: add_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addhq $r0 = $r4, $r0
; CHECK-NEXT:    addhq $r1 = $r5, $r1
; CHECK-NEXT:    addhq $r2 = $r6, $r2
; CHECK-NEXT:    addhq $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = add <16 x i16> %1, %0
  ret <16 x i16> %3
}

define <16 x i16> @add_v16i16_i16(<16 x i16> %0, i16 %1) {
; CHECK-LABEL: add_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbmm8 $r4 = $r4, 0x201020102010201
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addhq $r0 = $r4, $r0
; CHECK-NEXT:    addhq $r1 = $r4, $r1
; CHECK-NEXT:    addhq $r2 = $r4, $r2
; CHECK-NEXT:    addhq $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x i16> undef, i16 %1, i32 0
  %4 = shufflevector <16 x i16> %3, <16 x i16> undef, <16 x i32> zeroinitializer
  %5 = add <16 x i16> %4, %0
  ret <16 x i16> %5
}

define <16 x i16> @sub_v16i16_v16i16(<16 x i16> %0, <16 x i16> %1) {
; CHECK-LABEL: sub_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbfhq $r0 = $r4, $r0
; CHECK-NEXT:    sbfhq $r1 = $r5, $r1
; CHECK-NEXT:    sbfhq $r2 = $r6, $r2
; CHECK-NEXT:    sbfhq $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sub <16 x i16> %0, %1
  ret <16 x i16> %3
}

define <16 x i16> @sub_v16i16_i16(<16 x i16> %0, i16 %1) {
; CHECK-LABEL: sub_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbmm8 $r4 = $r4, 0x201020102010201
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfhq $r0 = $r4, $r0
; CHECK-NEXT:    sbfhq $r1 = $r4, $r1
; CHECK-NEXT:    sbfhq $r2 = $r4, $r2
; CHECK-NEXT:    sbfhq $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x i16> undef, i16 %1, i32 0
  %4 = shufflevector <16 x i16> %3, <16 x i16> undef, <16 x i32> zeroinitializer
  %5 = sub <16 x i16> %0, %4
  ret <16 x i16> %5
}

; TODO: Improve packetizer/scheduler to avoid RAW deps at every bundle.
; The three first maddhq could be placed alone.
define <16 x i16> @mul_add_v16i16_v16i16(<16 x i16> %0, <16 x i16> %1, <16 x i16> %2) {
; CHECK-LABEL: mul_add_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    maddhq $r8 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddhq $r9 = $r5, $r1
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddhq $r10 = $r6, $r2
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddhq $r11 = $r7, $r3
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = mul <16 x i16> %1, %0
  %5 = add <16 x i16> %4, %2
  ret <16 x i16> %5
}

define <32 x i8> @mul_v32i8_v32i8(<32 x i8> %0, <32 x i8> %1) {
; CHECK-LABEL: mul_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sxmbhq $r8 = $r0
; CHECK-NEXT:    sxmbhq $r9 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r0 = $r0
; CHECK-NEXT:    sxlbhq $r4 = $r4
; CHECK-NEXT:    mulhq $r8 = $r9, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r9 = $r5
; CHECK-NEXT:    sxlbhq $r5 = $r5
; CHECK-NEXT:    mulhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r4 = $r1
; CHECK-NEXT:    sxlbhq $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r4 = $r9, $r4
; CHECK-NEXT:    sxmbhq $r9 = $r6
; CHECK-NEXT:    sxlbhq $r6 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r8 = $r8, 0x40100401
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    mulhq $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r5 = $r2
; CHECK-NEXT:    sxlbhq $r2 = $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r2 = $r6, $r2
; CHECK-NEXT:    sxmbhq $r6 = $r3
; CHECK-NEXT:    sxlbhq $r3 = $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r4 = $r4, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    mulhq $r5 = $r9, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r9 = $r7
; CHECK-NEXT:    sxlbhq $r7 = $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r3 = $r7, $r3
; CHECK-NEXT:    insf $r1 = $r4, 63, 32
; CHECK-NEXT:    sbmm8 $r4 = $r5, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r2 = $r2, 0x40100401
; CHECK-NEXT:    insf $r0 = $r8, 63, 32
; CHECK-NEXT:    mulhq $r6 = $r9, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CHECK-NEXT:    insf $r2 = $r4, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r5 = $r6, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r5, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = mul <32 x i8> %1, %0
  ret <32 x i8> %3
}

define <32 x i8> @mul_v32i8_i8(<32 x i8> %0, i8 %1) {
; CHECK-LABEL: mul_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    insf $r4 = $r4, 15, 8
; CHECK-NEXT:    sxmbhq $r5 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r4, 31, 16
; CHECK-NEXT:    sxlbhq $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r4 = $r4, 0x8000400020001
; CHECK-NEXT:    sxmbhq $r6 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r7 = $r2
; CHECK-NEXT:    sxmbhq $r8 = $r3
; CHECK-NEXT:    mulhq $r5 = $r4, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r1 = $r1
; CHECK-NEXT:    sxlbhq $r2 = $r2
; CHECK-NEXT:    mulhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r3 = $r3
; CHECK-NEXT:    sbmm8 $r5 = $r5, 0x40100401
; CHECK-NEXT:    mulhq $r6 = $r4, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    mulhq $r1 = $r4, $r1
; CHECK-NEXT:    sbmm8 $r6 = $r6, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r5, 63, 32
; CHECK-NEXT:    mulhq $r2 = $r4, $r2
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r6, 63, 32
; CHECK-NEXT:    mulhq $r3 = $r4, $r3
; CHECK-NEXT:    sbmm8 $r2 = $r2, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r8 = $r4, $r8
; CHECK-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r7 = $r4, $r7
; CHECK-NEXT:    sbmm8 $r5 = $r8, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r5, 63, 32
; CHECK-NEXT:    sbmm8 $r4 = $r7, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r4, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <32 x i8> undef, i8 %1, i32 0
  %4 = shufflevector <32 x i8> %3, <32 x i8> undef, <32 x i32> zeroinitializer
  %5 = mul <32 x i8> %4, %0
  ret <32 x i8> %5
}

define <32 x i8> @div_v32i8_v32i8(<32 x i8> %0, <32 x i8> %1) {
; CHECK-LABEL: div_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 80[$r12] = $r28
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 28, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -24
; CHECK-NEXT:    .cfi_offset 25, -32
; CHECK-NEXT:    .cfi_offset 26, -40
; CHECK-NEXT:    .cfi_offset 27, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -56
; CHECK-NEXT:    .cfi_offset 21, -64
; CHECK-NEXT:    .cfi_offset 22, -72
; CHECK-NEXT:    .cfi_offset 23, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r21 = $r6
; CHECK-NEXT:    copyd $r23 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -88
; CHECK-NEXT:    .cfi_offset 19, -96
; CHECK-NEXT:    copyd $r20 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r22 = $r2
; CHECK-NEXT:    copyd $r24 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r0 = $r25, 56
; CHECK-NEXT:    srld $r1 = $r20, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r20, 55, 48
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r27 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 47, 40
; CHECK-NEXT:    extfz $r1 = $r20, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r27 = $r26, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r20, 39, 32
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r28 = $r0
; CHECK-NEXT:    srlw $r0 = $r25, 24
; CHECK-NEXT:    srlw $r1 = $r20, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r28 = $r26, 15, 8
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r28 = $r27, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r20, 23, 16
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r27 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 15, 8
; CHECK-NEXT:    extfz $r1 = $r20, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r27 = $r26, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxbd $r1 = $r20
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    zxbd $r0 = $r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srld $r0 = $r24, 56
; CHECK-NEXT:    srld $r1 = $r23, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r26, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    insf $r20 = $r27, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r28, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r23, 55, 48
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 47, 40
; CHECK-NEXT:    extfz $r1 = $r23, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r26 = $r25, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r23, 39, 32
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r27 = $r0
; CHECK-NEXT:    srlw $r0 = $r24, 24
; CHECK-NEXT:    srlw $r1 = $r23, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r27 = $r25, 15, 8
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r27 = $r26, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r23, 23, 16
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 15, 8
; CHECK-NEXT:    extfz $r1 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r26 = $r25, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxbd $r1 = $r23
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    zxbd $r0 = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    srld $r0 = $r22, 56
; CHECK-NEXT:    srld $r1 = $r21, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r25, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    insf $r23 = $r26, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r27, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r21, 55, 48
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 47, 40
; CHECK-NEXT:    extfz $r1 = $r21, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r25 = $r24, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r21, 39, 32
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    srlw $r0 = $r22, 24
; CHECK-NEXT:    srlw $r1 = $r21, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r26 = $r24, 15, 8
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r26 = $r25, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r21, 23, 16
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 15, 8
; CHECK-NEXT:    extfz $r1 = $r21, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r25 = $r24, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxbd $r1 = $r21
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    zxbd $r0 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srld $r0 = $r19, 56
; CHECK-NEXT:    srld $r1 = $r18, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    insf $r21 = $r25, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r26, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r18, 55, 48
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    extfz $r0 = $r19, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r19, 47, 40
; CHECK-NEXT:    extfz $r1 = $r18, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r22, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r18, 39, 32
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    extfz $r0 = $r19, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    srlw $r0 = $r19, 24
; CHECK-NEXT:    srlw $r1 = $r18, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r25 = $r22, 15, 8
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r25 = $r24, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r18, 23, 16
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    extfz $r0 = $r19, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r19, 15, 8
; CHECK-NEXT:    extfz $r1 = $r18, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r22, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxbd $r1 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    zxbd $r0 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r23
; CHECK-NEXT:    copyd $r2 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r22, 15, 8
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    insf $r3 = $r24, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r25, 63, 32
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r28 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sdiv <32 x i8> %0, %1
  ret <32 x i8> %3
}

define <32 x i8> @div_v32i8_i8(<32 x i8> %0, i8 %1) {
; CHECK-LABEL: div_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sq 72[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    .cfi_offset 25, -24
; CHECK-NEXT:    so 40[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -32
; CHECK-NEXT:    .cfi_offset 21, -40
; CHECK-NEXT:    .cfi_offset 22, -48
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    sq 24[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r21 = $r2
; CHECK-NEXT:    copyd $r22 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -64
; CHECK-NEXT:    .cfi_offset 19, -72
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r0 = $r20, 56
; CHECK-NEXT:    sxbd $r1 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxwd $r19 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 55, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 47, 40
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 39, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    srlw $r0 = $r20, 24
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r25 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r25 = $r24, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 23, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 15, 8
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    zxbd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srld $r0 = $r22, 56
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r23, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r24, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r25, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 55, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 47, 40
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 39, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    srlw $r0 = $r22, 24
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r25 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r25 = $r24, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 23, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 15, 8
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    zxbd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    srld $r0 = $r21, 56
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r23, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r24, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r25, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 55, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 47, 40
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 39, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    srlw $r0 = $r21, 24
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r25 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r25 = $r24, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 23, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 15, 8
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    zxbd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srld $r0 = $r18, 56
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r23, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r25, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r18, 55, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r18, 47, 40
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r18, 39, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    srlw $r0 = $r18, 24
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r25 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r25 = $r24, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r18, 23, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r18, 15, 8
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    zxbd $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    copyd $r2 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r23, 15, 8
; CHECK-NEXT:    lq $r18r19 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 40[$r12]
; CHECK-NEXT:    insf $r3 = $r24, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r25, 63, 32
; CHECK-NEXT:    lq $r24r25 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <32 x i8> undef, i8 %1, i32 0
  %4 = shufflevector <32 x i8> %3, <32 x i8> undef, <32 x i32> zeroinitializer
  %5 = sdiv <32 x i8> %0, %4
  ret <32 x i8> %5
}

define <32 x i8> @add_v32i8_v32i8(<32 x i8> %0, <32 x i8> %1) {
; CHECK-LABEL: add_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    andd $r8 = $r0, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r9 = $r4, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r4 = $r1, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    addd $r8 = $r9, $r8
; CHECK-NEXT:    andd $r9 = $r5, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r5 = $r2, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r2 = $r6, $r2
; CHECK-NEXT:    addd $r4 = $r9, $r4
; CHECK-NEXT:    andd $r9 = $r6, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r6 = $r3, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r3 = $r7, $r3
; CHECK-NEXT:    andd $r7 = $r7, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    andd $r1 = $r1, 0x8080808080808080
; CHECK-NEXT:    addd $r5 = $r9, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CHECK-NEXT:    addd $r6 = $r7, $r6
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    xord $r0 = $r8, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r1 = $r4, $r1
; CHECK-NEXT:    xord $r2 = $r5, $r2
; CHECK-NEXT:    xord $r3 = $r6, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = add <32 x i8> %1, %0
  ret <32 x i8> %3
}

define <32 x i8> @add_v32i8_i8(<32 x i8> %0, i8 %1) {
; CHECK-LABEL: add_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbmm8 $r4 = $r4, 0x101010101010101
; CHECK-NEXT:    andd $r5 = $r0, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r7 = $r1, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r8 = $r2, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r6 = $r4, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r0 = $r4, $r0
; CHECK-NEXT:    xord $r1 = $r4, $r1
; CHECK-NEXT:    xord $r2 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r9 = $r3, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r3 = $r4, $r3
; CHECK-NEXT:    addd $r5 = $r6, $r5
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r7 = $r6, $r7
; CHECK-NEXT:    andd $r1 = $r1, 0x8080808080808080
; CHECK-NEXT:    addd $r8 = $r6, $r8
; CHECK-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r6 = $r6, $r9
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    xord $r0 = $r5, $r0
; CHECK-NEXT:    xord $r1 = $r7, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r2 = $r8, $r2
; CHECK-NEXT:    xord $r3 = $r6, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <32 x i8> undef, i8 %1, i32 0
  %4 = shufflevector <32 x i8> %3, <32 x i8> undef, <32 x i32> zeroinitializer
  %5 = add <32 x i8> %4, %0
  ret <32 x i8> %5
}

define <32 x i8> @sub_v32i8_v32i8(<32 x i8> %0, <32 x i8> %1) {
; CHECK-LABEL: sub_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ord $r8 = $r0, 0x8080808080808080
; CHECK-NEXT:    andd $r9 = $r4, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    nxord $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r4 = $r1, 0x8080808080808080
; CHECK-NEXT:    sbfd $r8 = $r9, $r8
; CHECK-NEXT:    andd $r9 = $r5, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    nxord $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r5 = $r2, 0x8080808080808080
; CHECK-NEXT:    nxord $r2 = $r2, $r6
; CHECK-NEXT:    sbfd $r4 = $r9, $r4
; CHECK-NEXT:    andd $r9 = $r6, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r6 = $r3, 0x8080808080808080
; CHECK-NEXT:    nxord $r3 = $r3, $r7
; CHECK-NEXT:    andd $r7 = $r7, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    andd $r1 = $r1, 0x8080808080808080
; CHECK-NEXT:    sbfd $r5 = $r9, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CHECK-NEXT:    sbfd $r6 = $r7, $r6
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    xord $r0 = $r0, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r1 = $r1, $r4
; CHECK-NEXT:    xord $r2 = $r2, $r5
; CHECK-NEXT:    xord $r3 = $r3, $r6
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sub <32 x i8> %0, %1
  ret <32 x i8> %3
}

define <32 x i8> @sub_v32i8_i8(<32 x i8> %0, i8 %1) {
; CHECK-LABEL: sub_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbmm8 $r4 = $r4, 0x101010101010101
; CHECK-NEXT:    ord $r5 = $r0, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r7 = $r1, 0x8080808080808080
; CHECK-NEXT:    ord $r8 = $r2, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r6 = $r4, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    nxord $r0 = $r0, $r4
; CHECK-NEXT:    nxord $r1 = $r1, $r4
; CHECK-NEXT:    nxord $r2 = $r2, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r9 = $r3, 0x8080808080808080
; CHECK-NEXT:    nxord $r3 = $r3, $r4
; CHECK-NEXT:    sbfd $r5 = $r6, $r5
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfd $r7 = $r6, $r7
; CHECK-NEXT:    andd $r1 = $r1, 0x8080808080808080
; CHECK-NEXT:    sbfd $r8 = $r6, $r8
; CHECK-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfd $r6 = $r6, $r9
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    xord $r0 = $r0, $r5
; CHECK-NEXT:    xord $r1 = $r1, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r2 = $r2, $r8
; CHECK-NEXT:    xord $r3 = $r3, $r6
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <32 x i8> undef, i8 %1, i32 0
  %4 = shufflevector <32 x i8> %3, <32 x i8> undef, <32 x i32> zeroinitializer
  %5 = sub <32 x i8> %0, %4
  ret <32 x i8> %5
}

define <32 x i8> @mul_add_v32i8_v32i8(<32 x i8> %0, <32 x i8> %1, <32 x i8> %2) {
; CHECK-LABEL: mul_add_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sxmbhq $r15 = $r3
; CHECK-NEXT:    sxmbhq $r16 = $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r15 = $r16, $r15
; CHECK-NEXT:    sxlbhq $r3 = $r3
; CHECK-NEXT:    sxlbhq $r7 = $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r16 = $r6
; CHECK-NEXT:    sxmbhq $r17 = $r4
; CHECK-NEXT:    mulhq $r3 = $r7, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r7 = $r15, 0x40100401
; CHECK-NEXT:    sxmbhq $r15 = $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r15 = $r16, $r15
; CHECK-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CHECK-NEXT:    sxmbhq $r16 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r2 = $r2
; CHECK-NEXT:    sxlbhq $r6 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r0 = $r0
; CHECK-NEXT:    sxlbhq $r4 = $r4
; CHECK-NEXT:    mulhq $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r7, 63, 32
; CHECK-NEXT:    sbmm8 $r6 = $r15, 0x40100401
; CHECK-NEXT:    mulhq $r7 = $r17, $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r15 = $r1
; CHECK-NEXT:    sxmbhq $r16 = $r5
; CHECK-NEXT:    mulhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r4 = $r5
; CHECK-NEXT:    sxlbhq $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r1 = $r4, $r1
; CHECK-NEXT:    sbmm8 $r7 = $r7, 0x40100401
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r7, 63, 32
; CHECK-NEXT:    sbmm8 $r2 = $r2, 0x40100401
; CHECK-NEXT:    andd $r7 = $r8, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    mulhq $r5 = $r16, $r15
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    insf $r2 = $r6, 63, 32
; CHECK-NEXT:    andd $r6 = $r9, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r4 = $r5, 0x40100401
; CHECK-NEXT:    andd $r5 = $r0, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r0 = $r0, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r8 = $r3, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    insf $r1 = $r4, 63, 32
; CHECK-NEXT:    addd $r4 = $r5, $r7
; CHECK-NEXT:    xord $r3 = $r3, $r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r7 = $r10, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r5 = $r1, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r1 = $r1, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r9 = $r11, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    addd $r5 = $r5, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r6 = $r2, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r2 = $r2, $r10
; CHECK-NEXT:    andd $r1 = $r1, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r6 = $r6, $r7
; CHECK-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CHECK-NEXT:    addd $r7 = $r8, $r9
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r0 = $r4, $r0
; CHECK-NEXT:    xord $r1 = $r5, $r1
; CHECK-NEXT:    xord $r2 = $r6, $r2
; CHECK-NEXT:    xord $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = mul <32 x i8> %1, %0
  %5 = add <32 x i8> %4, %2
  ret <32 x i8> %5
}

define <4 x double> @p_mul_v4f64_v4f64(<4 x double>* nocapture readonly %0, <4 x double>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x double>, <4 x double>* %0, align 32
  %4 = load <4 x double>, <4 x double>* %1, align 32
  %5 = fmul <4 x double> %3, %4
  ret <4 x double> %5
}

define <4 x double> @p_mul_v4f64_f64(<4 x double>* nocapture readonly %0, double* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r1 = $r5, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r0 = $r4, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r2 = $r6, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x double>, <4 x double>* %0, align 32
  %4 = load double, double* %1, align 8
  %5 = insertelement <4 x double> undef, double %4, i32 0
  %6 = shufflevector <4 x double> %5, <4 x double> undef, <4 x i32> zeroinitializer
  %7 = fmul <4 x double> %3, %6
  ret <4 x double> %7
}

define <4 x double> @p_div_v4f64_v4f64(<4 x double>* nocapture readonly %0, <4 x double>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 56[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    .cfi_offset 25, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 27, -40
; CHECK-NEXT:    so 24[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    .cfi_offset 21, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 23, -72
; CHECK-NEXT:    lo $r20r21r22r23 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r1]
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r25
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r24
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r26
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r27
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x double>, <4 x double>* %0, align 32
  %4 = load <4 x double>, <4 x double>* %1, align 32
  %5 = fdiv <4 x double> %3, %4
  ret <4 x double> %5
}

define <4 x double> @p_div_v4f64_f64(<4 x double>* nocapture readonly %0, double* nocapture readonly %1) {
; CHECK-LABEL: p_div_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 24[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -16
; CHECK-NEXT:    .cfi_offset 21, -24
; CHECK-NEXT:    .cfi_offset 22, -32
; CHECK-NEXT:    .cfi_offset 23, -40
; CHECK-NEXT:    sd 16[$r12] = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -48
; CHECK-NEXT:    lo $r20r21r22r23 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r18 = 0[$r1]
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r18 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x double>, <4 x double>* %0, align 32
  %4 = load double, double* %1, align 8
  %5 = insertelement <4 x double> undef, double %4, i32 0
  %6 = shufflevector <4 x double> %5, <4 x double> undef, <4 x i32> zeroinitializer
  %7 = fdiv <4 x double> %3, %6
  ret <4 x double> %7
}

define <4 x double> @p_add_v4f64_v4f64(<4 x double>* nocapture readonly %0, <4 x double>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fadddp $r2r3 = $r6r7, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fadddp $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x double>, <4 x double>* %0, align 32
  %4 = load <4 x double>, <4 x double>* %1, align 32
  %5 = fadd <4 x double> %3, %4
  ret <4 x double> %5
}

define <4 x double> @p_add_v4f64_f64(<4 x double>* nocapture readonly %0, double* nocapture readonly %1) {
; CHECK-LABEL: p_add_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ld $r4 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r0]
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    copyd $r6 = $r4
; CHECK-NEXT:    copyd $r7 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fadddp $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fadddp $r0r1 = $r0r1, $r4r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x double>, <4 x double>* %0, align 32
  %4 = load double, double* %1, align 8
  %5 = insertelement <4 x double> undef, double %4, i32 0
  %6 = shufflevector <4 x double> %5, <4 x double> undef, <4 x i32> zeroinitializer
  %7 = fadd <4 x double> %3, %6
  ret <4 x double> %7
}

define <4 x double> @p_mul_add_v4f64_v4f64(<4 x double>* nocapture readonly %0, <4 x double>* nocapture readonly %1, <4 x double>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r32r33r34r35 = 0[$r2]
; CHECK-NEXT:    fmuld $r1 = $r5, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r0 = $r4, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r6 = $r6, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r7 = $r7, $r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fadddp $r6r7 = $r34r35, $r6r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fadddp $r4r5 = $r32r33, $r0r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    so 0[$r2] = $r4r5r6r7
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    copyd $r2 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <4 x double>, <4 x double>* %0, align 32
  %5 = load <4 x double>, <4 x double>* %1, align 32
  %6 = fmul <4 x double> %4, %5
  %7 = load <4 x double>, <4 x double>* %2, align 32
  %8 = fadd <4 x double> %7, %6
  store <4 x double> %8, <4 x double>* %2, align 32
  ret <4 x double> %8
}

define <4 x i64> @p_mul_v4i64_v4i64(<4 x i64>* nocapture readonly %0, <4 x i64>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x i64>, <4 x i64>* %0, align 32
  %4 = load <4 x i64>, <4 x i64>* %1, align 32
  %5 = mul <4 x i64> %4, %3
  ret <4 x i64> %5
}

define <4 x i64> @p_mul_v4i64_i64(<4 x i64>* nocapture readonly %0, i64* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r1 = $r3, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r0 = $r3, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r2 = $r3, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x i64>, <4 x i64>* %0, align 32
  %4 = load i64, i64* %1, align 8
  %5 = insertelement <4 x i64> undef, i64 %4, i32 0
  %6 = shufflevector <4 x i64> %5, <4 x i64> undef, <4 x i32> zeroinitializer
  %7 = mul <4 x i64> %6, %3
  ret <4 x i64> %7
}

define <4 x i64> @p_div_v4i64_v4i64(<4 x i64>* nocapture readonly %0, <4 x i64>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 56[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    .cfi_offset 25, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 27, -40
; CHECK-NEXT:    so 24[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    .cfi_offset 21, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 23, -72
; CHECK-NEXT:    lo $r20r21r22r23 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r1]
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r25
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r24
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r26
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r27
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x i64>, <4 x i64>* %0, align 32
  %4 = load <4 x i64>, <4 x i64>* %1, align 32
  %5 = sdiv <4 x i64> %3, %4
  ret <4 x i64> %5
}

define <4 x i64> @p_div_v4i64_i64(<4 x i64>* nocapture readonly %0, i64* nocapture readonly %1) {
; CHECK-LABEL: p_div_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 24[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -16
; CHECK-NEXT:    .cfi_offset 21, -24
; CHECK-NEXT:    .cfi_offset 22, -32
; CHECK-NEXT:    .cfi_offset 23, -40
; CHECK-NEXT:    sd 16[$r12] = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -48
; CHECK-NEXT:    lo $r20r21r22r23 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r18 = 0[$r1]
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r18 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x i64>, <4 x i64>* %0, align 32
  %4 = load i64, i64* %1, align 8
  %5 = insertelement <4 x i64> undef, i64 %4, i32 0
  %6 = shufflevector <4 x i64> %5, <4 x i64> undef, <4 x i32> zeroinitializer
  %7 = sdiv <4 x i64> %3, %6
  ret <4 x i64> %7
}

define <4 x i64> @p_add_v4i64_v4i64(<4 x i64>* nocapture readonly %0, <4 x i64>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r1 = $r1, $r5
; CHECK-NEXT:    addd $r0 = $r0, $r4
; CHECK-NEXT:    addd $r2 = $r2, $r6
; CHECK-NEXT:    addd $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x i64>, <4 x i64>* %0, align 32
  %4 = load <4 x i64>, <4 x i64>* %1, align 32
  %5 = add <4 x i64> %4, %3
  ret <4 x i64> %5
}

define <4 x i64> @p_add_v4i64_i64(<4 x i64>* nocapture readonly %0, i64* nocapture readonly %1) {
; CHECK-LABEL: p_add_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r1 = $r3, $r5
; CHECK-NEXT:    addd $r0 = $r3, $r4
; CHECK-NEXT:    addd $r2 = $r3, $r6
; CHECK-NEXT:    addd $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x i64>, <4 x i64>* %0, align 32
  %4 = load i64, i64* %1, align 8
  %5 = insertelement <4 x i64> undef, i64 %4, i32 0
  %6 = shufflevector <4 x i64> %5, <4 x i64> undef, <4 x i32> zeroinitializer
  %7 = add <4 x i64> %6, %3
  ret <4 x i64> %7
}

define <4 x i64> @p_mul_add_v4i64_v4i64(<4 x i64>* nocapture readonly %0, <4 x i64>* nocapture readonly %1, <4 x i64>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r32r33r34r35 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddd $r5 = $r33, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddd $r4 = $r32, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddd $r6 = $r34, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddd $r7 = $r35, $r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    so 0[$r2] = $r4r5r6r7
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    copyd $r2 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <4 x i64>, <4 x i64>* %0, align 32
  %5 = load <4 x i64>, <4 x i64>* %1, align 32
  %6 = mul <4 x i64> %5, %4
  %7 = load <4 x i64>, <4 x i64>* %2, align 32
  %8 = add <4 x i64> %7, %6
  store <4 x i64> %8, <4 x i64>* %2, align 32
  ret <4 x i64> %8
}

define <8 x float> @p_mul_vv8f32_v8f32(<8 x float>* nocapture readonly %0, <8 x float>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_vv8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r2r3 = $r6r7, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x float>, <8 x float>* %0, align 32
  %4 = load <8 x float>, <8 x float>* %1, align 32
  %5 = fmul <8 x float> %3, %4
  ret <8 x float> %5
}

define <8 x float> @p_mul_v8f32_f32(<8 x float>* nocapture readonly %0, float* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lwz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    insf $r1 = $r1, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r2r3 = $r6r7, $r0r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x float>, <8 x float>* %0, align 32
  %4 = load float, float* %1, align 4
  %5 = insertelement <8 x float> undef, float %4, i32 0
  %6 = shufflevector <8 x float> %5, <8 x float> undef, <8 x i32> zeroinitializer
  %7 = fmul <8 x float> %3, %6
  ret <8 x float> %7
}

define <8 x float> @p_div_v8f32_v8f32(<8 x float>* nocapture readonly %0, <8 x float>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 56[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    .cfi_offset 25, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 27, -40
; CHECK-NEXT:    so 24[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    .cfi_offset 21, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 23, -72
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -80
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    lo $r20r21r22r23 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r1]
; CHECK-NEXT:    srld $r0 = $r23, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r27, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r27
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r2 = $r22, 32
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    srld $r1 = $r26, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r26
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r2 = $r21, 32
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    srld $r1 = $r25, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r25
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r2 = $r20, 32
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srld $r1 = $r24, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r24
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r26, 63, 32
; CHECK-NEXT:    insf $r22 = $r23, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r18, 63, 32
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    insf $r0 = $r25, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r19
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x float>, <8 x float>* %0, align 32
  %4 = load <8 x float>, <8 x float>* %1, align 32
  %5 = fdiv <8 x float> %3, %4
  ret <8 x float> %5
}

define <8 x float> @p_div_v8f32_f32(<8 x float>* nocapture readonly %0, float* nocapture readonly %1) {
; CHECK-LABEL: p_div_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 80[$r12] = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 26, -16
; CHECK-NEXT:    sq 64[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -24
; CHECK-NEXT:    .cfi_offset 25, -32
; CHECK-NEXT:    so 32[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -40
; CHECK-NEXT:    .cfi_offset 21, -48
; CHECK-NEXT:    .cfi_offset 22, -56
; CHECK-NEXT:    .cfi_offset 23, -64
; CHECK-NEXT:    sq 16[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -72
; CHECK-NEXT:    .cfi_offset 19, -80
; CHECK-NEXT:    lo $r20r21r22r23 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lwz $r18 = 0[$r1]
; CHECK-NEXT:    srld $r0 = $r23, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r22, 32
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r21, 32
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r20, 32
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r25, 63, 32
; CHECK-NEXT:    insf $r22 = $r24, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r19, 63, 32
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    insf $r0 = $r26, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r23
; CHECK-NEXT:    lq $r18r19 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r26 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x float>, <8 x float>* %0, align 32
  %4 = load float, float* %1, align 4
  %5 = insertelement <8 x float> undef, float %4, i32 0
  %6 = shufflevector <8 x float> %5, <8 x float> undef, <8 x i32> zeroinitializer
  %7 = fdiv <8 x float> %3, %6
  ret <8 x float> %7
}

define <8 x float> @p_add_v8f32_v8f32(<8 x float>* nocapture readonly %0, <8 x float>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r2r3 = $r6r7, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x float>, <8 x float>* %0, align 32
  %4 = load <8 x float>, <8 x float>* %1, align 32
  %5 = fadd <8 x float> %3, %4
  ret <8 x float> %5
}

define <8 x float> @p_add_v8f32_f32(<8 x float>* nocapture readonly %0, float* nocapture readonly %1) {
; CHECK-LABEL: p_add_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lwz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    insf $r1 = $r1, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r2r3 = $r6r7, $r0r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x float>, <8 x float>* %0, align 32
  %4 = load float, float* %1, align 4
  %5 = insertelement <8 x float> undef, float %4, i32 0
  %6 = shufflevector <8 x float> %5, <8 x float> undef, <8 x i32> zeroinitializer
  %7 = fadd <8 x float> %3, %6
  ret <8 x float> %7
}

define <8 x float> @p_mul_add_v8f32_v8f32(<8 x float>* nocapture readonly %0, <8 x float>* nocapture readonly %1, <8 x float>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r32r33r34r35 = 0[$r2]
; CHECK-NEXT:    fmulwq $r0r1 = $r4r5, $r8r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r4r5 = $r6r7, $r10r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r6r7 = $r34r35, $r4r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r4r5 = $r32r33, $r0r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    so 0[$r2] = $r4r5r6r7
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    copyd $r2 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <8 x float>, <8 x float>* %0, align 32
  %5 = load <8 x float>, <8 x float>* %1, align 32
  %6 = fmul <8 x float> %4, %5
  %7 = load <8 x float>, <8 x float>* %2, align 32
  %8 = fadd <8 x float> %7, %6
  store <8 x float> %8, <8 x float>* %2, align 32
  ret <8 x float> %8
}

define <8 x i32> @p_mul_v8i32_v8i32(<8 x i32>* nocapture readonly %0, <8 x i32>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulwq $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulwq $r0r1 = $r0r1, $r4r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x i32>, <8 x i32>* %0, align 32
  %4 = load <8 x i32>, <8 x i32>* %1, align 32
  %5 = mul <8 x i32> %4, %3
  ret <8 x i32> %5
}

define <8 x i32> @p_mul_v8i32_i32(<8 x i32>* nocapture readonly %0, i32* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lwz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    insf $r1 = $r1, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulwq $r2r3 = $r0r1, $r6r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulwq $r0r1 = $r0r1, $r4r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x i32>, <8 x i32>* %0, align 32
  %4 = load i32, i32* %1, align 4
  %5 = insertelement <8 x i32> undef, i32 %4, i32 0
  %6 = shufflevector <8 x i32> %5, <8 x i32> undef, <8 x i32> zeroinitializer
  %7 = mul <8 x i32> %6, %3
  ret <8 x i32> %7
}

define <8 x i32> @p_div_v8i32_v8i32(<8 x i32>* nocapture readonly %0, <8 x i32>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -128
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 128
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 120[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 88[$r12] = $r28r29r30r31
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 28, -16
; CHECK-NEXT:    .cfi_offset 29, -24
; CHECK-NEXT:    .cfi_offset 30, -32
; CHECK-NEXT:    .cfi_offset 31, -40
; CHECK-NEXT:    so 56[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    .cfi_offset 25, -56
; CHECK-NEXT:    .cfi_offset 26, -64
; CHECK-NEXT:    .cfi_offset 27, -72
; CHECK-NEXT:    so 24[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    .cfi_offset 21, -88
; CHECK-NEXT:    .cfi_offset 22, -96
; CHECK-NEXT:    .cfi_offset 23, -104
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -112
; CHECK-NEXT:    .cfi_offset 19, -120
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r28r29r30r31 = 0[$r1]
; CHECK-NEXT:    sxwd $r0 = $r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r31
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r27, 32
; CHECK-NEXT:    srld $r3 = $r31, 32
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r2 = $r1
; CHECK-NEXT:    sxwd $r1 = $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r2 = $r26
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    sxwd $r1 = $r30
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r26, 32
; CHECK-NEXT:    srld $r3 = $r30, 32
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r2 = $r1
; CHECK-NEXT:    sxwd $r1 = $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r2 = $r25
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    sxwd $r1 = $r29
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r25, 32
; CHECK-NEXT:    srld $r3 = $r29, 32
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r2 = $r1
; CHECK-NEXT:    sxwd $r1 = $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r2 = $r24
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    sxwd $r1 = $r28
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r24, 32
; CHECK-NEXT:    srld $r3 = $r28, 32
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r2 = $r1
; CHECK-NEXT:    sxwd $r1 = $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r0, 63, 32
; CHECK-NEXT:    insf $r22 = $r23, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r21, 63, 32
; CHECK-NEXT:    insf $r18 = $r19, 63, 32
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r20
; CHECK-NEXT:    copyd $r3 = $r18
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r28r29r30r31 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 120[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 128
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x i32>, <8 x i32>* %0, align 32
  %4 = load <8 x i32>, <8 x i32>* %1, align 32
  %5 = sdiv <8 x i32> %3, %4
  ret <8 x i32> %5
}

define <8 x i32> @p_div_v8i32_i32(<8 x i32>* nocapture readonly %0, i32* nocapture readonly %1) {
; CHECK-LABEL: p_div_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -128
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 128
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 120[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 88[$r12] = $r28r29r30r31
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 28, -16
; CHECK-NEXT:    .cfi_offset 29, -24
; CHECK-NEXT:    .cfi_offset 30, -32
; CHECK-NEXT:    .cfi_offset 31, -40
; CHECK-NEXT:    sq 72[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    .cfi_offset 25, -56
; CHECK-NEXT:    so 40[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 22, -80
; CHECK-NEXT:    .cfi_offset 23, -88
; CHECK-NEXT:    sq 24[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    .cfi_offset 19, -104
; CHECK-NEXT:    lo $r28r29r30r31 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lws $r18 = 0[$r1]
; CHECK-NEXT:    sxwd $r0 = $r31
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r31, 32
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r30
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r30, 32
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r29
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r29, 32
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r28
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r28, 32
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r25 = $r0, 63, 32
; CHECK-NEXT:    insf $r23 = $r24, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r22, 63, 32
; CHECK-NEXT:    insf $r19 = $r20, 63, 32
; CHECK-NEXT:    copyd $r0 = $r25
; CHECK-NEXT:    copyd $r1 = $r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r21
; CHECK-NEXT:    copyd $r3 = $r19
; CHECK-NEXT:    lq $r18r19 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 40[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r28r29r30r31 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 120[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 128
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x i32>, <8 x i32>* %0, align 32
  %4 = load i32, i32* %1, align 4
  %5 = insertelement <8 x i32> undef, i32 %4, i32 0
  %6 = shufflevector <8 x i32> %5, <8 x i32> undef, <8 x i32> zeroinitializer
  %7 = sdiv <8 x i32> %3, %6
  ret <8 x i32> %7
}

define <8 x i32> @p_add_v8i32_v8i32(<8 x i32>* nocapture readonly %0, <8 x i32>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addwp $r3 = $r3, $r7
; CHECK-NEXT:    addwp $r2 = $r2, $r6
; CHECK-NEXT:    addwp $r1 = $r1, $r5
; CHECK-NEXT:    addwp $r0 = $r0, $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x i32>, <8 x i32>* %0, align 32
  %4 = load <8 x i32>, <8 x i32>* %1, align 32
  %5 = add <8 x i32> %4, %3
  ret <8 x i32> %5
}

define <8 x i32> @p_add_v8i32_i32(<8 x i32>* nocapture readonly %0, i32* nocapture readonly %1) {
; CHECK-LABEL: p_add_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lwz $r5 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r0]
; CHECK-NEXT:    insf $r5 = $r5, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r4 = $r5
; CHECK-NEXT:    addwp $r3 = $r5, $r3
; CHECK-NEXT:    addwp $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addwp $r2 = $r4, $r2
; CHECK-NEXT:    addwp $r0 = $r4, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x i32>, <8 x i32>* %0, align 32
  %4 = load i32, i32* %1, align 4
  %5 = insertelement <8 x i32> undef, i32 %4, i32 0
  %6 = shufflevector <8 x i32> %5, <8 x i32> undef, <8 x i32> zeroinitializer
  %7 = add <8 x i32> %6, %3
  ret <8 x i32> %7
}

define <8 x i32> @p_mul_add_v8i32_v8i32(<8 x i32>* nocapture readonly %0, <8 x i32>* nocapture readonly %1, <8 x i32>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r32r33r34r35 = 0[$r1]
; CHECK-NEXT:    copyd $r4 = $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r4]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddwp $r3 = $r35, $r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddwp $r2 = $r34, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddwp $r1 = $r33, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddwp $r0 = $r32, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    so 0[$r4] = $r0r1r2r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <8 x i32>, <8 x i32>* %0, align 32
  %5 = load <8 x i32>, <8 x i32>* %1, align 32
  %6 = mul <8 x i32> %5, %4
  %7 = load <8 x i32>, <8 x i32>* %2, align 32
  %8 = add <8 x i32> %7, %6
  store <8 x i32> %8, <8 x i32>* %2, align 32
  ret <8 x i32> %8
}

define <16 x half> @p_mul_vv16f16_v16f16(<16 x half>* nocapture readonly %0, <16 x half>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_vv16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x half>, <16 x half>* %0, align 32
  %4 = load <16 x half>, <16 x half>* %1, align 32
  %5 = fmul <16 x half> %3, %4
  ret <16 x half> %5
}

define <16 x half> @p_mul_v16f16_f16(<16 x half>* nocapture readonly %0, half* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lhz $r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    insf $r3 = $r3, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r3, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r0 = $r4, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r1 = $r5, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r2 = $r6, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x half>, <16 x half>* %0, align 32
  %4 = load half, half* %1, align 2
  %5 = insertelement <16 x half> undef, half %4, i32 0
  %6 = shufflevector <16 x half> %5, <16 x half> undef, <16 x i32> zeroinitializer
  %7 = fmul <16 x half> %3, %6
  ret <16 x half> %7
}

define <16 x half> @p_div_v16f16_v16f16(<16 x half>* nocapture readonly %0, <16 x half>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 80[$r12] = $r28
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 28, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -24
; CHECK-NEXT:    .cfi_offset 25, -32
; CHECK-NEXT:    .cfi_offset 26, -40
; CHECK-NEXT:    .cfi_offset 27, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -56
; CHECK-NEXT:    .cfi_offset 21, -64
; CHECK-NEXT:    .cfi_offset 22, -72
; CHECK-NEXT:    .cfi_offset 23, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -88
; CHECK-NEXT:    .cfi_offset 19, -96
; CHECK-NEXT:    lo $r20r21r22r23 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r1]
; CHECK-NEXT:    srld $r0 = $r20, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r24, 48
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r24, 32
; CHECK-NEXT:    fnarrowwh $r18 = $r0
; CHECK-NEXT:    srld $r0 = $r20, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r19 = $r0
; CHECK-NEXT:    srlw $r0 = $r20, 16
; CHECK-NEXT:    srlw $r1 = $r24, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r18, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r28 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r20
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r24
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r18 = $r0
; CHECK-NEXT:    srld $r0 = $r21, 48
; CHECK-NEXT:    srld $r1 = $r25, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r28, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r18 = $r19, 63, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r25, 32
; CHECK-NEXT:    fnarrowwh $r19 = $r0
; CHECK-NEXT:    srld $r0 = $r21, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r20 = $r0
; CHECK-NEXT:    srlw $r0 = $r21, 16
; CHECK-NEXT:    srlw $r1 = $r25, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r19, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r25
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r19 = $r0
; CHECK-NEXT:    srld $r0 = $r22, 48
; CHECK-NEXT:    srld $r1 = $r26, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r24, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r19 = $r20, 63, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r26, 32
; CHECK-NEXT:    fnarrowwh $r20 = $r0
; CHECK-NEXT:    srld $r0 = $r22, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r21 = $r0
; CHECK-NEXT:    srlw $r0 = $r22, 16
; CHECK-NEXT:    srlw $r1 = $r26, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r20, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r26
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r20 = $r0
; CHECK-NEXT:    srld $r0 = $r23, 48
; CHECK-NEXT:    srld $r1 = $r27, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r24, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r20 = $r21, 63, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r27, 32
; CHECK-NEXT:    fnarrowwh $r21 = $r0
; CHECK-NEXT:    srld $r0 = $r23, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r22 = $r0
; CHECK-NEXT:    srlw $r0 = $r23, 16
; CHECK-NEXT:    srlw $r1 = $r27, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r21, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r21 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r27
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    copyd $r2 = $r20
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r21, 31, 16
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r22, 63, 32
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r28 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x half>, <16 x half>* %0, align 32
  %4 = load <16 x half>, <16 x half>* %1, align 32
  %5 = fdiv <16 x half> %3, %4
  ret <16 x half> %5
}

define <16 x half> @p_div_v16f16_f16(<16 x half>* nocapture readonly %0, half* nocapture readonly %1) {
; CHECK-LABEL: p_div_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sq 72[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    .cfi_offset 25, -24
; CHECK-NEXT:    so 40[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -32
; CHECK-NEXT:    .cfi_offset 21, -40
; CHECK-NEXT:    .cfi_offset 22, -48
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    sq 24[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -64
; CHECK-NEXT:    .cfi_offset 19, -72
; CHECK-NEXT:    lo $r20r21r22r23 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lhz $r0 = 0[$r1]
; CHECK-NEXT:    srld $r1 = $r20, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r18 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r19 = $r0
; CHECK-NEXT:    srld $r0 = $r20, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    srlw $r0 = $r20, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r19, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r25 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r19 = $r0
; CHECK-NEXT:    srld $r0 = $r21, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r25, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r24, 63, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r20 = $r0
; CHECK-NEXT:    srld $r0 = $r21, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    srlw $r0 = $r21, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r20, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r25 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r20 = $r0
; CHECK-NEXT:    srld $r0 = $r22, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r25, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r24, 63, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r21 = $r0
; CHECK-NEXT:    srld $r0 = $r22, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    srlw $r0 = $r22, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r21, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r25 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r21 = $r0
; CHECK-NEXT:    srld $r0 = $r23, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r25, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 63, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r22 = $r0
; CHECK-NEXT:    srld $r0 = $r23, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    srlw $r0 = $r23, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    insf $r24 = $r22, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r22 = $r0
; CHECK-NEXT:    fwidenlhw $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    copyd $r2 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r22, 31, 16
; CHECK-NEXT:    lq $r18r19 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 40[$r12]
; CHECK-NEXT:    insf $r3 = $r24, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x half>, <16 x half>* %0, align 32
  %4 = load half, half* %1, align 2
  %5 = insertelement <16 x half> undef, half %4, i32 0
  %6 = shufflevector <16 x half> %5, <16 x half> undef, <16 x i32> zeroinitializer
  %7 = fdiv <16 x half> %3, %6
  ret <16 x half> %7
}

define <16 x half> @p_add_v16f16_v16f16(<16 x half>* nocapture readonly %0, <16 x half>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x half>, <16 x half>* %0, align 32
  %4 = load <16 x half>, <16 x half>* %1, align 32
  %5 = fadd <16 x half> %3, %4
  ret <16 x half> %5
}

define <16 x half> @p_add_v16f16_f16(<16 x half>* nocapture readonly %0, half* nocapture readonly %1) {
; CHECK-LABEL: p_add_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lhz $r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    insf $r3 = $r3, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r3, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r0 = $r4, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r1 = $r5, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r2 = $r6, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x half>, <16 x half>* %0, align 32
  %4 = load half, half* %1, align 2
  %5 = insertelement <16 x half> undef, half %4, i32 0
  %6 = shufflevector <16 x half> %5, <16 x half> undef, <16 x i32> zeroinitializer
  %7 = fadd <16 x half> %3, %6
  ret <16 x half> %7
}

define <16 x half> @p_mul_add_v16f16_v16f16(<16 x half>* nocapture readonly %0, <16 x half>* nocapture readonly %1, <16 x half>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r32r33r34r35 = 0[$r2]
; CHECK-NEXT:    fmulhq $r0 = $r7, $r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r1 = $r6, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r3 = $r4, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r4 = $r5, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r5 = $r33, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r4 = $r32, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r6 = $r34, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r7 = $r35, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    so 0[$r2] = $r4r5r6r7
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    copyd $r2 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <16 x half>, <16 x half>* %0, align 32
  %5 = load <16 x half>, <16 x half>* %1, align 32
  %6 = fmul <16 x half> %4, %5
  %7 = load <16 x half>, <16 x half>* %2, align 32
  %8 = fadd <16 x half> %7, %6
  store <16 x half> %8, <16 x half>* %2, align 32
  ret <16 x half> %8
}

define <16 x i16> @p_mul_v16i16_v16i16(<16 x i16>* nocapture readonly %0, <16 x i16>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x i16>, <16 x i16>* %0, align 32
  %4 = load <16 x i16>, <16 x i16>* %1, align 32
  %5 = mul <16 x i16> %4, %3
  ret <16 x i16> %5
}

define <16 x i16> @p_mul_v16i16_i16(<16 x i16>* nocapture readonly %0, i16* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lhz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    sbmm8 $r3 = $r1, 0x201020102010201
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r0 = $r3, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r1 = $r3, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r2 = $r3, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x i16>, <16 x i16>* %0, align 32
  %4 = load i16, i16* %1, align 2
  %5 = insertelement <16 x i16> undef, i16 %4, i32 0
  %6 = shufflevector <16 x i16> %5, <16 x i16> undef, <16 x i32> zeroinitializer
  %7 = mul <16 x i16> %6, %3
  ret <16 x i16> %7
}

define <16 x i16> @p_div_v16i16_v16i16(<16 x i16>* nocapture readonly %0, <16 x i16>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -128
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 128
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 120[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 88[$r12] = $r28r29r30r31
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 28, -16
; CHECK-NEXT:    .cfi_offset 29, -24
; CHECK-NEXT:    .cfi_offset 30, -32
; CHECK-NEXT:    .cfi_offset 31, -40
; CHECK-NEXT:    so 56[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    .cfi_offset 25, -56
; CHECK-NEXT:    .cfi_offset 26, -64
; CHECK-NEXT:    .cfi_offset 27, -72
; CHECK-NEXT:    sd 48[$r12] = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 22, -80
; CHECK-NEXT:    sq 32[$r12] = $r20r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -88
; CHECK-NEXT:    .cfi_offset 21, -96
; CHECK-NEXT:    sq 16[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -104
; CHECK-NEXT:    .cfi_offset 19, -112
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r28r29r30r31 = 0[$r1]
; CHECK-NEXT:    srad $r0 = $r24, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r28, 48
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r28, 47, 32
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    extfs $r0 = $r24, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfs $r0 = $r24, 31, 16
; CHECK-NEXT:    extfs $r1 = $r28, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r18, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxhd $r1 = $r28
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    sxhd $r0 = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    srad $r0 = $r25, 48
; CHECK-NEXT:    srad $r1 = $r29, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r20, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r18 = $r19, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r29, 47, 32
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfs $r0 = $r25, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfs $r0 = $r25, 31, 16
; CHECK-NEXT:    extfs $r1 = $r29, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r19, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxhd $r1 = $r29
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    sxhd $r0 = $r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srad $r0 = $r26, 48
; CHECK-NEXT:    srad $r1 = $r30, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r19, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r21 = $r20, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r30, 47, 32
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfs $r0 = $r26, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfs $r0 = $r26, 31, 16
; CHECK-NEXT:    extfs $r1 = $r30, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r19, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxhd $r1 = $r30
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    sxhd $r0 = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    srad $r0 = $r27, 48
; CHECK-NEXT:    srad $r1 = $r31, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r19, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r22 = $r20, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r31, 47, 32
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfs $r0 = $r27, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfs $r0 = $r27, 31, 16
; CHECK-NEXT:    extfs $r1 = $r31, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r19, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxhd $r1 = $r31
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    sxhd $r0 = $r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r19, 31, 16
; CHECK-NEXT:    lq $r18r19 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r20, 63, 32
; CHECK-NEXT:    lq $r20r21 = 32[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r22 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r28r29r30r31 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 120[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 128
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x i16>, <16 x i16>* %0, align 32
  %4 = load <16 x i16>, <16 x i16>* %1, align 32
  %5 = sdiv <16 x i16> %3, %4
  ret <16 x i16> %5
}

define <16 x i16> @p_div_v16i16_i16(<16 x i16>* nocapture readonly %0, i16* nocapture readonly %1) {
; CHECK-LABEL: p_div_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 56[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    .cfi_offset 25, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 27, -40
; CHECK-NEXT:    so 24[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    .cfi_offset 21, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 23, -72
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -80
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lhs $r18 = 0[$r1]
; CHECK-NEXT:    srad $r0 = $r24, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfs $r0 = $r24, 47, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfs $r0 = $r24, 31, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r20 = $r19, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    sxhd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srad $r0 = $r25, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r19, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r20, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfs $r0 = $r25, 47, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfs $r0 = $r25, 31, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r20 = $r19, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    sxhd $r0 = $r25
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    srad $r0 = $r26, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r19, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r20, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfs $r0 = $r26, 47, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfs $r0 = $r26, 31, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r20 = $r19, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    sxhd $r0 = $r26
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    srad $r0 = $r27, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r19, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r20, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfs $r0 = $r27, 47, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfs $r0 = $r27, 31, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r20 = $r19, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    sxhd $r0 = $r27
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    copyd $r2 = $r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r19, 31, 16
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r20, 63, 32
; CHECK-NEXT:    lo $r20r21r22r23 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x i16>, <16 x i16>* %0, align 32
  %4 = load i16, i16* %1, align 2
  %5 = insertelement <16 x i16> undef, i16 %4, i32 0
  %6 = shufflevector <16 x i16> %5, <16 x i16> undef, <16 x i32> zeroinitializer
  %7 = sdiv <16 x i16> %3, %6
  ret <16 x i16> %7
}

define <16 x i16> @p_add_v16i16_v16i16(<16 x i16>* nocapture readonly %0, <16 x i16>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addhq $r0 = $r0, $r4
; CHECK-NEXT:    addhq $r1 = $r1, $r5
; CHECK-NEXT:    addhq $r2 = $r2, $r6
; CHECK-NEXT:    addhq $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x i16>, <16 x i16>* %0, align 32
  %4 = load <16 x i16>, <16 x i16>* %1, align 32
  %5 = add <16 x i16> %4, %3
  ret <16 x i16> %5
}

define <16 x i16> @p_add_v16i16_i16(<16 x i16>* nocapture readonly %0, i16* nocapture readonly %1) {
; CHECK-LABEL: p_add_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lhz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    sbmm8 $r3 = $r1, 0x201020102010201
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addhq $r0 = $r3, $r4
; CHECK-NEXT:    addhq $r1 = $r3, $r5
; CHECK-NEXT:    addhq $r2 = $r3, $r6
; CHECK-NEXT:    addhq $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x i16>, <16 x i16>* %0, align 32
  %4 = load i16, i16* %1, align 2
  %5 = insertelement <16 x i16> undef, i16 %4, i32 0
  %6 = shufflevector <16 x i16> %5, <16 x i16> undef, <16 x i32> zeroinitializer
  %7 = add <16 x i16> %6, %3
  ret <16 x i16> %7
}

define <16 x i16> @p_mul_add_v16i16_v16i16(<16 x i16>* nocapture readonly %0, <16 x i16>* nocapture readonly %1, <16 x i16>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r32r33r34r35 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddhq $r5 = $r33, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddhq $r4 = $r32, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddhq $r6 = $r34, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddhq $r7 = $r35, $r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    so 0[$r2] = $r4r5r6r7
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    copyd $r2 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <16 x i16>, <16 x i16>* %0, align 32
  %5 = load <16 x i16>, <16 x i16>* %1, align 32
  %6 = mul <16 x i16> %5, %4
  %7 = load <16 x i16>, <16 x i16>* %2, align 32
  %8 = add <16 x i16> %7, %6
  store <16 x i16> %8, <16 x i16>* %2, align 32
  ret <16 x i16> %8
}

define <32 x i8> @p_mul_v32i8_v32i8(<32 x i8>* nocapture readonly %0, <32 x i8>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    sxmbhq $r8 = $r4
; CHECK-NEXT:    sxlbhq $r4 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r9 = $r0
; CHECK-NEXT:    sxlbhq $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r8 = $r9, $r8
; CHECK-NEXT:    sxmbhq $r10 = $r1
; CHECK-NEXT:    sxmbhq $r9 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r1 = $r1
; CHECK-NEXT:    sxmbhq $r11 = $r7
; CHECK-NEXT:    mulhq $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r4 = $r5
; CHECK-NEXT:    mulhq $r5 = $r10, $r9
; CHECK-NEXT:    sxmbhq $r9 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r10 = $r2
; CHECK-NEXT:    sxlbhq $r6 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r2 = $r2
; CHECK-NEXT:    mulhq $r1 = $r1, $r4
; CHECK-NEXT:    sxlbhq $r4 = $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r7 = $r8, 0x40100401
; CHECK-NEXT:    mulhq $r2 = $r2, $r6
; CHECK-NEXT:    sxmbhq $r6 = $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r3 = $r3
; CHECK-NEXT:    mulhq $r8 = $r10, $r9
; CHECK-NEXT:    sbmm8 $r5 = $r5, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    mulhq $r3 = $r3, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r5, 63, 32
; CHECK-NEXT:    sbmm8 $r4 = $r8, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r2 = $r2, 0x40100401
; CHECK-NEXT:    mulhq $r6 = $r6, $r11
; CHECK-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r7, 63, 32
; CHECK-NEXT:    sbmm8 $r5 = $r6, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r4, 63, 32
; CHECK-NEXT:    insf $r3 = $r5, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <32 x i8>, <32 x i8>* %0, align 32
  %4 = load <32 x i8>, <32 x i8>* %1, align 32
  %5 = mul <32 x i8> %4, %3
  ret <32 x i8> %5
}

define <32 x i8> @p_mul_v32i8_i8(<32 x i8>* nocapture readonly %0, i8* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lbz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    insf $r1 = $r1, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r0 = $r4
; CHECK-NEXT:    insf $r1 = $r1, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r3 = $r5
; CHECK-NEXT:    sbmm8 $r2 = $r1, 0x8000400020001
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r1 = $r4
; CHECK-NEXT:    sxlbhq $r4 = $r5
; CHECK-NEXT:    mulhq $r3 = $r2, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r5 = $r6
; CHECK-NEXT:    sxlbhq $r6 = $r6
; CHECK-NEXT:    mulhq $r0 = $r2, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r8 = $r7
; CHECK-NEXT:    sxlbhq $r7 = $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CHECK-NEXT:    mulhq $r1 = $r2, $r1
; CHECK-NEXT:    sbmm8 $r9 = $r0, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r4 = $r2, $r4
; CHECK-NEXT:    sbmm8 $r0 = $r1, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r9, 63, 32
; CHECK-NEXT:    sbmm8 $r1 = $r4, 0x40100401
; CHECK-NEXT:    mulhq $r5 = $r2, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r3, 63, 32
; CHECK-NEXT:    mulhq $r4 = $r2, $r8
; CHECK-NEXT:    sbmm8 $r5 = $r5, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r3 = $r2, $r7
; CHECK-NEXT:    sbmm8 $r4 = $r4, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r6 = $r2, $r6
; CHECK-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r4, 63, 32
; CHECK-NEXT:    sbmm8 $r2 = $r6, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r5, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <32 x i8>, <32 x i8>* %0, align 32
  %4 = load i8, i8* %1, align 1
  %5 = insertelement <32 x i8> undef, i8 %4, i32 0
  %6 = shufflevector <32 x i8> %5, <32 x i8> undef, <32 x i32> zeroinitializer
  %7 = mul <32 x i8> %6, %3
  ret <32 x i8> %7
}

define <32 x i8> @p_div_v32i8_v32i8(<32 x i8>* nocapture readonly %0, <32 x i8>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -128
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 128
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 120[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 88[$r12] = $r28r29r30r31
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 28, -16
; CHECK-NEXT:    .cfi_offset 29, -24
; CHECK-NEXT:    .cfi_offset 30, -32
; CHECK-NEXT:    .cfi_offset 31, -40
; CHECK-NEXT:    so 56[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    .cfi_offset 25, -56
; CHECK-NEXT:    .cfi_offset 26, -64
; CHECK-NEXT:    .cfi_offset 27, -72
; CHECK-NEXT:    so 24[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    .cfi_offset 21, -88
; CHECK-NEXT:    .cfi_offset 22, -96
; CHECK-NEXT:    .cfi_offset 23, -104
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -112
; CHECK-NEXT:    .cfi_offset 19, -120
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r28r29r30r31 = 0[$r1]
; CHECK-NEXT:    srld $r0 = $r24, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srld $r1 = $r28, 56
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r28, 55, 48
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 47, 40
; CHECK-NEXT:    extfz $r1 = $r28, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r18, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r28, 39, 32
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srlw $r0 = $r24, 24
; CHECK-NEXT:    srlw $r1 = $r28, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r18, 15, 8
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r20 = $r19, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r28, 23, 16
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 15, 8
; CHECK-NEXT:    extfz $r1 = $r28, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r18, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxbd $r1 = $r28
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    zxbd $r0 = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    srld $r0 = $r25, 56
; CHECK-NEXT:    srld $r1 = $r29, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r21, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    insf $r18 = $r19, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r20, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r29, 55, 48
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 47, 40
; CHECK-NEXT:    extfz $r1 = $r29, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r19, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r29, 39, 32
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srlw $r0 = $r25, 24
; CHECK-NEXT:    srlw $r1 = $r29, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r19, 15, 8
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r21 = $r20, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r29, 23, 16
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 15, 8
; CHECK-NEXT:    extfz $r1 = $r29, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r19, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxbd $r1 = $r29
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    zxbd $r0 = $r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    srld $r0 = $r26, 56
; CHECK-NEXT:    srld $r1 = $r30, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r22, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    insf $r19 = $r20, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r21, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r30, 55, 48
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 47, 40
; CHECK-NEXT:    extfz $r1 = $r30, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r20, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r30, 39, 32
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    srlw $r0 = $r26, 24
; CHECK-NEXT:    srlw $r1 = $r30, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r20, 15, 8
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r22 = $r21, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r30, 23, 16
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 15, 8
; CHECK-NEXT:    extfz $r1 = $r30, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r20, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxbd $r1 = $r30
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    zxbd $r0 = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    srld $r0 = $r27, 56
; CHECK-NEXT:    srld $r1 = $r31, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r20, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    insf $r23 = $r21, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r22, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r31, 55, 48
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r27, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r27, 47, 40
; CHECK-NEXT:    extfz $r1 = $r31, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r20, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r31, 39, 32
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r27, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    srlw $r0 = $r27, 24
; CHECK-NEXT:    srlw $r1 = $r31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r20, 15, 8
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    insf $r22 = $r21, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r31, 23, 16
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r27, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r27, 15, 8
; CHECK-NEXT:    extfz $r1 = $r31, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r20, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxbd $r1 = $r31
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    zxbd $r0 = $r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    copyd $r2 = $r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r20, 15, 8
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r21, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r22, 63, 32
; CHECK-NEXT:    lo $r20r21r22r23 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r28r29r30r31 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 120[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 128
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <32 x i8>, <32 x i8>* %0, align 32
  %4 = load <32 x i8>, <32 x i8>* %1, align 32
  %5 = sdiv <32 x i8> %3, %4
  ret <32 x i8> %5
}

define <32 x i8> @p_div_v32i8_i8(<32 x i8>* nocapture readonly %0, i8* nocapture readonly %1) {
; CHECK-LABEL: p_div_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    .cfi_register 67, 16
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    so 56[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    .cfi_offset 25, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 27, -40
; CHECK-NEXT:    so 24[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    .cfi_offset 21, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 23, -72
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -80
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lbs $r18 = 0[$r1]
; CHECK-NEXT:    srld $r0 = $r24, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 55, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 47, 40
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r20 = $r19, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 39, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srlw $r0 = $r24, 24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r21 = $r19, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r21 = $r20, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 23, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r24, 15, 8
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r20 = $r19, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    zxbd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    srld $r0 = $r25, 56
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r22, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r20, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r21, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 55, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 47, 40
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r21 = $r20, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 39, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    srlw $r0 = $r25, 24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r22 = $r20, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r22 = $r21, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 23, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 15, 8
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r21 = $r20, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    zxbd $r0 = $r25
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srld $r0 = $r26, 56
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r23, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r21, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r22, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 55, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 47, 40
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r22 = $r21, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 39, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    srlw $r0 = $r26, 24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r23 = $r21, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r23 = $r22, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 23, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 15, 8
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r22 = $r21, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    zxbd $r0 = $r26
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    srld $r0 = $r27, 56
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r21, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r22, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r23, 63, 32
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r27, 55, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    extfz $r0 = $r27, 47, 40
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r22 = $r21, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r27, 39, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    srlw $r0 = $r27, 24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r23 = $r21, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    insf $r23 = $r22, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r27, 23, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    extfz $r0 = $r27, 15, 8
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r22 = $r21, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    zxbd $r0 = $r27
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    copyd $r2 = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r21, 15, 8
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r22, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r23, 63, 32
; CHECK-NEXT:    lo $r20r21r22r23 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <32 x i8>, <32 x i8>* %0, align 32
  %4 = load i8, i8* %1, align 1
  %5 = insertelement <32 x i8> undef, i8 %4, i32 0
  %6 = shufflevector <32 x i8> %5, <32 x i8> undef, <32 x i32> zeroinitializer
  %7 = sdiv <32 x i8> %3, %6
  ret <32 x i8> %7
}

define <32 x i8> @p_add_v32i8_v32i8(<32 x i8>* nocapture readonly %0, <32 x i8>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r0r1r2r3 = 0[$r1]
; CHECK-NEXT:    andd $r10 = $r6, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r11 = $r7, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r8 = $r4, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r9 = $r0, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r4 = $r5, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r5 = $r1, $r5
; CHECK-NEXT:    andd $r1 = $r1, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r6 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r2 = $r2, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r7 = $r3, $r7
; CHECK-NEXT:    andd $r3 = $r3, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    addd $r1 = $r1, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r4 = $r5, 0x8080808080808080
; CHECK-NEXT:    andd $r5 = $r6, 0x8080808080808080
; CHECK-NEXT:    addd $r2 = $r2, $r10
; CHECK-NEXT:    addd $r8 = $r9, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    addd $r3 = $r3, $r11
; CHECK-NEXT:    andd $r6 = $r7, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r0 = $r8, $r0
; CHECK-NEXT:    xord $r1 = $r1, $r4
; CHECK-NEXT:    xord $r2 = $r2, $r5
; CHECK-NEXT:    xord $r3 = $r3, $r6
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <32 x i8>, <32 x i8>* %0, align 32
  %4 = load <32 x i8>, <32 x i8>* %1, align 32
  %5 = add <32 x i8> %4, %3
  ret <32 x i8> %5
}

define <32 x i8> @p_add_v32i8_i8(<32 x i8>* nocapture readonly %0, i8* nocapture readonly %1) {
; CHECK-LABEL: p_add_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lbz $r0 = 0[$r1]
; CHECK-NEXT:    andd $r1 = $r4, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r8 = $r6, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r9 = $r7, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x101010101010101
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r3 = $r0, $r4
; CHECK-NEXT:    xord $r6 = $r0, $r6
; CHECK-NEXT:    andd $r2 = $r0, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r4 = $r5, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r5 = $r0, $r5
; CHECK-NEXT:    xord $r0 = $r0, $r7
; CHECK-NEXT:    addd $r7 = $r2, $r8
; CHECK-NEXT:    addd $r8 = $r2, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r1 = $r2, $r1
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    andd $r9 = $r0, 0x8080808080808080
; CHECK-NEXT:    addd $r4 = $r2, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r6 = $r6, 0x8080808080808080
; CHECK-NEXT:    andd $r5 = $r5, 0x8080808080808080
; CHECK-NEXT:    xord $r0 = $r1, $r3
; CHECK-NEXT:    xord $r3 = $r8, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r1 = $r4, $r5
; CHECK-NEXT:    xord $r2 = $r7, $r6
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <32 x i8>, <32 x i8>* %0, align 32
  %4 = load i8, i8* %1, align 1
  %5 = insertelement <32 x i8> undef, i8 %4, i32 0
  %6 = shufflevector <32 x i8> %5, <32 x i8> undef, <32 x i32> zeroinitializer
  %7 = add <32 x i8> %6, %3
  ret <32 x i8> %7
}

define <32 x i8> @p_mul_add_v32i8_v32i8(<32 x i8>* nocapture readonly %0, <32 x i8>* nocapture readonly %1, <32 x i8>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r1]
; CHECK-NEXT:    sxmbhq $r0 = $r11
; CHECK-NEXT:    sxlbhq $r3 = $r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r1 = $r7
; CHECK-NEXT:    sxlbhq $r7 = $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r0 = $r1, $r0
; CHECK-NEXT:    sxmbhq $r11 = $r6
; CHECK-NEXT:    sxmbhq $r1 = $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r6 = $r6
; CHECK-NEXT:    mulhq $r3 = $r7, $r3
; CHECK-NEXT:    sxlbhq $r7 = $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sxmbhq $r10 = $r8
; CHECK-NEXT:    mulhq $r1 = $r11, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r11 = $r9
; CHECK-NEXT:    sxlbhq $r9 = $r9
; CHECK-NEXT:    mulhq $r6 = $r6, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxmbhq $r7 = $r5
; CHECK-NEXT:    sxlbhq $r5 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CHECK-NEXT:    mulhq $r7 = $r7, $r11
; CHECK-NEXT:    sxlbhq $r8 = $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r0, 63, 32
; CHECK-NEXT:    sxmbhq $r0 = $r4
; CHECK-NEXT:    mulhq $r5 = $r5, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxlbhq $r4 = $r4
; CHECK-NEXT:    sbmm8 $r7 = $r7, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r5 = $r5, 0x40100401
; CHECK-NEXT:    mulhq $r0 = $r0, $r10
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r7, 63, 32
; CHECK-NEXT:    mulhq $r4 = $r4, $r8
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r2]
; CHECK-NEXT:    sbmm8 $r6 = $r6, 0x40100401
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r7 = $r5, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    insf $r6 = $r1, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbmm8 $r4 = $r4, 0x40100401
; CHECK-NEXT:    xord $r5 = $r9, $r5
; CHECK-NEXT:    andd $r15 = $r9, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r9 = $r8, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    insf $r4 = $r0, 63, 32
; CHECK-NEXT:    addd $r0 = $r15, $r7
; CHECK-NEXT:    andd $r1 = $r5, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r15 = $r11, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r7 = $r4, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r4 = $r8, $r4
; CHECK-NEXT:    xord $r5 = $r0, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r8 = $r10, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r0 = $r6, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r10 = $r10, $r6
; CHECK-NEXT:    xord $r11 = $r11, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r3 = $r3, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    addd $r1 = $r9, $r7
; CHECK-NEXT:    andd $r4 = $r4, 0x8080808080808080
; CHECK-NEXT:    addd $r0 = $r8, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r6 = $r10, 0x8080808080808080
; CHECK-NEXT:    addd $r3 = $r15, $r3
; CHECK-NEXT:    andd $r7 = $r11, 0x8080808080808080
; CHECK-NEXT:    xord $r4 = $r1, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r6 = $r0, $r6
; CHECK-NEXT:    xord $r7 = $r3, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    so 0[$r2] = $r4r5r6r7
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    copyd $r2 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <32 x i8>, <32 x i8>* %0, align 32
  %5 = load <32 x i8>, <32 x i8>* %1, align 32
  %6 = mul <32 x i8> %5, %4
  %7 = load <32 x i8>, <32 x i8>* %2, align 32
  %8 = add <32 x i8> %7, %6
  store <32 x i8> %8, <32 x i8>* %2, align 32
  ret <32 x i8> %8
}

define <4 x i64> @fbnsigned_long_4__division_imm(<4 x i64> %a) {
; CHECK-LABEL: fbnsigned_long_4__division_imm:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    muldt $r4r5 = $r1, 0x5555555555555556
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    so 32[$r12] = $r0r1r2r3
; CHECK-NEXT:    muldt $r6r7 = $r0, 0x5555555555555556
; CHECK-NEXT:    srld $r4 = $r5, 63
; CHECK-NEXT:    ;;
; CHECK-NEXT:    adduwd $r5 = $r4, $r5
; CHECK-NEXT:    muldt $r8r9 = $r2, 0x5555555555555556
; CHECK-NEXT:    srld $r6 = $r7, 63
; CHECK-NEXT:    ;;
; CHECK-NEXT:    adduwd $r4 = $r6, $r7
; CHECK-NEXT:    muldt $r10r11 = $r3, 0x5555555555555556
; CHECK-NEXT:    srld $r8 = $r9, 63
; CHECK-NEXT:    ;;
; CHECK-NEXT:    adduwd $r6 = $r8, $r9
; CHECK-NEXT:    srld $r7 = $r11, 63
; CHECK-NEXT:    ;;
; CHECK-NEXT:    adduwd $r7 = $r7, $r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    so 0[$r12] = $r4r5r6r7
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    copyd $r2 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r7
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %a.addr = alloca <4 x i64>, align 32
  %s = alloca <4 x i64>, align 32
  store <4 x i64> %a, <4 x i64>* %a.addr, align 32
  %0 = load <4 x i64>, <4 x i64>* %a.addr, align 32
  %div = sdiv <4 x i64> %0, <i64 3, i64 3, i64 3, i64 3>
  store <4 x i64> %div, <4 x i64>* %s, align 32
  %1 = load <4 x i64>, <4 x i64>* %s, align 32
  ret <4 x i64> %1
}
