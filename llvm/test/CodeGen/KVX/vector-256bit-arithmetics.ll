; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O2 -o - %s | FileCheck %s
target datalayout = "e-S256-p:64:64-i1:8-i8:8-i16:16-i32:32-i64:64-v64:64-v128:128-v256:256-v512:512-v1024:1024-f16:16-f32:32-f64:64-a:0:64-m:e-n32:64"
target triple = "kvx-kalray-cos"

define <4 x double> @mul_v4f64_v4f64(<4 x double> %0, <4 x double> %1) {
; CHECK-LABEL: mul_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmuld $r9 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r8 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r10 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r11 = $r3, $r7
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fmul <4 x double> %0, %1
  ret <4 x double> %3
}

define <4 x double> @mul_v4f64_f64(<4 x double> %0, double %1) {
; CHECK-LABEL: mul_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmuld $r9 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r8 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r10 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r11 = $r4, $r3
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x double> undef, double %1, i32 0
  %4 = shufflevector <4 x double> %3, <4 x double> undef, <4 x i32> zeroinitializer
  %5 = fmul <4 x double> %4, %0
  ret <4 x double> %5
}

define <4 x double> @div_v4f64_v4f64(<4 x double> %0, <4 x double> %1) {
; CHECK-LABEL: div_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 80[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r19 = $r6
; CHECK-NEXT:    copyd $r24 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    copyd $r25 = $r3
; CHECK-NEXT:    copyd $r26 = $r2
; CHECK-NEXT:    copyd $r27 = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r27
; CHECK-NEXT:    copyd $r1 = $r24
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r26
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r25
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r23
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fdiv <4 x double> %0, %1
  ret <4 x double> %3
}

define <4 x double> @div_v4f64_f64(<4 x double> %0, double %1) {
; CHECK-LABEL: div_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 64[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -32
; CHECK-NEXT:    sq 48[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r24 = $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r25
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r23
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x double> undef, double %1, i32 0
  %4 = shufflevector <4 x double> %3, <4 x double> undef, <4 x i32> zeroinitializer
  %5 = fdiv <4 x double> %0, %4
  ret <4 x double> %5
}

define <4 x double> @add_v4f64_v4f64(<4 x double> %0, <4 x double> %1) {
; CHECK-LABEL: add_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    faddd $r9 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r8 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r10 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r11 = $r3, $r7
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd <4 x double> %0, %1
  ret <4 x double> %3
}

define <4 x double> @add_v4f64_f64(<4 x double> %0, double %1) {
; CHECK-LABEL: add_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    faddd $r9 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r8 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r10 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r11 = $r4, $r3
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x double> undef, double %1, i32 0
  %4 = shufflevector <4 x double> %3, <4 x double> undef, <4 x i32> zeroinitializer
  %5 = fadd <4 x double> %4, %0
  ret <4 x double> %5
}

define <4 x double> @sub_v4f64_v4f64(<4 x double> %0, <4 x double> %1) {
; CHECK-LABEL: sub_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fsbfd $r9 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfd $r8 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfd $r10 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfd $r11 = $r7, $r3
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fsub <4 x double> %0, %1
  ret <4 x double> %3
}

define <4 x double> @sub_v4f64_f64(<4 x double> %0, double %1) {
; CHECK-LABEL: sub_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fsbfd $r9 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfd $r8 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfd $r10 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfd $r11 = $r4, $r3
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x double> undef, double %1, i32 0
  %4 = shufflevector <4 x double> %3, <4 x double> undef, <4 x i32> zeroinitializer
  %5 = fsub <4 x double> %0, %4
  ret <4 x double> %5
}

define <4 x double> @mul_add_v4f64_v4f64(<4 x double> %0, <4 x double> %1, <4 x double> %2) {
; CHECK-LABEL: mul_add_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmuld $r4 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r0 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r7 = $r3, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r6 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r1 = $r0, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r0 = $r4, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r2 = $r6, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r3 = $r7, $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = fmul <4 x double> %0, %1
  %5 = fadd <4 x double> %4, %2
  ret <4 x double> %5
}

define <4 x i64> @mul_v4i64_v4i64(<4 x i64> %0, <4 x i64> %1) {
; CHECK-LABEL: mul_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    muld $r9 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r8 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r10 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r11 = $r7, $r3
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = mul <4 x i64> %1, %0
  ret <4 x i64> %3
}

define <4 x i64> @mul_v4i64_i64(<4 x i64> %0, i64 %1) {
; CHECK-LABEL: mul_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    muld $r9 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r8 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r10 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r11 = $r4, $r3
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x i64> undef, i64 %1, i32 0
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <4 x i32> zeroinitializer
  %5 = mul <4 x i64> %4, %0
  ret <4 x i64> %5
}

define <4 x i64> @div_v4i64_v4i64(<4 x i64> %0, <4 x i64> %1) {
; CHECK-LABEL: div_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 80[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r19 = $r6
; CHECK-NEXT:    copyd $r24 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    copyd $r25 = $r3
; CHECK-NEXT:    copyd $r26 = $r2
; CHECK-NEXT:    copyd $r27 = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r27
; CHECK-NEXT:    copyd $r1 = $r24
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r26
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r25
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r23
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sdiv <4 x i64> %0, %1
  ret <4 x i64> %3
}

define <4 x i64> @div_v4i64_i64(<4 x i64> %0, i64 %1) {
; CHECK-LABEL: div_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 64[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -32
; CHECK-NEXT:    sq 48[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r24 = $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r25
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r23
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x i64> undef, i64 %1, i32 0
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <4 x i32> zeroinitializer
  %5 = sdiv <4 x i64> %0, %4
  ret <4 x i64> %5
}

define <4 x i64> @add_v4i64_v4i64(<4 x i64> %0, <4 x i64> %1) {
; CHECK-LABEL: add_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r9 = $r5, $r1
; CHECK-NEXT:    addd $r8 = $r4, $r0
; CHECK-NEXT:    addd $r10 = $r6, $r2
; CHECK-NEXT:    addd $r11 = $r7, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = add <4 x i64> %1, %0
  ret <4 x i64> %3
}

define <4 x i64> @add_v4i64_i64(<4 x i64> %0, i64 %1) {
; CHECK-LABEL: add_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r9 = $r4, $r1
; CHECK-NEXT:    addd $r8 = $r4, $r0
; CHECK-NEXT:    addd $r10 = $r4, $r2
; CHECK-NEXT:    addd $r11 = $r4, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x i64> undef, i64 %1, i32 0
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <4 x i32> zeroinitializer
  %5 = add <4 x i64> %4, %0
  ret <4 x i64> %5
}

define <4 x i64> @sub_v4i64_v4i64(<4 x i64> %0, <4 x i64> %1) {
; CHECK-LABEL: sub_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbfd $r9 = $r5, $r1
; CHECK-NEXT:    sbfd $r8 = $r4, $r0
; CHECK-NEXT:    sbfd $r10 = $r6, $r2
; CHECK-NEXT:    sbfd $r11 = $r7, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sub <4 x i64> %0, %1
  ret <4 x i64> %3
}

define <4 x i64> @sub_v4i64_i64(<4 x i64> %0, i64 %1) {
; CHECK-LABEL: sub_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbfd $r9 = $r4, $r1
; CHECK-NEXT:    sbfd $r8 = $r4, $r0
; CHECK-NEXT:    sbfd $r10 = $r4, $r2
; CHECK-NEXT:    sbfd $r11 = $r4, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <4 x i64> undef, i64 %1, i32 0
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <4 x i32> zeroinitializer
  %5 = sub <4 x i64> %0, %4
  ret <4 x i64> %5
}

define <4 x i64> @mul_add_v4i64_v4i64(<4 x i64> %0, <4 x i64> %1, <4 x i64> %2) {
; CHECK-LABEL: mul_add_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    muld $r4 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r0 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r7 = $r7, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r6 = $r6, $r2
; CHECK-NEXT:    addd $r1 = $r0, $r9
; CHECK-NEXT:    addd $r0 = $r4, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r2 = $r6, $r10
; CHECK-NEXT:    addd $r3 = $r7, $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = mul <4 x i64> %1, %0
  %5 = add <4 x i64> %4, %2
  ret <4 x i64> %5
}

define <8 x float> @mul_vv8f32_v8f32(<8 x float> %0, <8 x float> %1) {
; CHECK-LABEL: mul_vv8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmulwp $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwp $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwp $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwp $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fmul <8 x float> %0, %1
  ret <8 x float> %3
}

define <8 x float> @mul_v8f32_f32(<8 x float> %0, float %1) {
; CHECK-LABEL: mul_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    zxwd $r5 = $r4
; CHECK-NEXT:    slld $r4 = $r4, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r4 = $r5, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r2r3 = $r4r5, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x float> undef, float %1, i32 0
  %4 = shufflevector <8 x float> %3, <8 x float> undef, <8 x i32> zeroinitializer
  %5 = fmul <8 x float> %4, %0
  ret <8 x float> %5
}

define <8 x float> @div_v8f32_v8f32(<8 x float> %0, <8 x float> %1) {
; CHECK-LABEL: div_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 72[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -24
; CHECK-NEXT:    sd 64[$r12] = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    sq 48[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r19 = $r6
; CHECK-NEXT:    copyd $r20 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    copyd $r21 = $r4
; CHECK-NEXT:    copyd $r22 = $r3
; CHECK-NEXT:    copyd $r23 = $r2
; CHECK-NEXT:    copyd $r24 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    srad $r0 = $r22, 32
; CHECK-NEXT:    srad $r1 = $r18, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    srad $r0 = $r23, 32
; CHECK-NEXT:    srad $r1 = $r19, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    srad $r0 = $r24, 32
; CHECK-NEXT:    srad $r1 = $r20, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r25, 32
; CHECK-NEXT:    srad $r1 = $r21, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    copyd $r0 = $r25
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r24, 63, 32
; CHECK-NEXT:    insf $r20 = $r23, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r22, 63, 32
; CHECK-NEXT:    insf $r18 = $r26, 63, 32
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r19
; CHECK-NEXT:    copyd $r3 = $r18
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r26 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fdiv <8 x float> %0, %1
  ret <8 x float> %3
}

define <8 x float> @div_v8f32_f32(<8 x float> %0, float %1) {
; CHECK-LABEL: div_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 72[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -24
; CHECK-NEXT:    sd 64[$r12] = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    sq 48[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r20 = $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    copyd $r21 = $r1
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    srad $r0 = $r19, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r19 = $r0
; CHECK-NEXT:    srad $r0 = $r20, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r21, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srad $r0 = $r22, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r26, 63, 32
; CHECK-NEXT:    insf $r21 = $r25, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r24, 63, 32
; CHECK-NEXT:    insf $r19 = $r23, 63, 32
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r20
; CHECK-NEXT:    copyd $r3 = $r19
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r26 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x float> undef, float %1, i32 0
  %4 = shufflevector <8 x float> %3, <8 x float> undef, <8 x i32> zeroinitializer
  %5 = fdiv <8 x float> %0, %4
  ret <8 x float> %5
}

define <8 x float> @add_v8f32_v8f32(<8 x float> %0, <8 x float> %1) {
; CHECK-LABEL: add_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    faddwp $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwp $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwp $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwp $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd <8 x float> %0, %1
  ret <8 x float> %3
}

define <8 x float> @add_v8f32_f32(<8 x float> %0, float %1) {
; CHECK-LABEL: add_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    zxwd $r5 = $r4
; CHECK-NEXT:    slld $r4 = $r4, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r4 = $r5, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r2r3 = $r4r5, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x float> undef, float %1, i32 0
  %4 = shufflevector <8 x float> %3, <8 x float> undef, <8 x i32> zeroinitializer
  %5 = fadd <8 x float> %4, %0
  ret <8 x float> %5
}

define <8 x float> @sub_v8f32_v8f32(<8 x float> %0, <8 x float> %1) {
; CHECK-LABEL: sub_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fsbfwp $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfwp $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfwp $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfwp $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fsub <8 x float> %0, %1
  ret <8 x float> %3
}

define <8 x float> @sub_v8f32_f32(<8 x float> %0, float %1) {
; CHECK-LABEL: sub_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    zxwd $r5 = $r4
; CHECK-NEXT:    slld $r4 = $r4, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r4 = $r5, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfwq $r2r3 = $r4r5, $r2r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x float> undef, float %1, i32 0
  %4 = shufflevector <8 x float> %3, <8 x float> undef, <8 x i32> zeroinitializer
  %5 = fsub <8 x float> %0, %4
  ret <8 x float> %5
}

define <8 x float> @mul_add_v8f32_v8f32(<8 x float> %0, <8 x float> %1, <8 x float> %2) {
; CHECK-LABEL: mul_add_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmulwq $r0r1 = $r0r1, $r4r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r2r3 = $r2r3, $r10r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r0r1 = $r0r1, $r8r9
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = fmul <8 x float> %0, %1
  %5 = fadd <8 x float> %4, %2
  ret <8 x float> %5
}

define <8 x i32> @mul_v8i32_v8i32(<8 x i32> %0, <8 x i32> %1) {
; CHECK-LABEL: mul_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mulwp $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulwp $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulwp $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulwp $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = mul <8 x i32> %1, %0
  ret <8 x i32> %3
}

define <8 x i32> @mul_v8i32_i32(<8 x i32> %0, i32 %1) {
; CHECK-LABEL: mul_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    srad $r5 = $r3, 32
; CHECK-NEXT:    srad $r6 = $r2, 32
; CHECK-NEXT:    srad $r7 = $r1, 32
; CHECK-NEXT:    srad $r8 = $r0, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r5 = $r4, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r4, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r4, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r7 = $r4, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r8 = $r4, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r8, 63, 32
; CHECK-NEXT:    insf $r1 = $r7, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 63, 32
; CHECK-NEXT:    insf $r3 = $r5, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x i32> undef, i32 %1, i32 0
  %4 = shufflevector <8 x i32> %3, <8 x i32> undef, <8 x i32> zeroinitializer
  %5 = mul <8 x i32> %4, %0
  ret <8 x i32> %5
}

define <8 x i32> @div_v8i32_v8i32(<8 x i32> %0, <8 x i32> %1) {
; CHECK-LABEL: div_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 72[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -24
; CHECK-NEXT:    sd 64[$r12] = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    sq 48[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r19 = $r6
; CHECK-NEXT:    copyd $r20 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    copyd $r21 = $r4
; CHECK-NEXT:    copyd $r22 = $r3
; CHECK-NEXT:    copyd $r23 = $r2
; CHECK-NEXT:    copyd $r24 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r18, 32
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    srad $r0 = $r22, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r26 = $r0
; CHECK-NEXT:    sxwd $r0 = $r22
; CHECK-NEXT:    sxwd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r19, 32
; CHECK-NEXT:    zxwd $r18 = $r0
; CHECK-NEXT:    srad $r0 = $r23, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r22 = $r0
; CHECK-NEXT:    sxwd $r0 = $r23
; CHECK-NEXT:    sxwd $r1 = $r19
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r20, 32
; CHECK-NEXT:    zxwd $r19 = $r0
; CHECK-NEXT:    srad $r0 = $r24, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r23 = $r0
; CHECK-NEXT:    sxwd $r0 = $r24
; CHECK-NEXT:    sxwd $r1 = $r20
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r21, 32
; CHECK-NEXT:    zxwd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r25, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    sxwd $r0 = $r25
; CHECK-NEXT:    sxwd $r1 = $r21
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r24, 63, 32
; CHECK-NEXT:    insf $r20 = $r23, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r22, 63, 32
; CHECK-NEXT:    insf $r18 = $r26, 63, 32
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r19
; CHECK-NEXT:    copyd $r3 = $r18
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r26 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sdiv <8 x i32> %0, %1
  ret <8 x i32> %3
}

define <8 x i32> @div_v8i32_i32(<8 x i32> %0, i32 %1) {
; CHECK-LABEL: div_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 72[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -24
; CHECK-NEXT:    sd 64[$r12] = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    sq 48[$r12] = $r24r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    srad $r0 = $r18, 32
; CHECK-NEXT:    sxwd $r22 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r23 = $r0
; CHECK-NEXT:    sxwd $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r18 = $r0
; CHECK-NEXT:    srad $r0 = $r19, 32
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    sxwd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r19 = $r0
; CHECK-NEXT:    srad $r0 = $r20, 32
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r25 = $r0
; CHECK-NEXT:    sxwd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r21, 32
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r26 = $r0
; CHECK-NEXT:    sxwd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r26, 63, 32
; CHECK-NEXT:    insf $r20 = $r25, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r24, 63, 32
; CHECK-NEXT:    insf $r18 = $r23, 63, 32
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r19
; CHECK-NEXT:    copyd $r3 = $r18
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r26 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x i32> undef, i32 %1, i32 0
  %4 = shufflevector <8 x i32> %3, <8 x i32> undef, <8 x i32> zeroinitializer
  %5 = sdiv <8 x i32> %0, %4
  ret <8 x i32> %5
}

define <8 x i32> @add_v8i32_v8i32(<8 x i32> %0, <8 x i32> %1) {
; CHECK-LABEL: add_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addwp $r0 = $r4, $r0
; CHECK-NEXT:    addwp $r1 = $r5, $r1
; CHECK-NEXT:    addwp $r2 = $r6, $r2
; CHECK-NEXT:    addwp $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = add <8 x i32> %1, %0
  ret <8 x i32> %3
}

define <8 x i32> @add_v8i32_i32(<8 x i32> %0, i32 %1) {
; CHECK-LABEL: add_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    srad $r5 = $r3, 32
; CHECK-NEXT:    srad $r6 = $r2, 32
; CHECK-NEXT:    srad $r7 = $r1, 32
; CHECK-NEXT:    srad $r8 = $r0, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r5 = $r4, $r5
; CHECK-NEXT:    addw $r3 = $r4, $r3
; CHECK-NEXT:    addw $r6 = $r4, $r6
; CHECK-NEXT:    addw $r2 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r7 = $r4, $r7
; CHECK-NEXT:    addw $r1 = $r4, $r1
; CHECK-NEXT:    addw $r8 = $r4, $r8
; CHECK-NEXT:    addw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r8, 63, 32
; CHECK-NEXT:    insf $r1 = $r7, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 63, 32
; CHECK-NEXT:    insf $r3 = $r5, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x i32> undef, i32 %1, i32 0
  %4 = shufflevector <8 x i32> %3, <8 x i32> undef, <8 x i32> zeroinitializer
  %5 = add <8 x i32> %4, %0
  ret <8 x i32> %5
}

define <8 x i32> @sub_v8i32_v8i32(<8 x i32> %0, <8 x i32> %1) {
; CHECK-LABEL: sub_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbfwp $r0 = $r4, $r0
; CHECK-NEXT:    sbfwp $r1 = $r5, $r1
; CHECK-NEXT:    sbfwp $r2 = $r6, $r2
; CHECK-NEXT:    sbfwp $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sub <8 x i32> %0, %1
  ret <8 x i32> %3
}

define <8 x i32> @sub_v8i32_i32(<8 x i32> %0, i32 %1) {
; CHECK-LABEL: sub_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    srad $r5 = $r3, 32
; CHECK-NEXT:    srad $r6 = $r2, 32
; CHECK-NEXT:    srad $r7 = $r1, 32
; CHECK-NEXT:    srad $r8 = $r0, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfw $r5 = $r4, $r5
; CHECK-NEXT:    sbfw $r3 = $r4, $r3
; CHECK-NEXT:    sbfw $r6 = $r4, $r6
; CHECK-NEXT:    sbfw $r2 = $r4, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfw $r7 = $r4, $r7
; CHECK-NEXT:    sbfw $r1 = $r4, $r1
; CHECK-NEXT:    sbfw $r8 = $r4, $r8
; CHECK-NEXT:    sbfw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r8, 63, 32
; CHECK-NEXT:    insf $r1 = $r7, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 63, 32
; CHECK-NEXT:    insf $r3 = $r5, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <8 x i32> undef, i32 %1, i32 0
  %4 = shufflevector <8 x i32> %3, <8 x i32> undef, <8 x i32> zeroinitializer
  %5 = sub <8 x i32> %0, %4
  ret <8 x i32> %5
}

define <8 x i32> @mul_add_v8i32_v8i32(<8 x i32> %0, <8 x i32> %1, <8 x i32> %2) {
; CHECK-LABEL: mul_add_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    srad $r15 = $r0, 32
; CHECK-NEXT:    srad $r17 = $r1, 32
; CHECK-NEXT:    srad $r33 = $r2, 32
; CHECK-NEXT:    srad $r35 = $r3, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r7, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r3 = $r11, $r3
; CHECK-NEXT:    mulw $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r2 = $r10, $r2
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r1 = $r9, $r1
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r0 = $r8, $r0
; CHECK-NEXT:    srad $r32 = $r5, 32
; CHECK-NEXT:    srad $r34 = $r6, 32
; CHECK-NEXT:    srad $r6 = $r9, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r36 = $r7, 32
; CHECK-NEXT:    srad $r7 = $r10, 32
; CHECK-NEXT:    srad $r37 = $r11, 32
; CHECK-NEXT:    srad $r16 = $r4, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r5 = $r8, 32
; CHECK-NEXT:    maddw $r6 = $r32, $r17
; CHECK-NEXT:    ;;
; CHECK-NEXT:    maddw $r5 = $r16, $r15
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r35 = $r36, $r35
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r35 = $r37, $r35
; CHECK-NEXT:    maddw $r7 = $r34, $r33
; CHECK-NEXT:    insf $r0 = $r5, 63, 32
; CHECK-NEXT:    insf $r1 = $r6, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r7, 63, 32
; CHECK-NEXT:    insf $r3 = $r35, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = mul <8 x i32> %1, %0
  %5 = add <8 x i32> %4, %2
  ret <8 x i32> %5
}

define <16 x half> @mul_vv16f16_v16f16(<16 x half> %0, <16 x half> %1) {
; CHECK-LABEL: mul_vv16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmulhq $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fmul <16 x half> %0, %1
  ret <16 x half> %3
}

define <16 x half> @mul_v16f16_f16(<16 x half> %0, half %1) {
; CHECK-LABEL: mul_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 63, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r0 = $r5, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r3 = $r5, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x half> undef, half %1, i32 0
  %4 = shufflevector <16 x half> %3, <16 x half> undef, <16 x i32> zeroinitializer
  %5 = fmul <16 x half> %4, %0
  ret <16 x half> %5
}

define <16 x half> @div_v16f16_v16f16(<16 x half> %0, <16 x half> %1) {
; CHECK-LABEL: div_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 80[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r21 = $r6
; CHECK-NEXT:    copyd $r24 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    copyd $r23 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r22 = $r2
; CHECK-NEXT:    copyd $r25 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r26, 31, 16
; CHECK-NEXT:    extfz $r1 = $r23, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r23, 15, 0
; CHECK-NEXT:    fnarrowwh $r27 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r26, 15, 0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r23, 47, 32
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r20 = $r27, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r23, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r26, 48
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r24, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 63, 48
; CHECK-NEXT:    extfz $r0 = $r25, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r24, 15, 0
; CHECK-NEXT:    fnarrowwh $r26 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r25, 15, 0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r24, 47, 32
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r23 = $r26, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r24, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r25, 48
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r21, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 63, 48
; CHECK-NEXT:    extfz $r0 = $r22, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r21, 15, 0
; CHECK-NEXT:    fnarrowwh $r25 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r22, 15, 0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r21, 47, 32
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r24 = $r25, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r21, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r22, 48
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r18, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r0, 63, 48
; CHECK-NEXT:    extfz $r0 = $r19, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r18, 15, 0
; CHECK-NEXT:    fnarrowwh $r22 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r19, 15, 0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r19, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r18, 47, 32
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r21 = $r22, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r18, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r19, 48
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 48
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r23
; CHECK-NEXT:    copyd $r2 = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r21
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fdiv <16 x half> %0, %1
  ret <16 x half> %3
}

define <16 x half> @div_v16f16_f16(<16 x half> %0, half %1) {
; CHECK-LABEL: div_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -24
; CHECK-NEXT:    .cfi_offset 22, -32
; CHECK-NEXT:    .cfi_offset 21, -40
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r21 = $r2
; CHECK-NEXT:    copyd $r22 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -56
; CHECK-NEXT:    .cfi_offset 18, -64
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r23, 31, 16
; CHECK-NEXT:    fwidenlhw $r19 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r23, 15, 0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r23, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r24, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r23, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 63, 48
; CHECK-NEXT:    extfz $r0 = $r22, 31, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 15, 0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r24, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r22, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 63, 48
; CHECK-NEXT:    extfz $r0 = $r21, 31, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 15, 0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r22 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r24, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r21, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 63, 48
; CHECK-NEXT:    extfz $r0 = $r18, 31, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r18, 15, 0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r18, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r18, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 48
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r23
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r21
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x half> undef, half %1, i32 0
  %4 = shufflevector <16 x half> %3, <16 x half> undef, <16 x i32> zeroinitializer
  %5 = fdiv <16 x half> %0, %4
  ret <16 x half> %5
}

define <16 x half> @add_v16f16_v16f16(<16 x half> %0, <16 x half> %1) {
; CHECK-LABEL: add_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    faddhq $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r3 = $r3, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fadd <16 x half> %0, %1
  ret <16 x half> %3
}

define <16 x half> @add_v16f16_f16(<16 x half> %0, half %1) {
; CHECK-LABEL: add_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 63, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r0 = $r5, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r3 = $r5, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x half> undef, half %1, i32 0
  %4 = shufflevector <16 x half> %3, <16 x half> undef, <16 x i32> zeroinitializer
  %5 = fadd <16 x half> %4, %0
  ret <16 x half> %5
}

define <16 x half> @sub_v16f16_v16f16(<16 x half> %0, <16 x half> %1) {
; CHECK-LABEL: sub_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fsbfhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = fsub <16 x half> %0, %1
  ret <16 x half> %3
}

define <16 x half> @sub_v16f16_f16(<16 x half> %0, half %1) {
; CHECK-LABEL: sub_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 63, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r0 = $r5, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fsbfhq $r3 = $r5, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x half> undef, half %1, i32 0
  %4 = shufflevector <16 x half> %3, <16 x half> undef, <16 x i32> zeroinitializer
  %5 = fsub <16 x half> %0, %4
  ret <16 x half> %5
}

define <16 x half> @mul_add_v16f16_v16f16(<16 x half> %0, <16 x half> %1, <16 x half> %2) {
; CHECK-LABEL: mul_add_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmulhq $r3 = $r3, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r0 = $r0, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r0 = $r0, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r1 = $r1, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r2 = $r2, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r3 = $r3, $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = fmul <16 x half> %0, %1
  %5 = fadd <16 x half> %4, %2
  ret <16 x half> %5
}

define <16 x i16> @mul_v16i16_v16i16(<16 x i16> %0, <16 x i16> %1) {
; CHECK-LABEL: mul_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mulhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = mul <16 x i16> %1, %0
  ret <16 x i16> %3
}

define <16 x i16> @mul_v16i16_i16(<16 x i16> %0, i16 %1) {
; CHECK-LABEL: mul_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 63, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r0 = $r5, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r3 = $r5, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x i16> undef, i16 %1, i32 0
  %4 = shufflevector <16 x i16> %3, <16 x i16> undef, <16 x i32> zeroinitializer
  %5 = mul <16 x i16> %4, %0
  ret <16 x i16> %5
}

define <16 x i16> @div_v16i16_v16i16(<16 x i16> %0, <16 x i16> %1) {
; CHECK-LABEL: div_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 80[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r21 = $r6
; CHECK-NEXT:    copyd $r24 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    copyd $r23 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r22 = $r2
; CHECK-NEXT:    copyd $r25 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r0 = $r26, 31, 16
; CHECK-NEXT:    extfs $r1 = $r23, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r23, 15, 0
; CHECK-NEXT:    zxwd $r27 = $r0
; CHECK-NEXT:    extfs $r0 = $r26, 15, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r20 = $r0
; CHECK-NEXT:    extfs $r0 = $r26, 47, 32
; CHECK-NEXT:    extfs $r1 = $r23, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r27, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srad $r1 = $r23, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r26, 48
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfs $r1 = $r24, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 63, 48
; CHECK-NEXT:    extfs $r0 = $r25, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r24, 15, 0
; CHECK-NEXT:    zxwd $r26 = $r0
; CHECK-NEXT:    extfs $r0 = $r25, 15, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r23 = $r0
; CHECK-NEXT:    extfs $r0 = $r25, 47, 32
; CHECK-NEXT:    extfs $r1 = $r24, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r26, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srad $r1 = $r24, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r25, 48
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfs $r1 = $r21, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 63, 48
; CHECK-NEXT:    extfs $r0 = $r22, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r21, 15, 0
; CHECK-NEXT:    zxwd $r25 = $r0
; CHECK-NEXT:    extfs $r0 = $r22, 15, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r22, 47, 32
; CHECK-NEXT:    extfs $r1 = $r21, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r25, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srad $r1 = $r21, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r22, 48
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfs $r1 = $r18, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r0, 63, 48
; CHECK-NEXT:    extfs $r0 = $r19, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r18, 15, 0
; CHECK-NEXT:    zxwd $r22 = $r0
; CHECK-NEXT:    extfs $r0 = $r19, 15, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r21 = $r0
; CHECK-NEXT:    extfs $r0 = $r19, 47, 32
; CHECK-NEXT:    extfs $r1 = $r18, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r22, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srad $r1 = $r18, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r19, 48
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 48
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r23
; CHECK-NEXT:    copyd $r2 = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r21
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sdiv <16 x i16> %0, %1
  ret <16 x i16> %3
}

define <16 x i16> @div_v16i16_i16(<16 x i16> %0, i16 %1) {
; CHECK-LABEL: div_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -24
; CHECK-NEXT:    .cfi_offset 22, -32
; CHECK-NEXT:    .cfi_offset 21, -40
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r21 = $r2
; CHECK-NEXT:    copyd $r22 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -56
; CHECK-NEXT:    .cfi_offset 18, -64
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    sxhd $r1 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r0 = $r23, 31, 16
; CHECK-NEXT:    sxwd $r19 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r23, 15, 0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r20 = $r0
; CHECK-NEXT:    extfs $r0 = $r23, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r24, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r23, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 63, 48
; CHECK-NEXT:    extfs $r0 = $r22, 31, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r22, 15, 0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r23 = $r0
; CHECK-NEXT:    extfs $r0 = $r22, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r24, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r22, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 63, 48
; CHECK-NEXT:    extfs $r0 = $r21, 31, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r21, 15, 0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r22 = $r0
; CHECK-NEXT:    extfs $r0 = $r21, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r24, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r21, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 63, 48
; CHECK-NEXT:    extfs $r0 = $r18, 31, 16
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r18, 15, 0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r21 = $r0
; CHECK-NEXT:    extfs $r0 = $r18, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r18, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 48
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r23
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r21
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x i16> undef, i16 %1, i32 0
  %4 = shufflevector <16 x i16> %3, <16 x i16> undef, <16 x i32> zeroinitializer
  %5 = sdiv <16 x i16> %0, %4
  ret <16 x i16> %5
}

define <16 x i16> @add_v16i16_v16i16(<16 x i16> %0, <16 x i16> %1) {
; CHECK-LABEL: add_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addhq $r0 = $r4, $r0
; CHECK-NEXT:    addhq $r1 = $r5, $r1
; CHECK-NEXT:    addhq $r2 = $r6, $r2
; CHECK-NEXT:    addhq $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = add <16 x i16> %1, %0
  ret <16 x i16> %3
}

define <16 x i16> @add_v16i16_i16(<16 x i16> %0, i16 %1) {
; CHECK-LABEL: add_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 63, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addhq $r0 = $r5, $r0
; CHECK-NEXT:    addhq $r1 = $r5, $r1
; CHECK-NEXT:    addhq $r2 = $r5, $r2
; CHECK-NEXT:    addhq $r3 = $r5, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x i16> undef, i16 %1, i32 0
  %4 = shufflevector <16 x i16> %3, <16 x i16> undef, <16 x i32> zeroinitializer
  %5 = add <16 x i16> %4, %0
  ret <16 x i16> %5
}

define <16 x i16> @sub_v16i16_v16i16(<16 x i16> %0, <16 x i16> %1) {
; CHECK-LABEL: sub_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbfhq $r0 = $r4, $r0
; CHECK-NEXT:    sbfhq $r1 = $r5, $r1
; CHECK-NEXT:    sbfhq $r2 = $r6, $r2
; CHECK-NEXT:    sbfhq $r3 = $r7, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sub <16 x i16> %0, %1
  ret <16 x i16> %3
}

define <16 x i16> @sub_v16i16_i16(<16 x i16> %0, i16 %1) {
; CHECK-LABEL: sub_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 63, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfhq $r0 = $r5, $r0
; CHECK-NEXT:    sbfhq $r1 = $r5, $r1
; CHECK-NEXT:    sbfhq $r2 = $r5, $r2
; CHECK-NEXT:    sbfhq $r3 = $r5, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <16 x i16> undef, i16 %1, i32 0
  %4 = shufflevector <16 x i16> %3, <16 x i16> undef, <16 x i32> zeroinitializer
  %5 = sub <16 x i16> %0, %4
  ret <16 x i16> %5
}

define <16 x i16> @mul_add_v16i16_v16i16(<16 x i16> %0, <16 x i16> %1, <16 x i16> %2) {
; CHECK-LABEL: mul_add_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mulhq $r3 = $r7, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r2 = $r6, $r2
; CHECK-NEXT:    addhq $r3 = $r3, $r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r1 = $r5, $r1
; CHECK-NEXT:    addhq $r2 = $r2, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r0 = $r4, $r0
; CHECK-NEXT:    addhq $r1 = $r1, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addhq $r0 = $r0, $r8
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = mul <16 x i16> %1, %0
  %5 = add <16 x i16> %4, %2
  ret <16 x i16> %5
}

define <32 x i8> @mul_v32i8_v32i8(<32 x i8> %0, <32 x i8> %1) {
; CHECK-LABEL: mul_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r8 = $r0
; CHECK-NEXT:    extfz $r9 = $r4, 15, 8
; CHECK-NEXT:    extfz $r10 = $r4, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r8, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r9 = $r9, $r0
; CHECK-NEXT:    extfz $r0 = $r8, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r10, $r0
; CHECK-NEXT:    extfz $r10 = $r4, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r9, 15, 8
; CHECK-NEXT:    extfz $r9 = $r8, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r9 = $r10, $r9
; CHECK-NEXT:    extfz $r10 = $r4, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r9, 23, 16
; CHECK-NEXT:    extfz $r9 = $r8, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r9 = $r10, $r9
; CHECK-NEXT:    extfz $r10 = $r4, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r9, 31, 24
; CHECK-NEXT:    extfz $r9 = $r8, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r9 = $r10, $r9
; CHECK-NEXT:    extfz $r10 = $r4, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r9, 39, 32
; CHECK-NEXT:    extfz $r9 = $r8, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r9 = $r10, $r9
; CHECK-NEXT:    extfz $r10 = $r4, 55, 48
; CHECK-NEXT:    srld $r4 = $r4, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r9, 47, 40
; CHECK-NEXT:    extfz $r9 = $r8, 55, 48
; CHECK-NEXT:    srld $r8 = $r8, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r9 = $r10, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r9, 55, 48
; CHECK-NEXT:    mulw $r4 = $r4, $r8
; CHECK-NEXT:    extfz $r8 = $r5, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r4, 63, 56
; CHECK-NEXT:    extfz $r4 = $r1, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r8 = $r8, $r4
; CHECK-NEXT:    extfz $r4 = $r1, 7, 0
; CHECK-NEXT:    extfz $r9 = $r5, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r4 = $r9, $r4
; CHECK-NEXT:    extfz $r9 = $r5, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r8, 15, 8
; CHECK-NEXT:    extfz $r8 = $r1, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r8 = $r9, $r8
; CHECK-NEXT:    extfz $r9 = $r5, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r8, 23, 16
; CHECK-NEXT:    extfz $r8 = $r1, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r8 = $r9, $r8
; CHECK-NEXT:    extfz $r9 = $r5, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r8, 31, 24
; CHECK-NEXT:    extfz $r8 = $r1, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r8 = $r9, $r8
; CHECK-NEXT:    extfz $r9 = $r5, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r8, 39, 32
; CHECK-NEXT:    extfz $r8 = $r1, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r8 = $r9, $r8
; CHECK-NEXT:    extfz $r9 = $r5, 55, 48
; CHECK-NEXT:    srld $r5 = $r5, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r8, 47, 40
; CHECK-NEXT:    extfz $r8 = $r1, 55, 48
; CHECK-NEXT:    srld $r1 = $r1, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r8 = $r9, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r8, 55, 48
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    extfz $r5 = $r6, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r1, 63, 56
; CHECK-NEXT:    extfz $r1 = $r2, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    extfz $r5 = $r2, 7, 0
; CHECK-NEXT:    extfz $r8 = $r6, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r5 = $r8, $r5
; CHECK-NEXT:    extfz $r8 = $r6, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 15, 8
; CHECK-NEXT:    extfz $r1 = $r2, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r8, $r1
; CHECK-NEXT:    extfz $r8 = $r6, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 23, 16
; CHECK-NEXT:    extfz $r1 = $r2, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r8, $r1
; CHECK-NEXT:    extfz $r8 = $r6, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 31, 24
; CHECK-NEXT:    extfz $r1 = $r2, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r8, $r1
; CHECK-NEXT:    extfz $r8 = $r6, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 39, 32
; CHECK-NEXT:    extfz $r1 = $r2, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r8, $r1
; CHECK-NEXT:    extfz $r8 = $r6, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 47, 40
; CHECK-NEXT:    extfz $r1 = $r2, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r8, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 55, 48
; CHECK-NEXT:    srld $r1 = $r2, 56
; CHECK-NEXT:    srld $r2 = $r6, 56
; CHECK-NEXT:    extfz $r6 = $r7, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r2, $r1
; CHECK-NEXT:    extfz $r2 = $r7, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 63, 56
; CHECK-NEXT:    extfz $r1 = $r3, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r2, $r1
; CHECK-NEXT:    extfz $r2 = $r3, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r6, $r2
; CHECK-NEXT:    extfz $r2 = $r7, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 15, 8
; CHECK-NEXT:    extfz $r1 = $r3, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r2, $r1
; CHECK-NEXT:    extfz $r2 = $r7, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 23, 16
; CHECK-NEXT:    extfz $r1 = $r3, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r2, $r1
; CHECK-NEXT:    extfz $r2 = $r7, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 31, 24
; CHECK-NEXT:    extfz $r1 = $r3, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r2, $r1
; CHECK-NEXT:    extfz $r2 = $r7, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 39, 32
; CHECK-NEXT:    extfz $r1 = $r3, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r2, $r1
; CHECK-NEXT:    extfz $r2 = $r7, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 47, 40
; CHECK-NEXT:    extfz $r1 = $r3, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r2, $r1
; CHECK-NEXT:    srld $r2 = $r7, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 55, 48
; CHECK-NEXT:    srld $r1 = $r3, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r2, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 63, 56
; CHECK-NEXT:    copyd $r1 = $r4
; CHECK-NEXT:    copyd $r2 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r6
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = mul <32 x i8> %1, %0
  ret <32 x i8> %3
}

define <32 x i8> @mul_v32i8_i8(<32 x i8> %0, i8 %1) {
; CHECK-LABEL: mul_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    extfz $r5 = $r0, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r4, $r5
; CHECK-NEXT:    extfz $r5 = $r0, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r5 = $r4, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r6, 15, 8
; CHECK-NEXT:    extfz $r6 = $r0, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r4, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r6, 23, 16
; CHECK-NEXT:    extfz $r6 = $r0, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r4, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r6, 31, 24
; CHECK-NEXT:    extfz $r6 = $r0, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r4, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r6, 39, 32
; CHECK-NEXT:    extfz $r6 = $r0, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r4, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r6, 47, 40
; CHECK-NEXT:    extfz $r6 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r0, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r4, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r6, 55, 48
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    extfz $r6 = $r1, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r1, 15, 8
; CHECK-NEXT:    mulw $r6 = $r4, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r0, 15, 8
; CHECK-NEXT:    extfz $r0 = $r1, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r1, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r1, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r1, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r1, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r1, 56
; CHECK-NEXT:    extfz $r1 = $r2, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r2, 15, 8
; CHECK-NEXT:    mulw $r7 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    extfz $r1 = $r3, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r0, 15, 8
; CHECK-NEXT:    extfz $r0 = $r2, 23, 16
; CHECK-NEXT:    mulw $r8 = $r4, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r2, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r2, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r2, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r2, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r2, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r3, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r0, 15, 8
; CHECK-NEXT:    extfz $r0 = $r3, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r3, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r3, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r3, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r3, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r3, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r0, 63, 56
; CHECK-NEXT:    copyd $r0 = $r5
; CHECK-NEXT:    copyd $r1 = $r6
; CHECK-NEXT:    copyd $r2 = $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r8
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <32 x i8> undef, i8 %1, i32 0
  %4 = shufflevector <32 x i8> %3, <32 x i8> undef, <32 x i32> zeroinitializer
  %5 = mul <32 x i8> %4, %0
  ret <32 x i8> %5
}

define <32 x i8> @div_v32i8_v32i8(<32 x i8> %0, <32 x i8> %1) {
; CHECK-LABEL: div_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 80[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r21 = $r6
; CHECK-NEXT:    copyd $r24 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    copyd $r23 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r22 = $r2
; CHECK-NEXT:    copyd $r25 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r26, 15, 8
; CHECK-NEXT:    extfz $r1 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r23, 7, 0
; CHECK-NEXT:    zxwd $r27 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r26, 23, 16
; CHECK-NEXT:    extfz $r1 = $r23, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r27, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r23, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r26, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r23, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r26, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r23, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r26, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r23, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r26, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r23, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r26, 56
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r24, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r25, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r24, 7, 0
; CHECK-NEXT:    zxwd $r26 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r25, 23, 16
; CHECK-NEXT:    extfz $r1 = $r24, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r26, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r24, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r25, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r24, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r25, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r24, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r25, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r24, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r25, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r24, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r25, 56
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r21, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r22, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r21, 7, 0
; CHECK-NEXT:    zxwd $r25 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 23, 16
; CHECK-NEXT:    extfz $r1 = $r21, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r25, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r21, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r22, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r21, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r22, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r21, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r22, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r21, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r22, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r21, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r22, 56
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r18, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r24 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r19, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r18, 7, 0
; CHECK-NEXT:    zxwd $r22 = $r0
; CHECK-NEXT:    extfz $r0 = $r19, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r19, 23, 16
; CHECK-NEXT:    extfz $r1 = $r18, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r22, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r18, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r19, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r18, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r19, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r18, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r19, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r18, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r19, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r18, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r19, 56
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 56
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r23
; CHECK-NEXT:    copyd $r2 = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r21
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sdiv <32 x i8> %0, %1
  ret <32 x i8> %3
}

define <32 x i8> @div_v32i8_i8(<32 x i8> %0, i8 %1) {
; CHECK-LABEL: div_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -24
; CHECK-NEXT:    .cfi_offset 22, -32
; CHECK-NEXT:    .cfi_offset 21, -40
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r21 = $r2
; CHECK-NEXT:    copyd $r23 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -56
; CHECK-NEXT:    .cfi_offset 18, -64
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    sxbd $r0 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 7, 0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r20 = $r24, 15, 8
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r22, 31, 24
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r22, 39, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r22, 47, 40
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r22, 55, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r22, 56
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r23, 15, 8
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r23, 7, 0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r22 = $r0
; CHECK-NEXT:    extfz $r0 = $r23, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r22 = $r24, 15, 8
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r23, 31, 24
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r23, 39, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r23, 47, 40
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r23, 55, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r23, 56
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r21, 15, 8
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 7, 0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r23 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r23 = $r24, 15, 8
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r21, 31, 24
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r21, 39, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r21, 47, 40
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r21, 55, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r21, 56
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r23 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r18, 15, 8
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r18, 7, 0
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r18, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r21 = $r24, 15, 8
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r18, 31, 24
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r18, 39, 32
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r18, 47, 40
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r18, 55, 48
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r18, 56
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 56
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    copyd $r2 = $r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r21
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <32 x i8> undef, i8 %1, i32 0
  %4 = shufflevector <32 x i8> %3, <32 x i8> undef, <32 x i32> zeroinitializer
  %5 = sdiv <32 x i8> %0, %4
  ret <32 x i8> %5
}

define <32 x i8> @add_v32i8_v32i8(<32 x i8> %0, <32 x i8> %1) {
; CHECK-LABEL: add_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    andd $r8 = $r0, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r0 = $r4, $r0
; CHECK-NEXT:    andd $r9 = $r4, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r4 = $r1, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    addd $r8 = $r9, $r8
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    xord $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r0 = $r8, $r0
; CHECK-NEXT:    andd $r8 = $r5, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r1 = $r1, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r5 = $r6, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    addd $r4 = $r8, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r1 = $r4, $r1
; CHECK-NEXT:    andd $r4 = $r2, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r4 = $r5, $r4
; CHECK-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CHECK-NEXT:    andd $r5 = $r7, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r2 = $r4, $r2
; CHECK-NEXT:    andd $r4 = $r3, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r3 = $r7, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r4 = $r5, $r4
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = add <32 x i8> %1, %0
  ret <32 x i8> %3
}

define <32 x i8> @add_v32i8_i8(<32 x i8> %0, i8 %1) {
; CHECK-LABEL: add_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    andd $r6 = $r0, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 63, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r0 = $r5, $r0
; CHECK-NEXT:    andd $r4 = $r5, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r6 = $r4, $r6
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r0 = $r6, $r0
; CHECK-NEXT:    andd $r6 = $r1, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r6 = $r4, $r6
; CHECK-NEXT:    andd $r1 = $r1, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r1 = $r6, $r1
; CHECK-NEXT:    andd $r6 = $r2, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r6 = $r4, $r6
; CHECK-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r2 = $r6, $r2
; CHECK-NEXT:    andd $r6 = $r3, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r3 = $r5, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r4 = $r4, $r6
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <32 x i8> undef, i8 %1, i32 0
  %4 = shufflevector <32 x i8> %3, <32 x i8> undef, <32 x i32> zeroinitializer
  %5 = add <32 x i8> %4, %0
  ret <32 x i8> %5
}

define <32 x i8> @sub_v32i8_v32i8(<32 x i8> %0, <32 x i8> %1) {
; CHECK-LABEL: sub_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ord $r8 = $r0, 0x8080808080808080
; CHECK-NEXT:    nxord $r0 = $r0, $r4
; CHECK-NEXT:    andd $r9 = $r4, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r4 = $r1, 0x8080808080808080
; CHECK-NEXT:    sbfd $r8 = $r9, $r8
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    nxord $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r0 = $r0, $r8
; CHECK-NEXT:    andd $r8 = $r5, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r1 = $r1, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r5 = $r6, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    sbfd $r4 = $r8, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r1 = $r1, $r4
; CHECK-NEXT:    ord $r4 = $r2, 0x8080808080808080
; CHECK-NEXT:    nxord $r2 = $r2, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfd $r4 = $r5, $r4
; CHECK-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CHECK-NEXT:    andd $r5 = $r7, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r2 = $r2, $r4
; CHECK-NEXT:    ord $r4 = $r3, 0x8080808080808080
; CHECK-NEXT:    nxord $r3 = $r3, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfd $r4 = $r5, $r4
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r3 = $r3, $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = sub <32 x i8> %0, %1
  ret <32 x i8> %3
}

define <32 x i8> @sub_v32i8_i8(<32 x i8> %0, i8 %1) {
; CHECK-LABEL: sub_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r5 = $r4
; CHECK-NEXT:    ord $r6 = $r0, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 63, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    nxord $r0 = $r0, $r5
; CHECK-NEXT:    andd $r4 = $r5, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfd $r6 = $r4, $r6
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r0 = $r0, $r6
; CHECK-NEXT:    ord $r6 = $r1, 0x8080808080808080
; CHECK-NEXT:    nxord $r1 = $r1, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfd $r6 = $r4, $r6
; CHECK-NEXT:    andd $r1 = $r1, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r1 = $r1, $r6
; CHECK-NEXT:    ord $r6 = $r2, 0x8080808080808080
; CHECK-NEXT:    nxord $r2 = $r2, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfd $r6 = $r4, $r6
; CHECK-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r2 = $r2, $r6
; CHECK-NEXT:    ord $r6 = $r3, 0x8080808080808080
; CHECK-NEXT:    nxord $r3 = $r3, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sbfd $r4 = $r4, $r6
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r3 = $r3, $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = insertelement <32 x i8> undef, i8 %1, i32 0
  %4 = shufflevector <32 x i8> %3, <32 x i8> undef, <32 x i32> zeroinitializer
  %5 = sub <32 x i8> %0, %4
  ret <32 x i8> %5
}

define <32 x i8> @mul_add_v32i8_v32i8(<32 x i8> %0, <32 x i8> %1, <32 x i8> %2) {
; CHECK-LABEL: mul_add_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    extfz $r15 = $r3, 15, 8
; CHECK-NEXT:    extfz $r16 = $r7, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r16 = $r16, $r15
; CHECK-NEXT:    extfz $r15 = $r3, 7, 0
; CHECK-NEXT:    extfz $r17 = $r7, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r15 = $r17, $r15
; CHECK-NEXT:    extfz $r17 = $r7, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r15 = $r16, 15, 8
; CHECK-NEXT:    extfz $r16 = $r3, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r16 = $r17, $r16
; CHECK-NEXT:    extfz $r17 = $r7, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r15 = $r16, 23, 16
; CHECK-NEXT:    extfz $r16 = $r3, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r16 = $r17, $r16
; CHECK-NEXT:    extfz $r17 = $r7, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r15 = $r16, 31, 24
; CHECK-NEXT:    extfz $r16 = $r3, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r16 = $r17, $r16
; CHECK-NEXT:    extfz $r17 = $r7, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r15 = $r16, 39, 32
; CHECK-NEXT:    extfz $r16 = $r3, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r16 = $r17, $r16
; CHECK-NEXT:    extfz $r17 = $r7, 55, 48
; CHECK-NEXT:    srld $r7 = $r7, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r15 = $r16, 47, 40
; CHECK-NEXT:    extfz $r16 = $r3, 55, 48
; CHECK-NEXT:    srld $r3 = $r3, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r16 = $r17, $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r15 = $r16, 55, 48
; CHECK-NEXT:    mulw $r3 = $r7, $r3
; CHECK-NEXT:    extfz $r7 = $r6, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r15 = $r3, 63, 56
; CHECK-NEXT:    extfz $r3 = $r2, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r7, $r3
; CHECK-NEXT:    extfz $r7 = $r2, 7, 0
; CHECK-NEXT:    extfz $r16 = $r6, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r7 = $r16, $r7
; CHECK-NEXT:    extfz $r16 = $r6, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r3, 15, 8
; CHECK-NEXT:    extfz $r3 = $r2, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r16, $r3
; CHECK-NEXT:    extfz $r16 = $r6, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r3, 23, 16
; CHECK-NEXT:    extfz $r3 = $r2, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r16, $r3
; CHECK-NEXT:    extfz $r16 = $r6, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r3, 31, 24
; CHECK-NEXT:    extfz $r3 = $r2, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r16, $r3
; CHECK-NEXT:    extfz $r16 = $r6, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r3, 39, 32
; CHECK-NEXT:    extfz $r3 = $r2, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r16, $r3
; CHECK-NEXT:    extfz $r16 = $r6, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r3, 47, 40
; CHECK-NEXT:    extfz $r3 = $r2, 55, 48
; CHECK-NEXT:    srld $r2 = $r2, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r16, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r3, 55, 48
; CHECK-NEXT:    srld $r3 = $r6, 56
; CHECK-NEXT:    extfz $r6 = $r5, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r3, $r2
; CHECK-NEXT:    extfz $r3 = $r5, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r7 = $r2, 63, 56
; CHECK-NEXT:    extfz $r2 = $r1, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r3, $r2
; CHECK-NEXT:    extfz $r3 = $r1, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r6, $r3
; CHECK-NEXT:    extfz $r6 = $r5, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r2, 15, 8
; CHECK-NEXT:    extfz $r2 = $r1, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r6, $r2
; CHECK-NEXT:    extfz $r6 = $r5, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r2, 23, 16
; CHECK-NEXT:    extfz $r2 = $r1, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r6, $r2
; CHECK-NEXT:    extfz $r6 = $r5, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r2, 31, 24
; CHECK-NEXT:    extfz $r2 = $r1, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r6, $r2
; CHECK-NEXT:    extfz $r6 = $r5, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r2, 39, 32
; CHECK-NEXT:    extfz $r2 = $r1, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r6, $r2
; CHECK-NEXT:    extfz $r6 = $r5, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r2, 47, 40
; CHECK-NEXT:    extfz $r2 = $r1, 55, 48
; CHECK-NEXT:    srld $r1 = $r1, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r6, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r2, 55, 48
; CHECK-NEXT:    srld $r2 = $r5, 56
; CHECK-NEXT:    extfz $r5 = $r4, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r2, $r1
; CHECK-NEXT:    extfz $r2 = $r4, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r1, 63, 56
; CHECK-NEXT:    extfz $r1 = $r0, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r2, $r1
; CHECK-NEXT:    extfz $r2 = $r0, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r5, $r2
; CHECK-NEXT:    extfz $r5 = $r4, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r1, 15, 8
; CHECK-NEXT:    extfz $r1 = $r0, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    extfz $r5 = $r4, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r1, 23, 16
; CHECK-NEXT:    extfz $r1 = $r0, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    extfz $r5 = $r4, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r1, 31, 24
; CHECK-NEXT:    extfz $r1 = $r0, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    extfz $r5 = $r4, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r1, 39, 32
; CHECK-NEXT:    extfz $r1 = $r0, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    extfz $r5 = $r4, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r1, 47, 40
; CHECK-NEXT:    extfz $r1 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r0, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r1, 55, 48
; CHECK-NEXT:    srld $r1 = $r4, 56
; CHECK-NEXT:    andd $r4 = $r11, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r1, $r0
; CHECK-NEXT:    andd $r1 = $r8, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r0, 63, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r0 = $r2, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r0 = $r0, $r1
; CHECK-NEXT:    xord $r1 = $r2, $r8
; CHECK-NEXT:    andd $r2 = $r9, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r1 = $r1, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r0 = $r0, $r1
; CHECK-NEXT:    andd $r1 = $r3, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r1 = $r1, $r2
; CHECK-NEXT:    xord $r2 = $r3, $r9
; CHECK-NEXT:    andd $r3 = $r10, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r1 = $r1, $r2
; CHECK-NEXT:    andd $r2 = $r7, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r2 = $r2, $r3
; CHECK-NEXT:    xord $r3 = $r7, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r2 = $r2, $r3
; CHECK-NEXT:    andd $r3 = $r15, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r3 = $r3, $r4
; CHECK-NEXT:    xord $r4 = $r15, $r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r4 = $r4, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r3 = $r3, $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = mul <32 x i8> %1, %0
  %5 = add <32 x i8> %4, %2
  ret <32 x i8> %5
}

define <4 x double> @p_mul_v4f64_v4f64(<4 x double>* nocapture readonly %0, <4 x double>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r1 = $r5, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r0 = $r4, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r2 = $r6, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r3 = $r7, $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x double>, <4 x double>* %0, align 32
  %4 = load <4 x double>, <4 x double>* %1, align 32
  %5 = fmul <4 x double> %3, %4
  ret <4 x double> %5
}

define <4 x double> @p_mul_v4f64_f64(<4 x double>* nocapture readonly %0, double* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r1 = $r5, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r0 = $r4, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r2 = $r6, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r3 = $r7, $r8
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x double>, <4 x double>* %0, align 32
  %4 = load double, double* %1, align 8
  %5 = insertelement <4 x double> undef, double %4, i32 0
  %6 = shufflevector <4 x double> %5, <4 x double> undef, <4 x i32> zeroinitializer
  %7 = fmul <4 x double> %3, %6
  ret <4 x double> %7
}

define <4 x double> @p_div_v4f64_v4f64(<4 x double>* nocapture readonly %0, <4 x double>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -128
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 128
; CHECK-NEXT:    sd 96[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -32
; CHECK-NEXT:    so 64[$r12] = $r28r29r30r31
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 31, -40
; CHECK-NEXT:    .cfi_offset 30, -48
; CHECK-NEXT:    .cfi_offset 29, -56
; CHECK-NEXT:    .cfi_offset 28, -64
; CHECK-NEXT:    so 32[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -72
; CHECK-NEXT:    .cfi_offset 26, -80
; CHECK-NEXT:    .cfi_offset 25, -88
; CHECK-NEXT:    .cfi_offset 24, -96
; CHECK-NEXT:    so 0[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -104
; CHECK-NEXT:    .cfi_offset 22, -112
; CHECK-NEXT:    .cfi_offset 21, -120
; CHECK-NEXT:    .cfi_offset 20, -128
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r28r29r30r31 = 0[$r1]
; CHECK-NEXT:    copyd $r0 = $r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r29
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r28
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r26
; CHECK-NEXT:    copyd $r1 = $r30
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r27
; CHECK-NEXT:    copyd $r1 = $r31
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r23
; CHECK-NEXT:    lo $r20r21r22r23 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 32[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r28r29r30r31 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 96[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 128
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x double>, <4 x double>* %0, align 32
  %4 = load <4 x double>, <4 x double>* %1, align 32
  %5 = fdiv <4 x double> %3, %4
  ret <4 x double> %5
}

define <4 x double> @p_div_v4f64_f64(<4 x double>* nocapture readonly %0, double* nocapture readonly %1) {
; CHECK-LABEL: p_div_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 72[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -24
; CHECK-NEXT:    so 40[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -32
; CHECK-NEXT:    .cfi_offset 26, -40
; CHECK-NEXT:    .cfi_offset 25, -48
; CHECK-NEXT:    .cfi_offset 24, -56
; CHECK-NEXT:    so 8[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -64
; CHECK-NEXT:    .cfi_offset 22, -72
; CHECK-NEXT:    .cfi_offset 21, -80
; CHECK-NEXT:    .cfi_offset 20, -88
; CHECK-NEXT:    sd 0[$r12] = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r18 = 0[$r1]
; CHECK-NEXT:    copyd $r0 = $r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r26
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r27
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r23
; CHECK-NEXT:    ld $r18 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 8[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 40[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x double>, <4 x double>* %0, align 32
  %4 = load double, double* %1, align 8
  %5 = insertelement <4 x double> undef, double %4, i32 0
  %6 = shufflevector <4 x double> %5, <4 x double> undef, <4 x i32> zeroinitializer
  %7 = fdiv <4 x double> %3, %6
  ret <4 x double> %7
}

define <4 x double> @p_add_v4f64_v4f64(<4 x double>* nocapture readonly %0, <4 x double>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r1 = $r5, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r0 = $r4, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r2 = $r6, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r3 = $r7, $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x double>, <4 x double>* %0, align 32
  %4 = load <4 x double>, <4 x double>* %1, align 32
  %5 = fadd <4 x double> %3, %4
  ret <4 x double> %5
}

define <4 x double> @p_add_v4f64_f64(<4 x double>* nocapture readonly %0, double* nocapture readonly %1) {
; CHECK-LABEL: p_add_v4f64_f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r1 = $r5, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r0 = $r4, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r2 = $r6, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r3 = $r7, $r8
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x double>, <4 x double>* %0, align 32
  %4 = load double, double* %1, align 8
  %5 = insertelement <4 x double> undef, double %4, i32 0
  %6 = shufflevector <4 x double> %5, <4 x double> undef, <4 x i32> zeroinitializer
  %7 = fadd <4 x double> %3, %6
  ret <4 x double> %7
}

define <4 x double> @p_mul_add_v4f64_v4f64(<4 x double>* nocapture readonly %0, <4 x double>* nocapture readonly %1, <4 x double>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v4f64_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r32r33r34r35 = 0[$r2]
; CHECK-NEXT:    fmuld $r3 = $r4, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r4 = $r5, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r0 = $r7, $r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmuld $r1 = $r6, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r5 = $r33, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r4 = $r32, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r6 = $r34, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddd $r7 = $r35, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    so 0[$r2] = $r4r5r6r7
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    copyd $r2 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <4 x double>, <4 x double>* %0, align 32
  %5 = load <4 x double>, <4 x double>* %1, align 32
  %6 = fmul <4 x double> %4, %5
  %7 = load <4 x double>, <4 x double>* %2, align 32
  %8 = fadd <4 x double> %7, %6
  store <4 x double> %8, <4 x double>* %2, align 32
  ret <4 x double> %8
}

define <4 x i64> @p_mul_v4i64_v4i64(<4 x i64>* nocapture readonly %0, <4 x i64>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r1 = $r9, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r0 = $r8, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r2 = $r10, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r3 = $r11, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x i64>, <4 x i64>* %0, align 32
  %4 = load <4 x i64>, <4 x i64>* %1, align 32
  %5 = mul <4 x i64> %4, %3
  ret <4 x i64> %5
}

define <4 x i64> @p_mul_v4i64_i64(<4 x i64>* nocapture readonly %0, i64* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r1 = $r8, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r0 = $r8, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r2 = $r8, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r3 = $r8, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x i64>, <4 x i64>* %0, align 32
  %4 = load i64, i64* %1, align 8
  %5 = insertelement <4 x i64> undef, i64 %4, i32 0
  %6 = shufflevector <4 x i64> %5, <4 x i64> undef, <4 x i32> zeroinitializer
  %7 = mul <4 x i64> %6, %3
  ret <4 x i64> %7
}

define <4 x i64> @p_div_v4i64_v4i64(<4 x i64>* nocapture readonly %0, <4 x i64>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -128
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 128
; CHECK-NEXT:    sd 96[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -32
; CHECK-NEXT:    so 64[$r12] = $r28r29r30r31
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 31, -40
; CHECK-NEXT:    .cfi_offset 30, -48
; CHECK-NEXT:    .cfi_offset 29, -56
; CHECK-NEXT:    .cfi_offset 28, -64
; CHECK-NEXT:    so 32[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -72
; CHECK-NEXT:    .cfi_offset 26, -80
; CHECK-NEXT:    .cfi_offset 25, -88
; CHECK-NEXT:    .cfi_offset 24, -96
; CHECK-NEXT:    so 0[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -104
; CHECK-NEXT:    .cfi_offset 22, -112
; CHECK-NEXT:    .cfi_offset 21, -120
; CHECK-NEXT:    .cfi_offset 20, -128
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r28r29r30r31 = 0[$r1]
; CHECK-NEXT:    copyd $r0 = $r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r29
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r28
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r26
; CHECK-NEXT:    copyd $r1 = $r30
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r27
; CHECK-NEXT:    copyd $r1 = $r31
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r23
; CHECK-NEXT:    lo $r20r21r22r23 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 32[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r28r29r30r31 = 64[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 96[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 128
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x i64>, <4 x i64>* %0, align 32
  %4 = load <4 x i64>, <4 x i64>* %1, align 32
  %5 = sdiv <4 x i64> %3, %4
  ret <4 x i64> %5
}

define <4 x i64> @p_div_v4i64_i64(<4 x i64>* nocapture readonly %0, i64* nocapture readonly %1) {
; CHECK-LABEL: p_div_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 72[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -24
; CHECK-NEXT:    so 40[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -32
; CHECK-NEXT:    .cfi_offset 26, -40
; CHECK-NEXT:    .cfi_offset 25, -48
; CHECK-NEXT:    .cfi_offset 24, -56
; CHECK-NEXT:    so 8[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -64
; CHECK-NEXT:    .cfi_offset 22, -72
; CHECK-NEXT:    .cfi_offset 21, -80
; CHECK-NEXT:    .cfi_offset 20, -88
; CHECK-NEXT:    sd 0[$r12] = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    lo $r24r25r26r27 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r18 = 0[$r1]
; CHECK-NEXT:    copyd $r0 = $r25
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    copyd $r0 = $r26
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    copyd $r0 = $r27
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r23
; CHECK-NEXT:    ld $r18 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 8[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 40[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x i64>, <4 x i64>* %0, align 32
  %4 = load i64, i64* %1, align 8
  %5 = insertelement <4 x i64> undef, i64 %4, i32 0
  %6 = shufflevector <4 x i64> %5, <4 x i64> undef, <4 x i32> zeroinitializer
  %7 = sdiv <4 x i64> %3, %6
  ret <4 x i64> %7
}

define <4 x i64> @p_add_v4i64_v4i64(<4 x i64>* nocapture readonly %0, <4 x i64>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r1 = $r9, $r5
; CHECK-NEXT:    addd $r0 = $r8, $r4
; CHECK-NEXT:    addd $r2 = $r10, $r6
; CHECK-NEXT:    addd $r3 = $r11, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x i64>, <4 x i64>* %0, align 32
  %4 = load <4 x i64>, <4 x i64>* %1, align 32
  %5 = add <4 x i64> %4, %3
  ret <4 x i64> %5
}

define <4 x i64> @p_add_v4i64_i64(<4 x i64>* nocapture readonly %0, i64* nocapture readonly %1) {
; CHECK-LABEL: p_add_v4i64_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r1 = $r8, $r5
; CHECK-NEXT:    addd $r0 = $r8, $r4
; CHECK-NEXT:    addd $r2 = $r8, $r6
; CHECK-NEXT:    addd $r3 = $r8, $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <4 x i64>, <4 x i64>* %0, align 32
  %4 = load i64, i64* %1, align 8
  %5 = insertelement <4 x i64> undef, i64 %4, i32 0
  %6 = shufflevector <4 x i64> %5, <4 x i64> undef, <4 x i32> zeroinitializer
  %7 = add <4 x i64> %6, %3
  ret <4 x i64> %7
}

define <4 x i64> @p_mul_add_v4i64_v4i64(<4 x i64>* nocapture readonly %0, <4 x i64>* nocapture readonly %1, <4 x i64>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v4i64_v4i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r8r9r10r11 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r32r33r34r35 = 0[$r2]
; CHECK-NEXT:    muld $r3 = $r8, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r4 = $r9, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r0 = $r11, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    muld $r1 = $r10, $r6
; CHECK-NEXT:    addd $r5 = $r33, $r4
; CHECK-NEXT:    addd $r4 = $r32, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r6 = $r34, $r1
; CHECK-NEXT:    addd $r7 = $r35, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    so 0[$r2] = $r4r5r6r7
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    copyd $r2 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <4 x i64>, <4 x i64>* %0, align 32
  %5 = load <4 x i64>, <4 x i64>* %1, align 32
  %6 = mul <4 x i64> %5, %4
  %7 = load <4 x i64>, <4 x i64>* %2, align 32
  %8 = add <4 x i64> %7, %6
  store <4 x i64> %8, <4 x i64>* %2, align 32
  ret <4 x i64> %8
}

define <8 x float> @p_mul_vv8f32_v8f32(<8 x float>* nocapture readonly %0, <8 x float>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_vv8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lq $r4r5 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r2r3 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r6r7 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r0r1 = 0[$r1]
; CHECK-NEXT:    fmulwq $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x float>, <8 x float>* %0, align 32
  %4 = load <8 x float>, <8 x float>* %1, align 32
  %5 = fmul <8 x float> %3, %4
  ret <8 x float> %5
}

define <8 x float> @p_mul_v8f32_f32(<8 x float>* nocapture readonly %0, float* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lwz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r2r3 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r4r5 = 0[$r0]
; CHECK-NEXT:    zxwd $r0 = $r1
; CHECK-NEXT:    slld $r1 = $r1, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r0 = $r0, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r2r3 = $r2r3, $r0r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x float>, <8 x float>* %0, align 32
  %4 = load float, float* %1, align 4
  %5 = insertelement <8 x float> undef, float %4, i32 0
  %6 = shufflevector <8 x float> %5, <8 x float> undef, <8 x i32> zeroinitializer
  %7 = fmul <8 x float> %3, %6
  ret <8 x float> %7
}

define <8 x float> @p_div_v8f32_v8f32(<8 x float>* nocapture readonly %0, <8 x float>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 80[$r12] = $r28
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 28, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    lq $r20r21 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r18r19 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r22r23 = 0[$r1]
; CHECK-NEXT:    srad $r0 = $r21, 32
; CHECK-NEXT:    srad $r1 = $r25, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r25
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r27 = $r0
; CHECK-NEXT:    srad $r0 = $r20, 32
; CHECK-NEXT:    srad $r1 = $r24, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r28 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r24
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r19, 32
; CHECK-NEXT:    srad $r1 = $r23, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r23
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    srad $r0 = $r18, 32
; CHECK-NEXT:    srad $r1 = $r22, 32
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r25, 63, 32
; CHECK-NEXT:    insf $r24 = $r21, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r28, 63, 32
; CHECK-NEXT:    insf $r27 = $r26, 63, 32
; CHECK-NEXT:    copyd $r1 = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r20
; CHECK-NEXT:    copyd $r3 = $r27
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r28 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x float>, <8 x float>* %0, align 32
  %4 = load <8 x float>, <8 x float>* %1, align 32
  %5 = fdiv <8 x float> %3, %4
  ret <8 x float> %5
}

define <8 x float> @p_div_v8f32_f32(<8 x float>* nocapture readonly %0, float* nocapture readonly %1) {
; CHECK-LABEL: p_div_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 80[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    lq $r20r21 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lwz $r22 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r18r19 = 0[$r0]
; CHECK-NEXT:    srad $r0 = $r21, 32
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r23 = $r0
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    srad $r0 = $r20, 32
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r19, 32
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    srad $r0 = $r18, 32
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r27 = $r0
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r22
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r27, 63, 32
; CHECK-NEXT:    insf $r26 = $r21, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r25, 63, 32
; CHECK-NEXT:    insf $r24 = $r23, 63, 32
; CHECK-NEXT:    copyd $r1 = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r20
; CHECK-NEXT:    copyd $r3 = $r24
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x float>, <8 x float>* %0, align 32
  %4 = load float, float* %1, align 4
  %5 = insertelement <8 x float> undef, float %4, i32 0
  %6 = shufflevector <8 x float> %5, <8 x float> undef, <8 x i32> zeroinitializer
  %7 = fdiv <8 x float> %3, %6
  ret <8 x float> %7
}

define <8 x float> @p_add_v8f32_v8f32(<8 x float>* nocapture readonly %0, <8 x float>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lq $r4r5 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r2r3 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r6r7 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r0r1 = 0[$r1]
; CHECK-NEXT:    faddwq $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x float>, <8 x float>* %0, align 32
  %4 = load <8 x float>, <8 x float>* %1, align 32
  %5 = fadd <8 x float> %3, %4
  ret <8 x float> %5
}

define <8 x float> @p_add_v8f32_f32(<8 x float>* nocapture readonly %0, float* nocapture readonly %1) {
; CHECK-LABEL: p_add_v8f32_f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lwz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r2r3 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r4r5 = 0[$r0]
; CHECK-NEXT:    zxwd $r0 = $r1
; CHECK-NEXT:    slld $r1 = $r1, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r0 = $r0, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r2r3 = $r2r3, $r0r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x float>, <8 x float>* %0, align 32
  %4 = load float, float* %1, align 4
  %5 = insertelement <8 x float> undef, float %4, i32 0
  %6 = shufflevector <8 x float> %5, <8 x float> undef, <8 x i32> zeroinitializer
  %7 = fadd <8 x float> %3, %6
  ret <8 x float> %7
}

define <8 x float> @p_mul_add_v8f32_v8f32(<8 x float>* nocapture readonly %0, <8 x float>* nocapture readonly %1, <8 x float>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v8f32_v8f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lq $r4r5 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r10r11 = 16[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r8r9 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r0r1 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r16r17 = 0[$r2]
; CHECK-NEXT:    fmulwq $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulwq $r6r7 = $r6r7, $r8r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r4r5 = $r10r11, $r0r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddwq $r0r1 = $r16r17, $r6r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sq 16[$r2] = $r4r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sq 0[$r2] = $r0r1
; CHECK-NEXT:    copyd $r2 = $r4
; CHECK-NEXT:    copyd $r3 = $r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <8 x float>, <8 x float>* %0, align 32
  %5 = load <8 x float>, <8 x float>* %1, align 32
  %6 = fmul <8 x float> %4, %5
  %7 = load <8 x float>, <8 x float>* %2, align 32
  %8 = fadd <8 x float> %7, %6
  store <8 x float> %8, <8 x float>* %2, align 32
  ret <8 x float> %8
}

define <8 x i32> @p_mul_v8i32_v8i32(<8 x i32>* nocapture readonly %0, <8 x i32>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lq $r4r5 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r6r7 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r8r9 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r10r11 = 0[$r1]
; CHECK-NEXT:    srad $r0 = $r5, 32
; CHECK-NEXT:    srad $r1 = $r7, 32
; CHECK-NEXT:    mulw $r3 = $r7, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r15 = $r1, $r0
; CHECK-NEXT:    srad $r0 = $r4, 32
; CHECK-NEXT:    srad $r1 = $r6, 32
; CHECK-NEXT:    srad $r5 = $r11, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r6, $r4
; CHECK-NEXT:    srad $r6 = $r8, 32
; CHECK-NEXT:    srad $r7 = $r10, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r4 = $r1, $r0
; CHECK-NEXT:    srad $r0 = $r9, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r5 = $r5, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r11, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r10, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r6, 63, 32
; CHECK-NEXT:    insf $r1 = $r5, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r4, 63, 32
; CHECK-NEXT:    insf $r3 = $r15, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x i32>, <8 x i32>* %0, align 32
  %4 = load <8 x i32>, <8 x i32>* %1, align 32
  %5 = mul <8 x i32> %4, %3
  ret <8 x i32> %5
}

define <8 x i32> @p_mul_v8i32_i32(<8 x i32>* nocapture readonly %0, i32* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lq $r4r5 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lwz $r6 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r8r9 = 0[$r0]
; CHECK-NEXT:    srad $r0 = $r5, 32
; CHECK-NEXT:    mulw $r2 = $r6, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r7 = $r6, $r0
; CHECK-NEXT:    srad $r0 = $r4, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r4 = $r6, $r0
; CHECK-NEXT:    srad $r0 = $r9, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r6, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r5 = $r6, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r6, $r8
; CHECK-NEXT:    srad $r8 = $r8, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r6, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r6, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r6, 63, 32
; CHECK-NEXT:    insf $r1 = $r5, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r4, 63, 32
; CHECK-NEXT:    insf $r3 = $r7, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x i32>, <8 x i32>* %0, align 32
  %4 = load i32, i32* %1, align 4
  %5 = insertelement <8 x i32> undef, i32 %4, i32 0
  %6 = shufflevector <8 x i32> %5, <8 x i32> undef, <8 x i32> zeroinitializer
  %7 = mul <8 x i32> %6, %3
  ret <8 x i32> %7
}

define <8 x i32> @p_div_v8i32_v8i32(<8 x i32>* nocapture readonly %0, <8 x i32>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 80[$r12] = $r28
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 28, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    lq $r20r21 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r26r27 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r22r23 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 0[$r1]
; CHECK-NEXT:    sxwd $r0 = $r21
; CHECK-NEXT:    sxwd $r1 = $r27
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r27, 32
; CHECK-NEXT:    zxwd $r18 = $r0
; CHECK-NEXT:    srad $r0 = $r21, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r28 = $r0
; CHECK-NEXT:    sxwd $r0 = $r20
; CHECK-NEXT:    sxwd $r1 = $r26
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r26, 32
; CHECK-NEXT:    zxwd $r19 = $r0
; CHECK-NEXT:    srad $r0 = $r20, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r26 = $r0
; CHECK-NEXT:    sxwd $r0 = $r23
; CHECK-NEXT:    sxwd $r1 = $r25
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r25, 32
; CHECK-NEXT:    zxwd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r23, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r27 = $r0
; CHECK-NEXT:    sxwd $r0 = $r22
; CHECK-NEXT:    sxwd $r1 = $r24
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r1 = $r24, 32
; CHECK-NEXT:    zxwd $r21 = $r0
; CHECK-NEXT:    srad $r0 = $r22, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 32
; CHECK-NEXT:    insf $r20 = $r27, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r26, 63, 32
; CHECK-NEXT:    insf $r18 = $r28, 63, 32
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r19
; CHECK-NEXT:    copyd $r3 = $r18
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r28 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x i32>, <8 x i32>* %0, align 32
  %4 = load <8 x i32>, <8 x i32>* %1, align 32
  %5 = sdiv <8 x i32> %3, %4
  ret <8 x i32> %5
}

define <8 x i32> @p_div_v8i32_i32(<8 x i32>* nocapture readonly %0, i32* nocapture readonly %1) {
; CHECK-LABEL: p_div_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 80[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    lq $r22r23 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lws $r18 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r24r25 = 0[$r0]
; CHECK-NEXT:    sxwd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r19 = $r0
; CHECK-NEXT:    srad $r0 = $r23, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r26 = $r0
; CHECK-NEXT:    sxwd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r20 = $r0
; CHECK-NEXT:    srad $r0 = $r22, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r23 = $r0
; CHECK-NEXT:    sxwd $r0 = $r25
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r21 = $r0
; CHECK-NEXT:    srad $r0 = $r25, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r27 = $r0
; CHECK-NEXT:    sxwd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r22 = $r0
; CHECK-NEXT:    srad $r0 = $r24, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 63, 32
; CHECK-NEXT:    insf $r21 = $r27, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r23, 63, 32
; CHECK-NEXT:    insf $r19 = $r26, 63, 32
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r20
; CHECK-NEXT:    copyd $r3 = $r19
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x i32>, <8 x i32>* %0, align 32
  %4 = load i32, i32* %1, align 4
  %5 = insertelement <8 x i32> undef, i32 %4, i32 0
  %6 = shufflevector <8 x i32> %5, <8 x i32> undef, <8 x i32> zeroinitializer
  %7 = sdiv <8 x i32> %3, %6
  ret <8 x i32> %7
}

define <8 x i32> @p_add_v8i32_v8i32(<8 x i32>* nocapture readonly %0, <8 x i32>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lq $r4r5 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r6r7 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r8r9 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r10r11 = 0[$r1]
; CHECK-NEXT:    srad $r0 = $r5, 32
; CHECK-NEXT:    srad $r1 = $r7, 32
; CHECK-NEXT:    addw $r3 = $r7, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r2 = $r6, $r4
; CHECK-NEXT:    addw $r15 = $r1, $r0
; CHECK-NEXT:    srad $r1 = $r6, 32
; CHECK-NEXT:    srad $r0 = $r4, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r5 = $r11, 32
; CHECK-NEXT:    addw $r4 = $r1, $r0
; CHECK-NEXT:    srad $r0 = $r9, 32
; CHECK-NEXT:    srad $r6 = $r8, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r7 = $r10, 32
; CHECK-NEXT:    addw $r5 = $r5, $r0
; CHECK-NEXT:    addw $r1 = $r11, $r9
; CHECK-NEXT:    addw $r0 = $r10, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r6 = $r7, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r6, 63, 32
; CHECK-NEXT:    insf $r1 = $r5, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r4, 63, 32
; CHECK-NEXT:    insf $r3 = $r15, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x i32>, <8 x i32>* %0, align 32
  %4 = load <8 x i32>, <8 x i32>* %1, align 32
  %5 = add <8 x i32> %4, %3
  ret <8 x i32> %5
}

define <8 x i32> @p_add_v8i32_i32(<8 x i32>* nocapture readonly %0, i32* nocapture readonly %1) {
; CHECK-LABEL: p_add_v8i32_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lq $r4r5 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lwz $r6 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r8r9 = 0[$r0]
; CHECK-NEXT:    srad $r0 = $r5, 32
; CHECK-NEXT:    addw $r2 = $r6, $r4
; CHECK-NEXT:    addw $r3 = $r6, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r7 = $r6, $r0
; CHECK-NEXT:    srad $r0 = $r4, 32
; CHECK-NEXT:    addw $r1 = $r6, $r9
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r4 = $r6, $r0
; CHECK-NEXT:    srad $r0 = $r9, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r5 = $r6, $r0
; CHECK-NEXT:    addw $r0 = $r6, $r8
; CHECK-NEXT:    srad $r8 = $r8, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r6 = $r6, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r6, 63, 32
; CHECK-NEXT:    insf $r1 = $r5, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r4, 63, 32
; CHECK-NEXT:    insf $r3 = $r7, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <8 x i32>, <8 x i32>* %0, align 32
  %4 = load i32, i32* %1, align 4
  %5 = insertelement <8 x i32> undef, i32 %4, i32 0
  %6 = shufflevector <8 x i32> %5, <8 x i32> undef, <8 x i32> zeroinitializer
  %7 = add <8 x i32> %6, %3
  ret <8 x i32> %7
}

define <8 x i32> @p_mul_add_v8i32_v8i32(<8 x i32>* nocapture readonly %0, <8 x i32>* nocapture readonly %1, <8 x i32>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v8i32_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lq $r6r7 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r10r11 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r34r35 = 16[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r8r9 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r0r1 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lq $r36r37 = 0[$r2]
; CHECK-NEXT:    srad $r4 = $r10, 32
; CHECK-NEXT:    srad $r38 = $r34, 32
; CHECK-NEXT:    srad $r3 = $r11, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r40 = $r35, 32
; CHECK-NEXT:    srad $r33 = $r0, 32
; CHECK-NEXT:    srad $r32 = $r1, 32
; CHECK-NEXT:    srad $r16 = $r6, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    srad $r17 = $r8, 32
; CHECK-NEXT:    mulw $r33 = $r33, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r33 = $r38, $r33
; CHECK-NEXT:    mulw $r32 = $r32, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r32 = $r40, $r32
; CHECK-NEXT:    mulw $r4 = $r0, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r4 = $r34, $r4
; CHECK-NEXT:    mulw $r3 = $r1, $r11
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r3 = $r35, $r3
; CHECK-NEXT:    srad $r5 = $r7, 32
; CHECK-NEXT:    srad $r15 = $r9, 32
; CHECK-NEXT:    slld $r38 = $r33, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    slld $r0 = $r32, 32
; CHECK-NEXT:    ord $r38 = $r4, $r38
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r39 = $r3, $r0
; CHECK-NEXT:    srad $r0 = $r36, 32
; CHECK-NEXT:    mulw $r10 = $r17, $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r10 = $r0, $r10
; CHECK-NEXT:    mulw $r0 = $r8, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r0 = $r36, $r0
; CHECK-NEXT:    sq 16[$r2] = $r38r39
; CHECK-NEXT:    slld $r1 = $r10, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r16 = $r0, $r1
; CHECK-NEXT:    srad $r1 = $r37, 32
; CHECK-NEXT:    mulw $r5 = $r15, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r5 = $r1, $r5
; CHECK-NEXT:    mulw $r1 = $r9, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addw $r1 = $r37, $r1
; CHECK-NEXT:    slld $r6 = $r5, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord $r17 = $r1, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sq 0[$r2] = $r16r17
; CHECK-NEXT:    insf $r0 = $r10, 63, 32
; CHECK-NEXT:    insf $r1 = $r5, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r33, 63, 32
; CHECK-NEXT:    insf $r3 = $r32, 63, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r2 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <8 x i32>, <8 x i32>* %0, align 32
  %5 = load <8 x i32>, <8 x i32>* %1, align 32
  %6 = mul <8 x i32> %5, %4
  %7 = load <8 x i32>, <8 x i32>* %2, align 32
  %8 = add <8 x i32> %7, %6
  store <8 x i32> %8, <8 x i32>* %2, align 32
  ret <8 x i32> %8
}

define <16 x half> @p_mul_vv16f16_v16f16(<16 x half>* nocapture readonly %0, <16 x half>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_vv16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ld $r3 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 24[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r2 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r7 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r6 = 8[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r5 = 0[$r1]
; CHECK-NEXT:    fmulhq $r1 = $r4, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r0 = $r0, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r2 = $r2, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r3 = $r3, $r8
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x half>, <16 x half>* %0, align 32
  %4 = load <16 x half>, <16 x half>* %1, align 32
  %5 = fmul <16 x half> %3, %4
  ret <16 x half> %5
}

define <16 x half> @p_mul_v16f16_f16(<16 x half>* nocapture readonly %0, half* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lhz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r2 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 0[$r0]
; CHECK-NEXT:    copyd $r5 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 63, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r0 = $r0, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r1 = $r4, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r2 = $r2, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r3 = $r3, $r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x half>, <16 x half>* %0, align 32
  %4 = load half, half* %1, align 2
  %5 = insertelement <16 x half> undef, half %4, i32 0
  %6 = shufflevector <16 x half> %5, <16 x half> undef, <16 x i32> zeroinitializer
  %7 = fmul <16 x half> %3, %6
  ret <16 x half> %7
}

define <16 x half> @p_div_v16f16_v16f16(<16 x half>* nocapture readonly %0, <16 x half>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 80[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    ld $r19 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r22 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r21 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r20 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r23 = 24[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r24 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r25 = 8[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r26 = 0[$r1]
; CHECK-NEXT:    extfz $r0 = $r19, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r26, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r26, 15, 0
; CHECK-NEXT:    fnarrowwh $r27 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r19, 15, 0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r18 = $r0
; CHECK-NEXT:    extfz $r0 = $r19, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r26, 47, 32
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r18 = $r27, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r26, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r19, 48
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r25, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r0, 63, 48
; CHECK-NEXT:    extfz $r0 = $r20, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r25, 15, 0
; CHECK-NEXT:    fnarrowwh $r26 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r20, 15, 0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r25, 47, 32
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r19 = $r26, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r25, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r20, 48
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r24, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 63, 48
; CHECK-NEXT:    extfz $r0 = $r21, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r24, 15, 0
; CHECK-NEXT:    fnarrowwh $r25 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r21, 15, 0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r24, 47, 32
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r20 = $r25, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r24, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r21, 48
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r23, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 63, 48
; CHECK-NEXT:    extfz $r0 = $r22, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r23, 15, 0
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r22, 15, 0
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r23, 47, 32
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    insf $r21 = $r24, 31, 16
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r23, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r22, 48
; CHECK-NEXT:    fwidenlhw $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 48
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    copyd $r2 = $r20
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r21
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x half>, <16 x half>* %0, align 32
  %4 = load <16 x half>, <16 x half>* %1, align 32
  %5 = fdiv <16 x half> %3, %4
  ret <16 x half> %5
}

define <16 x half> @p_div_v16f16_f16(<16 x half>* nocapture readonly %0, half* nocapture readonly %1) {
; CHECK-LABEL: p_div_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -24
; CHECK-NEXT:    .cfi_offset 22, -32
; CHECK-NEXT:    .cfi_offset 21, -40
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -56
; CHECK-NEXT:    .cfi_offset 18, -64
; CHECK-NEXT:    ld $r23 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r22 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r21 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r20 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lhz $r0 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r18 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 15, 0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r24, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r20, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 63, 48
; CHECK-NEXT:    extfz $r0 = $r21, 31, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 15, 0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r24, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r21, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 63, 48
; CHECK-NEXT:    extfz $r0 = $r22, 31, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 15, 0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r22, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 48
; CHECK-NEXT:    extfz $r0 = $r23, 31, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r23, 15, 0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r22 = $r0
; CHECK-NEXT:    extfz $r0 = $r23, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r24, 31, 16
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 47, 32
; CHECK-NEXT:    srld $r0 = $r23, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenlhw $r0 = $r0
; CHECK-NEXT:    call __divsf3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 63, 48
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    copyd $r2 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r22
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x half>, <16 x half>* %0, align 32
  %4 = load half, half* %1, align 2
  %5 = insertelement <16 x half> undef, half %4, i32 0
  %6 = shufflevector <16 x half> %5, <16 x half> undef, <16 x i32> zeroinitializer
  %7 = fdiv <16 x half> %3, %6
  ret <16 x half> %7
}

define <16 x half> @p_add_v16f16_v16f16(<16 x half>* nocapture readonly %0, <16 x half>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ld $r3 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 24[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r2 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r7 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r6 = 8[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r5 = 0[$r1]
; CHECK-NEXT:    faddhq $r1 = $r4, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r0 = $r0, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r2 = $r2, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r3 = $r3, $r8
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x half>, <16 x half>* %0, align 32
  %4 = load <16 x half>, <16 x half>* %1, align 32
  %5 = fadd <16 x half> %3, %4
  ret <16 x half> %5
}

define <16 x half> @p_add_v16f16_f16(<16 x half>* nocapture readonly %0, half* nocapture readonly %1) {
; CHECK-LABEL: p_add_v16f16_f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lhz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r2 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 0[$r0]
; CHECK-NEXT:    copyd $r5 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 63, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r0 = $r0, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r1 = $r4, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r2 = $r2, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r3 = $r3, $r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x half>, <16 x half>* %0, align 32
  %4 = load half, half* %1, align 2
  %5 = insertelement <16 x half> undef, half %4, i32 0
  %6 = shufflevector <16 x half> %5, <16 x half> undef, <16 x i32> zeroinitializer
  %7 = fadd <16 x half> %3, %6
  ret <16 x half> %7
}

define <16 x half> @p_mul_add_v16f16_v16f16(<16 x half>* nocapture readonly %0, <16 x half>* nocapture readonly %1, <16 x half>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v16f16_v16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ld $r3 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r5 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r7 = 24[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r6 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r1 = 8[$r1]
; CHECK-NEXT:    fmulhq $r6 = $r0, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmulhq $r0 = $r4, $r8
; CHECK-NEXT:    ld $r4 = 0[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 16[$r2]
; CHECK-NEXT:    fmulhq $r5 = $r5, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r7 = 24[$r2]
; CHECK-NEXT:    fmulhq $r1 = $r3, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 8[$r2]
; CHECK-NEXT:    faddhq $r0 = $r4, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r4 = $r8, $r6
; CHECK-NEXT:    sd 0[$r2] = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r1 = $r3, $r1
; CHECK-NEXT:    sd 16[$r2] = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddhq $r3 = $r7, $r5
; CHECK-NEXT:    sd 8[$r2] = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 24[$r2] = $r3
; CHECK-NEXT:    copyd $r2 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <16 x half>, <16 x half>* %0, align 32
  %5 = load <16 x half>, <16 x half>* %1, align 32
  %6 = fmul <16 x half> %4, %5
  %7 = load <16 x half>, <16 x half>* %2, align 32
  %8 = fadd <16 x half> %7, %6
  store <16 x half> %8, <16 x half>* %2, align 32
  ret <16 x half> %8
}

define <16 x i16> @p_mul_v16i16_v16i16(<16 x i16>* nocapture readonly %0, <16 x i16>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ld $r3 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 24[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r2 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r7 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r6 = 8[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r5 = 0[$r1]
; CHECK-NEXT:    mulhq $r1 = $r6, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r0 = $r5, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r2 = $r7, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r3 = $r8, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x i16>, <16 x i16>* %0, align 32
  %4 = load <16 x i16>, <16 x i16>* %1, align 32
  %5 = mul <16 x i16> %4, %3
  ret <16 x i16> %5
}

define <16 x i16> @p_mul_v16i16_i16(<16 x i16>* nocapture readonly %0, i16* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lhz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r2 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 0[$r0]
; CHECK-NEXT:    copyd $r5 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 63, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r0 = $r5, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r1 = $r5, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r3 = $r5, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x i16>, <16 x i16>* %0, align 32
  %4 = load i16, i16* %1, align 2
  %5 = insertelement <16 x i16> undef, i16 %4, i32 0
  %6 = shufflevector <16 x i16> %5, <16 x i16> undef, <16 x i32> zeroinitializer
  %7 = mul <16 x i16> %6, %3
  ret <16 x i16> %7
}

define <16 x i16> @p_div_v16i16_v16i16(<16 x i16>* nocapture readonly %0, <16 x i16>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 80[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    ld $r19 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r22 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r21 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r20 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r23 = 24[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r24 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r25 = 8[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r26 = 0[$r1]
; CHECK-NEXT:    extfs $r0 = $r19, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r26, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r26, 15, 0
; CHECK-NEXT:    zxwd $r27 = $r0
; CHECK-NEXT:    extfs $r0 = $r19, 15, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r18 = $r0
; CHECK-NEXT:    extfs $r0 = $r19, 47, 32
; CHECK-NEXT:    extfs $r1 = $r26, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r27, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srad $r1 = $r26, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r19, 48
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfs $r1 = $r25, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r0, 63, 48
; CHECK-NEXT:    extfs $r0 = $r20, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r25, 15, 0
; CHECK-NEXT:    zxwd $r26 = $r0
; CHECK-NEXT:    extfs $r0 = $r20, 15, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r19 = $r0
; CHECK-NEXT:    extfs $r0 = $r20, 47, 32
; CHECK-NEXT:    extfs $r1 = $r25, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r26, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srad $r1 = $r25, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r20, 48
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfs $r1 = $r24, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 63, 48
; CHECK-NEXT:    extfs $r0 = $r21, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r24, 15, 0
; CHECK-NEXT:    zxwd $r25 = $r0
; CHECK-NEXT:    extfs $r0 = $r21, 15, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r20 = $r0
; CHECK-NEXT:    extfs $r0 = $r21, 47, 32
; CHECK-NEXT:    extfs $r1 = $r24, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r25, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srad $r1 = $r24, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r21, 48
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfs $r1 = $r23, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 63, 48
; CHECK-NEXT:    extfs $r0 = $r22, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfs $r1 = $r23, 15, 0
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r22, 15, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r21 = $r0
; CHECK-NEXT:    extfs $r0 = $r22, 47, 32
; CHECK-NEXT:    extfs $r1 = $r23, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 31, 16
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srad $r1 = $r23, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r22, 48
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 48
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    copyd $r2 = $r20
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r21
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x i16>, <16 x i16>* %0, align 32
  %4 = load <16 x i16>, <16 x i16>* %1, align 32
  %5 = sdiv <16 x i16> %3, %4
  ret <16 x i16> %5
}

define <16 x i16> @p_div_v16i16_i16(<16 x i16>* nocapture readonly %0, i16* nocapture readonly %1) {
; CHECK-LABEL: p_div_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -24
; CHECK-NEXT:    .cfi_offset 22, -32
; CHECK-NEXT:    .cfi_offset 21, -40
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -56
; CHECK-NEXT:    .cfi_offset 18, -64
; CHECK-NEXT:    ld $r20 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r23 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r22 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r21 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lhs $r18 = 0[$r1]
; CHECK-NEXT:    extfs $r0 = $r20, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r20, 15, 0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r19 = $r0
; CHECK-NEXT:    extfs $r0 = $r20, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r24, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r20, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 63, 48
; CHECK-NEXT:    extfs $r0 = $r21, 31, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r21, 15, 0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r20 = $r0
; CHECK-NEXT:    extfs $r0 = $r21, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r24, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r21, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 63, 48
; CHECK-NEXT:    extfs $r0 = $r22, 31, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r22, 15, 0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r21 = $r0
; CHECK-NEXT:    extfs $r0 = $r22, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r22, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 48
; CHECK-NEXT:    extfs $r0 = $r23, 31, 16
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfs $r0 = $r23, 15, 0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r22 = $r0
; CHECK-NEXT:    extfs $r0 = $r23, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r24, 31, 16
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 47, 32
; CHECK-NEXT:    srad $r0 = $r23, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 63, 48
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    copyd $r2 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r22
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x i16>, <16 x i16>* %0, align 32
  %4 = load i16, i16* %1, align 2
  %5 = insertelement <16 x i16> undef, i16 %4, i32 0
  %6 = shufflevector <16 x i16> %5, <16 x i16> undef, <16 x i32> zeroinitializer
  %7 = sdiv <16 x i16> %3, %6
  ret <16 x i16> %7
}

define <16 x i16> @p_add_v16i16_v16i16(<16 x i16>* nocapture readonly %0, <16 x i16>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ld $r3 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 24[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r2 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r7 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r6 = 8[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r5 = 0[$r1]
; CHECK-NEXT:    addhq $r1 = $r6, $r4
; CHECK-NEXT:    addhq $r2 = $r7, $r2
; CHECK-NEXT:    addhq $r3 = $r8, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addhq $r0 = $r5, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x i16>, <16 x i16>* %0, align 32
  %4 = load <16 x i16>, <16 x i16>* %1, align 32
  %5 = add <16 x i16> %4, %3
  ret <16 x i16> %5
}

define <16 x i16> @p_add_v16i16_i16(<16 x i16>* nocapture readonly %0, i16* nocapture readonly %1) {
; CHECK-LABEL: p_add_v16i16_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lhz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r2 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 0[$r0]
; CHECK-NEXT:    copyd $r5 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 47, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 63, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addhq $r0 = $r5, $r0
; CHECK-NEXT:    addhq $r1 = $r5, $r4
; CHECK-NEXT:    addhq $r2 = $r5, $r2
; CHECK-NEXT:    addhq $r3 = $r5, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <16 x i16>, <16 x i16>* %0, align 32
  %4 = load i16, i16* %1, align 2
  %5 = insertelement <16 x i16> undef, i16 %4, i32 0
  %6 = shufflevector <16 x i16> %5, <16 x i16> undef, <16 x i32> zeroinitializer
  %7 = add <16 x i16> %6, %3
  ret <16 x i16> %7
}

define <16 x i16> @p_mul_add_v16i16_v16i16(<16 x i16>* nocapture readonly %0, <16 x i16>* nocapture readonly %1, <16 x i16>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v16i16_v16i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ld $r3 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r5 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r7 = 24[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r6 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r1 = 8[$r1]
; CHECK-NEXT:    mulhq $r6 = $r6, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulhq $r0 = $r8, $r4
; CHECK-NEXT:    ld $r4 = 0[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 16[$r2]
; CHECK-NEXT:    mulhq $r5 = $r7, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r7 = 24[$r2]
; CHECK-NEXT:    mulhq $r1 = $r1, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 8[$r2]
; CHECK-NEXT:    addhq $r0 = $r4, $r0
; CHECK-NEXT:    addhq $r4 = $r8, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 16[$r2] = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 0[$r2] = $r0
; CHECK-NEXT:    addhq $r1 = $r3, $r1
; CHECK-NEXT:    addhq $r3 = $r7, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 24[$r2] = $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 8[$r2] = $r1
; CHECK-NEXT:    copyd $r2 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <16 x i16>, <16 x i16>* %0, align 32
  %5 = load <16 x i16>, <16 x i16>* %1, align 32
  %6 = mul <16 x i16> %5, %4
  %7 = load <16 x i16>, <16 x i16>* %2, align 32
  %8 = add <16 x i16> %7, %6
  store <16 x i16> %8, <16 x i16>* %2, align 32
  ret <16 x i16> %8
}

define <32 x i8> @p_mul_v32i8_v32i8(<32 x i8>* nocapture readonly %0, <32 x i8>* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ld $r7 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r2 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r5 = 24[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r8 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r9 = 8[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r6 = 0[$r0]
; CHECK-NEXT:    extfz $r1 = $r7, 15, 8
; CHECK-NEXT:    extfz $r10 = $r7, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r0 = $r6, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r1, $r0
; CHECK-NEXT:    extfz $r0 = $r6, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r10, $r0
; CHECK-NEXT:    extfz $r10 = $r7, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 15, 8
; CHECK-NEXT:    extfz $r1 = $r6, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r10, $r1
; CHECK-NEXT:    extfz $r10 = $r7, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 23, 16
; CHECK-NEXT:    extfz $r1 = $r6, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r10, $r1
; CHECK-NEXT:    extfz $r10 = $r7, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 31, 24
; CHECK-NEXT:    extfz $r1 = $r6, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r10, $r1
; CHECK-NEXT:    extfz $r10 = $r7, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 39, 32
; CHECK-NEXT:    extfz $r1 = $r6, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r10, $r1
; CHECK-NEXT:    extfz $r10 = $r7, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 47, 40
; CHECK-NEXT:    extfz $r1 = $r6, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r10, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 55, 48
; CHECK-NEXT:    srld $r1 = $r6, 56
; CHECK-NEXT:    srld $r6 = $r7, 56
; CHECK-NEXT:    extfz $r7 = $r9, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r6, $r1
; CHECK-NEXT:    extfz $r6 = $r9, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 63, 56
; CHECK-NEXT:    extfz $r1 = $r2, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r6, $r1
; CHECK-NEXT:    extfz $r1 = $r2, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r7, $r1
; CHECK-NEXT:    extfz $r7 = $r9, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r6, 15, 8
; CHECK-NEXT:    extfz $r6 = $r2, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r9, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r6, 23, 16
; CHECK-NEXT:    extfz $r6 = $r2, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r9, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r6, 31, 24
; CHECK-NEXT:    extfz $r6 = $r2, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r9, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r6, 39, 32
; CHECK-NEXT:    extfz $r6 = $r2, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r9, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r6, 47, 40
; CHECK-NEXT:    extfz $r6 = $r2, 55, 48
; CHECK-NEXT:    srld $r2 = $r2, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r8, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r6, 55, 48
; CHECK-NEXT:    srld $r6 = $r9, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r6, $r2
; CHECK-NEXT:    extfz $r6 = $r8, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r2, 63, 56
; CHECK-NEXT:    extfz $r2 = $r3, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r6, $r2
; CHECK-NEXT:    extfz $r2 = $r3, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r7, $r2
; CHECK-NEXT:    extfz $r7 = $r8, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 15, 8
; CHECK-NEXT:    extfz $r6 = $r3, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r8, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 23, 16
; CHECK-NEXT:    extfz $r6 = $r3, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r8, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 31, 24
; CHECK-NEXT:    extfz $r6 = $r3, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r8, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 39, 32
; CHECK-NEXT:    extfz $r6 = $r3, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r8, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 47, 40
; CHECK-NEXT:    extfz $r6 = $r3, 55, 48
; CHECK-NEXT:    srld $r3 = $r3, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r5, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 55, 48
; CHECK-NEXT:    srld $r6 = $r8, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r6, $r3
; CHECK-NEXT:    extfz $r6 = $r5, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r3, 63, 56
; CHECK-NEXT:    extfz $r3 = $r4, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r6, $r3
; CHECK-NEXT:    extfz $r3 = $r4, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r7, $r3
; CHECK-NEXT:    extfz $r7 = $r5, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r6, 15, 8
; CHECK-NEXT:    extfz $r6 = $r4, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r5, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r6, 23, 16
; CHECK-NEXT:    extfz $r6 = $r4, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r5, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r6, 31, 24
; CHECK-NEXT:    extfz $r6 = $r4, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r5, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r6, 39, 32
; CHECK-NEXT:    extfz $r6 = $r4, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r5, 55, 48
; CHECK-NEXT:    srld $r5 = $r5, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r6, 47, 40
; CHECK-NEXT:    extfz $r6 = $r4, 55, 48
; CHECK-NEXT:    srld $r4 = $r4, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r6, 55, 48
; CHECK-NEXT:    mulw $r4 = $r5, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r4, 63, 56
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <32 x i8>, <32 x i8>* %0, align 32
  %4 = load <32 x i8>, <32 x i8>* %1, align 32
  %5 = mul <32 x i8> %4, %3
  ret <32 x i8> %5
}

define <32 x i8> @p_mul_v32i8_i8(<32 x i8>* nocapture readonly %0, i8* nocapture readonly %1) {
; CHECK-LABEL: p_mul_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ld $r2 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r6 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lbz $r5 = 0[$r1]
; CHECK-NEXT:    extfz $r0 = $r2, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r0
; CHECK-NEXT:    extfz $r0 = $r2, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r5, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 15, 8
; CHECK-NEXT:    extfz $r1 = $r2, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 23, 16
; CHECK-NEXT:    extfz $r1 = $r2, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 31, 24
; CHECK-NEXT:    extfz $r1 = $r2, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 39, 32
; CHECK-NEXT:    extfz $r1 = $r2, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 47, 40
; CHECK-NEXT:    extfz $r1 = $r2, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 55, 48
; CHECK-NEXT:    srld $r1 = $r2, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r1, 63, 56
; CHECK-NEXT:    extfz $r1 = $r6, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r5, $r1
; CHECK-NEXT:    extfz $r1 = $r6, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r2, 15, 8
; CHECK-NEXT:    extfz $r2 = $r6, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r2, 23, 16
; CHECK-NEXT:    extfz $r2 = $r6, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r2, 31, 24
; CHECK-NEXT:    extfz $r2 = $r6, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r2, 39, 32
; CHECK-NEXT:    extfz $r2 = $r6, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r2, 47, 40
; CHECK-NEXT:    extfz $r2 = $r6, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r2, 55, 48
; CHECK-NEXT:    srld $r2 = $r6, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r1 = $r2, 63, 56
; CHECK-NEXT:    extfz $r2 = $r3, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r5, $r2
; CHECK-NEXT:    extfz $r2 = $r3, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 15, 8
; CHECK-NEXT:    extfz $r6 = $r3, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r5, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 23, 16
; CHECK-NEXT:    extfz $r6 = $r3, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r5, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 31, 24
; CHECK-NEXT:    extfz $r6 = $r3, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r5, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 39, 32
; CHECK-NEXT:    extfz $r6 = $r3, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r5, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 47, 40
; CHECK-NEXT:    extfz $r6 = $r3, 55, 48
; CHECK-NEXT:    srld $r3 = $r3, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r5, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r6, 55, 48
; CHECK-NEXT:    mulw $r3 = $r5, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r2 = $r3, 63, 56
; CHECK-NEXT:    extfz $r3 = $r4, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r5, $r3
; CHECK-NEXT:    extfz $r3 = $r4, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r3 = $r5, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r6, 15, 8
; CHECK-NEXT:    extfz $r6 = $r4, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r5, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r6, 23, 16
; CHECK-NEXT:    extfz $r6 = $r4, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r5, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r6, 31, 24
; CHECK-NEXT:    extfz $r6 = $r4, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r5, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r6, 39, 32
; CHECK-NEXT:    extfz $r6 = $r4, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r5, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r6, 47, 40
; CHECK-NEXT:    extfz $r6 = $r4, 55, 48
; CHECK-NEXT:    srld $r4 = $r4, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r5, $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r6, 55, 48
; CHECK-NEXT:    mulw $r4 = $r5, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r3 = $r4, 63, 56
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <32 x i8>, <32 x i8>* %0, align 32
  %4 = load i8, i8* %1, align 1
  %5 = insertelement <32 x i8> undef, i8 %4, i32 0
  %6 = shufflevector <32 x i8> %5, <32 x i8> undef, <32 x i32> zeroinitializer
  %7 = mul <32 x i8> %6, %3
  ret <32 x i8> %7
}

define <32 x i8> @p_div_v32i8_v32i8(<32 x i8>* nocapture readonly %0, <32 x i8>* nocapture readonly %1) {
; CHECK-LABEL: p_div_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 96
; CHECK-NEXT:    sd 80[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -16
; CHECK-NEXT:    so 48[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -24
; CHECK-NEXT:    .cfi_offset 26, -32
; CHECK-NEXT:    .cfi_offset 25, -40
; CHECK-NEXT:    .cfi_offset 24, -48
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -56
; CHECK-NEXT:    .cfi_offset 22, -64
; CHECK-NEXT:    .cfi_offset 21, -72
; CHECK-NEXT:    .cfi_offset 20, -80
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -88
; CHECK-NEXT:    .cfi_offset 18, -96
; CHECK-NEXT:    ld $r19 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r22 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r21 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r20 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r23 = 24[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r24 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r25 = 8[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r26 = 0[$r1]
; CHECK-NEXT:    extfz $r0 = $r19, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r26, 15, 8
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r26, 7, 0
; CHECK-NEXT:    zxwd $r27 = $r0
; CHECK-NEXT:    extfz $r0 = $r19, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r18 = $r0
; CHECK-NEXT:    extfz $r0 = $r19, 23, 16
; CHECK-NEXT:    extfz $r1 = $r26, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r27, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r26, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r19, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r26, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r19, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r26, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r19, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r26, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r19, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r26, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r19, 56
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r25, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r18 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r20, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r25, 7, 0
; CHECK-NEXT:    zxwd $r26 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 23, 16
; CHECK-NEXT:    extfz $r1 = $r25, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r26, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r25, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r20, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r25, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r20, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r25, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r20, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r25, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r20, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r25, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r20, 56
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r24, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r21, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r24, 7, 0
; CHECK-NEXT:    zxwd $r25 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 23, 16
; CHECK-NEXT:    extfz $r1 = $r24, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r25, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r24, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r21, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r24, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r21, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r24, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r21, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r24, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r21, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r24, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r21, 56
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r23, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r22, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    extfz $r1 = $r23, 7, 0
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 23, 16
; CHECK-NEXT:    extfz $r1 = $r23, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r24, 15, 8
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r23, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r22, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r23, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r22, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r23, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r22, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    extfz $r1 = $r23, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r22, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    srld $r1 = $r23, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r22, 56
; CHECK-NEXT:    sxbd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 56
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    copyd $r2 = $r20
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r21
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 80[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <32 x i8>, <32 x i8>* %0, align 32
  %4 = load <32 x i8>, <32 x i8>* %1, align 32
  %5 = sdiv <32 x i8> %3, %4
  ret <32 x i8> %5
}

define <32 x i8> @p_div_v32i8_i8(<32 x i8>* nocapture readonly %0, i8* nocapture readonly %1) {
; CHECK-LABEL: p_div_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -8
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 24, -16
; CHECK-NEXT:    so 16[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -24
; CHECK-NEXT:    .cfi_offset 22, -32
; CHECK-NEXT:    .cfi_offset 21, -40
; CHECK-NEXT:    .cfi_offset 20, -48
; CHECK-NEXT:    sq 0[$r12] = $r18r19
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 19, -56
; CHECK-NEXT:    .cfi_offset 18, -64
; CHECK-NEXT:    ld $r20 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r23 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r22 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r21 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lbs $r18 = 0[$r1]
; CHECK-NEXT:    extfz $r0 = $r20, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 7, 0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r19 = $r0
; CHECK-NEXT:    extfz $r0 = $r20, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r19 = $r24, 15, 8
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r20, 31, 24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r20, 39, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r20, 47, 40
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r20, 55, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r20, 56
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r19 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r21, 15, 8
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 7, 0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r20 = $r0
; CHECK-NEXT:    extfz $r0 = $r21, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r20 = $r24, 15, 8
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r21, 31, 24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r21, 39, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r21, 47, 40
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r21, 55, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r21, 56
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r20 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r22, 15, 8
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 7, 0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r21 = $r0
; CHECK-NEXT:    extfz $r0 = $r22, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r21 = $r24, 15, 8
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r22, 31, 24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r22, 39, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r22, 47, 40
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r22, 55, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r22, 56
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r21 = $r0, 63, 56
; CHECK-NEXT:    extfz $r0 = $r23, 15, 8
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r24 = $r0
; CHECK-NEXT:    extfz $r0 = $r23, 7, 0
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r22 = $r0
; CHECK-NEXT:    extfz $r0 = $r23, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    insf $r22 = $r24, 15, 8
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 23, 16
; CHECK-NEXT:    extfz $r0 = $r23, 31, 24
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 31, 24
; CHECK-NEXT:    extfz $r0 = $r23, 39, 32
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 39, 32
; CHECK-NEXT:    extfz $r0 = $r23, 47, 40
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 47, 40
; CHECK-NEXT:    extfz $r0 = $r23, 55, 48
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r23, 56
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxbd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    zxwd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r22 = $r0, 63, 56
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    copyd $r2 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r22
; CHECK-NEXT:    lq $r18r19 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <32 x i8>, <32 x i8>* %0, align 32
  %4 = load i8, i8* %1, align 1
  %5 = insertelement <32 x i8> undef, i8 %4, i32 0
  %6 = shufflevector <32 x i8> %5, <32 x i8> undef, <32 x i32> zeroinitializer
  %7 = sdiv <32 x i8> %3, %6
  ret <32 x i8> %7
}

define <32 x i8> @p_add_v32i8_v32i8(<32 x i8>* nocapture readonly %0, <32 x i8>* nocapture readonly %1) {
; CHECK-LABEL: p_add_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ld $r6 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r2 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r5 = 24[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r7 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r1 = 8[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 0[$r0]
; CHECK-NEXT:    andd $r9 = $r6, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r8 = $r0, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r0 = $r6, $r0
; CHECK-NEXT:    andd $r6 = $r4, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r8 = $r9, $r8
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r0 = $r8, $r0
; CHECK-NEXT:    andd $r8 = $r1, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r1 = $r1, $r4
; CHECK-NEXT:    andd $r4 = $r2, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r6 = $r8, $r6
; CHECK-NEXT:    andd $r1 = $r1, 0x8080808080808080
; CHECK-NEXT:    xord $r2 = $r7, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r1 = $r6, $r1
; CHECK-NEXT:    andd $r6 = $r7, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r4 = $r6, $r4
; CHECK-NEXT:    andd $r6 = $r5, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r2 = $r4, $r2
; CHECK-NEXT:    andd $r4 = $r3, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r3 = $r5, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r4 = $r6, $r4
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <32 x i8>, <32 x i8>* %0, align 32
  %4 = load <32 x i8>, <32 x i8>* %1, align 32
  %5 = add <32 x i8> %4, %3
  ret <32 x i8> %5
}

define <32 x i8> @p_add_v32i8_i8(<32 x i8>* nocapture readonly %0, i8* nocapture readonly %1) {
; CHECK-LABEL: p_add_v32i8_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lbz $r1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r2 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r4 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 0[$r0]
; CHECK-NEXT:    copyd $r5 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r5, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 63, 56
; CHECK-NEXT:    andd $r1 = $r0, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r0 = $r5, $r0
; CHECK-NEXT:    andd $r6 = $r5, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r1 = $r6, $r1
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r0 = $r1, $r0
; CHECK-NEXT:    andd $r1 = $r4, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r4 = $r5, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r1 = $r6, $r1
; CHECK-NEXT:    andd $r4 = $r4, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r1 = $r1, $r4
; CHECK-NEXT:    andd $r4 = $r2, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r2 = $r5, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r4 = $r6, $r4
; CHECK-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r2 = $r4, $r2
; CHECK-NEXT:    andd $r4 = $r3, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r3 = $r5, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r4 = $r6, $r4
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r3 = $r4, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %3 = load <32 x i8>, <32 x i8>* %0, align 32
  %4 = load i8, i8* %1, align 1
  %5 = insertelement <32 x i8> undef, i8 %4, i32 0
  %6 = shufflevector <32 x i8> %5, <32 x i8> undef, <32 x i32> zeroinitializer
  %7 = add <32 x i8> %6, %3
  ret <32 x i8> %7
}

define <32 x i8> @p_mul_add_v32i8_v32i8(<32 x i8>* nocapture readonly %0, <32 x i8>* nocapture readonly %1, <32 x i8>* nocapture %2) {
; CHECK-LABEL: p_mul_add_v32i8_v32i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ld $r8 = 16[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r7 = 16[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 8[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r5 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r6 = 24[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r0 = 8[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r9 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r1 = 24[$r1]
; CHECK-NEXT:    extfz $r4 = $r7, 15, 8
; CHECK-NEXT:    extfz $r10 = $r8, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r10 = $r10, $r4
; CHECK-NEXT:    extfz $r4 = $r7, 7, 0
; CHECK-NEXT:    extfz $r11 = $r8, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r4 = $r11, $r4
; CHECK-NEXT:    extfz $r11 = $r8, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r10, 15, 8
; CHECK-NEXT:    extfz $r10 = $r7, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r10 = $r11, $r10
; CHECK-NEXT:    extfz $r11 = $r8, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r10, 23, 16
; CHECK-NEXT:    extfz $r10 = $r7, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r10 = $r11, $r10
; CHECK-NEXT:    extfz $r11 = $r8, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r10, 31, 24
; CHECK-NEXT:    extfz $r10 = $r7, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r10 = $r11, $r10
; CHECK-NEXT:    extfz $r11 = $r8, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r10, 39, 32
; CHECK-NEXT:    extfz $r10 = $r7, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r10 = $r11, $r10
; CHECK-NEXT:    extfz $r11 = $r8, 55, 48
; CHECK-NEXT:    srld $r8 = $r8, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r10, 47, 40
; CHECK-NEXT:    extfz $r10 = $r7, 55, 48
; CHECK-NEXT:    srld $r7 = $r7, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r10 = $r11, $r10
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r10, 55, 48
; CHECK-NEXT:    mulw $r7 = $r8, $r7
; CHECK-NEXT:    extfz $r8 = $r1, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r4 = $r7, 63, 56
; CHECK-NEXT:    extfz $r7 = $r6, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r7 = $r8, $r7
; CHECK-NEXT:    extfz $r8 = $r6, 7, 0
; CHECK-NEXT:    extfz $r10 = $r1, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r8 = $r10, $r8
; CHECK-NEXT:    extfz $r10 = $r1, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r7, 15, 8
; CHECK-NEXT:    extfz $r7 = $r6, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r7 = $r10, $r7
; CHECK-NEXT:    extfz $r10 = $r1, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r7, 23, 16
; CHECK-NEXT:    extfz $r7 = $r6, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r7 = $r10, $r7
; CHECK-NEXT:    extfz $r10 = $r1, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r7, 31, 24
; CHECK-NEXT:    extfz $r7 = $r6, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r7 = $r10, $r7
; CHECK-NEXT:    extfz $r10 = $r1, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r7, 39, 32
; CHECK-NEXT:    extfz $r7 = $r6, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r7 = $r10, $r7
; CHECK-NEXT:    extfz $r10 = $r1, 55, 48
; CHECK-NEXT:    srld $r1 = $r1, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r7, 47, 40
; CHECK-NEXT:    extfz $r7 = $r6, 55, 48
; CHECK-NEXT:    srld $r6 = $r6, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r7 = $r10, $r7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r7, 55, 48
; CHECK-NEXT:    mulw $r1 = $r1, $r6
; CHECK-NEXT:    extfz $r6 = $r9, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r8 = $r1, 63, 56
; CHECK-NEXT:    extfz $r1 = $r5, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r6, $r1
; CHECK-NEXT:    extfz $r6 = $r5, 7, 0
; CHECK-NEXT:    extfz $r7 = $r9, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r6 = $r7, $r6
; CHECK-NEXT:    extfz $r7 = $r9, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 15, 8
; CHECK-NEXT:    extfz $r1 = $r5, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r7, $r1
; CHECK-NEXT:    extfz $r7 = $r9, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 23, 16
; CHECK-NEXT:    extfz $r1 = $r5, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r7, $r1
; CHECK-NEXT:    extfz $r7 = $r9, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 31, 24
; CHECK-NEXT:    extfz $r1 = $r5, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r7, $r1
; CHECK-NEXT:    extfz $r7 = $r9, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 39, 32
; CHECK-NEXT:    extfz $r1 = $r5, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r7, $r1
; CHECK-NEXT:    extfz $r7 = $r9, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 47, 40
; CHECK-NEXT:    extfz $r1 = $r5, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r7, $r1
; CHECK-NEXT:    extfz $r7 = $r0, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 55, 48
; CHECK-NEXT:    srld $r1 = $r5, 56
; CHECK-NEXT:    srld $r5 = $r9, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    extfz $r5 = $r0, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r6 = $r1, 63, 56
; CHECK-NEXT:    extfz $r1 = $r3, 15, 8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r5, $r1
; CHECK-NEXT:    extfz $r5 = $r3, 7, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r5 = $r7, $r5
; CHECK-NEXT:    extfz $r7 = $r0, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 15, 8
; CHECK-NEXT:    extfz $r1 = $r3, 23, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r7, $r1
; CHECK-NEXT:    extfz $r7 = $r0, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 23, 16
; CHECK-NEXT:    extfz $r1 = $r3, 31, 24
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r7, $r1
; CHECK-NEXT:    extfz $r7 = $r0, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 31, 24
; CHECK-NEXT:    extfz $r1 = $r3, 39, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r7, $r1
; CHECK-NEXT:    extfz $r7 = $r0, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 39, 32
; CHECK-NEXT:    extfz $r1 = $r3, 47, 40
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r7, $r1
; CHECK-NEXT:    extfz $r7 = $r0, 55, 48
; CHECK-NEXT:    srld $r0 = $r0, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 47, 40
; CHECK-NEXT:    extfz $r1 = $r3, 55, 48
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r1 = $r7, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r1, 55, 48
; CHECK-NEXT:    srld $r1 = $r3, 56
; CHECK-NEXT:    ;;
; CHECK-NEXT:    mulw $r0 = $r0, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r0, 63, 56
; CHECK-NEXT:    ld $r0 = 8[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r9 = 0[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r3 = 24[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r7 = 16[$r2]
; CHECK-NEXT:    andd $r1 = $r5, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    andd $r10 = $r0, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r0 = $r0, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    andd $r5 = $r9, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    addd $r1 = $r10, $r1
; CHECK-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r1 = $r1, $r0
; CHECK-NEXT:    andd $r0 = $r6, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r0 = $r5, $r0
; CHECK-NEXT:    xord $r5 = $r9, $r6
; CHECK-NEXT:    andd $r6 = $r3, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r3 = $r3, $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 8[$r2] = $r1
; CHECK-NEXT:    andd $r5 = $r5, 0x8080808080808080
; CHECK-NEXT:    andd $r3 = $r3, 0x8080808080808080
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r0 = $r0, $r5
; CHECK-NEXT:    andd $r5 = $r8, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r5 = $r6, $r5
; CHECK-NEXT:    andd $r6 = $r7, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    sd 0[$r2] = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r3 = $r5, $r3
; CHECK-NEXT:    andd $r5 = $r4, 0x7f7f7f7f7f7f7f7f
; CHECK-NEXT:    xord $r4 = $r7, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r5 = $r6, $r5
; CHECK-NEXT:    andd $r4 = $r4, 0x8080808080808080
; CHECK-NEXT:    sd 24[$r2] = $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    xord $r4 = $r5, $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 16[$r2] = $r4
; CHECK-NEXT:    copyd $r2 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %4 = load <32 x i8>, <32 x i8>* %0, align 32
  %5 = load <32 x i8>, <32 x i8>* %1, align 32
  %6 = mul <32 x i8> %5, %4
  %7 = load <32 x i8>, <32 x i8>* %2, align 32
  %8 = add <32 x i8> %7, %6
  store <32 x i8> %8, <32 x i8>* %2, align 32
  ret <32 x i8> %8
}

define <4 x i64> @fbnsigned_long_4__division_imm(<4 x i64> %a) {
; CHECK-LABEL: fbnsigned_long_4__division_imm:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r12 = $r12, -160
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 160
; CHECK-NEXT:    sd 72[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 67, -88
; CHECK-NEXT:    so 40[$r12] = $r24r25r26r27
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 27, -96
; CHECK-NEXT:    .cfi_offset 26, -104
; CHECK-NEXT:    .cfi_offset 25, -112
; CHECK-NEXT:    .cfi_offset 24, -120
; CHECK-NEXT:    so 8[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 23, -128
; CHECK-NEXT:    .cfi_offset 22, -136
; CHECK-NEXT:    .cfi_offset 21, -144
; CHECK-NEXT:    .cfi_offset 20, -152
; CHECK-NEXT:    sd 0[$r12] = $r18
; CHECK-NEXT:    copyd $r23 = $r3
; CHECK-NEXT:    copyd $r22 = $r2
; CHECK-NEXT:    copyd $r21 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_offset 18, -160
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    so 96[$r12] = $r20r21r22r23
; CHECK-NEXT:    make $r18 = 3
; CHECK-NEXT:    copyd $r0 = $r21
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r25 = $r0
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    call __divdi3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r27 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    so 128[$r12] = $r24r25r26r27
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r25
; CHECK-NEXT:    copyd $r2 = $r26
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r3 = $r27
; CHECK-NEXT:    ld $r18 = 0[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r20r21r22r23 = 8[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lo $r24r25r26r27 = 40[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 72[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 160
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %a.addr = alloca <4 x i64>, align 32
  %s = alloca <4 x i64>, align 32
  store <4 x i64> %a, <4 x i64>* %a.addr, align 32
  %0 = load <4 x i64>, <4 x i64>* %a.addr, align 32
  %div = sdiv <4 x i64> %0, <i64 3, i64 3, i64 3, i64 3>
  store <4 x i64> %div, <4 x i64>* %s, align 32
  %1 = load <4 x i64>, <4 x i64>* %s, align 32
  ret <4 x i64> %1
}
