; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s | FileCheck %s
target triple = "kvx-kalray-cos"

declare <256 x i1> @llvm.kvx.movetohi(<256 x i1>, i64, i64)
define void @test_movetohi(i64 %a, i64 %b, <256 x i1>* %p0, <256 x i1>* %p1) {
; CHECK-LABEL: test_movetohi:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lv $a0 = 0[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a1 = 0[$r3]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    movetq $a1_hi = $r0, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    movetq $a0_hi = $r1, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r2] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r3] = $a1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = load <256 x i1>, <256 x i1>* %p1
  %v2 = tail call <256 x i1> @llvm.kvx.movetohi(<256 x i1> %v1, i64 %a, i64 %b)
  %v3 = tail call <256 x i1> @llvm.kvx.movetohi(<256 x i1> %v0, i64 %b, i64 %a)
  store <256 x i1> %v3, <256 x i1>* %p0, align 32
  store <256 x i1> %v2, <256 x i1>* %p1, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.movetolo(<256 x i1>, i64, i64)
define void @test_movetolo(i64 %a, i64 %b, <256 x i1>* %p0, <256 x i1>* %p1) {
; CHECK-LABEL: test_movetolo:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lv $a0 = 0[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a1 = 0[$r3]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    movetq $a1_lo = $r0, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    movetq $a0_lo = $r1, $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r2] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r3] = $a1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = load <256 x i1>, <256 x i1>* %p1
  %v2 = tail call <256 x i1> @llvm.kvx.movetolo(<256 x i1> %v1, i64 %a, i64 %b)
  %v3 = tail call <256 x i1> @llvm.kvx.movetolo(<256 x i1> %v0, i64 %b, i64 %a)
  store <256 x i1> %v3, <256 x i1>* %p0, align 32
  store <256 x i1> %v2, <256 x i1>* %p1, align 32
  ret void
}

define void @test_movetohilo(i64 %a, i64 %b, i64 %c, i64 %d, <256 x i1>* %p0) {
; CHECK-LABEL: test_movetohilo:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movetq $a0_lo = $r0, $r1
; CHECK-NEXT:    movetq $a0_hi = $r2, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r4] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v1 = tail call <256 x i1> @llvm.kvx.movetolo(<256 x i1> undef, i64 %a, i64 %b)
  %v2 = tail call <256 x i1> @llvm.kvx.movetohi(<256 x i1> %v1, i64 %c, i64 %d)
  store <256 x i1> %v2, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.moveto(i64, i64, i64, i64)
define void @test_moveto(i64 %a, i64 %b, i64 %c, i64 %d, <256 x i1>* %p0, <256 x i1>* %p1){
; CHECK-LABEL: test_moveto:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movetq $a0_lo = $r2, $r3
; CHECK-NEXT:    movetq $a0_hi = $r0, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    movetq $a1_lo = $r1, $r0
; CHECK-NEXT:    movetq $a1_hi = $r3, $r2
; CHECK-NEXT:    sv 0[$r4] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r5] = $a1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v1 = tail call <256 x i1> @llvm.kvx.moveto( i64 %a, i64 %b, i64 %c, i64 %d)
  %v2 = tail call <256 x i1> @llvm.kvx.moveto( i64 %d, i64 %c, i64 %b, i64 %a)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  store <256 x i1> %v2, <256 x i1>* %p1, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.moveoto(<4 x i64>)
define void @test_moveoto(<4 x i64> %r, <256 x i1>* %p0){
; CHECK-LABEL: test_moveoto:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movetq $a0_lo = $r0, $r1
; CHECK-NEXT:    movetq $a0_hi = $r2, $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r4] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = tail call <256 x i1> @llvm.kvx.moveoto(<4 x i64> %r)
  store <256 x i1> %v0, <256 x i1>* %p0, align 32
  ret void
}

declare <4 x i64> @llvm.kvx.movefo(<256 x i1>)
define <4 x i64> @test_movefo(<256 x i1>* %p0){
; CHECK-LABEL: test_movefo:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    movefo $r0r1r2r3 = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = tail call <4 x i64> @llvm.kvx.movefo(<256 x i1> %v0)
  ret <4 x i64> %v1
}

declare <4 x i64> @llvm.kvx.alignov(<256 x i1>, <256 x i1>, i64)
define <4 x i64> @test_alignovi(<256 x i1>* %p0, <256 x i1>* %p1){
; CHECK-LABEL: test_alignovi:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    aligno $r0r1r2r3 = $a0, $a1, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = load <256 x i1>, <256 x i1>* %p1
  %v2 = tail call <4 x i64> @llvm.kvx.alignov(<256 x i1> %v0, <256 x i1> %v1, i64 16)
  ret <4 x i64> %v2
}

define <4 x i64> @test_alignovr(<256 x i1>* %p0, <256 x i1>* %p1, i64 %s){
; CHECK-LABEL: test_alignovr:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    aligno $r0r1r2r3 = $a0, $a1, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = load <256 x i1>, <256 x i1>* %p1
  %v2 = tail call <4 x i64> @llvm.kvx.alignov(<256 x i1> %v0, <256 x i1> %v1, i64 %s)
  ret <4 x i64> %v2
}

declare <256 x i1> @llvm.kvx.alignv(<256 x i1>, <256 x i1>, i64 immarg)
define void @test_alignvi(<256 x i1>* %p0, <256 x i1>* %p1){
; CHECK-LABEL: test_alignvi:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    alignv $a0 = $a0, $a1, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = load <256 x i1>, <256 x i1>* %p1
  %v2 = tail call <256 x i1> @llvm.kvx.alignv(<256 x i1> %v0, <256 x i1> %v1, i64 16)
  store <256 x i1> %v2, <256 x i1>* %p0, align 32
  ret void
}

define void @test_alignvr(<256 x i1>* %p0, <256 x i1>* %p1, i64 %s){
; CHECK-LABEL: test_alignvr:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a1 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    alignv $a0 = $a0, $a1, $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = load <256 x i1>, <256 x i1>* %p1
  %v2 = tail call <256 x i1> @llvm.kvx.alignv(<256 x i1> %v0, <256 x i1> %v1, i64 %s)
  store <256 x i1> %v2, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.convdhv0(<256 x i1>, <1024 x i1>, i32, i32)
define void @test_convdhv0(<256 x i1>* %p0, <1024 x i1>* %p1){
; CHECK-LABEL: test_convdhv0:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a1 = 32[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a2 = 64[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a3 = 96[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    convdhv0.rhu.satu $a0_lo = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m0 = load <1024 x i1>, <1024 x i1>* %p1
  %v1 = tail call <256 x i1> @llvm.kvx.convdhv0(<256 x i1> undef, <1024 x i1> %m0, i32 4, i32 1)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.convdhv1(<256 x i1>, <1024 x i1>, i32, i32)
define void @test_convdhv1(<256 x i1>* %p0, <1024 x i1>* %p1){
; CHECK-LABEL: test_convdhv1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a1 = 32[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a2 = 64[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a3 = 96[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    convdhv1.rz.satu $a0_hi = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m0 = load <1024 x i1>, <1024 x i1>* %p1
  %v1 = tail call <256 x i1> @llvm.kvx.convdhv1(<256 x i1> undef, <1024 x i1> %m0, i32 3, i32 1)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.convdhv(<1024 x i1>, i32, i32)
define void @test_convdhv(<256 x i1>* %p0, <1024 x i1>* %p1){
; CHECK-LABEL: test_convdhv:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a1 = 32[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a2 = 64[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a3 = 96[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    convdhv1.rd.sat $a4_hi = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    convdhv0.rd.sat $a4_lo = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m0 = load <1024 x i1>, <1024 x i1>* %p1
  %v1 = tail call <256 x i1> @llvm.kvx.convdhv(<1024 x i1> %m0, i32 2, i32 0)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.convwbv0(<256 x i1>, <1024 x i1>, i32, i32)
define void @test_convwbv0(<256 x i1>* %p0){
; CHECK-LABEL: test_convwbv0:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    convwbv0.rn.sat $a0_x = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = tail call <256 x i1> @llvm.kvx.convwbv0(<256 x i1> %v0, <1024 x i1> undef, i32 0, i32 0)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.convwbv1(<256 x i1>, <1024 x i1>, i32, i32)
define void @test_convwbv1(<256 x i1>* %p0){
; CHECK-LABEL: test_convwbv1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    convwbv1.ru.satu $a0_y = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = tail call <256 x i1> @llvm.kvx.convwbv1(<256 x i1> %v0, <1024 x i1> undef, i32 1, i32 1)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.convwbv2(<256 x i1>, <1024 x i1>, i32, i32)
define void @test_convwbv2(<256 x i1>* %p0){
; CHECK-LABEL: test_convwbv2:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    convwbv2.rd.sat $a0_z = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = tail call <256 x i1> @llvm.kvx.convwbv2(<256 x i1> %v0, <1024 x i1> undef, i32 2, i32 0)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.convwbv3(<256 x i1>, <1024 x i1>, i32, i32)
define void @test_convwbv3(<256 x i1>* %p0){
; CHECK-LABEL: test_convwbv3:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    convwbv3.rz.sat $a0_t = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = tail call <256 x i1> @llvm.kvx.convwbv3(<256 x i1> %v0, <1024 x i1> undef, i32 3, i32 0)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.convwbv(<1024 x i1>, i32, i32)
define void @test_convwbv(<256 x i1>* %p0){
; CHECK-LABEL: test_convwbv:
; CHECK:       # %bb.0:
; CHECK-NEXT:    convwbv3.rhu.sat $a0_t = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    convwbv2.rhu.sat $a0_z = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    convwbv1.rhu.sat $a0_y = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    convwbv0.rhu.sat $a0_x = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v1 = tail call <256 x i1> @llvm.kvx.convwbv(<1024 x i1> undef, i32 4, i32 0)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.fmma242hw0(<256 x i1>, <512 x i1>, <256 x i1>, <256 x i1>)
define void @test_fmma242hw0(<256 x i1>* %p0){
; CHECK-LABEL: test_fmma242hw0:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmma242hw0 $a0_lo = $a0a1, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = tail call <256 x i1> @llvm.kvx.fmma242hw0(<256 x i1> %v0, <512 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.fmma242hw1(<256 x i1>, <512 x i1>, <256 x i1>, <256 x i1>)
define void @test_fmma242hw1(<256 x i1>* %p0){
; CHECK-LABEL: test_fmma242hw1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a0 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmma242hw1 $a0_hi = $a0a1, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = tail call <256 x i1> @llvm.kvx.fmma242hw1(<256 x i1> %v0, <512 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.fmma242hw2(<256 x i1>, <512 x i1>, <256 x i1>, <256 x i1>)
define void @test_fmma242hw2(<256 x i1>* %p0){
; CHECK-LABEL: test_fmma242hw2:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a1 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmma242hw2 $a1_lo = $a0a1, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = tail call <256 x i1> @llvm.kvx.fmma242hw2(<256 x i1> %v0, <512 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.fmma242hw3(<256 x i1>, <512 x i1>, <256 x i1>, <256 x i1>)
define void @test_fmma242hw3(<256 x i1>* %p0){
; CHECK-LABEL: test_fmma242hw3:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lv $a1 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmma242hw3 $a1_hi = $a0a1, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v0 = load <256 x i1>, <256 x i1>* %p0
  %v1 = tail call <256 x i1> @llvm.kvx.fmma242hw3(<256 x i1> %v0, <512 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <256 x i1> %v1, <256 x i1>* %p0, align 32
  ret void
}

declare <512 x i1> @llvm.kvx.fmma242hw(<512 x i1>, <256 x i1>, <256 x i1>)
define void @test_fmma242hw(<512 x i1>* %p0){
; CHECK-LABEL: test_fmma242hw:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmma242hw3 $a1_hi = $a0a1, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmma242hw2 $a1_lo = $a0a1, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmma242hw1 $a0_hi = $a0a1, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fmma242hw0 $a0_lo = $a0a1, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v1 = tail call <512 x i1> @llvm.kvx.fmma242hw(<512 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <512 x i1> %v1, <512 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mma444hbd0(<1024 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma444hbd0(<1024 x i1>* %p0){
; CHECK-LABEL: test_mma444hbd0:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma444hbd0 $a0a1a2a3 = $a0a1a2a3, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mma444hbd0(<1024 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mma444hbd1(<1024 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma444hbd1(<1024 x i1>* %p0){
; CHECK-LABEL: test_mma444hbd1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma444hbd1 $a0a1a2a3 = $a0a1a2a3, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mma444hbd1(<1024 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mma444hd(<1024 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma444hd(<1024 x i1>* %p0){
; CHECK-LABEL: test_mma444hd:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma444hd $a0a1a2a3 = $a0a1a2a3, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mma444hd(<1024 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mma444suhbd0(<1024 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma444suhbd0(<1024 x i1>* %p0){
; CHECK-LABEL: test_mma444suhbd0:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma444suhbd0 $a0a1a2a3 = $a0a1a2a3, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mma444suhbd0(<1024 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mma444suhbd1(<1024 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma444suhbd1(<1024 x i1>* %p0){
; CHECK-LABEL: test_mma444suhbd1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma444suhbd1 $a0a1a2a3 = $a0a1a2a3, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mma444suhbd1(<1024 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mma444suhd(<1024 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma444suhd(<1024 x i1>* %p0){
; CHECK-LABEL: test_mma444suhd:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma444suhd $a0a1a2a3 = $a0a1a2a3, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mma444suhd(<1024 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mma444uhbd0(<1024 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma444uhbd0(<1024 x i1>* %p0){
; CHECK-LABEL: test_mma444uhbd0:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma444uhbd0 $a0a1a2a3 = $a0a1a2a3, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mma444uhbd0(<1024 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mma444uhbd1(<1024 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma444uhbd1(<1024 x i1>* %p0){
; CHECK-LABEL: test_mma444uhbd1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma444uhbd1 $a0a1a2a3 = $a0a1a2a3, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mma444uhbd1(<1024 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mma444uhd(<1024 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma444uhd(<1024 x i1>* %p0){
; CHECK-LABEL: test_mma444uhd:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma444uhd $a0a1a2a3 = $a0a1a2a3, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mma444uhd(<1024 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mma444ushbd0(<1024 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma444ushbd0(<1024 x i1>* %p0){
; CHECK-LABEL: test_mma444ushbd0:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma444ushbd0 $a0a1a2a3 = $a0a1a2a3, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mma444ushbd0(<1024 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mma444ushbd1(<1024 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma444ushbd1(<1024 x i1>* %p0){
; CHECK-LABEL: test_mma444ushbd1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma444ushbd1 $a0a1a2a3 = $a0a1a2a3, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mma444ushbd1(<1024 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mma444ushd(<1024 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma444ushd(<1024 x i1>* %p0){
; CHECK-LABEL: test_mma444ushd:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma444ushd $a0a1a2a3 = $a0a1a2a3, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mma444ushd(<1024 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <512 x i1> @llvm.kvx.mma484bw(<512 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma484bw(<512 x i1>* %p0){
; CHECK-LABEL: test_mma484bw:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma484bw $a0a1 = $a0a1, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <512 x i1> @llvm.kvx.mma484bw(<512 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <512 x i1> %m1, <512 x i1>* %p0, align 32
  ret void
}

declare <512 x i1> @llvm.kvx.mma484subw(<512 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma484subw(<512 x i1>* %p0){
; CHECK-LABEL: test_mma484subw:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma484subw $a0a1 = $a0a1, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <512 x i1> @llvm.kvx.mma484subw(<512 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <512 x i1> %m1, <512 x i1>* %p0, align 32
  ret void
}

declare <512 x i1> @llvm.kvx.mma484ubw(<512 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma484ubw(<512 x i1>* %p0){
; CHECK-LABEL: test_mma484ubw:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma484ubw $a0a1 = $a0a1, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <512 x i1> @llvm.kvx.mma484ubw(<512 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <512 x i1> %m1, <512 x i1>* %p0, align 32
  ret void
}

declare <512 x i1> @llvm.kvx.mma484usbw(<512 x i1>, <256 x i1>, <256 x i1>)
define void @test_mma484usbw(<512 x i1>* %p0){
; CHECK-LABEL: test_mma484usbw:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mma484usbw $a0a1 = $a0a1, $a0, $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <512 x i1> @llvm.kvx.mma484usbw(<512 x i1> undef, <256 x i1> undef, <256 x i1> undef)
  store <512 x i1> %m1, <512 x i1>* %p0, align 32
  ret void
}

declare <1024 x i1> @llvm.kvx.mt44d(<1024 x i1>)
define void @test_mt44d(<1024 x i1>* %p0){
; CHECK-LABEL: test_mt44d:
; CHECK:       # %bb.0:
; CHECK-NEXT:    mt44d $a0a1a2a3 = $a0a1a2a3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r0] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r0] = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r0] = $a3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <1024 x i1> @llvm.kvx.mt44d(<1024 x i1> undef)
  store <1024 x i1> %m1, <1024 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.fscalewv(<256 x i1>, i32, i32, i32)
define void @test_fscalewv(<256 x i1>* %p0){
; CHECK-LABEL: test_fscalewv:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fscalewv.rn $a0 = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <256 x i1> @llvm.kvx.fscalewv(<256 x i1> undef, i32 0, i32 0, i32 0)
  store <256 x i1> %m1, <256 x i1>* %p0, align 32
  ret void
}

declare <256 x i1> @llvm.kvx.fnarrowwhv(<512 x i1>, i32, i32)
define void @test_fnarrowwhv(<256 x i1>* %p0){
; CHECK-LABEL: test_fnarrowwhv:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fnarrowwhv.rn $a0 = $a0a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r0] = $a0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %m1 = tail call <256 x i1> @llvm.kvx.fnarrowwhv(<512 x i1> undef, i32 0, i32 0)
  store <256 x i1> %m1, <256 x i1>* %p0, align 32
  ret void
}
