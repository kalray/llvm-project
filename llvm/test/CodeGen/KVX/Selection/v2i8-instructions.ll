; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mcpu=kv3-1 -O2 -o - %s | FileCheck %s --check-prefixes=ALL,V1
; RUN: llc -mcpu=kv3-2 -O2 -o - %s | FileCheck %s --check-prefixes=ALL,V2
; RUN: clang -O2 -c -o /dev/null %s
; RUN: clang -O2 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define <2 x i8> @test_ret_const() #0 {
; ALL-LABEL: test_ret_const:
; ALL:       # %bb.0:
; ALL-NEXT:    make $r0 = 513
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  ret <2 x i8> <i8 1, i8 2>
}

define i8 @test_extract_0(<2 x i8> %a) #0 {
; ALL-LABEL: test_extract_0:
; ALL:       # %bb.0:
; ALL-NEXT:    zxbd $r0 = $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %e = extractelement <2 x i8> %a, i8 0
  ret i8 %e
}

define i8 @test_extract_1(<2 x i8> %a) #0 {
; ALL-LABEL: test_extract_1:
; ALL:       # %bb.0:
; ALL-NEXT:    extfz $r0 = $r0, 15, 8
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %e = extractelement <2 x i8> %a, i8 1
  ret i8 %e
}

define i8 @test_extract_i(<2 x i8> %a, i64 %idx) #0 {
; ALL-LABEL: test_extract_i:
; ALL:       # %bb.0:
; ALL-NEXT:    sllw $r1 = $r1, 3
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    srlw $r0 = $r0, $r1
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    zxbd $r0 = $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 2)
  %e = extractelement <2 x i8> %a, i64 %idx
  ret i8 %e
}

define <2 x i8> @test_add(<2 x i8> %a, <2 x i8> %b) #0 {
; V1-LABEL: test_add:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_add:
; V2:       # %bb.0:
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = add <2 x i8> %a, %b
  ret <2 x i8> %r
}

define <2 x i8> @test_add_imm_0(<2 x i8> %a) #0 {
; V1-LABEL: test_add_imm_0:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    addhq $r0 = $r0, 0x20001
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_add_imm_0:
; V2:       # %bb.0:
; V2-NEXT:    addbo $r0 = $r0, 513
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = add <2 x i8> <i8 1, i8 2>, %a
  ret <2 x i8> %r
}

define <2 x i8> @test_add_imm_1(<2 x i8> %a) #0 {
; V1-LABEL: test_add_imm_1:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    addhq $r0 = $r0, 0x20001
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_add_imm_1:
; V2:       # %bb.0:
; V2-NEXT:    addbo $r0 = $r0, 513
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = add <2 x i8> %a, <i8 1, i8 2>
  ret <2 x i8> %r
}

define <2 x i8> @test_sub(<2 x i8> %a, <2 x i8> %b) #0 {
; V1-LABEL: test_sub:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sbfhq $r0 = $r1, $r0
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_sub:
; V2:       # %bb.0:
; V2-NEXT:    sbfbo $r0 = $r1, $r0
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = sub <2 x i8> %a, %b
  ret <2 x i8> %r
}

define <2 x i8> @test_sub_imm(<2 x i8> %a) #0 {
; V1-LABEL: test_sub_imm:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    addhq $r0 = $r0, 0xfffeffff
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_sub_imm:
; V2:       # %bb.0:
; V2-NEXT:    addbo $r0 = $r0, -257
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = sub <2 x i8> %a, <i8 1, i8 2>
  ret <2 x i8> %r
}

define <2 x i8> @test_sub_fromimm(<2 x i8> %a) #0 {
; V1-LABEL: test_sub_fromimm:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sbfhq $r0 = $r0, 0x20001
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_sub_fromimm:
; V2:       # %bb.0:
; V2-NEXT:    sbfbo $r0 = $r0, 513
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = sub <2 x i8> <i8 1, i8 2>, %a
  ret <2 x i8> %r
}


define <2 x i8> @test_fma(<2 x i8> %a, <2 x i8> %b, <2 x i8> %c) #0 {
; V1-LABEL: test_fma:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    sxlbhq $r2 = $r2
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    maddhq $r0 = $r1, $r2
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 4)
;
; V2-LABEL: test_fma:
; V2:       # %bb.0:
; V2-NEXT:    sxlbhq $r1 = $r1
; V2-NEXT:    sxlbhq $r2 = $r2
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    mulhq $r1 = $r1, $r2
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    sbmm8 $r1 = $r1, 0x401
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 4)
  %m = mul <2 x i8> %b, %c
  %ad = add <2 x i8> %a, %m
  ret <2 x i8> %ad
}

; TODO: V2 version is slower, need pattern for it
define <2 x i8> @test_fma_imm(<2 x i8> %a, <2 x i8> %b) #0 {
; V1-LABEL: test_fma_imm:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    maddhq $r0 = $r1, 0x20005
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 3)
;
; V2-LABEL: test_fma_imm:
; V2:       # %bb.0:
; V2-NEXT:    sxlbhq $r1 = $r1
; V2-NEXT:    make $r2 = 0x20005
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    mulhq $r1 = $r1, $r2
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    sbmm8 $r1 = $r1, 0x401
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 4)
  %m = mul <2 x i8> <i8 5, i8 2>, %b
  %ad = add <2 x i8> %a, %m
  ret <2 x i8> %ad
}

; TODO: V2 version is slower, need pattern for it
define <2 x i8> @test_fma_imm_2(<2 x i8> %a, <2 x i8> %b) #0 {
; V1-LABEL: test_fma_imm_2:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    maddhq $r0 = $r1, 0x20001
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 3)
;
; V2-LABEL: test_fma_imm_2:
; V2:       # %bb.0:
; V2-NEXT:    sxlbhq $r1 = $r1
; V2-NEXT:    make $r2 = 0x20001
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    mulhq $r1 = $r1, $r2
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    sbmm8 $r1 = $r1, 0x401
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 4)
  %m = mul <2 x i8> <i8 1, i8 2>, %b
  %ad = add <2 x i8> %a, %m
  ret <2 x i8> %ad
}

define <2 x i8> @test_neg(<2 x i8> %a) #0 {
; V1-LABEL: test_neg:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    neghq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_neg:
; V2:       # %bb.0:
; V2-NEXT:    negbo $r0 = $r0
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = sub <2 x i8> <i8 0, i8 0>, %a
  ret <2 x i8> %r
}

define <2 x i8> @test_mul(<2 x i8> %a, <2 x i8> %b) #0 {
; ALL-LABEL: test_mul:
; ALL:       # %bb.0:
; ALL-NEXT:    sxlbhq $r0 = $r0
; ALL-NEXT:    sxlbhq $r1 = $r1
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    mulhq $r0 = $r0, $r1
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x401
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 3)
  %r = mul <2 x i8> %a, %b
  ret <2 x i8> %r
}

define <2 x i8> @test_mul_2(<2 x i8> %a, <2 x i8> %b, <2 x i8> %c) #0 {
; ALL-LABEL: test_mul_2:
; ALL:       # %bb.0:
; ALL-NEXT:    sxlbhq $r0 = $r0
; ALL-NEXT:    sxlbhq $r1 = $r1
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    mulhq $r0 = $r0, $r1
; ALL-NEXT:    sxlbhq $r1 = $r2
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    mulhq $r0 = $r0, $r1
; ALL-NEXT:    ;; # (end cycle 3)
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x401
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 5)
  %r = mul <2 x i8> %a, %b
  %r1 = mul <2 x i8> %r, %c
  ret <2 x i8> %r1
}

define <2 x i8> @test_div(<2 x i8> %a, <2 x i8> %b) #0 {
; ALL-LABEL: test_div:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    sd 16[$r12] = $r20
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    sq 0[$r12] = $r18r19
; ALL-NEXT:    copyd $r18 = $r1
; ALL-NEXT:    copyd $r19 = $r0
; ALL-NEXT:    ;; # (end cycle 3)
; ALL-NEXT:    extfz $r0 = $r19, 15, 8
; ALL-NEXT:    extfz $r1 = $r18, 15, 8
; ALL-NEXT:    ;; # (end cycle 4)
; ALL-NEXT:    sxbd $r0 = $r0
; ALL-NEXT:    sxbd $r1 = $r1
; ALL-NEXT:    call __divsi3
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    zxbd $r0 = $r19
; ALL-NEXT:    zxbd $r1 = $r18
; ALL-NEXT:    copyd $r20 = $r0
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sxbd $r0 = $r0
; ALL-NEXT:    sxbd $r1 = $r1
; ALL-NEXT:    call __divsi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    lq $r18r19 = 0[$r12]
; ALL-NEXT:    insf $r0 = $r20, 15, 8
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    ld $r20 = 16[$r12]
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 7)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = sdiv <2 x i8> %a, %b
  ret <2 x i8> %r
}

define <2 x i8> @test_rem(<2 x i8> %a, <2 x i8> %b) #0 {
; ALL-LABEL: test_rem:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    sd 16[$r12] = $r20
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    sq 0[$r12] = $r18r19
; ALL-NEXT:    copyd $r18 = $r1
; ALL-NEXT:    copyd $r19 = $r0
; ALL-NEXT:    ;; # (end cycle 3)
; ALL-NEXT:    extfz $r0 = $r19, 15, 8
; ALL-NEXT:    extfz $r1 = $r18, 15, 8
; ALL-NEXT:    ;; # (end cycle 4)
; ALL-NEXT:    sxbd $r0 = $r0
; ALL-NEXT:    sxbd $r1 = $r1
; ALL-NEXT:    call __modsi3
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    zxbd $r0 = $r19
; ALL-NEXT:    zxbd $r1 = $r18
; ALL-NEXT:    copyd $r20 = $r0
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sxbd $r0 = $r0
; ALL-NEXT:    sxbd $r1 = $r1
; ALL-NEXT:    call __modsi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    lq $r18r19 = 0[$r12]
; ALL-NEXT:    insf $r0 = $r20, 15, 8
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    ld $r20 = 16[$r12]
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 7)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = srem <2 x i8> %a, %b
  ret <2 x i8> %r
}

define void @test_ldst_v2i8(<2 x i8>* %a, <2 x i8>* %b) {
; ALL-LABEL: test_ldst_v2i8:
; ALL:       # %bb.0:
; ALL-NEXT:    lhz $r0 = 0[$r0]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sh 0[$r1] = $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 2)
  %t1 = load <2 x i8>, <2 x i8>* %a
  store <2 x i8> %t1, <2 x i8>* %b, align 16
  ret void
}

declare <2 x i8> @test_callee(<2 x i8> %a, <2 x i8> %b) #0

define <2 x i8> @test_call(<2 x i8> %a, <2 x i8> %b) #0 {
; ALL-LABEL: test_call:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call test_callee
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = call <2 x i8> @test_callee(<2 x i8> %a, <2 x i8> %b)
  ret <2 x i8> %r
}

; TODO: Remove unecessary copyd for performing a swap
define <2 x i8> @test_call_flipped(<2 x i8> %a, <2 x i8> %b) #0 {
; ALL-LABEL: test_call_flipped:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    copyd $r0 = $r1
; ALL-NEXT:    copyd $r1 = $r0
; ALL-NEXT:    call test_callee
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = call <2 x i8> @test_callee(<2 x i8> %b, <2 x i8> %a)
  ret <2 x i8> %r
}

define <2 x i8> @test_tailcall_flipped(<2 x i8> %a, <2 x i8> %b) #0 {
; ALL-LABEL: test_tailcall_flipped:
; ALL:       # %bb.0:
; ALL-NEXT:    copyd $r0 = $r1
; ALL-NEXT:    copyd $r1 = $r0
; ALL-NEXT:    goto test_callee
; ALL-NEXT:    ;; # (end cycle 0)
  %r = tail call <2 x i8> @test_callee(<2 x i8> %b, <2 x i8> %a)
  ret <2 x i8> %r
}

define <2 x i8> @test_select(<2 x i8> %a, <2 x i8> %b, i1 zeroext %c) #0 {
; ALL-LABEL: test_select:
; ALL:       # %bb.0:
; ALL-NEXT:    cmoved.even $r2 ? $r0 = $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = select i1 %c, <2 x i8> %a, <2 x i8> %b
  ret <2 x i8> %r
}

define <2 x i8> @test_select_cc(<2 x i8> %a, <2 x i8> %b, <2 x i8> %c, <2 x i8> %d) #0 {
; V1-LABEL: test_select_cc:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r2 = $r2
; V1-NEXT:    sxlbhq $r3 = $r3
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    compnhq.lt $r2 = $r2, $r3
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    andw $r2 = $r2, 0xff00ff
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    cmovehq.even $r2 ? $r0 = $r1
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 4)
;
; V2-LABEL: test_select_cc:
; V2:       # %bb.0:
; V2-NEXT:    compnbo.lt $r2 = $r2, $r3
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    cmovebo.even $r2 ? $r0 = $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %cc = icmp slt <2 x i8> %c, %d
  %r = select <2 x i1> %cc, <2 x i8> %a, <2 x i8> %b
  ret <2 x i8> %r
}

define <2 x i64> @test_select_cc_f32_f32(<2 x i64> %a, <2 x i64> %b, <2 x i8> %c, <2 x i8> %d) #0 {
; V1-LABEL: test_select_cc_f32_f32:
; V1:       # %bb.0:
; V1-NEXT:    sbmm8 $r4 = $r4, 0x20001
; V1-NEXT:    sbmm8 $r5 = $r5, 0x20001
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    compnhq.ltu $r4 = $r4, $r5
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sxhd $r4 = $r4
; V1-NEXT:    extfs $r5 = $r4, 31, 16
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    cmoved.dnez $r4 ? $r2 = $r0
; V1-NEXT:    cmoved.dnez $r5 ? $r3 = $r1
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    copyd $r0 = $r2
; V1-NEXT:    copyd $r1 = $r3
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 4)
;
; V2-LABEL: test_select_cc_f32_f32:
; V2:       # %bb.0:
; V2-NEXT:    compnbo.ltu $r4 = $r4, $r5
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    sxbd $r4 = $r4
; V2-NEXT:    extfs $r5 = $r4, 15, 8
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    cmoved.dnez $r4 ? $r2 = $r0
; V2-NEXT:    cmoved.dnez $r5 ? $r3 = $r1
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    copyd $r0 = $r2
; V2-NEXT:    copyd $r1 = $r3
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 3)
  %cc = icmp ult <2 x i8> %c, %d
  %r = select <2 x i1> %cc, <2 x i64> %a, <2 x i64> %b
  ret <2 x i64> %r
}

define <2 x i1> @test_icmp_ule(<2 x i8> %a, <2 x i8> %b) #0 {
; V1-LABEL: test_icmp_ule:
; V1:       # %bb.0:
; V1-NEXT:    sbmm8 $r0 = $r0, 0x20001
; V1-NEXT:    sbmm8 $r1 = $r1, 0x20001
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    compnhq.leu $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_icmp_ule:
; V2:       # %bb.0:
; V2-NEXT:    compnbo.leu $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = icmp ule <2 x i8> %a, %b
  ret <2 x i1> %r
}

define <2 x i1> @test_icmp_slt(<2 x i8> %a, <2 x i8> %b) #0 {
; V1-LABEL: test_icmp_slt:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    compnhq.lt $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_icmp_slt:
; V2:       # %bb.0:
; V2-NEXT:    compnbo.lt $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = icmp slt <2 x i8> %a, %b
  ret <2 x i1> %r
}

define <2 x i1> @test_icmp_ugt(<2 x i8> %a, <2 x i8> %b) #0 {
; V1-LABEL: test_icmp_ugt:
; V1:       # %bb.0:
; V1-NEXT:    sbmm8 $r0 = $r0, 0x20001
; V1-NEXT:    sbmm8 $r1 = $r1, 0x20001
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    compnhq.gtu $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_icmp_ugt:
; V2:       # %bb.0:
; V2-NEXT:    compnbo.gtu $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = icmp ugt <2 x i8> %a, %b
  ret <2 x i1> %r
}

define <2 x i1> @test_icmp_uge(<2 x i8> %a, <2 x i8> %b) #0 {
; V1-LABEL: test_icmp_uge:
; V1:       # %bb.0:
; V1-NEXT:    sbmm8 $r0 = $r0, 0x20001
; V1-NEXT:    sbmm8 $r1 = $r1, 0x20001
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    compnhq.geu $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_icmp_uge:
; V2:       # %bb.0:
; V2-NEXT:    compnbo.geu $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = icmp uge <2 x i8> %a, %b
  ret <2 x i1> %r
}

define <2 x i1> @test_icmp_ult(<2 x i8> %a, <2 x i8> %b) #0 {
; V1-LABEL: test_icmp_ult:
; V1:       # %bb.0:
; V1-NEXT:    sbmm8 $r0 = $r0, 0x20001
; V1-NEXT:    sbmm8 $r1 = $r1, 0x20001
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    compnhq.ltu $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_icmp_ult:
; V2:       # %bb.0:
; V2-NEXT:    compnbo.ltu $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = icmp ult <2 x i8> %a, %b
  ret <2 x i1> %r
}

define <2 x i64> @test_sext_2xi64(<2 x i8> %a) #0 {
; ALL-LABEL: test_sext_2xi64:
; ALL:       # %bb.0:
; ALL-NEXT:    sxbd $r0 = $r0
; ALL-NEXT:    extfs $r1 = $r0, 15, 8
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = sext <2 x i8> %a to <2 x i64>
  ret <2 x i64> %r
}

declare <2 x i8> @llvm.abs.v2i8(<2 x i8>, i1) #0

define <2 x i8> @test_abs(<2 x i8> %a) #0 {
; V1-LABEL: test_abs:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    abshq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_abs:
; V2:       # %bb.0:
; V2-NEXT:    absbo $r0 = $r0
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = call <2 x i8> @llvm.abs.v2i8(<2 x i8> %a, i1 false)
  ret <2 x i8> %r
}


define <2 x i8> @test_insertelement0(<2 x i8> %a, i8 %x) #0 {
; ALL-LABEL: test_insertelement0:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r0 = $r1, 7, 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <2 x i8> %a, i8 %x, i8 0
  ret <2 x i8> %i
}

define <2 x i8> @test_insertelement1(<2 x i8> %a, i8 %x) #0 {
; ALL-LABEL: test_insertelement1:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r0 = $r1, 15, 8
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <2 x i8> %a, i8 %x, i8 1
  ret <2 x i8> %i
}

define <2 x i8> @test_insertelement(<2 x i8> %a, i8 %x, i64 %p) #0 {
; ALL-LABEL: test_insertelement:
; ALL:       # %bb.0:
; ALL-NEXT:    andd $r2 = $r2, 1
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sh 30[$r12] = $r0
; ALL-NEXT:    addd $r0 = $r12, 30
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    sb $r2[$r0] = $r1
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    lhz $r0 = 30[$r12]
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 3)
  %i = insertelement <2 x i8> %a, i8 %x, i64 %p
  ret <2 x i8> %i
}

define <2 x i8> @mulsub(<2 x i8> %a, <2 x i8> %b, <2 x i8> %c) #0 {
; V1-LABEL: mulsub:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    sxlbhq $r2 = $r2
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    msbfhq $r0 = $r1, $r2
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 4)
;
; V2-LABEL: mulsub:
; V2:       # %bb.0:
; V2-NEXT:    sxlbhq $r1 = $r1
; V2-NEXT:    sxlbhq $r2 = $r2
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    mulhq $r1 = $r1, $r2
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    sbmm8 $r1 = $r1, 0x401
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    sbfbo $r0 = $r1, $r0
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 4)
  %mul = mul <2 x i8> %b, %c
  %sub = sub <2 x i8> %a, %mul
  ret <2 x i8> %sub
}

define <2 x i8> @vnot(<2 x i8> %a) #0 {
; ALL-LABEL: vnot:
; ALL:       # %bb.0:
; ALL-NEXT:    notw $r0 = $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %vnot = xor <2 x i8> %a, <i8 -1, i8 -1>
  ret <2 x i8> %vnot
}

define <2 x i8> @nandw_v2i8_rr(<2 x i8> %0, <2 x i8> %1) {
; ALL-LABEL: nandw_v2i8_rr:
; ALL:       # %bb.0:
; ALL-NEXT:    nandw $r0 = $r1, $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %3 = and <2 x i8> %1, %0
  %4 = xor <2 x i8> %3, <i8 -1, i8 -1>
  ret <2 x i8> %4
}

define <2 x i8> @nandw_v2i8_ri10(<2 x i8> %0) {
; ALL-LABEL: nandw_v2i8_ri10:
; ALL:       # %bb.0:
; ALL-NEXT:    nandw $r0 = $r0, 255
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = and <2 x i8> %0, <i8 1023, i8 0>
  %3 = xor <2 x i8> %2, <i8 -1, i8 -1>
  ret <2 x i8> %3
}

define <2 x i8> @nandw_v2i8_ri37(<2 x i8> %0) {
; ALL-LABEL: nandw_v2i8_ri37:
; ALL:       # %bb.0:
; ALL-NEXT:    nandw $r0 = $r0, 252
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = and <2 x i8> %0, <i8 252, i8 0>
  %3 = xor <2 x i8> %2, <i8 -1, i8 -1>
  ret <2 x i8> %3
}

define <2 x i8> @nandw_v2i8_ri37_2(<2 x i8> %0) {
; ALL-LABEL: nandw_v2i8_ri37_2:
; ALL:       # %bb.0:
; ALL-NEXT:    nandw $r0 = $r0, 0xd0d
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = and <2 x i8> %0, <i8 13, i8 13>
  %3 = xor <2 x i8> %2, <i8 -1, i8 -1>
  ret <2 x i8> %3
}

define  <2 x i8> @v2_maxbo_rr_i8(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: v2_maxbo_rr_i8:
; V1:       # %bb.0: # %entry
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    maxhq $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: v2_maxbo_rr_i8:
; V2:       # %bb.0: # %entry
; V2-NEXT:    maxbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = call <2 x i8> @llvm.smax.v2i8(<2 x i8> %a, <2 x i8> %b)
  ret <2 x i8> %0
}

define  <2 x i8> @v2_minbo_rr_i8(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: v2_minbo_rr_i8:
; V1:       # %bb.0: # %entry
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    minhq $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: v2_minbo_rr_i8:
; V2:       # %bb.0: # %entry
; V2-NEXT:    minbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = call <2 x i8> @llvm.smin.v2i8(<2 x i8> %a, <2 x i8> %b)
  ret <2 x i8> %0
}

define  <2 x i8> @v2_umaxbo_rr_i8(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: v2_umaxbo_rr_i8:
; V1:       # %bb.0: # %entry
; V1-NEXT:    sbmm8 $r0 = $r0, 0x20001
; V1-NEXT:    sbmm8 $r1 = $r1, 0x20001
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    maxuhq $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: v2_umaxbo_rr_i8:
; V2:       # %bb.0: # %entry
; V2-NEXT:    maxubo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = call <2 x i8> @llvm.umax.v2i8(<2 x i8> %a, <2 x i8> %b)
  ret <2 x i8> %0
}

define  <2 x i8> @v2_uminbo_rr_i8(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: v2_uminbo_rr_i8:
; V1:       # %bb.0: # %entry
; V1-NEXT:    sbmm8 $r0 = $r0, 0x20001
; V1-NEXT:    sbmm8 $r1 = $r1, 0x20001
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    minuhq $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: v2_uminbo_rr_i8:
; V2:       # %bb.0: # %entry
; V2-NEXT:    minubo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = call <2 x i8> @llvm.umin.v2i8(<2 x i8> %a, <2 x i8> %b)
  ret <2 x i8> %0
}

define <2 x i8> @abdbo_rr(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: abdbo_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sbfhq $r0 = $r1, $r0
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    abshq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 5)
;
; V2-LABEL: abdbo_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    abdbo $r0 = $r1, $r0
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
entry:
  %sub = sub nsw <2 x i8> %a, %b
  %0 = tail call <2 x i8> @llvm.abs.v2i8(<2 x i8> %sub, i1 true)
  ret <2 x i8> %0
}

define <2 x i8> @abdbo_ri(<2 x i8> %0) {
; V1-LABEL: abdbo_ri:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sbfhq $r0 = $r0, 0x10000f
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    abshq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 5)
;
; V2-LABEL: abdbo_ri:
; V2:       # %bb.0:
; V2-NEXT:    abdbo $r0 = $r0, 0x100f
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %2 = sub nsw <2 x i8> <i8 15, i8 16>, %0
  %3 = tail call <2 x i8> @llvm.abs.v2i8(<2 x i8> %2, i1 true)
  ret <2 x i8> %3
}

declare <2 x i8> @llvm.smax.v2i8(<2 x i8> %a, <2 x i8> %b)
declare <2 x i8> @llvm.smin.v2i8(<2 x i8> %a, <2 x i8> %b)
declare <2 x i8> @llvm.umax.v2i8(<2 x i8> %a, <2 x i8> %b)
declare <2 x i8> @llvm.umin.v2i8(<2 x i8> %a, <2 x i8> %b)
attributes #0 = { nounwind }

define <2 x i8> @test_div_4(<2 x i8> %a, <2 x i8> %b) #0 {
; V1-LABEL: test_div_4:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    zxbd $r2 = $r0
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sxbd $r1 = $r1
; V1-NEXT:    sxbd $r2 = $r2
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    extfz $r1 = $r1, 14, 13
; V1-NEXT:    extfz $r2 = $r2, 14, 13
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    sxlbhq $r1 = $r2
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 5)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ;; # (end cycle 6)
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;; # (end cycle 7)
; V1-NEXT:    extfs $r0 = $r0, 7, 2
; V1-NEXT:    extfs $r1 = $r1, 7, 2
; V1-NEXT:    ;; # (end cycle 8)
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 9)
;
; V2-LABEL: test_div_4:
; V2:       # %bb.0:
; V2-NEXT:    srsbos $r0 = $r0, 2
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = sdiv <2 x i8> %a, <i8 4, i8 4>
  ret <2 x i8> %r
}

define <2 x i8> @test_div_32(<2 x i8> %a, <2 x i8> %b) #0 {
; V1-LABEL: test_div_32:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    zxbd $r2 = $r0
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sxbd $r1 = $r1
; V1-NEXT:    sxbd $r2 = $r2
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    extfz $r1 = $r1, 14, 10
; V1-NEXT:    extfz $r2 = $r2, 14, 10
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    sxlbhq $r1 = $r2
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 5)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ;; # (end cycle 6)
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;; # (end cycle 7)
; V1-NEXT:    extfs $r0 = $r0, 7, 5
; V1-NEXT:    extfs $r1 = $r1, 7, 5
; V1-NEXT:    ;; # (end cycle 8)
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 9)
;
; V2-LABEL: test_div_32:
; V2:       # %bb.0:
; V2-NEXT:    srsbos $r0 = $r0, 5
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 0)
  %r = sdiv <2 x i8> %a, <i8 32, i8 32>
  ret <2 x i8> %r
}


define <2 x i8> @test_div_neg64(<2 x i8> %a, <2 x i8> %b) #0 {
; V1-LABEL: test_div_neg64:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    zxbd $r2 = $r0
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sxbd $r1 = $r1
; V1-NEXT:    sxbd $r2 = $r2
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    extfz $r1 = $r1, 14, 9
; V1-NEXT:    extfz $r2 = $r2, 14, 9
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    sxlbhq $r1 = $r2
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 5)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ;; # (end cycle 6)
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;; # (end cycle 7)
; V1-NEXT:    extfs $r0 = $r0, 7, 6
; V1-NEXT:    extfs $r1 = $r1, 7, 6
; V1-NEXT:    ;; # (end cycle 8)
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;; # (end cycle 9)
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 10)
; V1-NEXT:    neghq $r0 = $r0
; V1-NEXT:    ;; # (end cycle 11)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 12)
;
; V2-LABEL: test_div_neg64:
; V2:       # %bb.0:
; V2-NEXT:    srsbos $r0 = $r0, 6
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    negbo $r0 = $r0
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %r = sdiv <2 x i8> %a, <i8 -64, i8 -64>
  ret <2 x i8> %r
}

define <2 x i8> @test_div_notsrs(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: test_div_notsrs:
; V1:       # %bb.0:
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    zxbd $r2 = $r0
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sxbd $r1 = $r1
; V1-NEXT:    sxbd $r2 = $r2
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    extfz $r1 = $r1, 14, 11
; V1-NEXT:    extfz $r2 = $r2, 14, 10
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    sxlbhq $r1 = $r2
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 5)
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ;; # (end cycle 6)
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;; # (end cycle 7)
; V1-NEXT:    extfs $r0 = $r0, 7, 5
; V1-NEXT:    extfs $r1 = $r1, 7, 4
; V1-NEXT:    ;; # (end cycle 8)
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 9)
;
; V2-LABEL: test_div_notsrs:
; V2:       # %bb.0:
; V2-NEXT:    srabos $r1 = $r0, 7
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    srlbos $r1 = $r1, 4
; V2-NEXT:    srlbos $r2 = $r1, 3
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    insf $r1 = $r2, 7, 0
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    srabos $r0 = $r0, 4
; V2-NEXT:    srabos $r1 = $r0, 5
; V2-NEXT:    ;; # (end cycle 4)
; V2-NEXT:    insf $r0 = $r1, 7, 0
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 5)
  %r = sdiv <2 x i8> %a, <i8 32, i8 16>
  ret <2 x i8> %r
}

; TODO: compw not required, can use cmove.w***
define <2 x i8> @test_select_cmp(<2 x i8> %a, <2 x i8> %b, <2 x i8> %c, <2 x i8> %d) {
; V1-LABEL: test_select_cmp:
; V1:       # %bb.0:
; V1-NEXT:    sbmm8 $r2 = $r2, 0x20001
; V1-NEXT:    sbmm8 $r3 = $r3, 0x20001
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    compnhq.ne $r2 = $r2, $r3
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    compw.eq $r2 = $r2, -1
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    cmoved.even $r2 ? $r0 = $r1
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 3)
;
; V2-LABEL: test_select_cmp:
; V2:       # %bb.0:
; V2-NEXT:    compnbo.ne $r2 = $r2, $r3
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    sxlbhq $r2 = $r2
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    compw.eq $r2 = $r2, -1
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    cmoved.even $r2 ? $r0 = $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 3)
  %cc = icmp ne <2 x i8> %c, %d
  %bc = bitcast <2 x i1> %cc to i2
  %cmp = icmp eq i2 %bc, -1
  %r = select i1 %cmp, <2 x i8> %a, <2 x i8> %b
  ret <2 x i8> %r
}

define <2 x i8> @test_select_cmp_2(<2 x i8> %a, <2 x i8> %b, <2 x i8> %c, <2 x i8> %d) {
; V1-LABEL: test_select_cmp_2:
; V1:       # %bb.0:
; V1-NEXT:    sbmm8 $r2 = $r2, 0x20001
; V1-NEXT:    sbmm8 $r3 = $r3, 0x20001
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    compnhq.ne $r2 = $r2, $r3
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    zxwd $r2 = $r2
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    compw.eq $r2 = $r2, 0
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    cmoved.even $r2 ? $r0 = $r1
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 4)
;
; V2-LABEL: test_select_cmp_2:
; V2:       # %bb.0:
; V2-NEXT:    compnbo.ne $r2 = $r2, $r3
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    zxhd $r2 = $r2
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    compw.eq $r2 = $r2, 0
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    cmoved.even $r2 ? $r0 = $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 3)
  %cc = icmp ne <2 x i8> %c, %d
  %bc = bitcast <2 x i1> %cc to i2
  %cmp = icmp eq i2 %bc, 0
  %r = select i1 %cmp, <2 x i8> %a, <2 x i8> %b
  ret <2 x i8> %r
}

define <2 x i8> @test_select_cmp_3(<2 x i8> %a, <2 x i8> %b, <2 x i8> %c, <2 x i8> %d) {
; V1-LABEL: test_select_cmp_3:
; V1:       # %bb.0:
; V1-NEXT:    sbmm8 $r2 = $r2, 0x20001
; V1-NEXT:    sbmm8 $r3 = $r3, 0x20001
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    compnhq.ne $r2 = $r2, $r3
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    zxwd $r2 = $r2
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    compw.ne $r2 = $r2, 0
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    cmoved.even $r2 ? $r0 = $r1
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 4)
;
; V2-LABEL: test_select_cmp_3:
; V2:       # %bb.0:
; V2-NEXT:    compnbo.ne $r2 = $r2, $r3
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    zxhd $r2 = $r2
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    compw.ne $r2 = $r2, 0
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    cmoved.even $r2 ? $r0 = $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 3)
  %cc = icmp ne <2 x i8> %c, %d
  %bc = bitcast <2 x i1> %cc to i2
  %cmp = icmp ne i2 %bc, 0
  %r = select i1 %cmp, <2 x i8> %a, <2 x i8> %b
  ret <2 x i8> %r
}

define <2 x i8> @test_select_cmp_4(<2 x i8> %a, <2 x i8> %b, <2 x i8> %c, <2 x i8> %d) {
; V1-LABEL: test_select_cmp_4:
; V1:       # %bb.0:
; V1-NEXT:    sbmm8 $r2 = $r2, 0x20001
; V1-NEXT:    sbmm8 $r3 = $r3, 0x20001
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    compnhq.ne $r2 = $r2, $r3
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    compw.ne $r2 = $r2, -1
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    cmoved.even $r2 ? $r0 = $r1
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 3)
;
; V2-LABEL: test_select_cmp_4:
; V2:       # %bb.0:
; V2-NEXT:    compnbo.ne $r2 = $r2, $r3
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    sxlbhq $r2 = $r2
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    compw.ne $r2 = $r2, -1
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    cmoved.even $r2 ? $r0 = $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 3)
  %cc = icmp ne <2 x i8> %c, %d
  %bc = bitcast <2 x i1> %cc to i2
  %cmp = icmp ne i2 %bc, -1
  %r = select i1 %cmp, <2 x i8> %a, <2 x i8> %b
  ret <2 x i8> %r
}

define <2 x i8> @fshl_rr(<2 x i8> %a, <2 x i8> %b, i8 %c) {
; V1-LABEL: fshl_rr:
; V1:       # %bb.0:
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    zxbd $r1 = $r1
; V1-NEXT:    extfz $r3 = $r1, 15, 8
; V1-NEXT:    extfz $r4 = $r0, 15, 8
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sllw $r0 = $r0, 8
; V1-NEXT:    zxbd $r1 = $r1
; V1-NEXT:    zxbd $r3 = $r3
; V1-NEXT:    sllw $r4 = $r4, 8
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    iorw $r0 = $r0, $r1
; V1-NEXT:    andw $r2 = $r2, 7
; V1-NEXT:    iorw $r3 = $r4, $r3
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    sllw $r0 = $r0, $r2
; V1-NEXT:    sllw $r1 = $r3, $r2
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    srlw $r0 = $r0, 8
; V1-NEXT:    srlw $r1 = $r1, 8
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 5)
;
; V2-LABEL: fshl_rr:
; V2:       # %bb.0:
; V2-NEXT:    srlbos $r1 = $r1, 1
; V2-NEXT:    insf $r2 = $r2, 15, 8
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    andw $r2 = $r2, 0x707
; V2-NEXT:    andnw $r3 = $r2, 0x707
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    sllbos $r2 = $r0, $r2
; V2-NEXT:    srlbos $r3 = $r1, $r3
; V2-NEXT:    extfz $r4 = $r3, 10, 8
; V2-NEXT:    extfz $r5 = $r2, 10, 8
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    sllbos $r0 = $r0, $r5
; V2-NEXT:    srlbos $r1 = $r1, $r4
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    insf $r0 = $r2, 7, 0
; V2-NEXT:    insf $r1 = $r3, 7, 0
; V2-NEXT:    ;; # (end cycle 4)
; V2-NEXT:    iorw $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 5)
  %i = insertelement <2 x i8> undef, i8 %c, i64 0
  %s = insertelement <2 x i8> %i, i8 %c, i64 1
  %r = call <2 x i8> @llvm.fshl.v2i8(<2 x i8> %a, <2 x i8> %b, <2 x i8> %s)
  ret <2 x i8> %r
}

define <2 x i8> @fshl_ri(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: fshl_ri:
; V1:       # %bb.0:
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    zxbd $r1 = $r1
; V1-NEXT:    extfz $r2 = $r1, 15, 8
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sllw $r0 = $r0, 3
; V1-NEXT:    extfz $r1 = $r1, 7, 5
; V1-NEXT:    extfz $r2 = $r2, 7, 5
; V1-NEXT:    sllw $r3 = $r3, 3
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    iorw $r0 = $r0, $r1
; V1-NEXT:    iorw $r2 = $r3, $r2
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    insf $r0 = $r2, 15, 8
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 3)
;
; V2-LABEL: fshl_ri:
; V2:       # %bb.0:
; V2-NEXT:    sllbos $r0 = $r0, 3
; V2-NEXT:    srlbos $r1 = $r1, 1
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    srlbos $r1 = $r1, 4
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    iorw $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 2)
  %r = call <2 x i8> @llvm.fshl.v2i8(<2 x i8> %a, <2 x i8> %b, <2 x i8> <i8 3, i8 3>)
  ret <2 x i8> %r
}

define <2 x i8> @fshl_vec(<2 x i8> %a, <2 x i8> %b, <2 x i8> %c) {
; V1-LABEL: fshl_vec:
; V1:       # %bb.0:
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    zxbd $r1 = $r1
; V1-NEXT:    extfz $r3 = $r1, 15, 8
; V1-NEXT:    extfz $r4 = $r0, 15, 8
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    zxbd $r1 = $r1
; V1-NEXT:    zxbd $r3 = $r3
; V1-NEXT:    sllw $r4 = $r4, 8
; V1-NEXT:    extfz $r5 = $r2, 15, 8
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sllw $r0 = $r0, 8
; V1-NEXT:    zxbd $r2 = $r2
; V1-NEXT:    iorw $r3 = $r4, $r3
; V1-NEXT:    andw $r4 = $r5, 7
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    iorw $r0 = $r0, $r1
; V1-NEXT:    andw $r1 = $r2, 7
; V1-NEXT:    sllw $r2 = $r3, $r4
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    sllw $r0 = $r0, $r1
; V1-NEXT:    srlw $r1 = $r2, 8
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    srlw $r0 = $r0, 8
; V1-NEXT:    ;; # (end cycle 5)
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 6)
;
; V2-LABEL: fshl_vec:
; V2:       # %bb.0:
; V2-NEXT:    srlbos $r1 = $r1, 1
; V2-NEXT:    andw $r2 = $r2, 0x707
; V2-NEXT:    andnw $r3 = $r2, 0x707
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    sllbos $r2 = $r0, $r2
; V2-NEXT:    srlbos $r3 = $r1, $r3
; V2-NEXT:    extfz $r4 = $r3, 10, 8
; V2-NEXT:    extfz $r5 = $r2, 10, 8
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    sllbos $r0 = $r0, $r5
; V2-NEXT:    srlbos $r1 = $r1, $r4
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    insf $r0 = $r2, 7, 0
; V2-NEXT:    insf $r1 = $r3, 7, 0
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    iorw $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 4)
  %r = call <2 x i8> @llvm.fshl.v2i8(<2 x i8> %a, <2 x i8> %b, <2 x i8> %c)
  ret <2 x i8> %r
}
define <2 x i8> @fshr_rr(<2 x i8> %a, <2 x i8> %b, i8 %c) {
; V1-LABEL: fshr_rr:
; V1:       # %bb.0:
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    zxbd $r1 = $r1
; V1-NEXT:    extfz $r3 = $r1, 15, 8
; V1-NEXT:    extfz $r4 = $r0, 15, 8
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sllw $r0 = $r0, 8
; V1-NEXT:    zxbd $r1 = $r1
; V1-NEXT:    zxbd $r3 = $r3
; V1-NEXT:    sllw $r4 = $r4, 8
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    iorw $r0 = $r0, $r1
; V1-NEXT:    andw $r2 = $r2, 7
; V1-NEXT:    iorw $r3 = $r4, $r3
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    srlw $r0 = $r0, $r2
; V1-NEXT:    srlw $r1 = $r3, $r2
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 4)
;
; V2-LABEL: fshr_rr:
; V2:       # %bb.0:
; V2-NEXT:    sllbos $r0 = $r0, 1
; V2-NEXT:    insf $r2 = $r2, 15, 8
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    andnw $r2 = $r2, 0x707
; V2-NEXT:    andw $r3 = $r2, 0x707
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    sllbos $r2 = $r0, $r2
; V2-NEXT:    srlbos $r3 = $r1, $r3
; V2-NEXT:    extfz $r4 = $r3, 10, 8
; V2-NEXT:    extfz $r5 = $r2, 10, 8
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    sllbos $r0 = $r0, $r5
; V2-NEXT:    srlbos $r1 = $r1, $r4
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    insf $r0 = $r2, 7, 0
; V2-NEXT:    insf $r1 = $r3, 7, 0
; V2-NEXT:    ;; # (end cycle 4)
; V2-NEXT:    iorw $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 5)
  %i = insertelement <2 x i8> undef, i8 %c, i64 0
  %s = insertelement <2 x i8> %i, i8 %c, i64 1
  %r = call <2 x i8> @llvm.fshr.v2i8(<2 x i8> %a, <2 x i8> %b, <2 x i8> %s)
  ret <2 x i8> %r
}

define <2 x i8> @fshr_ri(<2 x i8> %a, <2 x i8> %b, i8 %c) {
; V1-LABEL: fshr_ri:
; V1:       # %bb.0:
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    zxbd $r1 = $r1
; V1-NEXT:    extfz $r2 = $r1, 15, 8
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sllw $r0 = $r0, 5
; V1-NEXT:    extfz $r1 = $r1, 7, 3
; V1-NEXT:    extfz $r2 = $r2, 7, 3
; V1-NEXT:    sllw $r3 = $r3, 5
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    iorw $r0 = $r0, $r1
; V1-NEXT:    iorw $r2 = $r3, $r2
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    insf $r0 = $r2, 15, 8
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 3)
;
; V2-LABEL: fshr_ri:
; V2:       # %bb.0:
; V2-NEXT:    sllbos $r0 = $r0, 1
; V2-NEXT:    srlbos $r1 = $r1, 3
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    sllbos $r0 = $r0, 4
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    iorw $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 2)
  %r = call <2 x i8> @llvm.fshr.v2i8(<2 x i8> %a, <2 x i8> %b, <2 x i8> <i8 3, i8 3>)
  ret <2 x i8> %r
}

define <2 x i8> @fshr_vec(<2 x i8> %a, <2 x i8> %b, <2 x i8> %c) {
; V1-LABEL: fshr_vec:
; V1:       # %bb.0:
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    zxbd $r1 = $r1
; V1-NEXT:    extfz $r3 = $r1, 15, 8
; V1-NEXT:    extfz $r4 = $r0, 15, 8
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    zxbd $r1 = $r1
; V1-NEXT:    zxbd $r3 = $r3
; V1-NEXT:    sllw $r4 = $r4, 8
; V1-NEXT:    extfz $r5 = $r2, 15, 8
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sllw $r0 = $r0, 8
; V1-NEXT:    zxbd $r2 = $r2
; V1-NEXT:    iorw $r3 = $r4, $r3
; V1-NEXT:    andw $r4 = $r5, 7
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    iorw $r0 = $r0, $r1
; V1-NEXT:    andw $r1 = $r2, 7
; V1-NEXT:    srlw $r2 = $r3, $r4
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    srlw $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    insf $r0 = $r2, 15, 8
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 5)
;
; V2-LABEL: fshr_vec:
; V2:       # %bb.0:
; V2-NEXT:    sllbos $r0 = $r0, 1
; V2-NEXT:    andnw $r2 = $r2, 0x707
; V2-NEXT:    andw $r3 = $r2, 0x707
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    sllbos $r2 = $r0, $r2
; V2-NEXT:    srlbos $r3 = $r1, $r3
; V2-NEXT:    extfz $r4 = $r3, 10, 8
; V2-NEXT:    extfz $r5 = $r2, 10, 8
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    sllbos $r0 = $r0, $r5
; V2-NEXT:    srlbos $r1 = $r1, $r4
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    insf $r0 = $r2, 7, 0
; V2-NEXT:    insf $r1 = $r3, 7, 0
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    iorw $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 4)
  %r = call <2 x i8> @llvm.fshr.v2i8(<2 x i8> %a, <2 x i8> %b, <2 x i8> %c)
  ret <2 x i8> %r
}

declare <2 x i8> @llvm.fshr.v2i8(<2 x i8>, <2 x i8>, <2 x i8>)
declare <2 x i8> @llvm.fshl.v2i8(<2 x i8>, <2 x i8>, <2 x i8>)
