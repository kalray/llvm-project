; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mcpu=kv3-1 -o - %s | FileCheck %s --check-prefixes=V1
; RUN: llc -mcpu=kv3-2 -o - %s | FileCheck %s --check-prefixes=V2
; RUN: clang -march=kv3-1 -c -o /dev/null %s
; RUN: clang -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define <4 x float> @ffdmdawq(<4 x float> %0, <4 x float> %1, <4 x float> %2, <4 x float> %3, <4 x float> %4) {
; V1-LABEL: ffdmdawq:
; V1:       # %bb.0:
; V1-NEXT:    ffmawp $r1 = $r7, $r3
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    ffmawp $r0 = $r6, $r2
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    ffmawp $r1 = $r9, $r5
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    ffmawp $r0 = $r8, $r4
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 5)
;
; V2-LABEL: ffdmdawq:
; V2:       # %bb.0:
; V2-NEXT:    copyd $r6 = $r2
; V2-NEXT:    copyd $r7 = $r3
; V2-NEXT:    copyd $r10 = $r6
; V2-NEXT:    copyd $r11 = $r7
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    ffdmdawq $r0r1 = $r8r9r10r11, $r4r5r6r7
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %6 = fmul fast <4 x float> %4, %2
  %7 = fmul fast <4 x float> %3, %1
  %8 = fadd fast <4 x float> %7, %0
  %9 = fadd fast <4 x float> %8, %6
  ret <4 x float> %9
}

define <2 x float> @ffdmdawp(<2 x float> %0, <2 x float> %1, <2 x float> %2, <2 x float> %3, <2 x float> %4) {
; V1-LABEL: ffdmdawp:
; V1:       # %bb.0:
; V1-NEXT:    ffmawp $r0 = $r3, $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    ffmawp $r0 = $r4, $r2
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 4)
;
; V2-LABEL: ffdmdawp:
; V2:       # %bb.0:
; V2-NEXT:    copyd $r3 = $r1
; V2-NEXT:    copyd $r5 = $r3
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    ffdmdawp $r0 = $r4r5, $r2r3
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %6 = fmul fast <2 x float> %4, %2
  %7 = fmul fast <2 x float> %3, %1
  %8 = fadd fast <2 x float> %7, %0
  %9 = fadd fast <2 x float> %8, %6
  ret <2 x float> %9
}

define <4 x float> @ffdmdswq(<4 x float> %0, <4 x float> %1, <4 x float> %2, <4 x float> %3, <4 x float> %4) {
; V1-LABEL: ffdmdswq:
; V1:       # %bb.0:
; V1-NEXT:    ffmswp $r1 = $r7, $r3
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    ffmswp $r0 = $r6, $r2
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    ffmswp $r1 = $r9, $r5
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    ffmswp $r0 = $r8, $r4
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 5)
;
; V2-LABEL: ffdmdswq:
; V2:       # %bb.0:
; V2-NEXT:    copyd $r6 = $r2
; V2-NEXT:    copyd $r7 = $r3
; V2-NEXT:    copyd $r10 = $r6
; V2-NEXT:    copyd $r11 = $r7
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    ffdmdswq $r0r1 = $r8r9r10r11, $r4r5r6r7
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %6 = fmul fast <4 x float> %3, %1
  %7 = fmul fast <4 x float> %4, %2
  %8 = fadd fast <4 x float> %7, %6
  %9 = fsub fast <4 x float> %0, %8
  ret <4 x float> %9
}

define <2 x float> @ffdmdswp(<2 x float> %0, <2 x float> %1, <2 x float> %2, <2 x float> %3, <2 x float> %4) {
; V1-LABEL: ffdmdswp:
; V1:       # %bb.0:
; V1-NEXT:    ffmswp $r0 = $r1, $r3
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    ffmswp $r0 = $r2, $r4
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 4)
;
; V2-LABEL: ffdmdswp:
; V2:       # %bb.0:
; V2-NEXT:    copyd $r3 = $r1
; V2-NEXT:    copyd $r5 = $r3
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    ffdmdswp $r0 = $r4r5, $r2r3
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %6 = fmul fast <2 x float> %3, %1
  %7 = fmul fast <2 x float> %4, %2
  %8 = fadd fast <2 x float> %7, %6
  %9 = fsub fast <2 x float> %0, %8
  ret <2 x float> %9
}

define <4 x float> @ffdmsawq(<4 x float> %0, <4 x float> %1, <4 x float> %2, <4 x float> %3, <4 x float> %4) {
; V1-LABEL: ffdmsawq:
; V1:       # %bb.0:
; V1-NEXT:    ffmswp $r1 = $r3, $r7
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    ffmswp $r0 = $r2, $r6
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    ffmawp $r1 = $r9, $r5
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    ffmawp $r0 = $r8, $r4
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 5)
;
; V2-LABEL: ffdmsawq:
; V2:       # %bb.0:
; V2-NEXT:    copyd $r10 = $r2
; V2-NEXT:    copyd $r11 = $r3
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    ffdmsawq $r0r1 = $r8r9r10r11, $r4r5r6r7
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %6 = fmul fast <4 x float> %4, %2
  %7 = fmul fast <4 x float> %1, %3
  %8 = fsub fast <4 x float> %0, %7
  %9 = fadd fast <4 x float> %8, %6
  ret <4 x float> %9
}

define <2 x float> @ffdmaswp(<2 x float> %0, <2 x float> %1, <2 x float> %2, <2 x float> %3, <2 x float> %4) {
; V1-LABEL: ffdmaswp:
; V1:       # %bb.0:
; V1-NEXT:    ffmswp $r0 = $r3, $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    ffmawp $r0 = $r4, $r2
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 4)
;
; V2-LABEL: ffdmaswp:
; V2:       # %bb.0:
; V2-NEXT:    copyd $r5 = $r1
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    ffdmsawp $r0 = $r4r5, $r2r3
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %6 = fmul fast <2 x float> %4, %2
  %7 = fmul fast <2 x float> %1, %3
  %8 = fsub fast <2 x float> %0, %7
  %9 = fadd fast <2 x float> %8, %6
  ret <2 x float> %9
}

define <4 x float> @ffdmaswq(<4 x float> %0, <4 x float> %1, <4 x float> %2, <4 x float> %3, <4 x float> %4) {
; V1-LABEL: ffdmaswq:
; V1:       # %bb.0:
; V1-NEXT:    ffmawp $r1 = $r7, $r3
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    ffmawp $r0 = $r6, $r2
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    ffmswp $r1 = $r5, $r9
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    ffmswp $r0 = $r4, $r8
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 5)
;
; V2-LABEL: ffdmaswq:
; V2:       # %bb.0:
; V2-NEXT:    copyd $r10 = $r2
; V2-NEXT:    copyd $r11 = $r3
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    ffdmaswq $r0r1 = $r4r5r6r7, $r8r9r10r11
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %6 = fmul fast <4 x float> %3, %1
  %7 = fadd fast <4 x float> %6, %0
  %8 = fmul fast <4 x float> %2, %4
  %9 = fsub fast <4 x float> %7, %8
  ret <4 x float> %9
}

define <2 x float> @ffdmsawp(<2 x float> %0, <2 x float> %1, <2 x float> %2, <2 x float> %3, <2 x float> %4) {
; V1-LABEL: ffdmsawp:
; V1:       # %bb.0:
; V1-NEXT:    ffmawp $r0 = $r3, $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    ffmswp $r0 = $r4, $r2
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 4)
;
; V2-LABEL: ffdmsawp:
; V2:       # %bb.0:
; V2-NEXT:    copyd $r5 = $r1
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    ffdmaswp $r0 = $r2r3, $r4r5
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %6 = fmul fast <2 x float> %3, %1
  %7 = fadd fast <2 x float> %6, %0
  %8 = fmul fast <2 x float> %2, %4
  %9 = fsub fast <2 x float> %7, %8
  ret <2 x float> %9
}

