; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mcpu=kv3-1 -O2 -o - %s | FileCheck %s --check-prefixes=CHECK,V1
; RUN: llc -mcpu=kv3-2 -O2 -o - %s | FileCheck %s --check-prefixes=CHECK,V2
; RUN: clang -O2 -c -o /dev/null %s
; RUN: clang -O2 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define <2 x i16> @add_i16x2_rr(<2 x i16> %a, <2 x i16> %b) {
; CHECK-LABEL: add_i16x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addhq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %add = add <2 x i16> %a, %b
  ret <2 x i16> %add
}

define <2 x i16> @add_i16x2_ri(<2 x i16> %a) {
; CHECK-LABEL: add_i16x2_ri:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addhq $r0 = $r0, 0xffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %add = add <2 x i16> %a, <i16 -1, i16 0>
  ret <2 x i16> %add
}

define <2 x i16> @not_sub_i16x2_ri(<2 x i16> %a) {
; CHECK-LABEL: not_sub_i16x2_ri:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addhq $r0 = $r0, 1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %sub = sub <2 x i16> %a, <i16 -1, i16 0>
  ret <2 x i16> %sub
}

define <4 x i16> @add_i16x4_rr(<4 x i16> %a, <4 x i16> %b) {
; CHECK-LABEL: add_i16x4_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addhq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %add = add <4 x i16> %a, %b
  ret <4 x i16> %add
}

define <4 x i16> @add_i16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: add_i16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addhq $r0 = $r0, 0xffff0005
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %add = add <4 x i16> %a, <i16 5, i16 -1, i16 0, i16 0>
  ret <4 x i16> %add
}

define <4 x i16> @add_i16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: add_i16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addhq.@ $r0 = $r0, 0xffff0005
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %add = add <4 x i16> %a, <i16 5, i16 -1, i16 5, i16 -1>
  ret <4 x i16> %add
}

define <4 x i16> @add_i16x4_ri_rr2(<4 x i16> %a) {
; CHECK-LABEL: add_i16x4_ri_rr2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x10005ffff0005
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addhq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %add = add <4 x i16> %a, <i16 5, i16 -1, i16 5, i16 1>
  ret <4 x i16> %add
}
define <4 x i16> @not_sub_i16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: not_sub_i16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addhq.@ $r0 = $r0, 0x50001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %sub = sub <4 x i16> %a, <i16 -1, i16 -5, i16 -1, i16 -5>
  ret <4 x i16> %sub
}

define <4 x i16> @not_sub_i16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: not_sub_i16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addhq $r0 = $r0, 0x50001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %sub = sub <4 x i16> %a, <i16 -1, i16 -5, i16 0, i16 0>
  ret <4 x i16> %sub
}

define <2 x i32> @add_i32x2_rr(<2 x i32> %a, <2 x i32> %b) {
; CHECK-LABEL: add_i32x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addwp $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %add = add <2 x i32> %a, %b
  ret <2 x i32> %add
}

define <2 x i32> @add_i32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: add_i32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addwp $r0 = $r0, -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %add = add <2 x i32> %a, <i32 -1, i32 0>
  ret <2 x i32> %add
}

define <2 x i32> @add_i32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: add_i32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addwp.@ $r0 = $r0, -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %add = add <2 x i32> %a, <i32 -1, i32 -1>
  ret <2 x i32> %add
}

define <2 x i32> @not_sub_i32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: not_sub_i32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addwp $r0 = $r0, 1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %sub = sub <2 x i32> %a, <i32 -1, i32 0>
  ret <2 x i32> %sub
}

define <2 x i32> @not_sub_i32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: not_sub_i32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addwp.@ $r0 = $r0, 0x1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %sub = sub <2 x i32> %a, <i32 -1, i32 -1>
  ret <2 x i32> %sub
}

define <2 x i32> @add_i32x2_rr_2(<2 x i32> %a) {
; CHECK-LABEL: add_i32x2_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0xffffffff00000001
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addwp $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %add = add <2 x i32> %a, <i32 1, i32 -1>
  ret <2 x i32> %add
}

define <2 x i16> @addx2_i16x2_rr(<2 x i16> %a, <2 x i16> %b) {
; CHECK-LABEL: addx2_i16x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %b, <i16 1, i16 1>
  %add = add <2 x i16> %mul, %a
  ret <2 x i16> %add
}

define <2 x i16> @addx2_u16x2_rr(<2 x i16> %a, <2 x i16> %b) {
; CHECK-LABEL: addx2_u16x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %b, <i16 1, i16 1>
  %add = add <2 x i16> %mul, %a
  ret <2 x i16> %add
}

define <4 x i16> @addx2_i16x4_rr(<4 x i16> %a, <4 x i16> %b) {
; CHECK-LABEL: addx2_i16x4_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %b, <i16 1, i16 1, i16 1, i16 1>
  %add = add <4 x i16> %mul, %a
  ret <4 x i16> %add
}

define <4 x i16> @addx2_u16x4_rr(<4 x i16> %a, <4 x i16> %b) {
; CHECK-LABEL: addx2_u16x4_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %b, <i16 1, i16 1, i16 1, i16 1>
  %add = add <4 x i16> %mul, %a
  ret <4 x i16> %add
}

define <2 x i32> @addx2_i32x2_rr(<2 x i32> %a, <2 x i32> %b) {
; CHECK-LABEL: addx2_i32x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2wp $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %b, <i32 1, i32 1>
  %add = add <2 x i32> %mul, %a
  ret <2 x i32> %add
}

define <2 x i32> @addx2_u32x2_rr(<2 x i32> %a, <2 x i32> %b) {
; CHECK-LABEL: addx2_u32x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2wp $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %b, <i32 1, i32 1>
  %add = add <2 x i32> %mul, %a
  ret <2 x i32> %add
}

define <2 x i16> @addx4_i16x2_rr(<2 x i16> %a, <2 x i16> %b) {
; CHECK-LABEL: addx4_i16x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %b, <i16 2, i16 2>
  %add = add <2 x i16> %mul, %a
  ret <2 x i16> %add
}

define <2 x i16> @addx4_u16x2_rr(<2 x i16> %a, <2 x i16> %b) {
; CHECK-LABEL: addx4_u16x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %b, <i16 2, i16 2>
  %add = add <2 x i16> %mul, %a
  ret <2 x i16> %add
}

define <4 x i16> @addx4_i16x4_rr(<4 x i16> %a, <4 x i16> %b) {
; CHECK-LABEL: addx4_i16x4_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %b, <i16 2, i16 2, i16 2, i16 2>
  %add = add <4 x i16> %mul, %a
  ret <4 x i16> %add
}

define <4 x i16> @addx4_u16x4_rr(<4 x i16> %a, <4 x i16> %b) {
; CHECK-LABEL: addx4_u16x4_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %b, <i16 2, i16 2, i16 2, i16 2>
  %add = add <4 x i16> %mul, %a
  ret <4 x i16> %add
}

define <2 x i32> @addx4_i32x2_rr(<2 x i32> %a, <2 x i32> %b) {
; CHECK-LABEL: addx4_i32x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4wp $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %b, <i32 2, i32 2>
  %add = add <2 x i32> %mul, %a
  ret <2 x i32> %add
}

define <2 x i32> @addx4_u32x2_rr(<2 x i32> %a, <2 x i32> %b) {
; CHECK-LABEL: addx4_u32x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4wp $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %b, <i32 2, i32 2>
  %add = add <2 x i32> %mul, %a
  ret <2 x i32> %add
}

define <2 x i16> @addx8_i16x2_rr(<2 x i16> %a, <2 x i16> %b) {
; CHECK-LABEL: addx8_i16x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %b, <i16 3, i16 3>
  %add = add <2 x i16> %mul, %a
  ret <2 x i16> %add
}

define <2 x i16> @addx8_u16x2_rr(<2 x i16> %a, <2 x i16> %b) {
; CHECK-LABEL: addx8_u16x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %b, <i16 3, i16 3>
  %add = add <2 x i16> %mul, %a
  ret <2 x i16> %add
}

define <4 x i16> @addx8_i16x4_rr(<4 x i16> %a, <4 x i16> %b) {
; CHECK-LABEL: addx8_i16x4_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %b, <i16 3, i16 3, i16 3, i16 3>
  %add = add <4 x i16> %mul, %a
  ret <4 x i16> %add
}

define <4 x i16> @addx8_u16x4_rr(<4 x i16> %a, <4 x i16> %b) {
; CHECK-LABEL: addx8_u16x4_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %b, <i16 3, i16 3, i16 3, i16 3>
  %add = add <4 x i16> %mul, %a
  ret <4 x i16> %add
}

define <2 x i32> @addx8_i32x2_rr(<2 x i32> %a, <2 x i32> %b) {
; CHECK-LABEL: addx8_i32x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8wp $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %b, <i32 3, i32 3>
  %add = add <2 x i32> %mul, %a
  ret <2 x i32> %add
}

define <2 x i32> @addx8_u32x2_rr(<2 x i32> %a, <2 x i32> %b) {
; CHECK-LABEL: addx8_u32x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8wp $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %b, <i32 3, i32 3>
  %add = add <2 x i32> %mul, %a
  ret <2 x i32> %add
}

define <2 x i16> @addx16_i16x2_rr(<2 x i16> %a, <2 x i16> %b) {
; CHECK-LABEL: addx16_i16x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %b, <i16 4, i16 4>
  %add = add <2 x i16> %mul, %a
  ret <2 x i16> %add
}

define <2 x i16> @addx16_u16x2_rr(<2 x i16> %a, <2 x i16> %b) {
; CHECK-LABEL: addx16_u16x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %b, <i16 4, i16 4>
  %add = add <2 x i16> %mul, %a
  ret <2 x i16> %add
}

define <4 x i16> @addx16_i16x4_rr(<4 x i16> %a, <4 x i16> %b) {
; CHECK-LABEL: addx16_i16x4_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %b, <i16 4, i16 4, i16 4, i16 4>
  %add = add <4 x i16> %mul, %a
  ret <4 x i16> %add
}

define <4 x i16> @addx16_u16x4_rr(<4 x i16> %a, <4 x i16> %b) {
; CHECK-LABEL: addx16_u16x4_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %b, <i16 4, i16 4, i16 4, i16 4>
  %add = add <4 x i16> %mul, %a
  ret <4 x i16> %add
}

define <2 x i32> @addx16_i32x2_rr(<2 x i32> %a, <2 x i32> %b) {
; CHECK-LABEL: addx16_i32x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %b, <i32 4, i32 4>
  %add = add <2 x i32> %mul, %a
  ret <2 x i32> %add
}

define <2 x i32> @addx16_u32x2_rr(<2 x i32> %a, <2 x i32> %b) {
; CHECK-LABEL: addx16_u32x2_rr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp $r0 = $r1, $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %b, <i32 4, i32 4>
  %add = add <2 x i32> %mul, %a
  ret <2 x i32> %add
}

define <2 x i16> @addx2_i16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: addx2_i16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 1, i16 1>
  %add = add <2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %add
}

define <2 x i16> @addx2_u16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: addx2_u16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 1, i16 1>
  %add = add <2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %add
}

define <4 x i16> @addx2_i16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: addx2_i16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 1, i16 1, i16 1, i16 1>
  %add = add <4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %add
}

define <4 x i16> @addx2_i16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: addx2_i16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq.@ $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 1, i16 1, i16 1, i16 1>
  %add = add <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %add
}

define <4 x i16> @addx2_i16x4_rr_2(<4 x i16> %a) {
; CHECK-LABEL: addx2_i16x4_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x3000100020001
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx2hq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 1, i16 1, i16 1, i16 1>
  %add = add <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 3>
  ret <4 x i16> %add
}

define <4 x i16> @addx2_u16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: addx2_u16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 1, i16 1, i16 1, i16 1>
  %add = add <4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %add
}

define <4 x i16> @addx2_u16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: addx2_u16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq.@ $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 1, i16 1, i16 1, i16 1>
  %add = add <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %add
}

define <4 x i16> @addx2_u16x4_rr_2(<4 x i16> %a) {
; CHECK-LABEL: addx2_u16x4_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x3000100020001
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx2hq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 1, i16 1, i16 1, i16 1>
  %add = add <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 3>
  ret <4 x i16> %add
}

define <2 x i32> @addx2_i32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: addx2_i32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2wp $r0 = $r0, 1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 1, i32 1>
  %add = or <2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %add
}

define <2 x i32> @addx2_i32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: addx2_i32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2wp.@ $r0 = $r0, 0x3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 1, i32 1>
  %add = add <2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %add
}

define <2 x i32> @addx2_i32x2_rr_2(<2 x i32> %a) {
; CHECK-LABEL: addx2_i32x2_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x200000003
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx2wp $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 1, i32 1>
  %add = add <2 x i32> %mul, <i32 3, i32 2>
  ret <2 x i32> %add
}

define <2 x i32> @addx2_u32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: addx2_u32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2wp $r0 = $r0, 1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 1, i32 1>
  %add = or <2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %add
}

define <2 x i32> @addx2_u32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: addx2_u32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2wp.@ $r0 = $r0, 0x3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 1, i32 1>
  %add = add <2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %add
}

define <2 x i32> @addx2_u32x2_rr_2(<2 x i32> %a) {
; CHECK-LABEL: addx2_u32x2_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x200000003
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx2wp $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 1, i32 1>
  %add = add <2 x i32> %mul, <i32 3, i32 2>
  ret <2 x i32> %add
}

define <2 x i16> @addx4_i16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: addx4_i16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 2, i16 2>
  %add = or <2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %add
}

define <2 x i16> @addx4_u16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: addx4_u16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 2, i16 2>
  %add = or <2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %add
}

define <4 x i16> @addx4_i16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: addx4_i16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 2, i16 2, i16 2, i16 2>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %add
}

define <4 x i16> @addx4_i16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: addx4_i16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq.@ $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 2, i16 2, i16 2, i16 2>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %add
}

; For the RR variations, must look
; which is best, (ord(sll)) or (addx(make))
define <4 x i16> @addx4_i16x4_rr_2(<4 x i16> %a) {
; CHECK-LABEL: addx4_i16x4_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x3000100020001
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx4hq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 2, i16 2, i16 2, i16 2>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 3>
  ret <4 x i16> %add
}

; The constant in the or is too high, can't use addx4
define <4 x i16> @addx4_i16x4_rr_NOT(<4 x i16> %a) {
; CHECK-LABEL: addx4_i16x4_rr_NOT:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sllhqs $r0 = $r0, 2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ord.@ $r0 = $r0, 0x7d00001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 2, i16 2, i16 2, i16 2>
  %add = or <4 x i16> %mul, <i16 1, i16 2000, i16 1, i16 2000>
  ret <4 x i16> %add
}

define <4 x i16> @addx4_u16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: addx4_u16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 2, i16 2, i16 2, i16 2>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %add
}

define <4 x i16> @addx4_u16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: addx4_u16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq.@ $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 2, i16 2, i16 2, i16 2>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %add
}

define <4 x i16> @addx4_u16x4_rr_2(<4 x i16> %a) {
; CHECK-LABEL: addx4_u16x4_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x3000100020001
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx4hq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 2, i16 2, i16 2, i16 2>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 3>
  ret <4 x i16> %add
}

define <2 x i32> @addx4_i32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: addx4_i32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4wp $r0 = $r0, 1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 2, i32 2>
  %add = or <2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %add
}

define <2 x i32> @addx4_i32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: addx4_i32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4wp.@ $r0 = $r0, 0x3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 2, i32 2>
  %add = or <2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %add
}

define <2 x i32> @addx4_i32x2_rr_2(<2 x i32> %a) {
; CHECK-LABEL: addx4_i32x2_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x200000003
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx4wp $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 2, i32 2>
  %add = or <2 x i32> %mul, <i32 3, i32 2>
  ret <2 x i32> %add
}

define <2 x i32> @addx4_u32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: addx4_u32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4wp $r0 = $r0, 1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 2, i32 2>
  %add = or <2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %add
}

define <2 x i32> @addx4_u32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: addx4_u32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4wp.@ $r0 = $r0, 0x3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 2, i32 2>
  %add = or <2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %add
}

define <2 x i32> @addx4_u32x2_rr_2(<2 x i32> %a) {
; CHECK-LABEL: addx4_u32x2_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x200000003
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx4wp $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 2, i32 2>
  %add = or <2 x i32> %mul, <i32 3, i32 2>
  ret <2 x i32> %add
}

define <2 x i16> @addx8_i16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: addx8_i16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 3, i16 3>
  %add = or <2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %add
}

define <2 x i16> @addx8_u16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: addx8_u16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 3, i16 3>
  %add = or <2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %add
}

define <4 x i16> @addx8_i16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: addx8_i16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 3, i16 3, i16 3, i16 3>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %add
}

define <4 x i16> @addx8_i16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: addx8_i16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq.@ $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 3, i16 3, i16 3, i16 3>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %add
}

define <4 x i16> @addx8_i16x4_rr_2(<4 x i16> %a) {
; CHECK-LABEL: addx8_i16x4_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x3000100020001
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx8hq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 3, i16 3, i16 3, i16 3>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 3>
  ret <4 x i16> %add
}

define <4 x i16> @addx8_u16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: addx8_u16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 3, i16 3, i16 3, i16 3>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %add
}

define <4 x i16> @addx8_u16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: addx8_u16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq.@ $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 3, i16 3, i16 3, i16 3>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %add
}

define <4 x i16> @addx8_u16x4_rr_2(<4 x i16> %a) {
; CHECK-LABEL: addx8_u16x4_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x3000100020001
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx8hq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 3, i16 3, i16 3, i16 3>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 3>
  ret <4 x i16> %add
}

define <2 x i32> @addx8_i32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: addx8_i32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8wp $r0 = $r0, 1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 3, i32 3>
  %add = or <2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %add
}

define <2 x i32> @addx8_i32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: addx8_i32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8wp.@ $r0 = $r0, 0x3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 3, i32 3>
  %add = or <2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %add
}

define <2 x i32> @addx8_i32x2_rr_2(<2 x i32> %a) {
; CHECK-LABEL: addx8_i32x2_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x200000003
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx8wp $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 3, i32 3>
  %add = or <2 x i32> %mul, <i32 3, i32 2>
  ret <2 x i32> %add
}

define <2 x i32> @addx8_u32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: addx8_u32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8wp $r0 = $r0, 1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 3, i32 3>
  %add = or <2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %add
}

define <2 x i32> @addx8_u32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: addx8_u32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8wp.@ $r0 = $r0, 0x3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 3, i32 3>
  %add = or <2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %add
}

define <2 x i32> @addx8_u32x2_rr_2(<2 x i32> %a) {
; CHECK-LABEL: addx8_u32x2_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x200000003
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx8wp $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 3, i32 3>
  %add = or <2 x i32> %mul, <i32 3, i32 2>
  ret <2 x i32> %add
}

define <2 x i16> @addx16_i16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: addx16_i16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 4, i16 4>
  %add = or <2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %add
}

define <2 x i16> @addx16_u16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: addx16_u16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 4, i16 4>
  %add = or <2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %add
}

define <2 x i16> @not_addx16_u16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: not_addx16_u16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sllhqs $r0 = $r0, 4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    orw $r0 = $r0, 0x10010
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 4, i16 4>
  %add = or <2 x i16> %mul, <i16 16, i16 1>
  ret <2 x i16> %add
}

; Again, a negative value makes the or constant too high
define <2 x i16> @not_addx16_u16x2_ri_2(<2 x i16> %a) {
; CHECK-LABEL: not_addx16_u16x2_ri_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sllhqs $r0 = $r0, 4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    orw $r0 = $r0, 0xffff0000
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 4, i16 4>
  %add = or <2 x i16> %mul, <i16 0, i16 -1>
  ret <2 x i16> %add
}
define <4 x i16> @addx16_i16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: addx16_i16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 4, i16 4, i16 4, i16 4>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %add
}

define <4 x i16> @addx16_i16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: addx16_i16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq.@ $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 4, i16 4, i16 4, i16 4>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %add
}

define <4 x i16> @addx16_i16x4_rr_2(<4 x i16> %a) {
; CHECK-LABEL: addx16_i16x4_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x3000100020001
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx16hq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 4, i16 4, i16 4, i16 4>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 3>
  ret <4 x i16> %add
}

define <4 x i16> @addx16_u16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: addx16_u16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 4, i16 4, i16 4, i16 4>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %add
}

define <4 x i16> @addx16_u16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: addx16_u16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq.@ $r0 = $r0, 0x20001
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 4, i16 4, i16 4, i16 4>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %add
}

define <4 x i16> @addx16_u16x4_rr_2(<4 x i16> %a) {
; CHECK-LABEL: addx16_u16x4_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x3000100020001
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx16hq $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 4, i16 4, i16 4, i16 4>
  %add = or <4 x i16> %mul, <i16 1, i16 2, i16 1, i16 3>
  ret <4 x i16> %add
}

define <2 x i32> @addx16_i32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: addx16_i32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp $r0 = $r0, 1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %add = or <2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %add
}

define <2 x i32> @addx16_i32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: addx16_i32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp.@ $r0 = $r0, 0x3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %add = or <2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %add
}

define <2 x i32> @addx16_i32x2_rr_2(<2 x i32> %a) {
; CHECK-LABEL: addx16_i32x2_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x200000003
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx16wp $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %add = or <2 x i32> %mul, <i32 3, i32 2>
  ret <2 x i32> %add
}

define <2 x i32> @addx16_u32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: addx16_u32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp $r0 = $r0, 1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %add = or <2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %add
}

; This one uses a higher const, forcing the add not or
define <2 x i32> @addx16_u32x2_ri_2(<2 x i32> %a) {
; CHECK-LABEL: addx16_u32x2_ri_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp $r0 = $r0, 0xbeef
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %add = add <2 x i32> %mul, <i32 48879, i32 0>
  ret <2 x i32> %add
}

define <2 x i32> @addx16_u32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: addx16_u32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp.@ $r0 = $r0, 0x3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %add = or <2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %add
}

; This one uses a higher const, forcing the add not or
define <2 x i32> @addx16_u32x2_ri_at_2(<2 x i32> %a) {
; CHECK-LABEL: addx16_u32x2_ri_at_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp.@ $r0 = $r0, 0xbb8
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %add = add <2 x i32> %mul, <i32 3000, i32 3000>
  ret <2 x i32> %add
}

define <2 x i32> @addx16_u32x2_rr_2(<2 x i32> %a) {
; CHECK-LABEL: addx16_u32x2_rr_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 0x200000003
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addx16wp $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %add = or <2 x i32> %mul, <i32 3, i32 2>
  ret <2 x i32> %add
}

define <2 x i16> @not_subx2_i16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: not_subx2_i16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 1, i16 1>
  %sub = sub<2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %sub
}

define <2 x i16> @not_subx2_u16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: not_subx2_u16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 1, i16 1>
  %sub = sub<2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %sub
}

define <4 x i16> @not_subx2_i16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: not_subx2_i16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 1, i16 1, i16 1, i16 1>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %sub
}

define <4 x i16> @not_subx2_i16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: not_subx2_i16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq.@ $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 1, i16 1, i16 1, i16 1>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %sub
}

define <4 x i16> @not_subx2_u16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: not_subx2_u16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 1, i16 1, i16 1, i16 1>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %sub
}

define <4 x i16> @not_subx2_u16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: not_subx2_u16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2hq.@ $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 1, i16 1, i16 1, i16 1>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %sub
}

define <2 x i32> @not_subx2_i32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: not_subx2_i32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2wp $r0 = $r0, 0xffffffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 1, i32 1>
  %sub = sub<2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx2_i32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: not_subx2_i32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2wp.@ $r0 = $r0, 0xfffffffd
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 1, i32 1>
  %sub = sub<2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx2_u32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: not_subx2_u32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2wp $r0 = $r0, 0xffffffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 1, i32 1>
  %sub = sub<2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx2_u32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: not_subx2_u32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx2wp.@ $r0 = $r0, 0xfffffffd
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 1, i32 1>
  %sub = sub<2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %sub
}

define <2 x i16> @not_subx4_i16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: not_subx4_i16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 2, i16 2>
  %sub = sub<2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %sub
}

define <2 x i16> @not_subx4_u16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: not_subx4_u16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 2, i16 2>
  %sub = sub<2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %sub
}

define <4 x i16> @not_subx4_i16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: not_subx4_i16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 2, i16 2, i16 2, i16 2>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %sub
}

define <4 x i16> @not_subx4_i16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: not_subx4_i16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq.@ $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 2, i16 2, i16 2, i16 2>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %sub
}

define <4 x i16> @not_subx4_u16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: not_subx4_u16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 2, i16 2, i16 2, i16 2>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %sub
}

define <4 x i16> @not_subx4_u16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: not_subx4_u16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4hq.@ $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 2, i16 2, i16 2, i16 2>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %sub
}

define <2 x i32> @not_subx4_i32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: not_subx4_i32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4wp $r0 = $r0, 0xffffffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 2, i32 2>
  %sub = sub<2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx4_i32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: not_subx4_i32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4wp.@ $r0 = $r0, 0xfffffffd
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 2, i32 2>
  %sub = sub<2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx4_u32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: not_subx4_u32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4wp $r0 = $r0, 0xffffffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 2, i32 2>
  %sub = sub<2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx4_u32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: not_subx4_u32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx4wp.@ $r0 = $r0, 0xfffffffd
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 2, i32 2>
  %sub = sub<2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %sub
}

define <2 x i16> @not_subx8_i16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: not_subx8_i16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 3, i16 3>
  %sub = sub<2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %sub
}

define <2 x i16> @not_subx8_u16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: not_subx8_u16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 3, i16 3>
  %sub = sub<2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %sub
}

define <4 x i16> @not_subx8_i16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: not_subx8_i16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 3, i16 3, i16 3, i16 3>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %sub
}

define <4 x i16> @not_subx8_i16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: not_subx8_i16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq.@ $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 3, i16 3, i16 3, i16 3>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %sub
}

define <4 x i16> @not_subx8_u16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: not_subx8_u16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 3, i16 3, i16 3, i16 3>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %sub
}

define <4 x i16> @not_subx8_u16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: not_subx8_u16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8hq.@ $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 3, i16 3, i16 3, i16 3>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %sub
}

define <2 x i32> @not_subx8_i32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: not_subx8_i32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8wp $r0 = $r0, 0xffffffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 3, i32 3>
  %sub = sub<2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx8_i32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: not_subx8_i32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8wp.@ $r0 = $r0, 0xfffffffd
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 3, i32 3>
  %sub = sub<2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx8_u32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: not_subx8_u32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8wp $r0 = $r0, 0xffffffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 3, i32 3>
  %sub = sub<2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx8_u32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: not_subx8_u32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx8wp.@ $r0 = $r0, 0xfffffffd
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 3, i32 3>
  %sub = sub<2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %sub
}

define <2 x i16> @not_subx16_i16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: not_subx16_i16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 4, i16 4>
  %sub = sub<2 x i16> %mul, <i16 1, i16 2>
  ret <2 x i16> %sub
}

define <2 x i16> @not_subx16_u16x2_ri_(<2 x i16> %a) {
; CHECK-LABEL: not_subx16_u16x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r0, -16
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 4, i16 4>
  %sub = sub<2 x i16> %mul, <i16 16, i16 1>
  ret <2 x i16> %sub
}

define <2 x i16> @not_subx16_u16x2_ri_2(<2 x i16> %a) {
; CHECK-LABEL: not_subx16_u16x2_ri_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r0, 0x10000
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i16> %a, <i16 4, i16 4>
  %sub = sub<2 x i16> %mul, <i16 0, i16 -1>
  ret <2 x i16> %sub
}
define <4 x i16> @not_subx16_i16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: not_subx16_i16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 4, i16 4, i16 4, i16 4>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %sub
}

define <4 x i16> @not_subx16_i16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: not_subx16_i16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq.@ $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 4, i16 4, i16 4, i16 4>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %sub
}

define <4 x i16> @not_subx16_u16x4_ri_(<4 x i16> %a) {
; CHECK-LABEL: not_subx16_u16x4_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 4, i16 4, i16 4, i16 4>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 0, i16 0>
  ret <4 x i16> %sub
}

define <4 x i16> @not_subx16_u16x4_ri_at(<4 x i16> %a) {
; CHECK-LABEL: not_subx16_u16x4_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16hq.@ $r0 = $r0, 0xfffeffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <4 x i16> %a, <i16 4, i16 4, i16 4, i16 4>
  %sub = sub<4 x i16> %mul, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %sub
}

define <2 x i32> @not_subx16_i32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: not_subx16_i32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp $r0 = $r0, 0xffffffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %sub = sub<2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx16_i32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: not_subx16_i32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp.@ $r0 = $r0, 0xfffffffd
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %sub = sub<2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx16_u32x2_ri_(<2 x i32> %a) {
; CHECK-LABEL: not_subx16_u32x2_ri_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp $r0 = $r0, 0xffffffff
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %sub = sub<2 x i32> %mul, <i32 1, i32 0>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx16_u32x2_ri_2(<2 x i32> %a) {
; CHECK-LABEL: not_subx16_u32x2_ri_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp $r0 = $r0, 0xffff4111
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %sub = sub<2 x i32> %mul, <i32 48879, i32 0>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx16_u32x2_ri_at(<2 x i32> %a) {
; CHECK-LABEL: not_subx16_u32x2_ri_at:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp.@ $r0 = $r0, 0xfffffffd
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %sub = sub<2 x i32> %mul, <i32 3, i32 3>
  ret <2 x i32> %sub
}

define <2 x i32> @not_subx16_u32x2_ri_at_2(<2 x i32> %a) {
; CHECK-LABEL: not_subx16_u32x2_ri_at_2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addx16wp.@ $r0 = $r0, 0xfffff448
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %mul = shl <2 x i32> %a, <i32 4, i32 4>
  %sub = sub<2 x i32> %mul, <i32 3000, i32 3000>
  ret <2 x i32> %sub
}

define <2 x i8> @addx2_i8x2_ri(<2 x i8> %a) {
; V1-LABEL: addx2_i8x2_ri:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r1 = $r1, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, 0xf6000a
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x2_ri:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo $r0 = $r0, 0xfffff60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 1, i8 1>
  %add = add <2 x i8> %mul, <i8 10, i8 -10>
  ret <2 x i8> %add
}
define <2 x i8> @addx2_i8x2_ri_or(<2 x i8> %a) {
; V1-LABEL: addx2_i8x2_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r1 = $r1, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 1
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x2_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo $r0 = $r0, 1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 1, i8 1>
  %or = or <2 x i8> %mul, <i8 1, i8 0>
  ret <2 x i8> %or
}

define <2 x i8> @not_addx2_i8x2_ri_or(<2 x i8> %a) {
; V1-LABEL: not_addx2_i8x2_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r1 = $r1, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 513
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx2_i8x2_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 1
; V2-NEXT:    ;;
; V2-NEXT:    orw $r0 = $r0, 513
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 1, i8 1>
  %or = or <2 x i8> %mul, <i8 1, i8 2>
  ret <2 x i8> %or
}

define <2 x i8> @addx2_i8x2_ri_sub(<2 x i8> %a) {
; V1-LABEL: addx2_i8x2_ri_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r1 = $r1, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, 0xff02ff08
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x2_ri_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo $r0 = $r0, 520
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 1, i8 1>
  %sub = sub <2 x i8> %mul, <i8 -8, i8 -2>
  ret <2 x i8> %sub
}

define <2 x i8> @addx2_i8x2_rr(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: addx2_i8x2_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    extfz $r2 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r2 = $r2, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x2_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 1, i8 1>
  %add = add <2 x i8> %mul, %b
  ret <2 x i8> %add
}

define <2 x i8> @not_addx2_i8x2_rr(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: not_addx2_i8x2_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    extfz $r2 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx2_i8x2_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 2
; V2-NEXT:    sllbos $r2 = $r0, 1
; V2-NEXT:    ;;
; V2-NEXT:    insf $r0 = $r2, 7, 0
; V2-NEXT:    ;;
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 1, i8 2>
  %add = add <2 x i8> %mul, %b
  ret <2 x i8> %add
}

define <4 x i8> @addx2_i8x4_ri(<4 x i8> %a) {
; V1-LABEL: addx2_i8x4_ri:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r1 = $r1, 1
; V1-NEXT:    sllw $r2 = $r2, 1
; V1-NEXT:    sllw $r3 = $r3, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq.@ $r0 = $r0, 0xf6000a
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x4_ri:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo $r0 = $r0, 0xf60af60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 1, i8 1, i8 1, i8 1>
  %add = add <4 x i8> %mul, <i8 10, i8 -10, i8 10, i8 -10>
  ret <4 x i8> %add
}

define <4 x i8> @addx2_i8x4_ri_or(<4 x i8> %a) {
; V1-LABEL: addx2_i8x4_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r1 = $r1, 1
; V1-NEXT:    sllw $r2 = $r2, 1
; V1-NEXT:    sllw $r3 = $r3, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0x10001
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x4_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo $r0 = $r0, 0x10001
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 1, i8 1, i8 1, i8 1>
  %or = or <4 x i8> %mul, <i8 1, i8 0, i8 1, i8 0>
  ret <4 x i8> %or
}

define <4 x i8> @not_addx2_i8x4_ri_or(<4 x i8> %a) {
; V1-LABEL: not_addx2_i8x4_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r1 = $r1, 1
; V1-NEXT:    sllw $r2 = $r2, 1
; V1-NEXT:    sllw $r3 = $r3, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0x2010201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx2_i8x4_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 1
; V2-NEXT:    ;;
; V2-NEXT:    orw $r0 = $r0, 0x2010201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 1, i8 1, i8 1, i8 1>
  %or = or <4 x i8> %mul, <i8 1, i8 2, i8 1, i8 2>
  ret <4 x i8> %or
}

define <4 x i8> @addx2_i8x4_ri_sub(<4 x i8> %a) {
; V1-LABEL: addx2_i8x4_ri_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r1 = $r1, 1
; V1-NEXT:    sllw $r2 = $r2, 1
; V1-NEXT:    sllw $r3 = $r3, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq.@ $r0 = $r0, 0xff02ff08
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x4_ri_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo $r0 = $r0, 0x2080208
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 1, i8 1, i8 1, i8 1>
  %sub = sub <4 x i8> %mul, <i8 -8, i8 -2, i8 -8, i8 -2>
  ret <4 x i8> %sub
}

define <4 x i8> @addx2_i8x4_rr(<4 x i8> %a, <4 x i8> %b) {
; V1-LABEL: addx2_i8x4_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r2 = $r0, 24
; V1-NEXT:    extfz $r3 = $r0, 23, 16
; V1-NEXT:    extfz $r4 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r2 = $r2, 1
; V1-NEXT:    sllw $r3 = $r3, 1
; V1-NEXT:    sllw $r4 = $r4, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r4, 15, 8
; V1-NEXT:    insf $r3 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 31, 16
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x4_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 1, i8 1, i8 1, i8 1>
  %add = add <4 x i8> %mul, %b
  ret <4 x i8> %add
}

define <4 x i8> @not_addx2_i8x4_rr(<4 x i8> %a, <4 x i8> %b) {
; V1-LABEL: not_addx2_i8x4_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r2 = $r0, 24
; V1-NEXT:    extfz $r3 = $r0, 23, 16
; V1-NEXT:    extfz $r4 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r2 = $r2, 1
; V1-NEXT:    sllw $r3 = $r3, 2
; V1-NEXT:    sllw $r4 = $r4, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r4, 15, 8
; V1-NEXT:    insf $r3 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 31, 16
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx2_i8x4_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 2
; V2-NEXT:    sllbos $r2 = $r0, 1
; V2-NEXT:    ;;
; V2-NEXT:    copyd $r3 = $r2
; V2-NEXT:    ;;
; V2-NEXT:    insf $r3 = $r0, 7, 0
; V2-NEXT:    ;;
; V2-NEXT:    insf $r0 = $r3, 15, 0
; V2-NEXT:    ;;
; V2-NEXT:    insf $r2 = $r0, 23, 0
; V2-NEXT:    ;;
; V2-NEXT:    addbo $r0 = $r2, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 2, i8 1, i8 2, i8 1>
  %add = add <4 x i8> %mul, %b
  ret <4 x i8> %add
}

define <8 x i8> @addx2_i8x8_ri_(<8 x i8> %a) {
; V1-LABEL: addx2_i8x8_ri_:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 1
; V1-NEXT:    slld $r1 = $r1, 1
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xf60af60a
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x8_ri_:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo $r0 = $r0, 0xf60af60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %add = add <8 x i8> %mul, <i8 10, i8 -10, i8 10, i8 -10, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %add
}

define <8 x i8> @addx2_i8x8_ri_or(<8 x i8> %a) {
; V1-LABEL: addx2_i8x8_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 1
; V1-NEXT:    slld $r1 = $r1, 1
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, 0x10001
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x8_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo $r0 = $r0, 0x10001
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %or = or <8 x i8> %mul, <i8 1, i8 0, i8 1, i8 0, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @not_addx2_i8x8_ri_or(<8 x i8> %a) {
; V1-LABEL: not_addx2_i8x8_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 1
; V1-NEXT:    slld $r1 = $r1, 1
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, 0x10002
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx2_i8x8_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 1
; V2-NEXT:    ;;
; V2-NEXT:    ord $r0 = $r0, 0x10002
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %or = or <8 x i8> %mul, <i8 2, i8 0, i8 1, i8 0, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @addx2_i8x8_ri_sub(<8 x i8> %a) {
; V1-LABEL: addx2_i8x8_ri_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 1
; V1-NEXT:    slld $r1 = $r1, 1
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xfef8fef8
; V1-NEXT:    ;;
; V1-NEXT:    nxord $r0 = $r0, $r1
; V1-NEXT:    ord.@ $r2 = $r0, 0x80808080
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    sbfd $r1 = $r3, $r2
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x8_ri_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo $r0 = $r0, 0x2080208
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %sub = sub <8 x i8> %mul, <i8 -8, i8 -2, i8 -8, i8 -2, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %sub
}

define <8 x i8> @addx2_i8x8_ri_at(<8 x i8> %a) {
; V1-LABEL: addx2_i8x8_ri_at:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 1
; V1-NEXT:    slld $r1 = $r1, 1
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xf60af60af60af60a
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x8_ri_at:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo.@ $r0 = $r0, 0xf60af60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %add = add <8 x i8> %mul, <i8 10, i8 -10, i8 10, i8 -10, i8 10, i8 -10, i8 10, i8 -10>
  ret <8 x i8> %add
}

define <8 x i8> @addx2_i8x8_ri_at_or(<8 x i8> %a) {
; V1-LABEL: addx2_i8x8_ri_at_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 1
; V1-NEXT:    slld $r1 = $r1, 1
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord.@ $r0 = $r0, 0x10001
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x8_ri_at_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo.@ $r0 = $r0, 0x10001
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %or = or <8 x i8> %mul, <i8 1, i8 0, i8 1, i8 0, i8 1, i8 0, i8 1, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @not_addx2_i8x8_ri_at_or(<8 x i8> %a) {
; V1-LABEL: not_addx2_i8x8_ri_at_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 1
; V1-NEXT:    slld $r1 = $r1, 1
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord.@ $r0 = $r0, 0x10002
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx2_i8x8_ri_at_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 1
; V2-NEXT:    ;;
; V2-NEXT:    ord.@ $r0 = $r0, 0x10002
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %or = or <8 x i8> %mul, <i8 2, i8 0, i8 1, i8 0, i8 2, i8 0, i8 1, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @addx2_i8x8_ri_at_sub(<8 x i8> %a) {
; V1-LABEL: addx2_i8x8_ri_at_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 1
; V1-NEXT:    slld $r1 = $r1, 1
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xfef8fef8fef8fef8
; V1-NEXT:    ;;
; V1-NEXT:    nxord $r0 = $r0, $r1
; V1-NEXT:    ord.@ $r2 = $r0, 0x80808080
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    sbfd $r1 = $r3, $r2
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x8_ri_at_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo.@ $r0 = $r0, 0x2080208
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %sub = sub <8 x i8> %mul, <i8 -8, i8 -2, i8 -8, i8 -2, i8 -8, i8 -2, i8 -8, i8 -2>
  ret <8 x i8> %sub
}

define <8 x i8> @addx2_i8x8_rr(<8 x i8> %a, <8 x i8> %b) {
; V1-LABEL: addx2_i8x8_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r2 = $r0, 0xff00ff
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 1
; V1-NEXT:    slld $r2 = $r2, 1
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r2 = $r2, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r2
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx2_i8x8_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx2bo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %add = add <8 x i8> %mul, %b
  ret <8 x i8> %add
}

; TODO: This could be 2 shifts + 1 insert field
define <8 x i8> @not_addx2_i8x8_rr(<8 x i8> %a, <8 x i8> %b) {
; V1-LABEL: not_addx2_i8x8_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    extfz $r2 = $r0, 55, 48
; V1-NEXT:    srld $r3 = $r0, 56
; V1-NEXT:    extfz $r4 = $r0, 47, 40
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r2 = $r2, 1
; V1-NEXT:    sllw $r3 = $r3, 1
; V1-NEXT:    sllw $r4 = $r4, 1
; V1-NEXT:    extfz $r5 = $r0, 39, 32
; V1-NEXT:    ;;
; V1-NEXT:    insf $r2 = $r3, 15, 8
; V1-NEXT:    srlw $r3 = $r0, 24
; V1-NEXT:    sllw $r5 = $r5, 1
; V1-NEXT:    extfz $r6 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    sllw $r3 = $r3, 1
; V1-NEXT:    extfz $r4 = $r0, 23, 16
; V1-NEXT:    insf $r5 = $r4, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r4 = $r4, 1
; V1-NEXT:    insf $r5 = $r2, 31, 16
; V1-NEXT:    sllw $r6 = $r6, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r6, 15, 8
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    insf $r4 = $r3, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r4, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r5, 63, 32
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx2_i8x8_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    make $r2 = 0x101010101010102
; V2-NEXT:    ;;
; V2-NEXT:    extfz $r3 = $r2, 10, 8
; V2-NEXT:    sllbos $r4 = $r0, $r2
; V2-NEXT:    extfz $r5 = $r2, 18, 16
; V2-NEXT:    ;;
; V2-NEXT:    sllbos $r3 = $r0, $r3
; V2-NEXT:    ;;
; V2-NEXT:    insf $r3 = $r4, 7, 0
; V2-NEXT:    sllbos $r4 = $r0, $r5
; V2-NEXT:    extfz $r5 = $r2, 26, 24
; V2-NEXT:    ;;
; V2-NEXT:    sllbos $r3 = $r0, $r5
; V2-NEXT:    insf $r4 = $r3, 15, 0
; V2-NEXT:    extfz $r5 = $r2, 34, 32
; V2-NEXT:    ;;
; V2-NEXT:    insf $r3 = $r4, 23, 0
; V2-NEXT:    sllbos $r4 = $r0, $r5
; V2-NEXT:    extfz $r5 = $r2, 42, 40
; V2-NEXT:    ;;
; V2-NEXT:    extfz $r2 = $r2, 58, 56
; V2-NEXT:    sllbos $r3 = $r0, $r5
; V2-NEXT:    insf $r4 = $r3, 31, 0
; V2-NEXT:    extfz $r5 = $r2, 50, 48
; V2-NEXT:    ;;
; V2-NEXT:    sllbos $r0 = $r0, $r2
; V2-NEXT:    insf $r3 = $r4, 39, 0
; V2-NEXT:    sllbos $r4 = $r0, $r5
; V2-NEXT:    ;;
; V2-NEXT:    insf $r4 = $r3, 47, 0
; V2-NEXT:    ;;
; V2-NEXT:    insf $r0 = $r4, 55, 0
; V2-NEXT:    ;;
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 2, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %add = add <8 x i8> %mul, %b
  ret <8 x i8> %add
}

define <2 x i8> @addx4_i8x2_ri(<2 x i8> %a) {
; V1-LABEL: addx4_i8x2_ri:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r1 = $r1, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, 0xf6000a
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x2_ri:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo $r0 = $r0, 0xfffff60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 2, i8 2>
  %add = add <2 x i8> %mul, <i8 10, i8 -10>
  ret <2 x i8> %add
}
define <2 x i8> @addx4_i8x2_ri_or(<2 x i8> %a) {
; V1-LABEL: addx4_i8x2_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r1 = $r1, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 769
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x2_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo $r0 = $r0, 769
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 2, i8 2>
  %or = or <2 x i8> %mul, <i8 1, i8 3>
  ret <2 x i8> %or
}

define <2 x i8> @not_addx4_i8x2_ri_or(<2 x i8> %a) {
; V1-LABEL: not_addx4_i8x2_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r1 = $r1, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx4_i8x2_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 2
; V2-NEXT:    ;;
; V2-NEXT:    orw $r0 = $r0, 0x401
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 2, i8 2>
  %or = or <2 x i8> %mul, <i8 1, i8 4>
  ret <2 x i8> %or
}

define <2 x i8> @addx4_i8x2_ri_sub(<2 x i8> %a) {
; V1-LABEL: addx4_i8x2_ri_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r1 = $r1, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, 0xff02ff08
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x2_ri_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo $r0 = $r0, 520
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 2, i8 2>
  %sub = sub <2 x i8> %mul, <i8 -8, i8 -2>
  ret <2 x i8> %sub
}

define <2 x i8> @addx4_i8x2_rr(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: addx4_i8x2_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    extfz $r2 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x2_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 2, i8 2>
  %add = add <2 x i8> %mul, %b
  ret <2 x i8> %add
}

define <2 x i8> @not_addx4_i8x2_rr(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: not_addx4_i8x2_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    extfz $r2 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx4_i8x2_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 2
; V2-NEXT:    sllbos $r2 = $r0, 1
; V2-NEXT:    ;;
; V2-NEXT:    insf $r0 = $r2, 7, 0
; V2-NEXT:    ;;
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 1, i8 2>
  %add = add <2 x i8> %mul, %b
  ret <2 x i8> %add
}

define <4 x i8> @addx4_i8x4_ri(<4 x i8> %a) {
; V1-LABEL: addx4_i8x4_ri:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r1 = $r1, 2
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    sllw $r3 = $r3, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq.@ $r0 = $r0, 0xf6000a
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x4_ri:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo $r0 = $r0, 0xf60af60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 2, i8 2, i8 2, i8 2>
  %add = add <4 x i8> %mul, <i8 10, i8 -10, i8 10, i8 -10>
  ret <4 x i8> %add
}

define <4 x i8> @addx4_i8x4_ri_or(<4 x i8> %a) {
; V1-LABEL: addx4_i8x4_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r1 = $r1, 2
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    sllw $r3 = $r3, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0x30201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x4_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo $r0 = $r0, 0x30201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 2, i8 2, i8 2, i8 2>
  %or = or <4 x i8> %mul, <i8 1, i8 2, i8 3, i8 0>
  ret <4 x i8> %or
}

define <4 x i8> @not_addx4_i8x4_ri_or(<4 x i8> %a) {
; V1-LABEL: not_addx4_i8x4_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r1 = $r1, 2
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    sllw $r3 = $r3, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0x4030201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx4_i8x4_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 2
; V2-NEXT:    ;;
; V2-NEXT:    orw $r0 = $r0, 0x4030201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 2, i8 2, i8 2, i8 2>
  %or = or <4 x i8> %mul, <i8 1, i8 2, i8 3, i8 4>
  ret <4 x i8> %or
}

define <4 x i8> @addx4_i8x4_ri_sub(<4 x i8> %a) {
; V1-LABEL: addx4_i8x4_ri_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r1 = $r1, 2
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    sllw $r3 = $r3, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq.@ $r0 = $r0, 0xff02ff08
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x4_ri_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo $r0 = $r0, 0x2080208
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 2, i8 2, i8 2, i8 2>
  %sub = sub <4 x i8> %mul, <i8 -8, i8 -2, i8 -8, i8 -2>
  ret <4 x i8> %sub
}

define <4 x i8> @addx4_i8x4_rr(<4 x i8> %a, <4 x i8> %b) {
; V1-LABEL: addx4_i8x4_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r2 = $r0, 24
; V1-NEXT:    extfz $r3 = $r0, 23, 16
; V1-NEXT:    extfz $r4 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    sllw $r3 = $r3, 2
; V1-NEXT:    sllw $r4 = $r4, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r4, 15, 8
; V1-NEXT:    insf $r3 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 31, 16
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x4_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 2, i8 2, i8 2, i8 2>
  %add = add <4 x i8> %mul, %b
  ret <4 x i8> %add
}

define <4 x i8> @not_addx4_i8x4_rr(<4 x i8> %a, <4 x i8> %b) {
; V1-LABEL: not_addx4_i8x4_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r2 = $r0, 24
; V1-NEXT:    extfz $r3 = $r0, 23, 16
; V1-NEXT:    extfz $r4 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r2 = $r2, 1
; V1-NEXT:    sllw $r3 = $r3, 2
; V1-NEXT:    sllw $r4 = $r4, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r4, 15, 8
; V1-NEXT:    insf $r3 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 31, 16
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx4_i8x4_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 2
; V2-NEXT:    sllbos $r2 = $r0, 1
; V2-NEXT:    ;;
; V2-NEXT:    copyd $r3 = $r2
; V2-NEXT:    ;;
; V2-NEXT:    insf $r3 = $r0, 7, 0
; V2-NEXT:    ;;
; V2-NEXT:    insf $r0 = $r3, 15, 0
; V2-NEXT:    ;;
; V2-NEXT:    insf $r2 = $r0, 23, 0
; V2-NEXT:    ;;
; V2-NEXT:    addbo $r0 = $r2, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 2, i8 1, i8 2, i8 1>
  %add = add <4 x i8> %mul, %b
  ret <4 x i8> %add
}

define <8 x i8> @addx4_i8x8_ri_(<8 x i8> %a) {
; V1-LABEL: addx4_i8x8_ri_:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 2
; V1-NEXT:    slld $r1 = $r1, 2
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xf60af60a
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x8_ri_:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo $r0 = $r0, 0xf60af60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %add = add <8 x i8> %mul, <i8 10, i8 -10, i8 10, i8 -10, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %add
}

define <8 x i8> @addx4_i8x8_ri_or(<8 x i8> %a) {
; V1-LABEL: addx4_i8x8_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 2
; V1-NEXT:    slld $r1 = $r1, 2
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, 0x3000201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x8_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo $r0 = $r0, 0x3000201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %or = or <8 x i8> %mul, <i8 1, i8 2, i8 0, i8 3, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @not_addx4_i8x8_ri_or(<8 x i8> %a) {
; V1-LABEL: not_addx4_i8x8_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 2
; V1-NEXT:    slld $r1 = $r1, 2
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, 0x10004
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx4_i8x8_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 2
; V2-NEXT:    ;;
; V2-NEXT:    ord $r0 = $r0, 0x10004
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %or = or <8 x i8> %mul, <i8 4, i8 0, i8 1, i8 0, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @addx4_i8x8_ri_sub(<8 x i8> %a) {
; V1-LABEL: addx4_i8x8_ri_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 2
; V1-NEXT:    slld $r1 = $r1, 2
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xfef8fef8
; V1-NEXT:    ;;
; V1-NEXT:    nxord $r0 = $r0, $r1
; V1-NEXT:    ord.@ $r2 = $r0, 0x80808080
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    sbfd $r1 = $r3, $r2
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x8_ri_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo $r0 = $r0, 0x2080208
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %sub = sub <8 x i8> %mul, <i8 -8, i8 -2, i8 -8, i8 -2, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %sub
}

define <8 x i8> @addx4_i8x8_ri_at(<8 x i8> %a) {
; V1-LABEL: addx4_i8x8_ri_at:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 2
; V1-NEXT:    slld $r1 = $r1, 2
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xf60af60af60af60a
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x8_ri_at:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo.@ $r0 = $r0, 0xf60af60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %add = add <8 x i8> %mul, <i8 10, i8 -10, i8 10, i8 -10, i8 10, i8 -10, i8 10, i8 -10>
  ret <8 x i8> %add
}

define <8 x i8> @addx4_i8x8_ri_at_or(<8 x i8> %a) {
; V1-LABEL: addx4_i8x8_ri_at_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 2
; V1-NEXT:    slld $r1 = $r1, 2
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord.@ $r0 = $r0, 0x30201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x8_ri_at_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo.@ $r0 = $r0, 0x30201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %or = or <8 x i8> %mul, <i8 1, i8 2, i8 3, i8 0, i8 1, i8 2, i8 3, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @not_addx4_i8x8_ri_at_or(<8 x i8> %a) {
; V1-LABEL: not_addx4_i8x8_ri_at_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 2
; V1-NEXT:    slld $r1 = $r1, 2
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord.@ $r0 = $r0, 0x10402
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx4_i8x8_ri_at_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 2
; V2-NEXT:    ;;
; V2-NEXT:    ord.@ $r0 = $r0, 0x10402
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %or = or <8 x i8> %mul, <i8 2, i8 4, i8 1, i8 0, i8 2, i8 4, i8 1, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @addx4_i8x8_ri_at_sub(<8 x i8> %a) {
; V1-LABEL: addx4_i8x8_ri_at_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 2
; V1-NEXT:    slld $r1 = $r1, 2
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xfef8fef8fef8fef8
; V1-NEXT:    ;;
; V1-NEXT:    nxord $r0 = $r0, $r1
; V1-NEXT:    ord.@ $r2 = $r0, 0x80808080
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    sbfd $r1 = $r3, $r2
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x8_ri_at_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo.@ $r0 = $r0, 0x2080208
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %sub = sub <8 x i8> %mul, <i8 -8, i8 -2, i8 -8, i8 -2, i8 -8, i8 -2, i8 -8, i8 -2>
  ret <8 x i8> %sub
}

define <8 x i8> @addx4_i8x8_rr(<8 x i8> %a, <8 x i8> %b) {
; V1-LABEL: addx4_i8x8_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r2 = $r0, 0xff00ff
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 2
; V1-NEXT:    slld $r2 = $r2, 2
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r2 = $r2, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r2
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx4_i8x8_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx4bo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %add = add <8 x i8> %mul, %b
  ret <8 x i8> %add
}

define <8 x i8> @not_addx4_i8x8_rr(<8 x i8> %a, <8 x i8> %b) {
; V1-LABEL: not_addx4_i8x8_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    extfz $r2 = $r0, 55, 48
; V1-NEXT:    srld $r3 = $r0, 56
; V1-NEXT:    extfz $r4 = $r0, 47, 40
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    sllw $r3 = $r3, 1
; V1-NEXT:    sllw $r4 = $r4, 2
; V1-NEXT:    extfz $r5 = $r0, 39, 32
; V1-NEXT:    ;;
; V1-NEXT:    insf $r2 = $r3, 15, 8
; V1-NEXT:    srlw $r3 = $r0, 24
; V1-NEXT:    sllw $r5 = $r5, 2
; V1-NEXT:    extfz $r6 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    sllw $r3 = $r3, 2
; V1-NEXT:    extfz $r4 = $r0, 23, 16
; V1-NEXT:    insf $r5 = $r4, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r4 = $r4, 2
; V1-NEXT:    insf $r5 = $r2, 31, 16
; V1-NEXT:    sllw $r6 = $r6, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r6, 15, 8
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    insf $r4 = $r3, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r4, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r5, 63, 32
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx4_i8x8_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    make $r2 = 0x102020202020202
; V2-NEXT:    ;;
; V2-NEXT:    extfz $r3 = $r2, 10, 8
; V2-NEXT:    sllbos $r4 = $r0, $r2
; V2-NEXT:    extfz $r5 = $r2, 18, 16
; V2-NEXT:    ;;
; V2-NEXT:    sllbos $r3 = $r0, $r3
; V2-NEXT:    ;;
; V2-NEXT:    insf $r3 = $r4, 7, 0
; V2-NEXT:    sllbos $r4 = $r0, $r5
; V2-NEXT:    extfz $r5 = $r2, 26, 24
; V2-NEXT:    ;;
; V2-NEXT:    sllbos $r3 = $r0, $r5
; V2-NEXT:    insf $r4 = $r3, 15, 0
; V2-NEXT:    extfz $r5 = $r2, 34, 32
; V2-NEXT:    ;;
; V2-NEXT:    insf $r3 = $r4, 23, 0
; V2-NEXT:    sllbos $r4 = $r0, $r5
; V2-NEXT:    extfz $r5 = $r2, 42, 40
; V2-NEXT:    ;;
; V2-NEXT:    extfz $r2 = $r2, 58, 56
; V2-NEXT:    sllbos $r3 = $r0, $r5
; V2-NEXT:    insf $r4 = $r3, 31, 0
; V2-NEXT:    extfz $r5 = $r2, 50, 48
; V2-NEXT:    ;;
; V2-NEXT:    sllbos $r0 = $r0, $r2
; V2-NEXT:    insf $r3 = $r4, 39, 0
; V2-NEXT:    sllbos $r4 = $r0, $r5
; V2-NEXT:    ;;
; V2-NEXT:    insf $r4 = $r3, 47, 0
; V2-NEXT:    ;;
; V2-NEXT:    insf $r0 = $r4, 55, 0
; V2-NEXT:    ;;
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 1>
  %add = add <8 x i8> %mul, %b
  ret <8 x i8> %add
}

define <2 x i8> @addx8_i8x2_ri(<2 x i8> %a) {
; V1-LABEL: addx8_i8x2_ri:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 3
; V1-NEXT:    sllw $r1 = $r1, 3
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, 0xf6000a
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x2_ri:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo $r0 = $r0, 0xfffff60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 3, i8 3>
  %add = add <2 x i8> %mul, <i8 10, i8 -10>
  ret <2 x i8> %add
}
define <2 x i8> @addx8_i8x2_ri_or(<2 x i8> %a) {
; V1-LABEL: addx8_i8x2_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 3
; V1-NEXT:    sllw $r1 = $r1, 3
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0x701
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x2_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo $r0 = $r0, 0x701
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 3, i8 3>
  %or = or <2 x i8> %mul, <i8 1, i8 7>
  ret <2 x i8> %or
}

define <2 x i8> @not_addx8_i8x2_ri_or(<2 x i8> %a) {
; V1-LABEL: not_addx8_i8x2_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 3
; V1-NEXT:    sllw $r1 = $r1, 3
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0x801
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx8_i8x2_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 3
; V2-NEXT:    ;;
; V2-NEXT:    orw $r0 = $r0, 0x801
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 3, i8 3>
  %or = or <2 x i8> %mul, <i8 1, i8 8>
  ret <2 x i8> %or
}

define <2 x i8> @addx8_i8x2_ri_sub(<2 x i8> %a) {
; V1-LABEL: addx8_i8x2_ri_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 3
; V1-NEXT:    sllw $r1 = $r1, 3
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, 0xff02ff08
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x2_ri_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo $r0 = $r0, 520
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 3, i8 3>
  %sub = sub <2 x i8> %mul, <i8 -8, i8 -2>
  ret <2 x i8> %sub
}

define <2 x i8> @addx8_i8x2_rr(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: addx8_i8x2_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    extfz $r2 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 3
; V1-NEXT:    sllw $r2 = $r2, 3
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x2_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 3, i8 3>
  %add = add <2 x i8> %mul, %b
  ret <2 x i8> %add
}

define <2 x i8> @not_addx8_i8x2_rr(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: not_addx8_i8x2_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    extfz $r2 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx8_i8x2_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 2
; V2-NEXT:    sllbos $r2 = $r0, 1
; V2-NEXT:    ;;
; V2-NEXT:    insf $r0 = $r2, 7, 0
; V2-NEXT:    ;;
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 1, i8 2>
  %add = add <2 x i8> %mul, %b
  ret <2 x i8> %add
}

define <4 x i8> @addx8_i8x4_ri(<4 x i8> %a) {
; V1-LABEL: addx8_i8x4_ri:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 3
; V1-NEXT:    sllw $r1 = $r1, 3
; V1-NEXT:    sllw $r2 = $r2, 3
; V1-NEXT:    sllw $r3 = $r3, 3
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq.@ $r0 = $r0, 0xf6000a
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x4_ri:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo $r0 = $r0, 0xf60af60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 3, i8 3, i8 3, i8 3>
  %add = add <4 x i8> %mul, <i8 10, i8 -10, i8 10, i8 -10>
  ret <4 x i8> %add
}

define <4 x i8> @addx8_i8x4_ri_or(<4 x i8> %a) {
; V1-LABEL: addx8_i8x4_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 3
; V1-NEXT:    sllw $r1 = $r1, 3
; V1-NEXT:    sllw $r2 = $r2, 3
; V1-NEXT:    sllw $r3 = $r3, 3
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0x70201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x4_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo $r0 = $r0, 0x70201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 3, i8 3, i8 3, i8 3>
  %or = or <4 x i8> %mul, <i8 1, i8 2, i8 7, i8 0>
  ret <4 x i8> %or
}

define <4 x i8> @not_addx8_i8x4_ri_or(<4 x i8> %a) {
; V1-LABEL: not_addx8_i8x4_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 3
; V1-NEXT:    sllw $r1 = $r1, 3
; V1-NEXT:    sllw $r2 = $r2, 3
; V1-NEXT:    sllw $r3 = $r3, 3
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0x8030201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx8_i8x4_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 3
; V2-NEXT:    ;;
; V2-NEXT:    orw $r0 = $r0, 0x8030201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 3, i8 3, i8 3, i8 3>
  %or = or <4 x i8> %mul, <i8 1, i8 2, i8 3, i8 8>
  ret <4 x i8> %or
}

define <4 x i8> @addx8_i8x4_ri_sub(<4 x i8> %a) {
; V1-LABEL: addx8_i8x4_ri_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 3
; V1-NEXT:    sllw $r1 = $r1, 3
; V1-NEXT:    sllw $r2 = $r2, 3
; V1-NEXT:    sllw $r3 = $r3, 3
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq.@ $r0 = $r0, 0xff02ff08
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x4_ri_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo $r0 = $r0, 0x2080208
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 3, i8 3, i8 3, i8 3>
  %sub = sub <4 x i8> %mul, <i8 -8, i8 -2, i8 -8, i8 -2>
  ret <4 x i8> %sub
}

define <4 x i8> @addx8_i8x4_rr(<4 x i8> %a, <4 x i8> %b) {
; V1-LABEL: addx8_i8x4_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r2 = $r0, 24
; V1-NEXT:    extfz $r3 = $r0, 23, 16
; V1-NEXT:    extfz $r4 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 3
; V1-NEXT:    sllw $r2 = $r2, 3
; V1-NEXT:    sllw $r3 = $r3, 3
; V1-NEXT:    sllw $r4 = $r4, 3
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r4, 15, 8
; V1-NEXT:    insf $r3 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 31, 16
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x4_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 3, i8 3, i8 3, i8 3>
  %add = add <4 x i8> %mul, %b
  ret <4 x i8> %add
}

define <4 x i8> @not_addx8_i8x4_rr(<4 x i8> %a, <4 x i8> %b) {
; V1-LABEL: not_addx8_i8x4_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r2 = $r0, 24
; V1-NEXT:    extfz $r3 = $r0, 23, 16
; V1-NEXT:    extfz $r4 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r2 = $r2, 1
; V1-NEXT:    sllw $r3 = $r3, 2
; V1-NEXT:    sllw $r4 = $r4, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r4, 15, 8
; V1-NEXT:    insf $r3 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 31, 16
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx8_i8x4_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 2
; V2-NEXT:    sllbos $r2 = $r0, 1
; V2-NEXT:    ;;
; V2-NEXT:    copyd $r3 = $r2
; V2-NEXT:    ;;
; V2-NEXT:    insf $r3 = $r0, 7, 0
; V2-NEXT:    ;;
; V2-NEXT:    insf $r0 = $r3, 15, 0
; V2-NEXT:    ;;
; V2-NEXT:    insf $r2 = $r0, 23, 0
; V2-NEXT:    ;;
; V2-NEXT:    addbo $r0 = $r2, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 2, i8 1, i8 2, i8 1>
  %add = add <4 x i8> %mul, %b
  ret <4 x i8> %add
}

define <8 x i8> @addx8_i8x8_ri_(<8 x i8> %a) {
; V1-LABEL: addx8_i8x8_ri_:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 3
; V1-NEXT:    slld $r1 = $r1, 3
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xf60af60a
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x8_ri_:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo $r0 = $r0, 0xf60af60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %add = add <8 x i8> %mul, <i8 10, i8 -10, i8 10, i8 -10, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %add
}

define <8 x i8> @addx8_i8x8_ri_or(<8 x i8> %a) {
; V1-LABEL: addx8_i8x8_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 3
; V1-NEXT:    slld $r1 = $r1, 3
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, 0x7000201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x8_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo $r0 = $r0, 0x7000201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %or = or <8 x i8> %mul, <i8 1, i8 2, i8 0, i8 7, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @not_addx8_i8x8_ri_or(<8 x i8> %a) {
; V1-LABEL: not_addx8_i8x8_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 3
; V1-NEXT:    slld $r1 = $r1, 3
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, 0x10008
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx8_i8x8_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 3
; V2-NEXT:    ;;
; V2-NEXT:    ord $r0 = $r0, 0x10008
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %or = or <8 x i8> %mul, <i8 8, i8 0, i8 1, i8 0, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @addx8_i8x8_ri_sub(<8 x i8> %a) {
; V1-LABEL: addx8_i8x8_ri_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 3
; V1-NEXT:    slld $r1 = $r1, 3
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xfef8fef8
; V1-NEXT:    ;;
; V1-NEXT:    nxord $r0 = $r0, $r1
; V1-NEXT:    ord.@ $r2 = $r0, 0x80808080
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    sbfd $r1 = $r3, $r2
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x8_ri_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo $r0 = $r0, 0x2080208
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %sub = sub <8 x i8> %mul, <i8 -8, i8 -2, i8 -8, i8 -2, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %sub
}

define <8 x i8> @addx8_i8x8_ri_at(<8 x i8> %a) {
; V1-LABEL: addx8_i8x8_ri_at:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 3
; V1-NEXT:    slld $r1 = $r1, 3
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xf60af60af60af60a
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x8_ri_at:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo.@ $r0 = $r0, 0xf60af60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %add = add <8 x i8> %mul, <i8 10, i8 -10, i8 10, i8 -10, i8 10, i8 -10, i8 10, i8 -10>
  ret <8 x i8> %add
}

define <8 x i8> @addx8_i8x8_ri_at_or(<8 x i8> %a) {
; V1-LABEL: addx8_i8x8_ri_at_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 3
; V1-NEXT:    slld $r1 = $r1, 3
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord.@ $r0 = $r0, 0x70201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x8_ri_at_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo.@ $r0 = $r0, 0x70201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %or = or <8 x i8> %mul, <i8 1, i8 2, i8 7, i8 0, i8 1, i8 2, i8 7, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @not_addx8_i8x8_ri_at_or(<8 x i8> %a) {
; V1-LABEL: not_addx8_i8x8_ri_at_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 3
; V1-NEXT:    slld $r1 = $r1, 3
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord.@ $r0 = $r0, 0x10802
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx8_i8x8_ri_at_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 3
; V2-NEXT:    ;;
; V2-NEXT:    ord.@ $r0 = $r0, 0x10802
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %or = or <8 x i8> %mul, <i8 2, i8 8, i8 1, i8 0, i8 2, i8 8, i8 1, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @addx8_i8x8_ri_at_sub(<8 x i8> %a) {
; V1-LABEL: addx8_i8x8_ri_at_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 3
; V1-NEXT:    slld $r1 = $r1, 3
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xfef8fef8fef8fef8
; V1-NEXT:    ;;
; V1-NEXT:    nxord $r0 = $r0, $r1
; V1-NEXT:    ord.@ $r2 = $r0, 0x80808080
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    sbfd $r1 = $r3, $r2
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x8_ri_at_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo.@ $r0 = $r0, 0x2080208
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %sub = sub <8 x i8> %mul, <i8 -8, i8 -2, i8 -8, i8 -2, i8 -8, i8 -2, i8 -8, i8 -2>
  ret <8 x i8> %sub
}

define <8 x i8> @addx8_i8x8_rr(<8 x i8> %a, <8 x i8> %b) {
; V1-LABEL: addx8_i8x8_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r2 = $r0, 0xff00ff
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 3
; V1-NEXT:    slld $r2 = $r2, 3
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r2 = $r2, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r2
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx8_i8x8_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx8bo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %add = add <8 x i8> %mul, %b
  ret <8 x i8> %add
}

define <8 x i8> @not_addx8_i8x8_rr(<8 x i8> %a, <8 x i8> %b) {
; V1-LABEL: not_addx8_i8x8_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    extfz $r2 = $r0, 55, 48
; V1-NEXT:    srld $r3 = $r0, 56
; V1-NEXT:    extfz $r4 = $r0, 47, 40
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    sllw $r3 = $r3, 1
; V1-NEXT:    sllw $r4 = $r4, 3
; V1-NEXT:    extfz $r5 = $r0, 39, 32
; V1-NEXT:    ;;
; V1-NEXT:    insf $r2 = $r3, 15, 8
; V1-NEXT:    srlw $r3 = $r0, 24
; V1-NEXT:    sllw $r5 = $r5, 3
; V1-NEXT:    extfz $r6 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    sllw $r3 = $r3, 3
; V1-NEXT:    extfz $r4 = $r0, 23, 16
; V1-NEXT:    insf $r5 = $r4, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 3
; V1-NEXT:    sllw $r4 = $r4, 3
; V1-NEXT:    insf $r5 = $r2, 31, 16
; V1-NEXT:    sllw $r6 = $r6, 3
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r6, 15, 8
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    insf $r4 = $r3, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r4, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r5, 63, 32
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx8_i8x8_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    make $r2 = 0x102030303030303
; V2-NEXT:    ;;
; V2-NEXT:    extfz $r3 = $r2, 10, 8
; V2-NEXT:    sllbos $r4 = $r0, $r2
; V2-NEXT:    extfz $r5 = $r2, 18, 16
; V2-NEXT:    ;;
; V2-NEXT:    sllbos $r3 = $r0, $r3
; V2-NEXT:    ;;
; V2-NEXT:    insf $r3 = $r4, 7, 0
; V2-NEXT:    sllbos $r4 = $r0, $r5
; V2-NEXT:    extfz $r5 = $r2, 26, 24
; V2-NEXT:    ;;
; V2-NEXT:    sllbos $r3 = $r0, $r5
; V2-NEXT:    insf $r4 = $r3, 15, 0
; V2-NEXT:    extfz $r5 = $r2, 34, 32
; V2-NEXT:    ;;
; V2-NEXT:    insf $r3 = $r4, 23, 0
; V2-NEXT:    sllbos $r4 = $r0, $r5
; V2-NEXT:    extfz $r5 = $r2, 42, 40
; V2-NEXT:    ;;
; V2-NEXT:    extfz $r2 = $r2, 58, 56
; V2-NEXT:    sllbos $r3 = $r0, $r5
; V2-NEXT:    insf $r4 = $r3, 31, 0
; V2-NEXT:    extfz $r5 = $r2, 50, 48
; V2-NEXT:    ;;
; V2-NEXT:    sllbos $r0 = $r0, $r2
; V2-NEXT:    insf $r3 = $r4, 39, 0
; V2-NEXT:    sllbos $r4 = $r0, $r5
; V2-NEXT:    ;;
; V2-NEXT:    insf $r4 = $r3, 47, 0
; V2-NEXT:    ;;
; V2-NEXT:    insf $r0 = $r4, 55, 0
; V2-NEXT:    ;;
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 2, i8 1>
  %add = add <8 x i8> %mul, %b
  ret <8 x i8> %add
}

define <2 x i8> @addx16_i8x2_ri(<2 x i8> %a) {
; V1-LABEL: addx16_i8x2_ri:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 4
; V1-NEXT:    sllw $r1 = $r1, 4
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, 0xf6000a
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x2_ri:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo $r0 = $r0, 0xfffff60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 4, i8 4>
  %add = add <2 x i8> %mul, <i8 10, i8 -10>
  ret <2 x i8> %add
}
define <2 x i8> @addx16_i8x2_ri_or(<2 x i8> %a) {
; V1-LABEL: addx16_i8x2_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 4
; V1-NEXT:    sllw $r1 = $r1, 4
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0xf01
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x2_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo $r0 = $r0, 0xf01
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 4, i8 4>
  %or = or <2 x i8> %mul, <i8 1, i8 15>
  ret <2 x i8> %or
}

define <2 x i8> @not_addx16_i8x2_ri_or(<2 x i8> %a) {
; V1-LABEL: not_addx16_i8x2_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 4
; V1-NEXT:    sllw $r1 = $r1, 4
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0x1001
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx16_i8x2_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 4
; V2-NEXT:    ;;
; V2-NEXT:    orw $r0 = $r0, 0x1001
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 4, i8 4>
  %or = or <2 x i8> %mul, <i8 1, i8 16>
  ret <2 x i8> %or
}

define <2 x i8> @addx16_i8x2_ri_sub(<2 x i8> %a) {
; V1-LABEL: addx16_i8x2_ri_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    extfz $r1 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 4
; V1-NEXT:    sllw $r1 = $r1, 4
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, 0xff02ff08
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x2_ri_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo $r0 = $r0, 520
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 4, i8 4>
  %sub = sub <2 x i8> %mul, <i8 -8, i8 -2>
  ret <2 x i8> %sub
}

define <2 x i8> @addx16_i8x2_rr(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: addx16_i8x2_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    extfz $r2 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 4
; V1-NEXT:    sllw $r2 = $r2, 4
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x2_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 4, i8 4>
  %add = add <2 x i8> %mul, %b
  ret <2 x i8> %add
}

define <2 x i8> @not_addx16_i8x2_rr(<2 x i8> %a, <2 x i8> %b) {
; V1-LABEL: not_addx16_i8x2_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    extfz $r2 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 1
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx16_i8x2_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 2
; V2-NEXT:    sllbos $r2 = $r0, 1
; V2-NEXT:    ;;
; V2-NEXT:    insf $r0 = $r2, 7, 0
; V2-NEXT:    ;;
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <2 x i8> %a, <i8 1, i8 2>
  %add = add <2 x i8> %mul, %b
  ret <2 x i8> %add
}

define <4 x i8> @addx16_i8x4_ri(<4 x i8> %a) {
; V1-LABEL: addx16_i8x4_ri:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 4
; V1-NEXT:    sllw $r1 = $r1, 4
; V1-NEXT:    sllw $r2 = $r2, 4
; V1-NEXT:    sllw $r3 = $r3, 4
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq.@ $r0 = $r0, 0xf6000a
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x4_ri:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo $r0 = $r0, 0xf60af60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 4, i8 4, i8 4, i8 4>
  %add = add <4 x i8> %mul, <i8 10, i8 -10, i8 10, i8 -10>
  ret <4 x i8> %add
}

define <4 x i8> @addx16_i8x4_ri_or(<4 x i8> %a) {
; V1-LABEL: addx16_i8x4_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 4
; V1-NEXT:    sllw $r1 = $r1, 4
; V1-NEXT:    sllw $r2 = $r2, 4
; V1-NEXT:    sllw $r3 = $r3, 4
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0xf0201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x4_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo $r0 = $r0, 0xf0201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 4, i8 4, i8 4, i8 4>
  %or = or <4 x i8> %mul, <i8 1, i8 2, i8 15, i8 0>
  ret <4 x i8> %or
}

define <4 x i8> @not_addx16_i8x4_ri_or(<4 x i8> %a) {
; V1-LABEL: not_addx16_i8x4_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 4
; V1-NEXT:    sllw $r1 = $r1, 4
; V1-NEXT:    sllw $r2 = $r2, 4
; V1-NEXT:    sllw $r3 = $r3, 4
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    orw $r0 = $r0, 0x10030201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx16_i8x4_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 4
; V2-NEXT:    ;;
; V2-NEXT:    orw $r0 = $r0, 0x10030201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 4, i8 4, i8 4, i8 4>
  %or = or <4 x i8> %mul, <i8 1, i8 2, i8 3, i8 16>
  ret <4 x i8> %or
}

define <4 x i8> @addx16_i8x4_ri_sub(<4 x i8> %a) {
; V1-LABEL: addx16_i8x4_ri_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r1 = $r0, 24
; V1-NEXT:    extfz $r2 = $r0, 23, 16
; V1-NEXT:    extfz $r3 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 4
; V1-NEXT:    sllw $r1 = $r1, 4
; V1-NEXT:    sllw $r2 = $r2, 4
; V1-NEXT:    sllw $r3 = $r3, 4
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 15, 8
; V1-NEXT:    insf $r2 = $r1, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r2, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq.@ $r0 = $r0, 0xff02ff08
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x4_ri_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo $r0 = $r0, 0x2080208
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 4, i8 4, i8 4, i8 4>
  %sub = sub <4 x i8> %mul, <i8 -8, i8 -2, i8 -8, i8 -2>
  ret <4 x i8> %sub
}

define <4 x i8> @addx16_i8x4_rr(<4 x i8> %a, <4 x i8> %b) {
; V1-LABEL: addx16_i8x4_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r2 = $r0, 24
; V1-NEXT:    extfz $r3 = $r0, 23, 16
; V1-NEXT:    extfz $r4 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 4
; V1-NEXT:    sllw $r2 = $r2, 4
; V1-NEXT:    sllw $r3 = $r3, 4
; V1-NEXT:    sllw $r4 = $r4, 4
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r4, 15, 8
; V1-NEXT:    insf $r3 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 31, 16
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x4_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 4, i8 4, i8 4, i8 4>
  %add = add <4 x i8> %mul, %b
  ret <4 x i8> %add
}

define <4 x i8> @not_addx16_i8x4_rr(<4 x i8> %a, <4 x i8> %b) {
; V1-LABEL: not_addx16_i8x4_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    srlw $r2 = $r0, 24
; V1-NEXT:    extfz $r3 = $r0, 23, 16
; V1-NEXT:    extfz $r4 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 2
; V1-NEXT:    sllw $r2 = $r2, 1
; V1-NEXT:    sllw $r3 = $r3, 2
; V1-NEXT:    sllw $r4 = $r4, 1
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r4, 15, 8
; V1-NEXT:    insf $r3 = $r2, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r3, 31, 16
; V1-NEXT:    sxlbhq $r1 = $r1
; V1-NEXT:    ;;
; V1-NEXT:    sxlbhq $r0 = $r0
; V1-NEXT:    ;;
; V1-NEXT:    addhq $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx16_i8x4_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 2
; V2-NEXT:    sllbos $r2 = $r0, 1
; V2-NEXT:    ;;
; V2-NEXT:    copyd $r3 = $r2
; V2-NEXT:    ;;
; V2-NEXT:    insf $r3 = $r0, 7, 0
; V2-NEXT:    ;;
; V2-NEXT:    insf $r0 = $r3, 15, 0
; V2-NEXT:    ;;
; V2-NEXT:    insf $r2 = $r0, 23, 0
; V2-NEXT:    ;;
; V2-NEXT:    addbo $r0 = $r2, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <4 x i8> %a, <i8 2, i8 1, i8 2, i8 1>
  %add = add <4 x i8> %mul, %b
  ret <4 x i8> %add
}

define <8 x i8> @addx16_i8x8_ri_(<8 x i8> %a) {
; V1-LABEL: addx16_i8x8_ri_:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 4
; V1-NEXT:    slld $r1 = $r1, 4
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xf60af60a
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x8_ri_:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo $r0 = $r0, 0xf60af60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %add = add <8 x i8> %mul, <i8 10, i8 -10, i8 10, i8 -10, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %add
}

define <8 x i8> @addx16_i8x8_ri_or(<8 x i8> %a) {
; V1-LABEL: addx16_i8x8_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 4
; V1-NEXT:    slld $r1 = $r1, 4
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, 0xf000201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x8_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo $r0 = $r0, 0xf000201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %or = or <8 x i8> %mul, <i8 1, i8 2, i8 0, i8 15, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @not_addx16_i8x8_ri_or(<8 x i8> %a) {
; V1-LABEL: not_addx16_i8x8_ri_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 4
; V1-NEXT:    slld $r1 = $r1, 4
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, 0x10010
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx16_i8x8_ri_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 4
; V2-NEXT:    ;;
; V2-NEXT:    ord $r0 = $r0, 0x10010
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %or = or <8 x i8> %mul, <i8 16, i8 0, i8 1, i8 0, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @addx16_i8x8_ri_sub(<8 x i8> %a) {
; V1-LABEL: addx16_i8x8_ri_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 4
; V1-NEXT:    slld $r1 = $r1, 4
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xfef8fef8
; V1-NEXT:    ;;
; V1-NEXT:    nxord $r0 = $r0, $r1
; V1-NEXT:    ord.@ $r2 = $r0, 0x80808080
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    sbfd $r1 = $r3, $r2
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x8_ri_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo $r0 = $r0, 0x2080208
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %sub = sub <8 x i8> %mul, <i8 -8, i8 -2, i8 -8, i8 -2, i8 0, i8 0, i8 0, i8 0>
  ret <8 x i8> %sub
}

define <8 x i8> @addx16_i8x8_ri_at(<8 x i8> %a) {
; V1-LABEL: addx16_i8x8_ri_at:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 4
; V1-NEXT:    slld $r1 = $r1, 4
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xf60af60af60af60a
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x8_ri_at:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo.@ $r0 = $r0, 0xf60af60a
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %add = add <8 x i8> %mul, <i8 10, i8 -10, i8 10, i8 -10, i8 10, i8 -10, i8 10, i8 -10>
  ret <8 x i8> %add
}

define <8 x i8> @addx16_i8x8_ri_at_or(<8 x i8> %a) {
; V1-LABEL: addx16_i8x8_ri_at_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 4
; V1-NEXT:    slld $r1 = $r1, 4
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord.@ $r0 = $r0, 0xf0201
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x8_ri_at_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo.@ $r0 = $r0, 0xf0201
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %or = or <8 x i8> %mul, <i8 1, i8 2, i8 15, i8 0, i8 1, i8 2, i8 15, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @not_addx16_i8x8_ri_at_or(<8 x i8> %a) {
; V1-LABEL: not_addx16_i8x8_ri_at_or:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 4
; V1-NEXT:    slld $r1 = $r1, 4
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    ;;
; V1-NEXT:    ord.@ $r0 = $r0, 0x11002
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx16_i8x8_ri_at_or:
; V2:       # %bb.0: # %entry
; V2-NEXT:    sllbos $r0 = $r0, 4
; V2-NEXT:    ;;
; V2-NEXT:    ord.@ $r0 = $r0, 0x11002
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %or = or <8 x i8> %mul, <i8 2, i8 16, i8 1, i8 0, i8 2, i8 16, i8 1, i8 0>
  ret <8 x i8> %or
}

define <8 x i8> @addx16_i8x8_ri_at_sub(<8 x i8> %a) {
; V1-LABEL: addx16_i8x8_ri_at_sub:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r0, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 4
; V1-NEXT:    slld $r1 = $r1, 4
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r1 = $r1, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r1
; V1-NEXT:    make $r1 = 0xfef8fef8fef8fef8
; V1-NEXT:    ;;
; V1-NEXT:    nxord $r0 = $r0, $r1
; V1-NEXT:    ord.@ $r2 = $r0, 0x80808080
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    sbfd $r1 = $r3, $r2
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x8_ri_at_sub:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo.@ $r0 = $r0, 0x2080208
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %sub = sub <8 x i8> %mul, <i8 -8, i8 -2, i8 -8, i8 -2, i8 -8, i8 -2, i8 -8, i8 -2>
  ret <8 x i8> %sub
}

define <8 x i8> @addx16_i8x8_rr(<8 x i8> %a, <8 x i8> %b) {
; V1-LABEL: addx16_i8x8_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r2 = $r0, 0xff00ff
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    slld $r0 = $r0, 4
; V1-NEXT:    slld $r2 = $r2, 4
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0xff00ff00
; V1-NEXT:    andd.@ $r2 = $r2, 0xff00ff
; V1-NEXT:    ;;
; V1-NEXT:    ord $r0 = $r0, $r2
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: addx16_i8x8_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    addx16bo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %add = add <8 x i8> %mul, %b
  ret <8 x i8> %add
}

define <8 x i8> @not_addx16_i8x8_rr(<8 x i8> %a, <8 x i8> %b) {
; V1-LABEL: not_addx16_i8x8_rr:
; V1:       # %bb.0: # %entry
; V1-NEXT:    extfz $r2 = $r0, 55, 48
; V1-NEXT:    srld $r3 = $r0, 56
; V1-NEXT:    extfz $r4 = $r0, 47, 40
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r2 = $r2, 2
; V1-NEXT:    sllw $r3 = $r3, 1
; V1-NEXT:    sllw $r4 = $r4, 4
; V1-NEXT:    extfz $r5 = $r0, 39, 32
; V1-NEXT:    ;;
; V1-NEXT:    insf $r2 = $r3, 15, 8
; V1-NEXT:    srlw $r3 = $r0, 24
; V1-NEXT:    sllw $r5 = $r5, 4
; V1-NEXT:    extfz $r6 = $r0, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    zxbd $r0 = $r0
; V1-NEXT:    sllw $r3 = $r3, 4
; V1-NEXT:    extfz $r4 = $r0, 23, 16
; V1-NEXT:    insf $r5 = $r4, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    sllw $r0 = $r0, 4
; V1-NEXT:    sllw $r4 = $r4, 4
; V1-NEXT:    insf $r5 = $r2, 31, 16
; V1-NEXT:    sllw $r6 = $r6, 4
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r6, 15, 8
; V1-NEXT:    andd.@ $r3 = $r1, 0x7f7f7f7f
; V1-NEXT:    insf $r4 = $r3, 15, 8
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r4, 31, 16
; V1-NEXT:    ;;
; V1-NEXT:    insf $r0 = $r5, 63, 32
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r0, $r1
; V1-NEXT:    andd.@ $r2 = $r0, 0x7f7f7f7f
; V1-NEXT:    ;;
; V1-NEXT:    andd.@ $r0 = $r0, 0x80808080
; V1-NEXT:    addd $r1 = $r2, $r3
; V1-NEXT:    ;;
; V1-NEXT:    xord $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;;
;
; V2-LABEL: not_addx16_i8x8_rr:
; V2:       # %bb.0: # %entry
; V2-NEXT:    make $r2 = 0x102040404040404
; V2-NEXT:    ;;
; V2-NEXT:    extfz $r3 = $r2, 10, 8
; V2-NEXT:    sllbos $r4 = $r0, $r2
; V2-NEXT:    extfz $r5 = $r2, 18, 16
; V2-NEXT:    ;;
; V2-NEXT:    sllbos $r3 = $r0, $r3
; V2-NEXT:    ;;
; V2-NEXT:    insf $r3 = $r4, 7, 0
; V2-NEXT:    sllbos $r4 = $r0, $r5
; V2-NEXT:    extfz $r5 = $r2, 26, 24
; V2-NEXT:    ;;
; V2-NEXT:    sllbos $r3 = $r0, $r5
; V2-NEXT:    insf $r4 = $r3, 15, 0
; V2-NEXT:    extfz $r5 = $r2, 34, 32
; V2-NEXT:    ;;
; V2-NEXT:    insf $r3 = $r4, 23, 0
; V2-NEXT:    sllbos $r4 = $r0, $r5
; V2-NEXT:    extfz $r5 = $r2, 42, 40
; V2-NEXT:    ;;
; V2-NEXT:    extfz $r2 = $r2, 58, 56
; V2-NEXT:    sllbos $r3 = $r0, $r5
; V2-NEXT:    insf $r4 = $r3, 31, 0
; V2-NEXT:    extfz $r5 = $r2, 50, 48
; V2-NEXT:    ;;
; V2-NEXT:    sllbos $r0 = $r0, $r2
; V2-NEXT:    insf $r3 = $r4, 39, 0
; V2-NEXT:    sllbos $r4 = $r0, $r5
; V2-NEXT:    ;;
; V2-NEXT:    insf $r4 = $r3, 47, 0
; V2-NEXT:    ;;
; V2-NEXT:    insf $r0 = $r4, 55, 0
; V2-NEXT:    ;;
; V2-NEXT:    addbo $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;;
entry:
  %mul = shl <8 x i8> %a, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 2, i8 1>
  %add = add <8 x i8> %mul, %b
  ret <8 x i8> %add
}
