; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mcpu=kv3-1 -O2 -o - %s | FileCheck %s --check-prefixes=CHECK,CV1
; RUN: llc -mcpu=kv3-2 -O2 -o - %s | FileCheck %s --check-prefixes=CHECK,CV2
; RUN: clang -O2 -march=kv3-1 -c -o /dev/null %s
; RUN: clang -O2 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define <8 x half> @test_ret_const() #0 {
; CHECK-LABEL: test_ret_const:
; CHECK:       # %bb.0:
; CHECK-NEXT:    make $r0 = 0x4400420040003c00
; CHECK-NEXT:    make $r1 = 0x4400420040003c00
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  ret <8 x half> <half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0>
}

define half @test_extract_0(<8 x half> %a) #0 {
; CHECK-LABEL: test_extract_0:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %e = extractelement <8 x half> %a, i32 0
  ret half %e
}

define half @test_extract_1(<8 x half> %a) #0 {
; CHECK-LABEL: test_extract_1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    srlw $r0 = $r0, 16
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %e = extractelement <8 x half> %a, i32 1
  ret half %e
}

define half @test_extract_2(<8 x half> %a) #0 {
; CHECK-LABEL: test_extract_2:
; CHECK:       # %bb.0:
; CHECK-NEXT:    srld $r0 = $r0, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %e = extractelement <8 x half> %a, i32 2
  ret half %e
}

define half @test_extract_3(<8 x half> %a) #0 {
; CHECK-LABEL: test_extract_3:
; CHECK:       # %bb.0:
; CHECK-NEXT:    srld $r0 = $r0, 48
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %e = extractelement <8 x half> %a, i32 3
  ret half %e
}

define half @test_extract_4(<8 x half> %a) #0 {
; CHECK-LABEL: test_extract_4:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %e = extractelement <8 x half> %a, i32 4
  ret half %e
}

define half @test_extract_5(<8 x half> %a) #0 {
; CHECK-LABEL: test_extract_5:
; CHECK:       # %bb.0:
; CHECK-NEXT:    srlw $r0 = $r1, 16
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %e = extractelement <8 x half> %a, i32 5
  ret half %e
}

define half @test_extract_6(<8 x half> %a) #0 {
; CHECK-LABEL: test_extract_6:
; CHECK:       # %bb.0:
; CHECK-NEXT:    srld $r0 = $r1, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %e = extractelement <8 x half> %a, i32 6
  ret half %e
}

define half @test_extract_i(<8 x half> %a, i64 %idx) #0 {
; CHECK-LABEL: test_extract_i:
; CHECK:       # %bb.0:
; CHECK-NEXT:    andw $r2 = $r2, 3
; CHECK-NEXT:    compw.geu $r3 = $r2, 4
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    cmoved.odd $r3 ? $r0 = $r1
; CHECK-NEXT:    sllw $r1 = $r2, 4
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    srld $r0 = $r0, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %e = extractelement <8 x half> %a, i64 %idx
  ret half %e
}

define <8 x half> @test_fadd(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: test_fadd:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, $r2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fadd:
; CV2:       # %bb.0:
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = fadd <8 x half> %a, %b
  ret <8 x half> %r
}

define <8 x half> @test_fadd_imm_0(<8 x half> %a) #0 {
; CV1-LABEL: test_fadd_imm_0:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0x4400420040003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0x4400420040003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fadd_imm_0:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r3 = 0x4400420040003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r2 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fadd <8 x half> <half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0>, %a
  ret <8 x half> %r
}

define <8 x half> @test_fadd_imm_1(<8 x half> %a) #0 {
; CV1-LABEL: test_fadd_imm_1:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0x4400420040003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0x4400420040003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fadd_imm_1:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r3 = 0x4400420040003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r2 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fadd <8 x half> %a, <half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0>
  ret <8 x half> %r
}

define <8 x half> @test_fadd_imm_2(<8 x half> %a) #0 {
; CV1-LABEL: test_fadd_imm_2:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0x40003c0040003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0x40003c0040003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fadd_imm_2:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r3 = 0x40003c0040003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r2 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fadd <8 x half> %a, <half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0>
  ret <8 x half> %r
}

define <8 x half> @test_fadd_imm_3(<8 x half> %a) #0 {
; CV1-LABEL: test_fadd_imm_3:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0x40003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0x40003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fadd_imm_3:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r3 = 0x40003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r2 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fadd <8 x half> %a, <half 1.0, half 2.0, half 0.0, half 0.0, half 1.0, half 2.0, half 0.0, half 0.0>
  ret <8 x half> %r
}

define <8 x half> @test_fsub(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: test_fsub:
; CV1:       # %bb.0:
; CV1-NEXT:    fsbfhq $r0 = $r2, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fsbfhq $r1 = $r3, $r1
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fsub:
; CV2:       # %bb.0:
; CV2-NEXT:    fsbfho $r0r1 = $r2r3, $r0r1
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = fsub <8 x half> %a, %b
  ret <8 x half> %r
}

define <8 x half> @test_fsub_imm_1(<8 x half> %a) #0 {
; CV1-LABEL: test_fsub_imm_1:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0xc400c200c000bc00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0xc400c200c000bc00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fsub_imm_1:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r3 = 0xc400c200c000bc00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r2 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fsub <8 x half> %a, <half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0>
  ret <8 x half> %r
}

define <8 x half> @test_fsub_imm_2(<8 x half> %a) #0 {
; CV1-LABEL: test_fsub_imm_2:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0x80008000c000bc00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0x80008000c000bc00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fsub_imm_2:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r3 = 0x80008000c000bc00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r2 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fsub <8 x half> %a, <half 1.0, half 2.0, half 0.0, half 0.0, half 1.0, half 2.0, half 0.0, half 0.0>
  ret <8 x half> %r
}

define <8 x half> @test_fsub_imm_3(<8 x half> %a) #0 {
; CV1-LABEL: test_fsub_imm_3:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0xc000bc00c000bc00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0xc000bc00c000bc00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fsub_imm_3:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r3 = 0xc000bc00c000bc00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r2 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fsub <8 x half> %a, <half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0>
  ret <8 x half> %r
}

define <8 x half> @test_fsub_fromimm1(<8 x half> %a) #0 {
; CV1-LABEL: test_fsub_fromimm1:
; CV1:       # %bb.0:
; CV1-NEXT:    fsbfhq $r0 = $r0, 0x4400420040003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fsbfhq $r1 = $r1, 0x4400420040003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fsub_fromimm1:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r3 = 0x4400420040003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r2 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fsbfho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fsub <8 x half> <half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0>, %a
  ret <8 x half> %r
}

define <8 x half> @test_fsub_fromimm2(<8 x half> %a) #0 {
; CV1-LABEL: test_fsub_fromimm2:
; CV1:       # %bb.0:
; CV1-NEXT:    fsbfhq $r0 = $r0, 0x40003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fsbfhq $r1 = $r1, 0x40003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fsub_fromimm2:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r3 = 0x40003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r2 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fsbfho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fsub <8 x half> <half 1.0, half 2.0, half 0.0, half 0.0, half 1.0, half 2.0, half 0.0, half 0.0>, %a
  ret <8 x half> %r
}

define <8 x half> @test_fsub_fromimm3(<8 x half> %a) #0 {
; CV1-LABEL: test_fsub_fromimm3:
; CV1:       # %bb.0:
; CV1-NEXT:    fsbfhq $r0 = $r0, 0x40003c0040003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fsbfhq $r1 = $r1, 0x40003c0040003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fsub_fromimm3:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r3 = 0x40003c0040003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r2 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fsbfho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fsub <8 x half> <half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0>, %a
  ret <8 x half> %r
}

define <8 x half> @test_fneg(<8 x half> %a) #0 {
; CV1-LABEL: test_fneg:
; CV1:       # %bb.0:
; CV1-NEXT:    fneghq $r0 = $r0
; CV1-NEXT:    fneghq $r1 = $r1
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 0)
;
; CV2-LABEL: test_fneg:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r3 = 0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r2 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fsbfho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fsub <8 x half> <half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0>, %a
  ret <8 x half> %r
}

define <8 x half> @test_fmul(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: test_fmul:
; CV1:       # %bb.0:
; CV1-NEXT:    fmulhq $r0 = $r0, $r2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fmulhq $r1 = $r1, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fmul:
; CV2:       # %bb.0:
; CV2-NEXT:    fmulho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = fmul <8 x half> %a, %b
  ret <8 x half> %r
}

define <8 x half> @test_fmul_imm(<8 x half> %a) {
; CV1-LABEL: test_fmul_imm:
; CV1:       # %bb.0:
; CV1-NEXT:    fmulhq $r0 = $r0, 0x40003c0040003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fmulhq $r1 = $r1, 0x40003c0040003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fmul_imm:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r3 = 0x40003c0040003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r2 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fmulho $r0r1 = $r0r1, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fmul <8 x half> %a, <half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0>
  ret <8 x half> %r
}

define <8 x half> @test_fdiv(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fdiv:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fwidenlhwp $r4 = $r2
; CHECK-NEXT:    fwidenlhwp $r6 = $r3
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    frecw $r4 = $r4
; CHECK-NEXT:    fwidenmhwp $r5 = $r0
; CHECK-NEXT:    srld $r7 = $r4, 32
; CHECK-NEXT:    srld $r8 = $r6, 32
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    frecw $r9 = $r7
; CHECK-NEXT:    fwidenmhwp $r11 = $r2
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fwidenmhwp $r3 = $r3
; CHECK-NEXT:    fwidenmhwp $r7 = $r1
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    fwidenlhwp $r0 = $r0
; CHECK-NEXT:    frecw $r2 = $r6
; CHECK-NEXT:    srld $r6 = $r11, 32
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    frecw $r10 = $r11
; CHECK-NEXT:    fwidenlhwp $r16 = $r1
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    srld $r1 = $r16, 32
; CHECK-NEXT:    srld $r3 = $r3, 32
; CHECK-NEXT:    frecw $r11 = $r3
; CHECK-NEXT:    ;; # (end cycle 6)
; CHECK-NEXT:    frecw $r8 = $r8
; CHECK-NEXT:    ;; # (end cycle 7)
; CHECK-NEXT:    frecw $r6 = $r6
; CHECK-NEXT:    ;; # (end cycle 8)
; CHECK-NEXT:    frecw $r3 = $r3
; CHECK-NEXT:    ;; # (end cycle 9)
; CHECK-NEXT:    srld $r0 = $r0, 32
; CHECK-NEXT:    fmulw $r4 = $r0, $r4
; CHECK-NEXT:    ;; # (end cycle 12)
; CHECK-NEXT:    fmulw $r0 = $r0, $r9
; CHECK-NEXT:    ;; # (end cycle 13)
; CHECK-NEXT:    srld $r2 = $r5, 32
; CHECK-NEXT:    fmulw $r32 = $r16, $r2
; CHECK-NEXT:    ;; # (end cycle 15)
; CHECK-NEXT:    fmulw $r5 = $r5, $r10
; CHECK-NEXT:    ;; # (end cycle 16)
; CHECK-NEXT:    srld $r0 = $r7, 32
; CHECK-NEXT:    insf $r4 = $r0, 63, 32
; CHECK-NEXT:    fmulw $r33 = $r7, $r11
; CHECK-NEXT:    ;; # (end cycle 17)
; CHECK-NEXT:    fmulw $r1 = $r1, $r8
; CHECK-NEXT:    ;; # (end cycle 18)
; CHECK-NEXT:    fmulw $r2 = $r2, $r6
; CHECK-NEXT:    ;; # (end cycle 19)
; CHECK-NEXT:    fmulw $r0 = $r0, $r3
; CHECK-NEXT:    ;; # (end cycle 20)
; CHECK-NEXT:    insf $r32 = $r1, 63, 32
; CHECK-NEXT:    ;; # (end cycle 22)
; CHECK-NEXT:    insf $r5 = $r2, 63, 32
; CHECK-NEXT:    ;; # (end cycle 23)
; CHECK-NEXT:    fnarrowwhq $r0 = $r4r5
; CHECK-NEXT:    insf $r33 = $r0, 63, 32
; CHECK-NEXT:    ;; # (end cycle 24)
; CHECK-NEXT:    fnarrowwhq $r1 = $r32r33
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 25)
  %r = fdiv <8 x half> %a, %b
  ret <8 x half> %r
}

define <8 x half> @test_frem(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: test_frem:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    fwidenmhw $r1 = $r18
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    fnarrowwh $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r1 = $r18
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    srld $r1 = $r18, 48
; CV1-NEXT:    fnarrowwh $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    srld $r1 = $r18, 32
; CV1-NEXT:    fnarrowwh $r24 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r1 = $r19
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    fnarrowwh $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r1 = $r19
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    srld $r1 = $r19, 48
; CV1-NEXT:    fnarrowwh $r18 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    srld $r1 = $r19, 32
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r18 = $r25, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r26, 31, 16
; CV1-NEXT:    insf $r20 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r0, 63, 32
; CV1-NEXT:    insf $r22 = $r23, 31, 16
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r18
; CV1-NEXT:    insf $r22 = $r20, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r22
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_frem:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    fwidenmhw $r1 = $r18
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    fnarrowwh $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r1 = $r18
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    srld $r1 = $r18, 48
; CV2-NEXT:    fnarrowwh $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    srld $r1 = $r18, 32
; CV2-NEXT:    fnarrowwh $r24 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r1 = $r19
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    fnarrowwh $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r1 = $r19
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    srld $r1 = $r19, 48
; CV2-NEXT:    fnarrowwh $r18 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    srld $r1 = $r19, 32
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r25, 31, 16
; CV2-NEXT:    insf $r20 = $r24, 31, 16
; CV2-NEXT:    insf $r22 = $r23, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r26, 31, 16
; CV2-NEXT:    insf $r22 = $r20, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r18 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r18
; CV2-NEXT:    copyd $r1 = $r22
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = frem <8 x half> %a, %b
  ret <8 x half> %r
}

define void @test_ldst_v8f16(<8 x half>* %a, <8 x half>* %b) {
; CHECK-LABEL: test_ldst_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lq $r2r3 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sq 0[$r1] = $r2r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %t1 = load <8 x half>, <8 x half>* %a
  store <8 x half> %t1, <8 x half>* %b, align 16
  ret void
}

declare <8 x half> @test_callee(<8 x half> %a, <8 x half> %b) #0

define <8 x half> @test_call(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_call:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 24[$r12] = $r16
; CHECK-NEXT:    call test_callee
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    ld $r16 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <8 x half> @test_callee(<8 x half> %a, <8 x half> %b)
  ret <8 x half> %r
}

define <8 x half> @test_call_flipped(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_call_flipped:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 24[$r12] = $r16
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    copyd $r2 = $r0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    copyd $r1 = $r3
; CHECK-NEXT:    copyd $r3 = $r1
; CHECK-NEXT:    call test_callee
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r16 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <8 x half> @test_callee(<8 x half> %b, <8 x half> %a)
  ret <8 x half> %r
}

define <8 x half> @test_tailcall_flipped(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_tailcall_flipped:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    copyd $r1 = $r3
; CHECK-NEXT:    copyd $r2 = $r0
; CHECK-NEXT:    copyd $r3 = $r1
; CHECK-NEXT:    goto test_callee
; CHECK-NEXT:    ;; # (end cycle 0)
  %r = tail call <8 x half> @test_callee(<8 x half> %b, <8 x half> %a)
  ret <8 x half> %r
}

define <8 x half> @test_select(<8 x half> %a, <8 x half> %b, i1 zeroext %c) #0 {
; CHECK-LABEL: test_select:
; CHECK:       # %bb.0:
; CHECK-NEXT:    cmoved.even $r4 ? $r0 = $r2
; CHECK-NEXT:    cmoved.even $r4 ? $r1 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %r = select i1 %c, <8 x half> %a, <8 x half> %b
  ret <8 x half> %r
}

define <8 x half> @test_select_cc(<8 x half> %a, <8 x half> %b, <8 x half> %c, <8 x half> %d) #0 {
; CHECK-LABEL: test_select_cc:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.une $r4 = $r4, $r6
; CHECK-NEXT:    fcompnhq.une $r5 = $r5, $r7
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    cmovehq.even $r4 ? $r0 = $r2
; CHECK-NEXT:    cmovehq.even $r5 ? $r1 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
  %cc = fcmp une <8 x half> %c, %d
  %r = select <8 x i1> %cc, <8 x half> %a, <8 x half> %b
  ret <8 x half> %r
}

define <8 x float> @test_select_cc_f32_f16(<8 x float> %a, <8 x float> %b, <8 x half> %c, <8 x half> %d) #0 {
; CV1-LABEL: test_select_cc_f32_f16:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.une $r8 = $r8, $r10
; CV1-NEXT:    fcompnhq.une $r9 = $r9, $r11
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sxlhwp $r10 = $r8
; CV1-NEXT:    sxmhwp $r11 = $r8
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sxlhwp $r8 = $r9
; CV1-NEXT:    sxmhwp $r9 = $r9
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmovewp.even $r8 ? $r2 = $r6
; CV1-NEXT:    cmovewp.even $r9 ? $r3 = $r7
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    cmovewp.even $r10 ? $r0 = $r4
; CV1-NEXT:    cmovewp.even $r11 ? $r1 = $r5
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_select_cc_f32_f16:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.une $r8 = $r8, $r10
; CV2-NEXT:    fcompnhq.une $r9 = $r9, $r11
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sxlhwp $r8 = $r9
; CV2-NEXT:    sxmhwp $r9 = $r9
; CV2-NEXT:    sxlhwp $r10 = $r8
; CV2-NEXT:    sxmhwp $r11 = $r8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    cmovewp.even $r10 ? $r0 = $r4
; CV2-NEXT:    cmovewp.even $r11 ? $r1 = $r5
; CV2-NEXT:    cmovewp.even $r8 ? $r2 = $r6
; CV2-NEXT:    cmovewp.even $r9 ? $r3 = $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %cc = fcmp une <8 x half> %c, %d
  %r = select <8 x i1> %cc, <8 x float> %a, <8 x float> %b
  ret <8 x float> %r
}

define <8 x half> @test_select_cc_f16_f32(<8 x half> %a, <8 x half> %b, <8 x float> %c, <8 x float> %d) #0 {
; CV1-LABEL: test_select_cc_f16_f32:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnwp.une $r6 = $r6, $r10
; CV1-NEXT:    fcompnwp.une $r7 = $r7, $r11
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnwp.une $r4 = $r4, $r8
; CV1-NEXT:    fcompnwp.une $r5 = $r5, $r9
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r4 = $r4, 0x20100201
; CV1-NEXT:    sbmm8 $r5 = $r5, 0x20100201
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r6 = $r6, 0x20100201
; CV1-NEXT:    sbmm8 $r7 = $r7, 0x20100201
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r4 = $r5, 63, 32
; CV1-NEXT:    insf $r6 = $r7, 63, 32
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    cmovehq.even $r4 ? $r0 = $r2
; CV1-NEXT:    cmovehq.even $r6 ? $r1 = $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 5)
;
; CV2-LABEL: test_select_cc_f16_f32:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnwp.une $r4 = $r4, $r8
; CV2-NEXT:    fcompnwp.une $r5 = $r5, $r9
; CV2-NEXT:    fcompnwp.une $r6 = $r6, $r10
; CV2-NEXT:    fcompnwp.une $r7 = $r7, $r11
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r4 = $r4, 0x20100201
; CV2-NEXT:    sbmm8 $r5 = $r5, 0x20100201
; CV2-NEXT:    sbmm8 $r6 = $r6, 0x20100201
; CV2-NEXT:    sbmm8 $r7 = $r7, 0x20100201
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r4 = $r5, 63, 32
; CV2-NEXT:    insf $r6 = $r7, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    cmovehq.even $r4 ? $r0 = $r2
; CV2-NEXT:    cmovehq.even $r6 ? $r1 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %cc = fcmp une <8 x float> %c, %d
  %r = select <8 x i1> %cc, <8 x half> %a, <8 x half> %b
  ret <8 x half> %r
}

define <8 x i1> @test_fcmp_une(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fcmp_une:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.une $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.une $r1 = $r1, $r3
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fcmp une <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_ueq(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fcmp_ueq:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.ueq $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.ueq $r1 = $r1, $r3
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fcmp ueq <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_ugt(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fcmp_ugt:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.ult $r0 = $r2, $r0
; CHECK-NEXT:    fcompnhq.ult $r1 = $r3, $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fcmp ugt <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_uge(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fcmp_uge:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.uge $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.uge $r1 = $r1, $r3
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fcmp uge <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_ult(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fcmp_ult:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.ult $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.ult $r1 = $r1, $r3
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fcmp ult <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_ule(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fcmp_ule:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.uge $r0 = $r2, $r0
; CHECK-NEXT:    fcompnhq.uge $r1 = $r3, $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fcmp ule <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_uno(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: test_fcmp_uno:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r3
; CV1-NEXT:    fcompnhq.ult $r4 = $r1, $r3
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r2
; CV1-NEXT:    andd $r1 = $r1, $r4
; CV1-NEXT:    fcompnhq.ult $r3 = $r0, $r2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r0 = $r0, $r3
; CV1-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r1, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_uno:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r2
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r3
; CV2-NEXT:    fcompnhq.ult $r3 = $r0, $r2
; CV2-NEXT:    fcompnhq.ult $r4 = $r1, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    andd $r0 = $r0, $r3
; CV2-NEXT:    andd $r1 = $r1, $r4
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r0 = $r1, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fcmp uno <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_one(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fcmp_one:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.one $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.one $r1 = $r1, $r3
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fcmp one <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_oeq(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fcmp_oeq:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.oeq $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.oeq $r1 = $r1, $r3
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fcmp oeq <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_ogt(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fcmp_ogt:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.olt $r0 = $r2, $r0
; CHECK-NEXT:    fcompnhq.olt $r1 = $r3, $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fcmp ogt <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_oge(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fcmp_oge:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.oge $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.oge $r1 = $r1, $r3
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fcmp oge <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_olt(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fcmp_olt:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.olt $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.olt $r1 = $r1, $r3
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fcmp olt <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_ole(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_fcmp_ole:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.oge $r0 = $r2, $r0
; CHECK-NEXT:    fcompnhq.oge $r1 = $r3, $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CHECK-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fcmp ole <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i1> @test_fcmp_ord(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: test_fcmp_ord:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.oge $r1 = $r1, $r3
; CV1-NEXT:    fcompnhq.olt $r4 = $r1, $r3
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oge $r0 = $r0, $r2
; CV1-NEXT:    ord $r1 = $r1, $r4
; CV1-NEXT:    fcompnhq.olt $r3 = $r0, $r2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ord $r0 = $r0, $r3
; CV1-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r1, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_ord:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.oge $r0 = $r0, $r2
; CV2-NEXT:    fcompnhq.oge $r1 = $r1, $r3
; CV2-NEXT:    fcompnhq.olt $r3 = $r0, $r2
; CV2-NEXT:    fcompnhq.olt $r4 = $r1, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    ord $r0 = $r0, $r3
; CV2-NEXT:    ord $r1 = $r1, $r4
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r0 = $r1, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fcmp ord <8 x half> %a, %b
  ret <8 x i1> %r
}

define <8 x i16> @test_fptosi_i16(<8 x half> %a) #0 {
; CHECK-LABEL: test_fptosi_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fwidenlhwp $r0 = $r0
; CHECK-NEXT:    fwidenmhwp $r2 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fwidenlhwp $r1 = $r1
; CHECK-NEXT:    fwidenmhwp $r3 = $r1
; CHECK-NEXT:    fixedwp.rz $r5 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fixedwp.rz $r0 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fixedwp.rz $r3 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    fixedwp.rz $r2 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sbmm8 $r4 = $r5, 0x20100201
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x20100201
; CHECK-NEXT:    ;; # (end cycle 6)
; CHECK-NEXT:    insf $r0 = $r4, 63, 32
; CHECK-NEXT:    sbmm8 $r3 = $r3, 0x20100201
; CHECK-NEXT:    ;; # (end cycle 7)
; CHECK-NEXT:    sbmm8 $r1 = $r2, 0x20100201
; CHECK-NEXT:    ;; # (end cycle 8)
; CHECK-NEXT:    insf $r1 = $r3, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 9)
  %r = fptosi <8 x half> %a to <8 x i16>
  ret <8 x i16> %r
}

define <8 x i32> @test_fptosi_i32(<8 x half> %a) #0 {
; CHECK-LABEL: test_fptosi_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fwidenlhwp $r1 = $r1
; CHECK-NEXT:    fwidenmhwp $r2 = $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fwidenlhwp $r0 = $r0
; CHECK-NEXT:    fixedwp.rz $r3 = $r2, 0
; CHECK-NEXT:    fwidenmhwp $r4 = $r0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fixedwp.rz $r2 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fixedwp.rz $r1 = $r4, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    fixedwp.rz $r0 = $r0, 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
  %r = fptosi <8 x half> %a to <8 x i32>
  ret <8 x i32> %r
}

define <8 x i32> @test_fptoui_8xi32(<8 x half> %a) #0 {
; CHECK-LABEL: test_fptoui_8xi32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fwidenlhwp $r1 = $r1
; CHECK-NEXT:    fwidenmhwp $r2 = $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fwidenlhwp $r0 = $r0
; CHECK-NEXT:    fixeduwp.rz $r3 = $r2, 0
; CHECK-NEXT:    fwidenmhwp $r4 = $r0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fixeduwp.rz $r2 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fixeduwp.rz $r1 = $r4, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    fixeduwp.rz $r0 = $r0, 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
  %r = fptoui <8 x half> %a to <8 x i32>
  ret <8 x i32> %r
}

define <8 x half> @test_uitofp_8xi16(<8 x i16> %a) #0 {
; CV1-LABEL: test_uitofp_8xi16:
; CV1:       # %bb.0:
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x80400000201
; CV1-NEXT:    sbmm8 $r3 = $r0, 0x804000002010
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sbmm8 $r0 = $r1, 0x80400000201
; CV1-NEXT:    sbmm8 $r1 = $r1, 0x804000002010
; CV1-NEXT:    floatuwp.rn $r2 = $r0, 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    floatuwp.rn $r3 = $r3, 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    floatuwp.rn $r4 = $r0, 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    floatuwp.rn $r5 = $r1, 0
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    fnarrowwhq.rn $r0 = $r2r3
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwhq.rn $r1 = $r4r5
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 8)
;
; CV2-LABEL: test_uitofp_8xi16:
; CV2:       # %bb.0:
; CV2-NEXT:    zxlhwp $r0 = $r0
; CV2-NEXT:    zxmhwp $r3 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    zxlhwp $r0 = $r1
; CV2-NEXT:    zxmhwp $r1 = $r1
; CV2-NEXT:    floatuwp.rn $r2 = $r0, 0
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    floatuwp.rn $r3 = $r3, 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    floatuwp.rn $r4 = $r0, 0
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    floatuwp.rn $r5 = $r1, 0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    fnarrowwhq.rn $r0 = $r2r3
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwhq.rn $r1 = $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 8)
  %r = uitofp <8 x i16> %a to <8 x half>
  ret <8 x half> %r
}

define <8 x half> @test_uitofp_8xi32(<8 x i32> %a) #0 {
; CHECK-LABEL: test_uitofp_8xi32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    floatuwp.rn $r0 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    floatuwp.rn $r2 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    floatuwp.rn $r1 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    floatuwp.rn $r3 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    fnarrowwhq.rn $r0 = $r0r1
; CHECK-NEXT:    ;; # (end cycle 6)
; CHECK-NEXT:    fnarrowwhq.rn $r1 = $r2r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 7)
  %r = uitofp <8 x i32> %a to <8 x half>
  ret <8 x half> %r
}

define <8 x half> @test_sitofp_8xi32(<8 x i32> %a) #0 {
; CHECK-LABEL: test_sitofp_8xi32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    floatwp.rn $r0 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    floatwp.rn $r2 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    floatwp.rn $r1 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    floatwp.rn $r3 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    fnarrowwhq.rn $r0 = $r0r1
; CHECK-NEXT:    ;; # (end cycle 6)
; CHECK-NEXT:    fnarrowwhq.rn $r1 = $r2r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 7)
  %r = sitofp <8 x i32> %a to <8 x half>
  ret <8 x half> %r
}

define <8 x half> @test_uitofp_8xi32_fadd(<8 x i32> %a, <8 x half> %b) #0 {
; CV1-LABEL: test_uitofp_8xi32_fadd:
; CV1:       # %bb.0:
; CV1-NEXT:    floatuwp.rn $r2 = $r2, 0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    floatuwp.rn $r0 = $r0, 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    floatuwp.rn $r1 = $r1, 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    floatuwp.rn $r3 = $r3, 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwhq.rn $r0 = $r0r1
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    faddhq $r0 = $r4, $r0
; CV1-NEXT:    fnarrowwhq.rn $r1 = $r2r3
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    faddhq $r1 = $r5, $r1
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 8)
;
; CV2-LABEL: test_uitofp_8xi32_fadd:
; CV2:       # %bb.0:
; CV2-NEXT:    floatuwp.rn $r2 = $r2, 0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    floatuwp.rn $r3 = $r3, 0
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    floatuwp.rn $r0 = $r0, 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    floatuwp.rn $r1 = $r1, 0
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwhq.rn $r3 = $r2r3
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwhq.rn $r2 = $r0r1
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    faddho $r0r1 = $r4r5, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 8)
  %c = uitofp <8 x i32> %a to <8 x half>
  %r = fadd <8 x half> %b, %c
  ret <8 x half> %r
}

define <8 x half> @test_sitofp_8xi32_fadd(<8 x i32> %a, <8 x half> %b) #0 {
; CV1-LABEL: test_sitofp_8xi32_fadd:
; CV1:       # %bb.0:
; CV1-NEXT:    floatwp.rn $r2 = $r2, 0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    floatwp.rn $r0 = $r0, 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    floatwp.rn $r1 = $r1, 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    floatwp.rn $r3 = $r3, 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwhq.rn $r0 = $r0r1
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    faddhq $r0 = $r4, $r0
; CV1-NEXT:    fnarrowwhq.rn $r1 = $r2r3
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    faddhq $r1 = $r5, $r1
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 8)
;
; CV2-LABEL: test_sitofp_8xi32_fadd:
; CV2:       # %bb.0:
; CV2-NEXT:    floatwp.rn $r2 = $r2, 0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    floatwp.rn $r3 = $r3, 0
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    floatwp.rn $r0 = $r0, 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    floatwp.rn $r1 = $r1, 0
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwhq.rn $r3 = $r2r3
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwhq.rn $r2 = $r0r1
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    faddho $r0r1 = $r4r5, $r2r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 8)
  %c = sitofp <8 x i32> %a to <8 x half>
  %r = fadd <8 x half> %b, %c
  ret <8 x half> %r
}

define <8 x half> @test_fptrunc_8xfloat(<8 x float> %a) #0 {
; CHECK-LABEL: test_fptrunc_8xfloat:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fnarrowwhq $r0 = $r0r1
; CHECK-NEXT:    fnarrowwhq $r1 = $r2r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %r = fptrunc <8 x float> %a to <8 x half>
  ret <8 x half> %r
}

define <8 x float> @test_fpext_8xfloat(<8 x half> %a) #0 {
; CHECK-LABEL: test_fpext_8xfloat:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fwidenlhwp $r2 = $r1
; CHECK-NEXT:    fwidenlhwp $r4 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    fwidenmhwp $r1 = $r0
; CHECK-NEXT:    fwidenmhwp $r3 = $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
  %r = fpext <8 x half> %a to <8 x float>
  ret <8 x float> %r
}

define <8 x i16> @test_bitcast_8xhalf_to_8xi16(<8 x half> %a) #0 {
; CHECK-LABEL: test_bitcast_8xhalf_to_8xi16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = bitcast <8 x half> %a to <8 x i16>
  ret <8 x i16> %r
}

define <8 x half> @test_bitcast_8xi16_to_8xhalf(<8 x i16> %a) #0 {
; CHECK-LABEL: test_bitcast_8xi16_to_8xhalf:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = bitcast <8 x i16> %a to <8 x half>
  ret <8 x half> %r
}

declare <8 x half> @llvm.sqrt.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.powi.v8f16(<8 x half> %a, i32 %b) #0
declare <8 x half> @llvm.sin.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.cos.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.pow.v8f16(<8 x half> %a, <8 x half> %b) #0
declare <8 x half> @llvm.exp.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.exp2.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.log.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.log10.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.log2.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.fma.v8f16(<8 x half> %a, <8 x half> %b, <8 x half> %c) #0
declare <8 x half> @llvm.fabs.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.minnum.v8f16(<8 x half> %a, <8 x half> %b) #0
declare <8 x half> @llvm.maxnum.v8f16(<8 x half> %a, <8 x half> %b) #0
declare <8 x half> @llvm.copysign.v8f16(<8 x half> %a, <8 x half> %b) #0
declare <8 x half> @llvm.floor.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.ceil.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.trunc.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.rint.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.nearbyint.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.round.v8f16(<8 x half> %a) #0
declare <8 x half> @llvm.fmuladd.v8f16(<8 x half> %a, <8 x half> %b, <8 x half> %c) #0

define <8 x half> @test_sqrt(<8 x half> %a) #0 {
; CV1-LABEL: test_sqrt:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_sqrt:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <8 x half> @llvm.sqrt.v8f16(<8 x half> %a)
  ret <8 x half> %r
}

define <8 x half> @test_powi(<8 x half> %a, i32 %b) #0 {
; CV1-LABEL: test_powi:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r2
; CV1-NEXT:    copyd $r19 = $r1
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    fnarrowwh $r22 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    fnarrowwh $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    fnarrowwh $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    fnarrowwh $r24 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    fnarrowwh $r25 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    fnarrowwh $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r25, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r26, 31, 16
; CV1-NEXT:    insf $r24 = $r23, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    insf $r21 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r21 = $r24, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r21
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_powi:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r2
; CV2-NEXT:    copyd $r19 = $r1
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    fnarrowwh $r22 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    fnarrowwh $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    fnarrowwh $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    fnarrowwh $r24 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    fnarrowwh $r25 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    fnarrowwh $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r19 = $r25, 31, 16
; CV2-NEXT:    insf $r21 = $r22, 31, 16
; CV2-NEXT:    insf $r24 = $r23, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r26, 31, 16
; CV2-NEXT:    insf $r21 = $r24, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r21
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
 %r = call <8 x half> @llvm.powi.v8f16(<8 x half> %a, i32 %b)
 ret <8 x half> %r
}

define <8 x half> @test_sin(<8 x half> %a) #0 {
; CV1-LABEL: test_sin:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_sin:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <8 x half> @llvm.sin.v8f16(<8 x half> %a)
  ret <8 x half> %r
}

define <8 x half> @test_cos(<8 x half> %a) #0 {
; CV1-LABEL: test_cos:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_cos:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <8 x half> @llvm.cos.v8f16(<8 x half> %a)
  ret <8 x half> %r
}

define <8 x half> @test_pow(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: test_pow:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    fwidenmhw $r1 = $r18
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    fnarrowwh $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r1 = $r18
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    srld $r1 = $r18, 48
; CV1-NEXT:    fnarrowwh $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    srld $r1 = $r18, 32
; CV1-NEXT:    fnarrowwh $r24 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r1 = $r19
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    fnarrowwh $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r1 = $r19
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    srld $r1 = $r19, 48
; CV1-NEXT:    fnarrowwh $r18 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    srld $r1 = $r19, 32
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r18 = $r25, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r26, 31, 16
; CV1-NEXT:    insf $r20 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r0, 63, 32
; CV1-NEXT:    insf $r22 = $r23, 31, 16
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r18
; CV1-NEXT:    insf $r22 = $r20, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r22
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_pow:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    fwidenmhw $r1 = $r18
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    fnarrowwh $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r1 = $r18
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    srld $r1 = $r18, 48
; CV2-NEXT:    fnarrowwh $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    srld $r1 = $r18, 32
; CV2-NEXT:    fnarrowwh $r24 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r1 = $r19
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    fnarrowwh $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r1 = $r19
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    srld $r1 = $r19, 48
; CV2-NEXT:    fnarrowwh $r18 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    srld $r1 = $r19, 32
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r25, 31, 16
; CV2-NEXT:    insf $r20 = $r24, 31, 16
; CV2-NEXT:    insf $r22 = $r23, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r26, 31, 16
; CV2-NEXT:    insf $r22 = $r20, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r18 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r18
; CV2-NEXT:    copyd $r1 = $r22
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
 %r = call <8 x half> @llvm.pow.v8f16(<8 x half> %a, <8 x half> %b)
 ret <8 x half> %r
}

define <8 x half> @test_exp(<8 x half> %a) #0 {
; CV1-LABEL: test_exp:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_exp:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
 %r = call <8 x half> @llvm.exp.v8f16(<8 x half> %a)
 ret <8 x half> %r
}

define <8 x half> @test_exp2(<8 x half> %a) #0 {
; CV1-LABEL: test_exp2:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_exp2:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
 %r = call <8 x half> @llvm.exp2.v8f16(<8 x half> %a)
 ret <8 x half> %r
}

define <8 x half> @test_log(<8 x half> %a) #0 {
; CV1-LABEL: test_log:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_log:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
 %r = call <8 x half> @llvm.log.v8f16(<8 x half> %a)
 ret <8 x half> %r
}

define <8 x half> @test_log10(<8 x half> %a) #0 {
; CV1-LABEL: test_log10:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_log10:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
 %r = call <8 x half> @llvm.log10.v8f16(<8 x half> %a)
 ret <8 x half> %r
}

define <8 x half> @test_log2(<8 x half> %a) #0 {
; CV1-LABEL: test_log2:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_log2:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
 %r = call <8 x half> @llvm.log2.v8f16(<8 x half> %a)
 ret <8 x half> %r
}

define <8 x half> @test_fma(<8 x half> %a, <8 x half> %b, <8 x half> %c) #0 {
; CV1-LABEL: test_fma:
; CV1:       # %bb.0:
; CV1-NEXT:    ffmahq $r4 = $r0, $r2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    ffmahq $r5 = $r1, $r3
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    copyd $r0 = $r4
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r1 = $r5
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 5)
;
; CV2-LABEL: test_fma:
; CV2:       # %bb.0:
; CV2-NEXT:    ffmaho $r4r5 = $r0r1, $r2r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r0 = $r4
; CV2-NEXT:    copyd $r1 = $r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 4)
  %r = call <8 x half> @llvm.fma.v8f16(<8 x half> %a, <8 x half> %b, <8 x half> %c)
  ret <8 x half> %r
}

define <8 x half> @test_fabs(<8 x half> %a) #0 {
; CHECK-LABEL: test_fabs:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fabshq $r0 = $r0
; CHECK-NEXT:    fabshq $r1 = $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %r = call <8 x half> @llvm.fabs.v8f16(<8 x half> %a)
  ret <8 x half> %r
}

define <8 x half> @test_minnum(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: test_minnum:
; CV1:       # %bb.0:
; CV1-NEXT:    sllhqs $r4 = $r0, 1
; CV1-NEXT:    sllhqs $r5 = $r1, 1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    compnhq.gtu $r4 = $r4, 0xf800f800.@
; CV1-NEXT:    compnhq.gtu $r5 = $r5, 0xf800f800.@
; CV1-NEXT:    fcompnhq.olt $r6 = $r2, $r0
; CV1-NEXT:    fcompnhq.olt $r7 = $r3, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ord $r4 = $r6, $r4
; CV1-NEXT:    ord $r5 = $r7, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmovehq.odd $r4 ? $r0 = $r2
; CV1-NEXT:    cmovehq.odd $r5 ? $r1 = $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_minnum:
; CV2:       # %bb.0:
; CV2-NEXT:    fminhq $r0 = $r0, $r2
; CV2-NEXT:    fminhq $r1 = $r1, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = call <8 x half> @llvm.minnum.v8f16(<8 x half> %a, <8 x half> %b)
  ret <8 x half> %r
}

define <8 x half> @test_minnum_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_minnum_fast:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fminhq $r0 = $r0, $r2
; CHECK-NEXT:    fminhq $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %r = call fast <8 x half> @llvm.minnum.v8f16(<8 x half> %a, <8 x half> %b)
  ret <8 x half> %r
}

define <8 x half> @test_maxnum(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: test_maxnum:
; CV1:       # %bb.0:
; CV1-NEXT:    sllhqs $r4 = $r0, 1
; CV1-NEXT:    sllhqs $r5 = $r1, 1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    compnhq.gtu $r4 = $r4, 0xf800f800.@
; CV1-NEXT:    compnhq.gtu $r5 = $r5, 0xf800f800.@
; CV1-NEXT:    fcompnhq.olt $r6 = $r0, $r2
; CV1-NEXT:    fcompnhq.olt $r7 = $r1, $r3
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ord $r4 = $r6, $r4
; CV1-NEXT:    ord $r5 = $r7, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmovehq.odd $r4 ? $r0 = $r2
; CV1-NEXT:    cmovehq.odd $r5 ? $r1 = $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_maxnum:
; CV2:       # %bb.0:
; CV2-NEXT:    fmaxhq $r0 = $r0, $r2
; CV2-NEXT:    fmaxhq $r1 = $r1, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = call <8 x half> @llvm.maxnum.v8f16(<8 x half> %a, <8 x half> %b)
  ret <8 x half> %r
}

define <8 x half> @test_maxnum_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_maxnum_fast:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmaxhq $r0 = $r0, $r2
; CHECK-NEXT:    fmaxhq $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %r = call fast <8 x half> @llvm.maxnum.v8f16(<8 x half> %a, <8 x half> %b)
  ret <8 x half> %r
}

define <8 x half> @test_copysign(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_copysign:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fabshq $r0 = $r0
; CHECK-NEXT:    fabshq $r1 = $r1
; CHECK-NEXT:    andd $r2 = $r2, 0x80008000.@
; CHECK-NEXT:    andd $r3 = $r3, 0x80008000.@
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    ord $r0 = $r0, $r2
; CHECK-NEXT:    ord $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
  %r = call <8 x half> @llvm.copysign.v8f16(<8 x half> %a, <8 x half> %b)
  ret <8 x half> %r
}

define <8 x half> @test_copysign_v4f32(<8 x half> %a, <8 x float> %b) #0 {
; CV1-LABEL: test_copysign_v4f32:
; CV1:       # %bb.0:
; CV1-NEXT:    fnarrowwhq $r2 = $r2r3
; CV1-NEXT:    fnarrowwhq $r4 = $r4r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fabshq $r0 = $r0
; CV1-NEXT:    fabshq $r1 = $r1
; CV1-NEXT:    andd $r2 = $r2, 0x80008000.@
; CV1-NEXT:    andd $r3 = $r4, 0x80008000.@
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ord $r0 = $r0, $r2
; CV1-NEXT:    ord $r1 = $r1, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 2)
;
; CV2-LABEL: test_copysign_v4f32:
; CV2:       # %bb.0:
; CV2-NEXT:    fabshq $r0 = $r0
; CV2-NEXT:    fabshq $r1 = $r1
; CV2-NEXT:    fnarrowwhq $r2 = $r2r3
; CV2-NEXT:    fnarrowwhq $r4 = $r4r5
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    andd $r2 = $r2, 0x80008000.@
; CV2-NEXT:    andd $r3 = $r4, 0x80008000.@
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ord $r0 = $r0, $r2
; CV2-NEXT:    ord $r1 = $r1, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %tb = fptrunc <8 x float> %b to <8 x half>
  %r = call <8 x half> @llvm.copysign.v8f16(<8 x half> %a, <8 x half> %tb)
  ret <8 x half> %r
}

define <8 x float> @test_copysign_extended(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: test_copysign_extended:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fabshq $r0 = $r0
; CHECK-NEXT:    fabshq $r1 = $r1
; CHECK-NEXT:    andd $r2 = $r2, 0x80008000.@
; CHECK-NEXT:    andd $r3 = $r3, 0x80008000.@
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    ord $r1 = $r1, $r3
; CHECK-NEXT:    ord $r4 = $r0, $r2
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fwidenlhwp $r2 = $r1
; CHECK-NEXT:    fwidenmhwp $r3 = $r1
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fwidenlhwp $r0 = $r4
; CHECK-NEXT:    fwidenmhwp $r1 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 3)
  %r = call <8 x half> @llvm.copysign.v8f16(<8 x half> %a, <8 x half> %b)
  %xr = fpext <8 x half> %r to <8 x float>
  ret <8 x float> %xr
}

define <8 x half> @test_floor(<8 x half> %a) #0 {
; CV1-LABEL: test_floor:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_floor:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <8 x half> @llvm.floor.v8f16(<8 x half> %a)
  ret <8 x half> %r
}

define <8 x half> @test_ceil(<8 x half> %a) #0 {
; CV1-LABEL: test_ceil:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_ceil:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <8 x half> @llvm.ceil.v8f16(<8 x half> %a)
  ret <8 x half> %r
}

define <8 x half> @test_trunc(<8 x half> %a) #0 {
; CV1-LABEL: test_trunc:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_trunc:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <8 x half> @llvm.trunc.v8f16(<8 x half> %a)
  ret <8 x half> %r
}

define <8 x half> @test_rint(<8 x half> %a) #0 {
; CV1-LABEL: test_rint:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_rint:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <8 x half> @llvm.rint.v8f16(<8 x half> %a)
  ret <8 x half> %r
}

define <8 x half> @test_nearbyint(<8 x half> %a) #0 {
; CV1-LABEL: test_nearbyint:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_nearbyint:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <8 x half> @llvm.nearbyint.v8f16(<8 x half> %a)
  ret <8 x half> %r
}

define <8 x half> @test_round(<8 x half> %a) #0 {
; CV1-LABEL: test_round:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -96
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 88[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sd 80[$r12] = $r26
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sq 64[$r12] = $r24r25
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 32[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 16[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r1
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    fnarrowwh $r18 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r23 = $r23
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fnarrowwh $r19 = $r21
; CV1-NEXT:    fnarrowwh $r20 = $r20
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r19 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r20, 31, 16
; CV1-NEXT:    insf $r23 = $r24, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r18 = $r26, 31, 16
; CV1-NEXT:    insf $r19 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    lq $r18r19 = 16[$r12]
; CV1-NEXT:    copyd $r1 = $r18
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    lq $r24r25 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r26 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    ld $r16 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 96
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_round:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -96
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 88[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    sd 80[$r12] = $r26
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sq 64[$r12] = $r24r25
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 32[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 16[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r1
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    fnarrowwh $r18 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r23 = $r23
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fnarrowwh $r19 = $r21
; CV2-NEXT:    fnarrowwh $r20 = $r20
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    insf $r18 = $r26, 31, 16
; CV2-NEXT:    insf $r19 = $r22, 31, 16
; CV2-NEXT:    insf $r23 = $r24, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r20, 31, 16
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    lq $r18r19 = 16[$r12]
; CV2-NEXT:    copyd $r0 = $r19
; CV2-NEXT:    copyd $r1 = $r18
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    lo $r20r21r22r23 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r24r25 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    ld $r26 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    ld $r16 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 96
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <8 x half> @llvm.round.v8f16(<8 x half> %a)
  ret <8 x half> %r
}

define <8 x half> @test_fmuladd(<8 x half> %a, <8 x half> %b, <8 x half> %c) #0 {
; CV1-LABEL: test_fmuladd:
; CV1:       # %bb.0:
; CV1-NEXT:    ffmahq $r4 = $r0, $r2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    ffmahq $r5 = $r1, $r3
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    copyd $r0 = $r4
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r1 = $r5
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 5)
;
; CV2-LABEL: test_fmuladd:
; CV2:       # %bb.0:
; CV2-NEXT:    ffmaho $r4r5 = $r0r1, $r2r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r0 = $r4
; CV2-NEXT:    copyd $r1 = $r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 4)
  %r = call <8 x half> @llvm.fmuladd.v8f16(<8 x half> %a, <8 x half> %b, <8 x half> %c)
  ret <8 x half> %r
}

define <8 x half> @test_shufflevector(<8 x half> %a) #0 {
; CV1-LABEL: test_shufflevector:
; CV1:       # %bb.0:
; CV1-NEXT:    srld $r2 = $r1, 48
; CV1-NEXT:    srlw $r3 = $r1, 16
; CV1-NEXT:    srld $r4 = $r1, 32
; CV1-NEXT:    srlw $r5 = $r0, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r1 = $r0, 48
; CV1-NEXT:    insf $r2 = $r4, 31, 16
; CV1-NEXT:    insf $r3 = $r1, 31, 16
; CV1-NEXT:    srld $r4 = $r0, 32
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r1 = $r4, 31, 16
; CV1-NEXT:    insf $r5 = $r0, 31, 16
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r1 = $r5, 63, 32
; CV1-NEXT:    insf $r2 = $r3, 63, 32
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_shufflevector:
; CV2:       # %bb.0:
; CV2-NEXT:    srld $r2 = $r1, 48
; CV2-NEXT:    srlw $r4 = $r1, 16
; CV2-NEXT:    srld $r5 = $r1, 32
; CV2-NEXT:    srlw $r6 = $r0, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r2 = $r5, 31, 16
; CV2-NEXT:    srld $r3 = $r0, 48
; CV2-NEXT:    insf $r4 = $r1, 31, 16
; CV2-NEXT:    srld $r7 = $r0, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r2 = $r4, 63, 32
; CV2-NEXT:    insf $r3 = $r7, 31, 16
; CV2-NEXT:    insf $r6 = $r0, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r2
; CV2-NEXT:    insf $r3 = $r6, 63, 32
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    copyd $r1 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 4)
  %s = shufflevector <8 x half> %a, <8 x half> undef, <8 x i32> <i32 7, i32 6, i32 5, i32 4, i32 3, i32 2, i32 1, i32 0>
  ret <8 x half> %s
}

define <8 x half> @test_shufflevector2(<8 x half> %a) #0 {
; CV1-LABEL: test_shufflevector2:
; CV1:       # %bb.0:
; CV1-NEXT:    srld $r2 = $r0, 32
; CV1-NEXT:    srld $r3 = $r0, 48
; CV1-NEXT:    srld $r4 = $r1, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srlw $r2 = $r0, 16
; CV1-NEXT:    insf $r3 = $r2, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r0 = $r2, 31, 16
; CV1-NEXT:    insf $r1 = $r4, 31, 16
; CV1-NEXT:    srld $r2 = $r1, 48
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r0 = $r3, 63, 32
; CV1-NEXT:    insf $r2 = $r2, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r1 = $r2, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_shufflevector2:
; CV2:       # %bb.0:
; CV2-NEXT:    srld $r2 = $r0, 32
; CV2-NEXT:    srld $r3 = $r0, 48
; CV2-NEXT:    srld $r4 = $r1, 32
; CV2-NEXT:    srld $r5 = $r1, 48
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r1 = $r4, 31, 16
; CV2-NEXT:    srlw $r2 = $r0, 16
; CV2-NEXT:    insf $r3 = $r2, 31, 16
; CV2-NEXT:    insf $r5 = $r5, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    insf $r1 = $r5, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r0 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %s = shufflevector <8 x half> %a, <8 x half> undef, <8 x i32> <i32 0, i32 1, i32 3, i32 2, i32 4, i32 6, i32 7, i32 7>
  ret <8 x half> %s
}

define <8 x half> @test_insertelement0(<8 x half> %a, half %x) #0 {
; CHECK-LABEL: test_insertelement0:
; CHECK:       # %bb.0:
; CHECK-NEXT:    insf $r0 = $r2, 15, 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %i = insertelement <8 x half> %a, half %x, i64 0
  ret <8 x half> %i
}

define <8 x half> @test_insertelement1(<8 x half> %a, half %x) #0 {
; CHECK-LABEL: test_insertelement1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    insf $r0 = $r2, 31, 16
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %i = insertelement <8 x half> %a, half %x, i64 1
  ret <8 x half> %i
}

define <8 x half> @test_insertelement2(<8 x half> %a, half %x) #0 {
; CHECK-LABEL: test_insertelement2:
; CHECK:       # %bb.0:
; CHECK-NEXT:    insf $r0 = $r2, 47, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %i = insertelement <8 x half> %a, half %x, i64 2
  ret <8 x half> %i
}

define <8 x half> @test_insertelement3(<8 x half> %a, half %x) #0 {
; CHECK-LABEL: test_insertelement3:
; CHECK:       # %bb.0:
; CHECK-NEXT:    insf $r0 = $r2, 63, 48
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %i = insertelement <8 x half> %a, half %x, i64 3
  ret <8 x half> %i
}

define <8 x half> @test_insertelement4(<8 x half> %a, half %x) #0 {
; CHECK-LABEL: test_insertelement4:
; CHECK:       # %bb.0:
; CHECK-NEXT:    insf $r1 = $r2, 15, 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %i = insertelement <8 x half> %a, half %x, i64 4
  ret <8 x half> %i
}

define <8 x half> @test_insertelement5(<8 x half> %a, half %x) #0 {
; CHECK-LABEL: test_insertelement5:
; CHECK:       # %bb.0:
; CHECK-NEXT:    insf $r1 = $r2, 31, 16
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %i = insertelement <8 x half> %a, half %x, i64 5
  ret <8 x half> %i
}

define <8 x half> @test_insertelement6(<8 x half> %a, half %x) #0 {
; CHECK-LABEL: test_insertelement6:
; CHECK:       # %bb.0:
; CHECK-NEXT:    insf $r1 = $r2, 47, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %i = insertelement <8 x half> %a, half %x, i64 6
  ret <8 x half> %i
}

define <8 x half> @test_insertelement7(<8 x half> %a, half %x) #0 {
; CHECK-LABEL: test_insertelement7:
; CHECK:       # %bb.0:
; CHECK-NEXT:    insf $r1 = $r2, 63, 48
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %i = insertelement <8 x half> %a, half %x, i64 7
  ret <8 x half> %i
}

define <8 x half> @test_insertelement(<8 x half> %a, half %x, i64 %p) #0 {
; CHECK-LABEL: test_insertelement:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sbmm8 $r3 = $r3, 0x10001.@
; CHECK-NEXT:    make $r4 = 0x7000600050004
; CHECK-NEXT:    make $r5 = 0x3000200010000
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sbmm8 $r2 = $r2, 0x2010201.@
; CHECK-NEXT:    compnhq.eq $r3 = $r5, $r3
; CHECK-NEXT:    compnhq.eq $r4 = $r4, $r3
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    cmovehq.nez $r3 ? $r0 = $r2
; CHECK-NEXT:    cmovehq.nez $r4 ? $r1 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %i = insertelement <8 x half> %a, half %x, i64 %p
  ret <8 x half> %i
}

define <8 x i16> @fcmp_setoeq(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setoeq:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oeq $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.oeq $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp oeq <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setoeq_single(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setoeq_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CHECK-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp oeq <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setogt(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setogt:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.olt $r0 = $r2, $r0
; CHECK-NEXT:    fcompnhq.olt $r1 = $r3, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ogt <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setogt_single(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setogt_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    make $r1 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ogt <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setoge(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setoge:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oge $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.oge $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp oge <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setoge_single(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setoge_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CHECK-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp oge <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setolt(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setolt:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.olt $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.olt $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp olt <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setolt_single(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setolt_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    make $r1 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp olt <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setole(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setole:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oge $r0 = $r2, $r0
; CHECK-NEXT:    fcompnhq.oge $r1 = $r3, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ole <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setole_single(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setole_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CHECK-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ole <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setone(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setone:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.one $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.one $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp one <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setone_single(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setone_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    make $r1 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp one <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setord(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: fcmp_setord:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oge $r0 = $r0, $r2
; CV1-NEXT:    fcompnhq.olt $r4 = $r0, $r2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    ord $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.oge $r1 = $r1, $r3
; CV1-NEXT:    fcompnhq.olt $r2 = $r1, $r3
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ord $r1 = $r1, $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 2)
;
; CV2-LABEL: fcmp_setord:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oge $r0 = $r0, $r2
; CV2-NEXT:    fcompnhq.oge $r1 = $r1, $r3
; CV2-NEXT:    fcompnhq.olt $r2 = $r1, $r3
; CV2-NEXT:    fcompnhq.olt $r4 = $r0, $r2
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    ord $r0 = $r0, $r4
; CV2-NEXT:    ord $r1 = $r1, $r2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = fcmp ord <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setord_single(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setord_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CHECK-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ord <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setuno(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: fcmp_setuno:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r2
; CV1-NEXT:    fcompnhq.ult $r4 = $r0, $r2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r3
; CV1-NEXT:    fcompnhq.ult $r2 = $r1, $r3
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 2)
;
; CV2-LABEL: fcmp_setuno:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r2
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r3
; CV2-NEXT:    fcompnhq.ult $r2 = $r1, $r3
; CV2-NEXT:    fcompnhq.ult $r4 = $r0, $r2
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    andd $r0 = $r0, $r4
; CV2-NEXT:    andd $r1 = $r1, $r2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = fcmp uno <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setuno_single(<8 x half> %a) #0 {
; CV1-LABEL: fcmp_setuno_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.ult $r2 = $r0, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r2
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV1-NEXT:    fcompnhq.ult $r3 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 2)
;
; CV2-LABEL: fcmp_setuno_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.ult $r2 = $r0, $r0
; CV2-NEXT:    fcompnhq.ult $r3 = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    andd $r0 = $r0, $r2
; CV2-NEXT:    andd $r1 = $r1, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = fcmp uno <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setueq(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setueq:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.ueq $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.ueq $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ueq <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setueq_single(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setueq_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    make $r1 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ueq <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setugt(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setugt:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.ult $r0 = $r2, $r0
; CHECK-NEXT:    fcompnhq.ult $r1 = $r3, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ugt <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setugt_single(<8 x half> %a) #0 {
; CV1-LABEL: fcmp_setugt_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.ult $r2 = $r0, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r2
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV1-NEXT:    fcompnhq.ult $r3 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 2)
;
; CV2-LABEL: fcmp_setugt_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.ult $r2 = $r0, $r0
; CV2-NEXT:    fcompnhq.ult $r3 = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    andd $r0 = $r0, $r2
; CV2-NEXT:    andd $r1 = $r1, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = fcmp ugt <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setuge(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setuge:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.uge $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.uge $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp uge <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setuge_single(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setuge_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    make $r1 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp uge <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setult(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setult:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.ult $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.ult $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ult <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setult_single(<8 x half> %a) #0 {
; CV1-LABEL: fcmp_setult_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.ult $r2 = $r0, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r2
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV1-NEXT:    fcompnhq.ult $r3 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 2)
;
; CV2-LABEL: fcmp_setult_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.ult $r2 = $r0, $r0
; CV2-NEXT:    fcompnhq.ult $r3 = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    andd $r0 = $r0, $r2
; CV2-NEXT:    andd $r1 = $r1, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = fcmp ult <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setule(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setule:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.uge $r0 = $r2, $r0
; CHECK-NEXT:    fcompnhq.uge $r1 = $r3, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ule <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setule_single(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setule_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    make $r1 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ule <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setune(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setune:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.une $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.une $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp une <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setune_single(<8 x half> %a) #0 {
; CV1-LABEL: fcmp_setune_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.ult $r2 = $r0, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r2
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV1-NEXT:    fcompnhq.ult $r3 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 2)
;
; CV2-LABEL: fcmp_setune_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.ult $r2 = $r0, $r0
; CV2-NEXT:    fcompnhq.ult $r3 = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    andd $r0 = $r0, $r2
; CV2-NEXT:    andd $r1 = $r1, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = fcmp une <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setoeq_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setoeq_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oeq $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.oeq $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast oeq <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setoeq_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setoeq_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    make $r1 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast oeq <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setogt_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setogt_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.olt $r0 = $r2, $r0
; CHECK-NEXT:    fcompnhq.olt $r1 = $r3, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ogt <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setogt_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setogt_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    make $r1 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ogt <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setoge_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setoge_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oge $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.oge $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast oge <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setoge_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setoge_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    make $r1 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast oge <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setolt_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setolt_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.olt $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.olt $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast olt <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setolt_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setolt_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    make $r1 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast olt <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setole_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setole_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oge $r0 = $r2, $r0
; CHECK-NEXT:    fcompnhq.oge $r1 = $r3, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ole <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setole_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setole_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    make $r1 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ole <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setone_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setone_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.one $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.one $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast one <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setone_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setone_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    make $r1 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast one <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setord_fast(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: fcmp_setord_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oge $r0 = $r0, $r2
; CV1-NEXT:    fcompnhq.olt $r4 = $r0, $r2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    ord $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.oge $r1 = $r1, $r3
; CV1-NEXT:    fcompnhq.olt $r2 = $r1, $r3
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ord $r1 = $r1, $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 2)
;
; CV2-LABEL: fcmp_setord_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oge $r0 = $r0, $r2
; CV2-NEXT:    fcompnhq.oge $r1 = $r1, $r3
; CV2-NEXT:    fcompnhq.olt $r2 = $r1, $r3
; CV2-NEXT:    fcompnhq.olt $r4 = $r0, $r2
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    ord $r0 = $r0, $r4
; CV2-NEXT:    ord $r1 = $r1, $r2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = fcmp fast ord <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setord_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setord_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CHECK-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ord <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

; Shouldn't this be just a true? Isn't fast unordered free?
define <8 x i16> @fcmp_setuno_fast(<8 x half> %a, <8 x half> %b) #0 {
; CV1-LABEL: fcmp_setuno_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r2
; CV1-NEXT:    fcompnhq.ult $r4 = $r0, $r2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r3
; CV1-NEXT:    fcompnhq.ult $r2 = $r1, $r3
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 2)
;
; CV2-LABEL: fcmp_setuno_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r2
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r3
; CV2-NEXT:    fcompnhq.ult $r2 = $r1, $r3
; CV2-NEXT:    fcompnhq.ult $r4 = $r0, $r2
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    andd $r0 = $r0, $r4
; CV2-NEXT:    andd $r1 = $r1, $r2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = fcmp fast uno <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setuno_single_fast(<8 x half> %a) #0 {
; CV1-LABEL: fcmp_setuno_single_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.ult $r2 = $r0, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r2
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV1-NEXT:    fcompnhq.ult $r3 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 2)
;
; CV2-LABEL: fcmp_setuno_single_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.ult $r2 = $r0, $r0
; CV2-NEXT:    fcompnhq.ult $r3 = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    andd $r0 = $r0, $r2
; CV2-NEXT:    andd $r1 = $r1, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 1)
entry:
  %0 = fcmp fast uno <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setueq_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setueq_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oeq $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.oeq $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ueq <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setueq_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setueq_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    make $r1 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ueq <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setugt_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setugt_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.olt $r0 = $r2, $r0
; CHECK-NEXT:    fcompnhq.olt $r1 = $r3, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ugt <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setugt_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setugt_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    make $r1 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ugt <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setuge_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setuge_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oge $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.oge $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast uge <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setuge_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setuge_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    make $r1 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast uge <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setult_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setult_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.olt $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.olt $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ult <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setult_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setult_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    make $r1 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ult <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setule_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setule_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.oge $r0 = $r2, $r0
; CHECK-NEXT:    fcompnhq.oge $r1 = $r3, $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ule <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setule_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setule_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    make $r1 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ule <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setune_fast(<8 x half> %a, <8 x half> %b) #0 {
; CHECK-LABEL: fcmp_setune_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fcompnhq.one $r0 = $r0, $r2
; CHECK-NEXT:    fcompnhq.one $r1 = $r1, $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast une <8 x half> %a, %b
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define <8 x i16> @fcmp_setune_single_fast(<8 x half> %a) #0 {
; CHECK-LABEL: fcmp_setune_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    make $r1 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast une <8 x half> %a, %a
  %1 = sext <8 x i1> %0 to <8 x i16>
  ret <8 x i16> %1
}

define float @fwidenmhw(<8 x half> %v) #0 {
; CHECK-LABEL: fwidenmhw:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fwidenmhw $r0 = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %vecext = extractelement <8 x half> %v, i32 1
  %conv = fpext half %vecext to float
  ret float %conv
}

define <8 x half> @concat (<4 x half> %a, <4 x half> %b) #0 {
; CHECK-LABEL: concat:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %v = shufflevector <4 x half> %a, <4 x half> %b, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  ret <8 x half> %v
}

attributes #0 = { nounwind }

define <16 x half> @select_shufflehx_2(<16 x half> %0, half %1, i32 %2) {
; CV1-LABEL: select_shufflehx_2:
; CV1:       # %bb.0:
; CV1-NEXT:    cb.weqz $r5 ? .LBB155_2
; CV1-NEXT:    ;;
; CV1-NEXT:  # %bb.1:
; CV1-NEXT:    extfz $r0 = $r0, 47, 32
; CV1-NEXT:    srlw $r5 = $r1, 16
; CV1-NEXT:    copyd $r6 = $r1
; CV1-NEXT:    srld $r7 = $r0, 48
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r7, 31, 16
; CV1-NEXT:    srld $r5 = $r1, 48
; CV1-NEXT:    insf $r6 = $r5, 31, 16
; CV1-NEXT:    srlw $r8 = $r2, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r0 = $r6, 63, 32
; CV1-NEXT:    extfz $r1 = $r1, 47, 32
; CV1-NEXT:    copyd $r7 = $r2
; CV1-NEXT:    srlw $r9 = $r3, 16
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r1 = $r5, 31, 16
; CV1-NEXT:    copyd $r5 = $r3
; CV1-NEXT:    srld $r6 = $r2, 48
; CV1-NEXT:    insf $r7 = $r8, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r1 = $r7, 63, 32
; CV1-NEXT:    extfz $r2 = $r2, 47, 32
; CV1-NEXT:    srld $r7 = $r3, 48
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    extfz $r3 = $r3, 47, 32
; CV1-NEXT:    insf $r4 = $r4, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    insf $r5 = $r9, 31, 16
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    insf $r2 = $r5, 63, 32
; CV1-NEXT:    insf $r3 = $r7, 31, 16
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    insf $r3 = $r4, 63, 32
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:  .LBB155_2:
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: select_shufflehx_2:
; CV2:       # %bb.0:
; CV2-NEXT:    cb.weqz $r5 ? .LBB155_2
; CV2-NEXT:    ;;
; CV2-NEXT:  # %bb.1:
; CV2-NEXT:    extfz $r0 = $r0, 47, 32
; CV2-NEXT:    srlw $r5 = $r1, 16
; CV2-NEXT:    copyd $r6 = $r1
; CV2-NEXT:    srld $r7 = $r0, 48
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r7, 31, 16
; CV2-NEXT:    extfz $r1 = $r1, 47, 32
; CV2-NEXT:    srld $r5 = $r1, 48
; CV2-NEXT:    insf $r6 = $r5, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r1 = $r5, 31, 16
; CV2-NEXT:    srlw $r5 = $r2, 16
; CV2-NEXT:    copyd $r7 = $r2
; CV2-NEXT:    srlw $r8 = $r3, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    extfz $r2 = $r2, 47, 32
; CV2-NEXT:    copyd $r9 = $r3
; CV2-NEXT:    srld $r10 = $r2, 48
; CV2-NEXT:    srld $r11 = $r3, 48
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    extfz $r3 = $r3, 47, 32
; CV2-NEXT:    insf $r4 = $r4, 31, 16
; CV2-NEXT:    insf $r7 = $r5, 31, 16
; CV2-NEXT:    insf $r9 = $r8, 31, 16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    insf $r0 = $r6, 63, 32
; CV2-NEXT:    insf $r1 = $r7, 63, 32
; CV2-NEXT:    insf $r2 = $r10, 31, 16
; CV2-NEXT:    insf $r3 = $r11, 31, 16
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    insf $r2 = $r9, 63, 32
; CV2-NEXT:    insf $r3 = $r4, 63, 32
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:  .LBB155_2:
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = icmp eq i32 %2, 0
  br i1 %4, label %8, label %5

5:
  %6 = insertelement <16 x half> undef, half %1, i64 0
  %7 = shufflevector <16 x half> %6, <16 x half> %0, <16 x i32> <i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31, i32 0, i32 0>
  br label %8

8:
  %9 = phi <16 x half> [ %7, %5 ], [ %0, %3 ]
  ret <16 x half> %9
}

define <8 x half> @test_select_cmp(<8 x half> %a, <8 x half> %b, <8 x half> %c, <8 x half> %d) #0 {
; CHECK-LABEL: test_select_cmp:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fcompnhq.une $r4 = $r4, $r6
; CHECK-NEXT:    fcompnhq.une $r5 = $r5, $r7
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    andd $r4 = $r4, $r5
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    compd.eq $r4 = $r4, -1
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    cmoved.even $r4 ? $r0 = $r2
; CHECK-NEXT:    cmoved.even $r4 ? $r1 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 3)
  %cc = fcmp une <8 x half> %c, %d
  %bc = bitcast <8 x i1> %cc to i8
  %cmp = icmp eq i8 %bc, -1
  %r = select i1 %cmp, <8 x half> %a, <8 x half> %b
  ret <8 x half> %r
}
