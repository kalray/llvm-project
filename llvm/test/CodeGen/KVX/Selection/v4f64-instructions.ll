; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -o - %s -O2 | FileCheck %s --check-prefixes=CHECK,CV1
; RUN: llc -mcpu=kv3-2 -o - %s -O2 | FileCheck %s --check-prefixes=CHECK,CV2
; RUN: clang -O2 -c -o /dev/null %s
; RUN: clang -O2 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define <4 x double> @test_ret_const() #0 {
; CHECK-LABEL: test_ret_const:
; CHECK:       # %bb.0:
; CHECK-NEXT:    make $r0 = 0x3ff0000000000000
; CHECK-NEXT:    make $r1 = 0x4000000000000000
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    make $r2 = 0x3ff0000000000000
; CHECK-NEXT:    make $r3 = 0x4000000000000000
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
  ret <4 x double> <double 1.0, double 2.0, double 1.0, double 2.0>
}

define double @test_extract_0(<4 x double> %a) #0 {
; CHECK-LABEL: test_extract_0:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %e = extractelement <4 x double> %a, i32 0
  ret double %e
}

define double @test_extract_1(<4 x double> %a) #0 {
; CHECK-LABEL: test_extract_1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %e = extractelement <4 x double> %a, i32 1
  ret double %e
}

define double @test_extract_i(<4 x double> %a, i64 %idx) #0 {
; CHECK-LABEL: test_extract_i:
; CHECK:       # %bb.0:
; CHECK-NEXT:    andd $r4 = $r4, 3
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    so 0[$r12] = $r0r1r2r3
; CHECK-NEXT:    addd $r0 = $r12, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    ld.xs $r0 = $r4[$r0]
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %e = extractelement <4 x double> %a, i64 %idx
  ret double %e
}

define <4 x double> @test_fadd(<4 x double> %a, <4 x double> %b) #0 {
; CHECK-LABEL: test_fadd:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fadddp $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fadddp $r0r1 = $r0r1, $r4r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
  %r = fadd <4 x double> %a, %b
  ret <4 x double> %r
}

define <4 x double> @test_fadd_imm_0(<4 x double> %a) #0 {
; CHECK-LABEL: test_fadd_imm_0:
; CHECK:       # %bb.0:
; CHECK-NEXT:    make $r4 = 0x3ff0000000000000
; CHECK-NEXT:    make $r5 = 0x4000000000000000
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fadddp $r0r1 = $r0r1, $r4r5
; CHECK-NEXT:    copyd $r6 = $r4
; CHECK-NEXT:    copyd $r7 = $r5
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fadddp $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fadd <4 x double> <double 1.0, double 2.0, double 1.0, double 2.0>, %a
  ret <4 x double> %r
}

define <4 x double> @test_fadd_imm_1(<4 x double> %a) #0 {
; CHECK-LABEL: test_fadd_imm_1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    make $r4 = 0x3ff0000000000000
; CHECK-NEXT:    make $r5 = 0x4000000000000000
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fadddp $r0r1 = $r0r1, $r4r5
; CHECK-NEXT:    copyd $r6 = $r4
; CHECK-NEXT:    copyd $r7 = $r5
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fadddp $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fadd <4 x double> %a, <double 1.0, double 2.0, double 1.0, double 2.0>
  ret <4 x double> %r
}

define <4 x double> @test_fsub(<4 x double> %a, <4 x double> %b) #0 {
; CHECK-LABEL: test_fsub:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fsbfdp $r2r3 = $r6r7, $r2r3
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fsbfdp $r0r1 = $r4r5, $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
  %r = fsub <4 x double> %a, %b
  ret <4 x double> %r
}

define <4 x double> @test_fsub_imm(<4 x double> %a) #0 {
; CHECK-LABEL: test_fsub_imm:
; CHECK:       # %bb.0:
; CHECK-NEXT:    make $r4 = 0xbff0000000000000
; CHECK-NEXT:    make $r5 = 0xc000000000000000
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fadddp $r0r1 = $r0r1, $r4r5
; CHECK-NEXT:    copyd $r6 = $r4
; CHECK-NEXT:    copyd $r7 = $r5
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fadddp $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fsub <4 x double> %a, <double 1.0, double 2.0, double 1.0, double 2.0>
  ret <4 x double> %r
}

; TODO: Could use ri variant
define <4 x double> @test_fsub_fromimm(<4 x double> %a) #0 {
; CHECK-LABEL: test_fsub_fromimm:
; CHECK:       # %bb.0:
; CHECK-NEXT:    make $r4 = 0x3ff0000000000000
; CHECK-NEXT:    make $r5 = 0x4000000000000000
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fsbfdp $r0r1 = $r0r1, $r4r5
; CHECK-NEXT:    copyd $r6 = $r4
; CHECK-NEXT:    copyd $r7 = $r5
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fsbfdp $r2r3 = $r2r3, $r6r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %r = fsub <4 x double> <double 1.0, double 2.0, double 1.0, double 2.0>, %a
  ret <4 x double> %r
}

define <4 x double> @test_fneg(<4 x double> %a) #0 {
; CHECK-LABEL: test_fneg:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fnegd $r0 = $r0
; CHECK-NEXT:    fnegd $r1 = $r1
; CHECK-NEXT:    eord $r2 = $r2, 0x8000000000000000
; CHECK-NEXT:    eord $r3 = $r3, 0x8000000000000000
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = fsub <4 x double> <double 0.0, double 0.0, double 0.0, double 0.0>, %a
  ret <4 x double> %r
}

define <4 x double> @test_fmul(<4 x double> %a, <4 x double> %b) #0 {
; CHECK-LABEL: test_fmul:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fmuld $r3 = $r3, $r7
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fmuld $r2 = $r2, $r6
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fmuld $r1 = $r1, $r5
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fmuld $r0 = $r0, $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 3)
  %r = fmul <4 x double> %a, %b
  ret <4 x double> %r
}

define <4 x double> @test_fdiv(<4 x double> %a, <4 x double> %b) #0 {
; CHECK-LABEL: test_fdiv:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 24[$r12] = $r16
; CHECK-NEXT:    call __divv4df3
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    ld $r16 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = fdiv <4 x double> %a, %b
  ret <4 x double> %r
}

define <4 x double> @test_frem(<4 x double> %a, <4 x double> %b) #0 {
; CHECK-LABEL: test_frem:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 80[$r12] = $r26
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 72[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    so 40[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 24[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r19 = $r6
; CHECK-NEXT:    copyd $r20 = $r4
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r22 = $r3
; CHECK-NEXT:    copyd $r23 = $r2
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    ;; # (end cycle 6)
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    call fmod
; CHECK-NEXT:    ;; # (end cycle 7)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call fmod
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    call fmod
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    call fmod
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r26
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lo $r20r21r22r23 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r24 = 72[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r26 = 80[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = frem <4 x double> %a, %b
  ret <4 x double> %r
}

define void @test_ldst_v4f64(ptr %a, ptr %b) {
; CHECK-LABEL: test_ldst_v4f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    lo $r4r5r6r7 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    so 0[$r1] = $r4r5r6r7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
  %t1 = load <4 x double>, ptr %a
  store <4 x double> %t1, ptr %b, align 16
  ret void
}

declare <4 x double> @test_callee(<4 x double> %a, <4 x double> %b) #0

define <4 x double> @test_call(<4 x double> %a, <4 x double> %b) #0 {
; CHECK-LABEL: test_call:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 24[$r12] = $r16
; CHECK-NEXT:    call test_callee
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    ld $r16 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <4 x double> @test_callee(<4 x double> %a, <4 x double> %b)
  ret <4 x double> %r
}

define <4 x double> @test_call_flipped(<4 x double> %a, <4 x double> %b) #0 {
; CHECK-LABEL: test_call_flipped:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 24[$r12] = $r16
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    copyd $r4 = $r0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    copyd $r2 = $r6
; CHECK-NEXT:    copyd $r5 = $r1
; CHECK-NEXT:    copyd $r6 = $r2
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    copyd $r3 = $r7
; CHECK-NEXT:    copyd $r7 = $r3
; CHECK-NEXT:    call test_callee
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r16 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <4 x double> @test_callee(<4 x double> %b, <4 x double> %a)
  ret <4 x double> %r
}

define <4 x double> @test_tailcall_flipped(<4 x double> %a, <4 x double> %b) #0 {
; CHECK-LABEL: test_tailcall_flipped:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    copyd $r4 = $r0
; CHECK-NEXT:    copyd $r5 = $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r2 = $r6
; CHECK-NEXT:    copyd $r3 = $r7
; CHECK-NEXT:    copyd $r6 = $r2
; CHECK-NEXT:    copyd $r7 = $r3
; CHECK-NEXT:    goto test_callee
; CHECK-NEXT:    ;; # (end cycle 1)
  %r = tail call <4 x double> @test_callee(<4 x double> %b, <4 x double> %a)
  ret <4 x double> %r
}

define <4 x double> @test_select(<4 x double> %a, <4 x double> %b, i1 zeroext %c) #0 {
; CV1-LABEL: test_select:
; CV1:       # %bb.0:
; CV1-NEXT:    cmoved.even $r8 ? $r2 = $r6
; CV1-NEXT:    cmoved.even $r8 ? $r3 = $r7
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    cmoved.even $r8 ? $r0 = $r4
; CV1-NEXT:    cmoved.even $r8 ? $r1 = $r5
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_select:
; CV2:       # %bb.0:
; CV2-NEXT:    cmoved.even $r8 ? $r0 = $r4
; CV2-NEXT:    cmoved.even $r8 ? $r1 = $r5
; CV2-NEXT:    cmoved.even $r8 ? $r2 = $r6
; CV2-NEXT:    cmoved.even $r8 ? $r3 = $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = select i1 %c, <4 x double> %a, <4 x double> %b
  ret <4 x double> %r
}

define <4 x double> @test_select_cc(<4 x double> %a, <4 x double> %b, <4 x double> %c, <4 x double> %d) #0 {
; CV1-LABEL: test_select_cc:
; CV1:       # %bb.0:
; CV1-NEXT:    ld $r15 = 16[$r12]
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    ld $r16 = 24[$r12]
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r17 = 8[$r12]
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fcompd.une $r10 = $r10, $r15
; CV1-NEXT:    make $r15 = -1
; CV1-NEXT:    ld $r32 = 0[$r12]
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    make $r10 = -1
; CV1-NEXT:    fcompd.une $r11 = $r11, $r16
; CV1-NEXT:    cmoved.even $r10 ? $r15 = 0
; CV1-NEXT:    make $r16 = -1
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    fcompd.une $r9 = $r9, $r17
; CV1-NEXT:    make $r11 = -1
; CV1-NEXT:    cmoved.even $r11 ? $r16 = 0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fcompd.une $r8 = $r8, $r32
; CV1-NEXT:    cmoved.even $r9 ? $r10 = 0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    cmoved.dnez $r10 ? $r5 = $r1
; CV1-NEXT:    cmoved.even $r8 ? $r11 = 0
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    cmoved.dnez $r11 ? $r4 = $r0
; CV1-NEXT:    cmoved.dnez $r15 ? $r6 = $r2
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    copyd $r0 = $r4
; CV1-NEXT:    copyd $r1 = $r5
; CV1-NEXT:    copyd $r2 = $r6
; CV1-NEXT:    cmoved.dnez $r16 ? $r7 = $r3
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    copyd $r3 = $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 10)
;
; CV2-LABEL: test_select_cc:
; CV2:       # %bb.0:
; CV2-NEXT:    ld $r15 = 8[$r12]
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    ld $r16 = 0[$r12]
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r17 = 16[$r12]
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fcompnd.une $r9 = $r9, $r15
; CV2-NEXT:    ld $r32 = 24[$r12]
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    cmoved.dnez $r9 ? $r5 = $r1
; CV2-NEXT:    fcompnd.une $r8 = $r8, $r16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    cmoved.dnez $r8 ? $r4 = $r0
; CV2-NEXT:    fcompnd.une $r10 = $r10, $r17
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r0 = $r4
; CV2-NEXT:    copyd $r1 = $r5
; CV2-NEXT:    cmoved.dnez $r10 ? $r6 = $r2
; CV2-NEXT:    fcompnd.une $r11 = $r11, $r32
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    copyd $r2 = $r6
; CV2-NEXT:    cmoved.dnez $r11 ? $r7 = $r3
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    copyd $r3 = $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 8)
  %cc = fcmp une <4 x double> %c, %d
  %r = select <4 x i1> %cc, <4 x double> %a, <4 x double> %b
  ret <4 x double> %r
}

define <4 x float> @test_select_cc_f32_f32(<4 x float> %a, <4 x float> %b, <4 x double> %c, <4 x double> %d) #0 {
; CV1-LABEL: test_select_cc_f32_f32:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.une $r5 = $r5, $r9
; CV1-NEXT:    fcompd.une $r7 = $r7, $r11
; CV1-NEXT:    make $r9 = -1
; CV1-NEXT:    make $r35 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompd.une $r5 = $r6, $r10
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    cmoved.even $r5 ? $r9 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    make $r4 = -1
; CV1-NEXT:    cmoved.even $r5 ? $r6 = 0
; CV1-NEXT:    fcompd.une $r8 = $r4, $r8
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r8 ? $r4 = 0
; CV1-NEXT:    cmoved.even $r7 ? $r35 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r4 = $r9, 63, 32
; CV1-NEXT:    insf $r6 = $r35, 63, 32
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    cmovewp.even $r4 ? $r0 = $r2
; CV1-NEXT:    copyd $r5 = $r6
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    cmovewp.even $r5 ? $r1 = $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_select_cc_f32_f32:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.une $r4 = $r4, $r8
; CV2-NEXT:    fcompnd.une $r5 = $r5, $r9
; CV2-NEXT:    fcompnd.une $r6 = $r6, $r10
; CV2-NEXT:    fcompnd.une $r7 = $r7, $r11
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r4 = $r5, 63, 32
; CV2-NEXT:    insf $r6 = $r7, 63, 32
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    cmovewp.even $r4 ? $r0 = $r2
; CV2-NEXT:    copyd $r5 = $r6
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    cmovewp.even $r5 ? $r1 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %cc = fcmp une <4 x double> %c, %d
  %r = select <4 x i1> %cc, <4 x float> %a, <4 x float> %b
  ret <4 x float> %r
}

define <4 x i1> @test_fcmp_une(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_une:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.une $r2 = $r2, $r6
; CV1-NEXT:    fcompd.une $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.une $r0 = $r0, $r4
; CV1-NEXT:    fcompd.une $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_une:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.une $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.une $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.une $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.une $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp une <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_ueq(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_ueq:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.ueq $r2 = $r2, $r6
; CV1-NEXT:    fcompd.ueq $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.ueq $r0 = $r0, $r4
; CV1-NEXT:    fcompd.ueq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_ueq:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.ueq $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.ueq $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.ueq $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.ueq $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp ueq <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_ugt(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_ugt:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.ult $r2 = $r6, $r2
; CV1-NEXT:    fcompd.ult $r3 = $r7, $r3
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.ult $r0 = $r4, $r0
; CV1-NEXT:    fcompd.ult $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_ugt:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.ult $r0 = $r4, $r0
; CV2-NEXT:    fcompnd.ult $r1 = $r5, $r1
; CV2-NEXT:    fcompnd.ult $r2 = $r6, $r2
; CV2-NEXT:    fcompnd.ult $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp ugt <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_uge(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_uge:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.uge $r2 = $r2, $r6
; CV1-NEXT:    fcompd.uge $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.uge $r0 = $r0, $r4
; CV1-NEXT:    fcompd.uge $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_uge:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.uge $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.uge $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.uge $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.uge $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp uge <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_ult(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_ult:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.ult $r2 = $r2, $r6
; CV1-NEXT:    fcompd.ult $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.ult $r0 = $r0, $r4
; CV1-NEXT:    fcompd.ult $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_ult:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.ult $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.ult $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.ult $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.ult $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp ult <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_ule(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_ule:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.uge $r2 = $r6, $r2
; CV1-NEXT:    fcompd.uge $r3 = $r7, $r3
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.uge $r0 = $r4, $r0
; CV1-NEXT:    fcompd.uge $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_ule:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.uge $r0 = $r4, $r0
; CV2-NEXT:    fcompnd.uge $r1 = $r5, $r1
; CV2-NEXT:    fcompnd.uge $r2 = $r6, $r2
; CV2-NEXT:    fcompnd.uge $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp ule <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_uno(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_uno:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.uge $r3 = $r3, $r7
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    fcompd.ult $r8 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompd.uge $r1 = $r1, $r5
; CV1-NEXT:    andw $r3 = $r3, $r8
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    fcompd.ult $r8 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andw $r1 = $r1, $r8
; CV1-NEXT:    fcompd.ult $r3 = $r2, $r6
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    fcompd.uge $r6 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fcompd.uge $r0 = $r0, $r4
; CV1-NEXT:    andw $r3 = $r6, $r3
; CV1-NEXT:    fcompd.ult $r6 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    andw $r0 = $r0, $r6
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 9)
;
; CV2-LABEL: test_fcmp_uno:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompd.uge $r3 = $r3, $r7
; CV2-NEXT:    fcompd.uge $r6 = $r2, $r6
; CV2-NEXT:    fcompd.ult $r7 = $r2, $r6
; CV2-NEXT:    fcompd.ult $r8 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.uge $r1 = $r1, $r5
; CV2-NEXT:    fcompd.ult $r5 = $r0, $r4
; CV2-NEXT:    andw $r6 = $r6, $r7
; CV2-NEXT:    fcompd.ult $r7 = $r1, $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fcompd.uge $r0 = $r0, $r4
; CV2-NEXT:    make $r2 = -1
; CV2-NEXT:    andw $r3 = $r3, $r8
; CV2-NEXT:    make $r8 = -1
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    andw $r0 = $r0, $r5
; CV2-NEXT:    andw $r1 = $r1, $r7
; CV2-NEXT:    make $r4 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV2-NEXT:    cmoved.even $r6 ? $r4 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    cmoved.even $r3 ? $r8 = 0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    insf $r2 = $r7, 15, 8
; CV2-NEXT:    insf $r4 = $r8, 15, 8
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    insf $r2 = $r4, 31, 16
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    copyd $r0 = $r2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 7)
  %r = fcmp uno <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_one(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_one:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.one $r2 = $r2, $r6
; CV1-NEXT:    fcompd.one $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.one $r0 = $r0, $r4
; CV1-NEXT:    fcompd.one $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_one:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.one $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.one $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.one $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.one $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp one <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_oeq(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_oeq:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.oeq $r2 = $r2, $r6
; CV1-NEXT:    fcompd.oeq $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oeq $r0 = $r0, $r4
; CV1-NEXT:    fcompd.oeq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_oeq:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.oeq $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.oeq $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.oeq $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.oeq $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp oeq <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_ogt(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_ogt:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.olt $r2 = $r6, $r2
; CV1-NEXT:    fcompd.olt $r3 = $r7, $r3
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.olt $r0 = $r4, $r0
; CV1-NEXT:    fcompd.olt $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_ogt:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.olt $r0 = $r4, $r0
; CV2-NEXT:    fcompnd.olt $r1 = $r5, $r1
; CV2-NEXT:    fcompnd.olt $r2 = $r6, $r2
; CV2-NEXT:    fcompnd.olt $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp ogt <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_oge(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_oge:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.oge $r2 = $r2, $r6
; CV1-NEXT:    fcompd.oge $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oge $r0 = $r0, $r4
; CV1-NEXT:    fcompd.oge $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_oge:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.oge $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.oge $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.oge $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp oge <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_olt(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_olt:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.olt $r2 = $r2, $r6
; CV1-NEXT:    fcompd.olt $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.olt $r0 = $r0, $r4
; CV1-NEXT:    fcompd.olt $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_olt:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.olt $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.olt $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.olt $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.olt $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp olt <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_ole(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_ole:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.oge $r2 = $r6, $r2
; CV1-NEXT:    fcompd.oge $r3 = $r7, $r3
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oge $r0 = $r4, $r0
; CV1-NEXT:    fcompd.oge $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_ole:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnd.oge $r0 = $r4, $r0
; CV2-NEXT:    fcompnd.oge $r1 = $r5, $r1
; CV2-NEXT:    fcompnd.oge $r2 = $r6, $r2
; CV2-NEXT:    fcompnd.oge $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp ole <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_fcmp_ord(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_fcmp_ord:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.oge $r3 = $r3, $r7
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    fcompd.olt $r8 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompd.oge $r1 = $r1, $r5
; CV1-NEXT:    iorw $r3 = $r3, $r8
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    fcompd.olt $r8 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    iorw $r1 = $r1, $r8
; CV1-NEXT:    fcompd.olt $r3 = $r2, $r6
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    fcompd.oge $r6 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fcompd.oge $r0 = $r0, $r4
; CV1-NEXT:    iorw $r3 = $r6, $r3
; CV1-NEXT:    fcompd.olt $r6 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    iorw $r0 = $r0, $r6
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 9)
;
; CV2-LABEL: test_fcmp_ord:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompd.oge $r3 = $r3, $r7
; CV2-NEXT:    fcompd.oge $r6 = $r2, $r6
; CV2-NEXT:    fcompd.olt $r7 = $r2, $r6
; CV2-NEXT:    fcompd.olt $r8 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompd.olt $r5 = $r0, $r4
; CV2-NEXT:    iorw $r6 = $r6, $r7
; CV2-NEXT:    fcompd.olt $r7 = $r1, $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fcompd.oge $r0 = $r0, $r4
; CV2-NEXT:    make $r2 = -1
; CV2-NEXT:    iorw $r3 = $r3, $r8
; CV2-NEXT:    make $r8 = -1
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    iorw $r0 = $r0, $r5
; CV2-NEXT:    iorw $r1 = $r1, $r7
; CV2-NEXT:    make $r4 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV2-NEXT:    cmoved.even $r6 ? $r4 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    cmoved.even $r3 ? $r8 = 0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    insf $r2 = $r7, 15, 8
; CV2-NEXT:    insf $r4 = $r8, 15, 8
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    insf $r2 = $r4, 31, 16
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    copyd $r0 = $r2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 7)
  %r = fcmp ord <4 x double> %a, %b
  ret <4 x i1> %r
}

define <4 x i32> @test_fptosi_i32(<4 x double> %a) #0 {
; CHECK-LABEL: test_fptosi_i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fixedd.rz $r4 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fixedd.rz $r3 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fixedd.rz $r1 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fixedd.rz $r0 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    insf $r3 = $r4, 63, 32
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    copyd $r1 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 7)
  %r = fptosi <4 x double> %a to <4 x i32>
  ret <4 x i32> %r
}

define <4 x i64> @test_fptosi_i64(<4 x double> %a) #0 {
; CHECK-LABEL: test_fptosi_i64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fixedd.rz $r3 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fixedd.rz $r2 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fixedd.rz $r1 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fixedd.rz $r0 = $r0, 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 3)
  %r = fptosi <4 x double> %a to <4 x i64>
  ret <4 x i64> %r
}

define <4 x i32> @test_fptoui_2xi32(<4 x double> %a) #0 {
; CHECK-LABEL: test_fptoui_2xi32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fixedud.rz $r4 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fixedud.rz $r3 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fixedud.rz $r1 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fixedud.rz $r0 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    insf $r3 = $r4, 63, 32
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    copyd $r1 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 7)
  %r = fptoui <4 x double> %a to <4 x i32>
  ret <4 x i32> %r
}

define <4 x i64> @test_fptoui_2xi64(<4 x double> %a) #0 {
; CHECK-LABEL: test_fptoui_2xi64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fixedud.rz $r3 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fixedud.rz $r2 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fixedud.rz $r1 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fixedud.rz $r0 = $r0, 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 3)
  %r = fptoui <4 x double> %a to <4 x i64>
  ret <4 x i64> %r
}

; TODO: Don't need the sbmm8, just 3 insf
define <4 x i16> @test_fptosi_i16(<4 x double> %a) #0 {
; CHECK-LABEL: test_fptosi_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fixedd.rz $r3 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fixedd.rz $r5 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fixedd.rz $r1 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fixedd.rz $r0 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    insf $r5 = $r3, 63, 32
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    sbmm8 $r1 = $r5, 0x20100201
; CHECK-NEXT:    ;; # (end cycle 7)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x20100201
; CHECK-NEXT:    ;; # (end cycle 8)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 9)
  %r = fptosi <4 x double> %a to <4 x i16>
  ret <4 x i16> %r
}

define <4 x i16> @test_fptoui_i16(<4 x double> %a) #0 {
; CHECK-LABEL: test_fptoui_i16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fixedud.rz $r3 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fixedud.rz $r5 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fixedud.rz $r1 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fixedud.rz $r0 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    insf $r5 = $r3, 63, 32
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    sbmm8 $r1 = $r5, 0x20100201
; CHECK-NEXT:    ;; # (end cycle 7)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x20100201
; CHECK-NEXT:    ;; # (end cycle 8)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 9)
  %r = fptoui <4 x double> %a to <4 x i16>
  ret <4 x i16> %r
}

define <4 x i8> @test_fptosi_i8(<4 x double> %a) #0 {
; CHECK-LABEL: test_fptosi_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fixedd.rz $r3 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fixedd.rz $r5 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fixedd.rz $r1 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fixedd.rz $r0 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    insf $r5 = $r3, 63, 32
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    sbmm8 $r1 = $r5, 0x1001
; CHECK-NEXT:    ;; # (end cycle 7)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x1001
; CHECK-NEXT:    ;; # (end cycle 8)
; CHECK-NEXT:    insf $r0 = $r1, 31, 16
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 9)
  %r = fptosi <4 x double> %a to <4 x i8>
  ret <4 x i8> %r
}

define <4 x i8> @test_fptoui_i8(<4 x double> %a) #0 {
; CHECK-LABEL: test_fptoui_i8:
; CHECK:       # %bb.0:
; CHECK-NEXT:    fixedud.rz $r3 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    fixedud.rz $r5 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    fixedud.rz $r1 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    fixedud.rz $r0 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    insf $r5 = $r3, 63, 32
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    insf $r0 = $r1, 63, 32
; CHECK-NEXT:    sbmm8 $r1 = $r5, 0x1001
; CHECK-NEXT:    ;; # (end cycle 7)
; CHECK-NEXT:    sbmm8 $r0 = $r0, 0x1001
; CHECK-NEXT:    ;; # (end cycle 8)
; CHECK-NEXT:    insf $r0 = $r1, 31, 16
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 9)
  %r = fptoui <4 x double> %a to <4 x i8>
  ret <4 x i8> %r
}
define <4 x double> @test_uitofp_2xi32(<4 x i32> %a) #0 {
; CHECK-LABEL: test_uitofp_2xi32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    zxwd $r2 = $r0
; CHECK-NEXT:    srld $r3 = $r0, 32
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    floatud.rn $r0 = $r2, 0
; CHECK-NEXT:    srld $r1 = $r1, 32
; CHECK-NEXT:    zxwd $r2 = $r1
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    floatud.rn $r5 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    floatud.rn $r2 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    floatud.rn $r3 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 6)
  %r = uitofp <4 x i32> %a to <4 x double>
  ret <4 x double> %r
}

define <4 x double> @test_uitofp_2xi64(<4 x i64> %a) #0 {
; CHECK-LABEL: test_uitofp_2xi64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    floatud.rn $r0 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    floatud.rn $r1 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    floatud.rn $r2 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    floatud.rn $r3 = $r3, 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 3)
  %r = uitofp <4 x i64> %a to <4 x double>
  ret <4 x double> %r
}

define <4 x double> @test_sitofp_2xi32(<4 x i32> %a) #0 {
; CHECK-LABEL: test_sitofp_2xi32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    sxwd $r2 = $r0
; CHECK-NEXT:    srad $r3 = $r0, 32
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    floatd.rn $r0 = $r2, 0
; CHECK-NEXT:    srad $r1 = $r1, 32
; CHECK-NEXT:    sxwd $r2 = $r1
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    floatd.rn $r5 = $r3, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    floatd.rn $r2 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    floatd.rn $r3 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 6)
  %r = sitofp <4 x i32> %a to <4 x double>
  ret <4 x double> %r
}

define <4 x double> @test_sitofp_2xi64(<4 x i64> %a) #0 {
; CHECK-LABEL: test_sitofp_2xi64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    floatd.rn $r0 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    floatd.rn $r1 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    floatd.rn $r2 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    floatd.rn $r3 = $r3, 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 3)
  %r = sitofp <4 x i64> %a to <4 x double>
  ret <4 x double> %r
}

define <4 x double> @test_uitofp_2xi32_fadd(<4 x i32> %a, <4 x double> %b) #0 {
; CHECK-LABEL: test_uitofp_2xi32_fadd:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r4 = $r2
; CHECK-NEXT:    copyd $r5 = $r3
; CHECK-NEXT:    copyd $r6 = $r4
; CHECK-NEXT:    copyd $r7 = $r5
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    srld $r0 = $r0, 32
; CHECK-NEXT:    zxwd $r2 = $r0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    srld $r1 = $r1, 32
; CHECK-NEXT:    zxwd $r2 = $r1
; CHECK-NEXT:    floatud.rn $r8 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    floatud.rn $r2 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    floatud.rn $r3 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    floatud.rn $r9 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    fadddp $r2r3 = $r6r7, $r2r3
; CHECK-NEXT:    ;; # (end cycle 8)
; CHECK-NEXT:    fadddp $r0r1 = $r4r5, $r8r9
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 9)
  %c = uitofp <4 x i32> %a to <4 x double>
  %r = fadd <4 x double> %b, %c
  ret <4 x double> %r
}

define <4 x double> @test_sitofp_2xi32_fadd(<4 x i32> %a, <4 x double> %b) #0 {
; CHECK-LABEL: test_sitofp_2xi32_fadd:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r4 = $r2
; CHECK-NEXT:    copyd $r5 = $r3
; CHECK-NEXT:    copyd $r6 = $r4
; CHECK-NEXT:    copyd $r7 = $r5
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    srad $r0 = $r0, 32
; CHECK-NEXT:    sxwd $r2 = $r0
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    srad $r1 = $r1, 32
; CHECK-NEXT:    sxwd $r2 = $r1
; CHECK-NEXT:    floatd.rn $r8 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    floatd.rn $r2 = $r2, 0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    floatd.rn $r3 = $r1, 0
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    floatd.rn $r9 = $r0, 0
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    fadddp $r2r3 = $r6r7, $r2r3
; CHECK-NEXT:    ;; # (end cycle 8)
; CHECK-NEXT:    fadddp $r0r1 = $r4r5, $r8r9
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 9)
  %c = sitofp <4 x i32> %a to <4 x double>
  %r = fadd <4 x double> %b, %c
  ret <4 x double> %r
}

define <4 x i64> @test_bitcast_2xdouble_to_2xi64(<4 x double> %a) #0 {
; CHECK-LABEL: test_bitcast_2xdouble_to_2xi64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = bitcast <4 x double> %a to <4 x i64>
  ret <4 x i64> %r
}

define <4 x double> @test_bitcast_2xi64_to_2xdouble(<4 x i64> %a) #0 {
; CHECK-LABEL: test_bitcast_2xi64_to_2xdouble:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = bitcast <4 x i64> %a to <4 x double>
  ret <4 x double> %r
}

declare <4 x double> @llvm.sqrt.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.powi.v4f64(<4 x double> %a, i32 %b) #0
declare <4 x double> @llvm.sin.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.cos.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.pow.v4f64(<4 x double> %a, <4 x double> %b) #0
declare <4 x double> @llvm.exp.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.exp2.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.log.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.log10.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.log2.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.fma.v4f64(<4 x double> %a, <4 x double> %b, <4 x double> %c) #0
declare <4 x double> @llvm.fabs.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.minnum.v4f64(<4 x double> %a, <4 x double> %b) #0
declare <4 x double> @llvm.maxnum.v4f64(<4 x double> %a, <4 x double> %b) #0
declare <4 x double> @llvm.copysign.v4f64(<4 x double> %a, <4 x double> %b) #0
declare <4 x double> @llvm.floor.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.ceil.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.trunc.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.rint.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.nearbyint.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.round.v4f64(<4 x double> %a) #0
declare <4 x double> @llvm.fmuladd.v4f64(<4 x double> %a, <4 x double> %b, <4 x double> %c) #0

define <4 x double> @test_sqrt(<4 x double> %a) #0 {
; CHECK-LABEL: test_sqrt:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call sqrt
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call sqrt
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call sqrt
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call sqrt
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <4 x double> @llvm.sqrt.v4f64(<4 x double> %a)
  ret <4 x double> %r
}

define <4 x double> @test_powi(<4 x double> %a, i32 %b) #0 {
; CHECK-LABEL: test_powi:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r4
; CHECK-NEXT:    copyd $r19 = $r3
; CHECK-NEXT:    copyd $r20 = $r2
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call __powidf2
; CHECK-NEXT:    ;; # (end cycle 6)
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call __powidf2
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call __powidf2
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call __powidf2
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
 %r = call <4 x double> @llvm.powi.v4f64(<4 x double> %a, i32 %b)
 ret <4 x double> %r
}

define <4 x double> @test_sin(<4 x double> %a) #0 {
; CHECK-LABEL: test_sin:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call sin
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call sin
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call sin
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call sin
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <4 x double> @llvm.sin.v4f64(<4 x double> %a)
  ret <4 x double> %r
}

define <4 x double> @test_cos(<4 x double> %a) #0 {
; CHECK-LABEL: test_cos:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call cos
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call cos
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call cos
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call cos
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <4 x double> @llvm.cos.v4f64(<4 x double> %a)
  ret <4 x double> %r
}

define <4 x double> @test_pow(<4 x double> %a, <4 x double> %b) #0 {
; CHECK-LABEL: test_pow:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -96
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 88[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 80[$r12] = $r26
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 72[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    so 40[$r12] = $r20r21r22r23
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 24[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r7
; CHECK-NEXT:    copyd $r19 = $r6
; CHECK-NEXT:    copyd $r20 = $r4
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    copyd $r22 = $r3
; CHECK-NEXT:    copyd $r23 = $r2
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    ;; # (end cycle 6)
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    call pow
; CHECK-NEXT:    ;; # (end cycle 7)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r20
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call pow
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r23
; CHECK-NEXT:    copyd $r1 = $r19
; CHECK-NEXT:    copyd $r20 = $r0
; CHECK-NEXT:    call pow
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r22
; CHECK-NEXT:    copyd $r1 = $r18
; CHECK-NEXT:    copyd $r26 = $r0
; CHECK-NEXT:    call pow
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r26
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lo $r20r21r22r23 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r24 = 72[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r26 = 80[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 88[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 96
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
 %r = call <4 x double> @llvm.pow.v4f64(<4 x double> %a, <4 x double> %b)
 ret <4 x double> %r
}

define <4 x double> @test_exp(<4 x double> %a) #0 {
; CHECK-LABEL: test_exp:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call exp
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call exp
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call exp
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call exp
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
 %r = call <4 x double> @llvm.exp.v4f64(<4 x double> %a)
 ret <4 x double> %r
}

define <4 x double> @test_exp2(<4 x double> %a) #0 {
; CHECK-LABEL: test_exp2:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call exp2
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call exp2
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call exp2
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call exp2
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
 %r = call <4 x double> @llvm.exp2.v4f64(<4 x double> %a)
 ret <4 x double> %r
}

define <4 x double> @test_log(<4 x double> %a) #0 {
; CHECK-LABEL: test_log:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call log
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call log
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call log
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call log
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
 %r = call <4 x double> @llvm.log.v4f64(<4 x double> %a)
 ret <4 x double> %r
}

define <4 x double> @test_log10(<4 x double> %a) #0 {
; CHECK-LABEL: test_log10:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call log10
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call log10
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call log10
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call log10
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
 %r = call <4 x double> @llvm.log10.v4f64(<4 x double> %a)
 ret <4 x double> %r
}

define <4 x double> @test_log2(<4 x double> %a) #0 {
; CHECK-LABEL: test_log2:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call log2
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call log2
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call log2
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call log2
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
 %r = call <4 x double> @llvm.log2.v4f64(<4 x double> %a)
 ret <4 x double> %r
}

define <4 x double> @test_fma(<4 x double> %a, <4 x double> %b, <4 x double> %c) #0 {
; CHECK-LABEL: test_fma:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ffmad $r11 = $r3, $r7
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    ffmad $r10 = $r2, $r6
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    ffmad $r9 = $r1, $r5
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ffmad $r8 = $r0, $r4
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 7)
  %r = call <4 x double> @llvm.fma.v4f64(<4 x double> %a, <4 x double> %b, <4 x double> %c)
  ret <4 x double> %r
}

define <4 x double> @test_fabs(<4 x double> %a) #0 {
; CV1-LABEL: test_fabs:
; CV1:       # %bb.0:
; CV1-NEXT:    fabsd $r0 = $r0
; CV1-NEXT:    fabsd $r1 = $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fabsd $r2 = $r2
; CV1-NEXT:    fabsd $r3 = $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fabs:
; CV2:       # %bb.0:
; CV2-NEXT:    fabsd $r0 = $r0
; CV2-NEXT:    fabsd $r1 = $r1
; CV2-NEXT:    fabsd $r2 = $r2
; CV2-NEXT:    fabsd $r3 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = call <4 x double> @llvm.fabs.v4f64(<4 x double> %a)
  ret <4 x double> %r
}

define <4 x double> @test_minnum(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_minnum:
; CV1:       # %bb.0:
; CV1-NEXT:    slld $r8 = $r1, 1
; CV1-NEXT:    slld $r9 = $r0, 1
; CV1-NEXT:    fcompd.olt $r10 = $r5, $r1
; CV1-NEXT:    fcompd.olt $r11 = $r4, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    compd.gtu $r8 = $r8, 0xffe0000000000000
; CV1-NEXT:    compd.gtu $r9 = $r9, 0xffe0000000000000
; CV1-NEXT:    fcompd.olt $r15 = $r6, $r2
; CV1-NEXT:    fcompd.olt $r16 = $r7, $r3
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    iord $r8 = $r10, $r8
; CV1-NEXT:    iord $r9 = $r11, $r9
; CV1-NEXT:    slld $r10 = $r2, 1
; CV1-NEXT:    slld $r11 = $r3, 1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.odd $r9 ? $r0 = $r4
; CV1-NEXT:    cmoved.odd $r8 ? $r1 = $r5
; CV1-NEXT:    compd.gtu $r10 = $r10, 0xffe0000000000000
; CV1-NEXT:    compd.gtu $r11 = $r11, 0xffe0000000000000
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    iord $r4 = $r15, $r10
; CV1-NEXT:    iord $r5 = $r16, $r11
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    cmoved.odd $r4 ? $r2 = $r6
; CV1-NEXT:    cmoved.odd $r5 ? $r3 = $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 5)
;
; CV2-LABEL: test_minnum:
; CV2:       # %bb.0:
; CV2-NEXT:    fmind $r0 = $r0, $r4
; CV2-NEXT:    fmind $r1 = $r1, $r5
; CV2-NEXT:    fmind $r2 = $r2, $r6
; CV2-NEXT:    fmind $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = call <4 x double> @llvm.minnum.v4f64(<4 x double> %a, <4 x double> %b)
  ret <4 x double> %r
}

define <4 x double> @test_minnum_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_minnum_fast:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.olt $r8 = $r1, $r5
; CV1-NEXT:    fcompd.olt $r9 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    cmoved.wnez $r9 ? $r4 = $r0
; CV1-NEXT:    cmoved.wnez $r8 ? $r5 = $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.olt $r0 = $r2, $r6
; CV1-NEXT:    fcompd.olt $r1 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r4
; CV1-NEXT:    copyd $r1 = $r5
; CV1-NEXT:    cmoved.wnez $r0 ? $r6 = $r2
; CV1-NEXT:    cmoved.wnez $r1 ? $r7 = $r3
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    copyd $r2 = $r6
; CV1-NEXT:    copyd $r3 = $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_minnum_fast:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompd.olt $r8 = $r1, $r5
; CV2-NEXT:    fcompd.olt $r9 = $r0, $r4
; CV2-NEXT:    fcompd.olt $r10 = $r2, $r6
; CV2-NEXT:    fcompd.olt $r11 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    cmoved.wnez $r9 ? $r4 = $r0
; CV2-NEXT:    cmoved.wnez $r8 ? $r5 = $r1
; CV2-NEXT:    cmoved.wnez $r10 ? $r6 = $r2
; CV2-NEXT:    cmoved.wnez $r11 ? $r7 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    copyd $r0 = $r4
; CV2-NEXT:    copyd $r1 = $r5
; CV2-NEXT:    copyd $r2 = $r6
; CV2-NEXT:    copyd $r3 = $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = call fast <4 x double> @llvm.minnum.v4f64(<4 x double> %a, <4 x double> %b)
  ret <4 x double> %r
}

define <4 x double> @test_maxnum(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_maxnum:
; CV1:       # %bb.0:
; CV1-NEXT:    slld $r8 = $r1, 1
; CV1-NEXT:    slld $r9 = $r0, 1
; CV1-NEXT:    fcompd.olt $r10 = $r1, $r5
; CV1-NEXT:    fcompd.olt $r11 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    compd.gtu $r8 = $r8, 0xffe0000000000000
; CV1-NEXT:    compd.gtu $r9 = $r9, 0xffe0000000000000
; CV1-NEXT:    fcompd.olt $r15 = $r2, $r6
; CV1-NEXT:    fcompd.olt $r16 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    iord $r8 = $r10, $r8
; CV1-NEXT:    iord $r9 = $r11, $r9
; CV1-NEXT:    slld $r10 = $r2, 1
; CV1-NEXT:    slld $r11 = $r3, 1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.odd $r9 ? $r0 = $r4
; CV1-NEXT:    cmoved.odd $r8 ? $r1 = $r5
; CV1-NEXT:    compd.gtu $r10 = $r10, 0xffe0000000000000
; CV1-NEXT:    compd.gtu $r11 = $r11, 0xffe0000000000000
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    iord $r4 = $r15, $r10
; CV1-NEXT:    iord $r5 = $r16, $r11
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    cmoved.odd $r4 ? $r2 = $r6
; CV1-NEXT:    cmoved.odd $r5 ? $r3 = $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 5)
;
; CV2-LABEL: test_maxnum:
; CV2:       # %bb.0:
; CV2-NEXT:    fmaxd $r0 = $r0, $r4
; CV2-NEXT:    fmaxd $r1 = $r1, $r5
; CV2-NEXT:    fmaxd $r2 = $r2, $r6
; CV2-NEXT:    fmaxd $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = call <4 x double> @llvm.maxnum.v4f64(<4 x double> %a, <4 x double> %b)
  ret <4 x double> %r
}

define <4 x double> @test_maxnum_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_maxnum_fast:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompd.olt $r8 = $r5, $r1
; CV1-NEXT:    fcompd.olt $r9 = $r4, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    cmoved.wnez $r9 ? $r4 = $r0
; CV1-NEXT:    cmoved.wnez $r8 ? $r5 = $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.olt $r0 = $r6, $r2
; CV1-NEXT:    fcompd.olt $r1 = $r7, $r3
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r4
; CV1-NEXT:    copyd $r1 = $r5
; CV1-NEXT:    cmoved.wnez $r0 ? $r6 = $r2
; CV1-NEXT:    cmoved.wnez $r1 ? $r7 = $r3
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    copyd $r2 = $r6
; CV1-NEXT:    copyd $r3 = $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_maxnum_fast:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompd.olt $r8 = $r5, $r1
; CV2-NEXT:    fcompd.olt $r9 = $r4, $r0
; CV2-NEXT:    fcompd.olt $r10 = $r6, $r2
; CV2-NEXT:    fcompd.olt $r11 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    cmoved.wnez $r9 ? $r4 = $r0
; CV2-NEXT:    cmoved.wnez $r8 ? $r5 = $r1
; CV2-NEXT:    cmoved.wnez $r10 ? $r6 = $r2
; CV2-NEXT:    cmoved.wnez $r11 ? $r7 = $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    copyd $r0 = $r4
; CV2-NEXT:    copyd $r1 = $r5
; CV2-NEXT:    copyd $r2 = $r6
; CV2-NEXT:    copyd $r3 = $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = call fast <4 x double> @llvm.maxnum.v4f64(<4 x double> %a, <4 x double> %b)
  ret <4 x double> %r
}

define <4 x double> @test_copysign(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: test_copysign:
; CV1:       # %bb.0:
; CV1-NEXT:    srad $r4 = $r4, 63
; CV1-NEXT:    srad $r5 = $r5, 63
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r4, 63, 63
; CV1-NEXT:    insf $r1 = $r5, 63, 63
; CV1-NEXT:    srad $r4 = $r6, 63
; CV1-NEXT:    srad $r5 = $r7, 63
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r2 = $r4, 63, 63
; CV1-NEXT:    insf $r3 = $r5, 63, 63
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 2)
;
; CV2-LABEL: test_copysign:
; CV2:       # %bb.0:
; CV2-NEXT:    srad $r4 = $r4, 63
; CV2-NEXT:    srad $r5 = $r5, 63
; CV2-NEXT:    srad $r6 = $r6, 63
; CV2-NEXT:    srad $r7 = $r7, 63
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r4, 63, 63
; CV2-NEXT:    insf $r1 = $r5, 63, 63
; CV2-NEXT:    insf $r2 = $r6, 63, 63
; CV2-NEXT:    insf $r3 = $r7, 63, 63
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 1)
  %r = call <4 x double> @llvm.copysign.v4f64(<4 x double> %a, <4 x double> %b)
  ret <4 x double> %r
}

define <4 x double> @test_copysign_v4f16(<4 x double> %a, <4 x half> %b) #0 {
; CV1-LABEL: test_copysign_v4f16:
; CV1:       # %bb.0:
; CV1-NEXT:    fwidenlhwp $r4 = $r4
; CV1-NEXT:    fwidenmhwp $r5 = $r4
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmwd $r7 = $r5
; CV1-NEXT:    fwidenmwd $r9 = $r4
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlwd $r4 = $r4
; CV1-NEXT:    srad $r5 = $r9, 63
; CV1-NEXT:    fwidenlwd $r6 = $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r1 = $r5, 63, 63
; CV1-NEXT:    srad $r4 = $r4, 63
; CV1-NEXT:    srad $r6 = $r6, 63
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 63
; CV1-NEXT:    insf $r2 = $r6, 63, 63
; CV1-NEXT:    srad $r4 = $r7, 63
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r3 = $r4, 63, 63
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 5)
;
; CV2-LABEL: test_copysign_v4f16:
; CV2:       # %bb.0:
; CV2-NEXT:    fwidenlhwp $r4 = $r4
; CV2-NEXT:    fwidenmhwp $r5 = $r4
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlwd $r6 = $r5
; CV2-NEXT:    fwidenmwd $r7 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlwd $r4 = $r4
; CV2-NEXT:    fwidenmwd $r5 = $r4
; CV2-NEXT:    srad $r6 = $r6, 63
; CV2-NEXT:    srad $r7 = $r7, 63
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r2 = $r6, 63, 63
; CV2-NEXT:    insf $r3 = $r7, 63, 63
; CV2-NEXT:    srad $r4 = $r4, 63
; CV2-NEXT:    srad $r5 = $r5, 63
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r0 = $r4, 63, 63
; CV2-NEXT:    insf $r1 = $r5, 63, 63
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 4)
  %tb = fpext <4 x half> %b to <4 x double>
  %r = call <4 x double> @llvm.copysign.v4f64(<4 x double> %a, <4 x double> %tb)
  ret <4 x double> %r
}

define <4 x double> @test_copysign_v4f32(<4 x double> %a, <4 x float> %b) #0 {
; CV1-LABEL: test_copysign_v4f32:
; CV1:       # %bb.0:
; CV1-NEXT:    fwidenmwd $r7 = $r5
; CV1-NEXT:    fwidenmwd $r9 = $r4
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlwd $r4 = $r4
; CV1-NEXT:    srad $r5 = $r9, 63
; CV1-NEXT:    fwidenlwd $r6 = $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r1 = $r5, 63, 63
; CV1-NEXT:    srad $r4 = $r4, 63
; CV1-NEXT:    srad $r5 = $r7, 63
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r0 = $r4, 63, 63
; CV1-NEXT:    insf $r3 = $r5, 63, 63
; CV1-NEXT:    srad $r4 = $r6, 63
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r4, 63, 63
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_copysign_v4f32:
; CV2:       # %bb.0:
; CV2-NEXT:    fwidenlwd $r6 = $r5
; CV2-NEXT:    fwidenmwd $r7 = $r5
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlwd $r4 = $r4
; CV2-NEXT:    fwidenmwd $r5 = $r4
; CV2-NEXT:    srad $r6 = $r6, 63
; CV2-NEXT:    srad $r7 = $r7, 63
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r2 = $r6, 63, 63
; CV2-NEXT:    insf $r3 = $r7, 63, 63
; CV2-NEXT:    srad $r4 = $r4, 63
; CV2-NEXT:    srad $r5 = $r5, 63
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r0 = $r4, 63, 63
; CV2-NEXT:    insf $r1 = $r5, 63, 63
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %tb = fpext <4 x float> %b to <4 x double>
  %r = call <4 x double> @llvm.copysign.v4f64(<4 x double> %a, <4 x double> %tb)
  ret <4 x double> %r
}

define <4 x double> @test_floor(<4 x double> %a) #0 {
; CHECK-LABEL: test_floor:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call floor
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call floor
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call floor
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call floor
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <4 x double> @llvm.floor.v4f64(<4 x double> %a)
  ret <4 x double> %r
}

define <4 x double> @test_ceil(<4 x double> %a) #0 {
; CHECK-LABEL: test_ceil:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call ceil
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call ceil
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call ceil
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call ceil
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <4 x double> @llvm.ceil.v4f64(<4 x double> %a)
  ret <4 x double> %r
}

define <4 x double> @test_trunc(<4 x double> %a) #0 {
; CHECK-LABEL: test_trunc:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call trunc
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call trunc
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call trunc
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call trunc
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <4 x double> @llvm.trunc.v4f64(<4 x double> %a)
  ret <4 x double> %r
}

define <4 x double> @test_rint(<4 x double> %a) #0 {
; CHECK-LABEL: test_rint:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call rint
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call rint
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call rint
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call rint
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <4 x double> @llvm.rint.v4f64(<4 x double> %a)
  ret <4 x double> %r
}

define <4 x double> @test_nearbyint(<4 x double> %a) #0 {
; CHECK-LABEL: test_nearbyint:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call nearbyint
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call nearbyint
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call nearbyint
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call nearbyint
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <4 x double> @llvm.nearbyint.v4f64(<4 x double> %a)
  ret <4 x double> %r
}

define <4 x double> @test_round(<4 x double> %a) #0 {
; CHECK-LABEL: test_round:
; CHECK:       # %bb.0:
; CHECK-NEXT:    addd $r12 = $r12, -64
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 56[$r12] = $r16
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    sd 48[$r12] = $r24
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sd 40[$r12] = $r22
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sq 24[$r12] = $r20r21
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sq 8[$r12] = $r18r19
; CHECK-NEXT:    copyd $r18 = $r3
; CHECK-NEXT:    copyd $r19 = $r2
; CHECK-NEXT:    copyd $r20 = $r1
; CHECK-NEXT:    call round
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    copyd $r0 = $r20
; CHECK-NEXT:    copyd $r24 = $r0
; CHECK-NEXT:    call round
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r19
; CHECK-NEXT:    copyd $r21 = $r0
; CHECK-NEXT:    call round
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r18
; CHECK-NEXT:    copyd $r22 = $r0
; CHECK-NEXT:    call round
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r24
; CHECK-NEXT:    copyd $r1 = $r21
; CHECK-NEXT:    copyd $r2 = $r22
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lq $r18r19 = 8[$r12]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lq $r20r21 = 24[$r12]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ld $r22 = 40[$r12]
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    ld $r24 = 48[$r12]
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    ld $r16 = 56[$r12]
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 64
; CHECK-NEXT:    ;; # (end cycle 10)
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
  %r = call <4 x double> @llvm.round.v4f64(<4 x double> %a)
  ret <4 x double> %r
}

define <4 x double> @test_fmuladd(<4 x double> %a, <4 x double> %b, <4 x double> %c) #0 {
; CHECK-LABEL: test_fmuladd:
; CHECK:       # %bb.0:
; CHECK-NEXT:    ffmad $r11 = $r3, $r7
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    ffmad $r10 = $r2, $r6
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    ffmad $r9 = $r1, $r5
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    ffmad $r8 = $r0, $r4
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r8
; CHECK-NEXT:    copyd $r1 = $r9
; CHECK-NEXT:    copyd $r2 = $r10
; CHECK-NEXT:    copyd $r3 = $r11
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 7)
  %r = call <4 x double> @llvm.fmuladd.v4f64(<4 x double> %a, <4 x double> %b, <4 x double> %c)
  ret <4 x double> %r
}

define <4 x double> @test_shufflevector(<4 x double> %a) #0 {
; CHECK-LABEL: test_shufflevector:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r0 = $r3
; CHECK-NEXT:    copyd $r1 = $r2
; CHECK-NEXT:    copyd $r2 = $r1
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %s = shufflevector <4 x double> %a, <4 x double> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  ret <4 x double> %s
}

define <4 x double> @test_insertelement0(<4 x double> %a, double %x) #0 {
; CHECK-LABEL: test_insertelement0:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %i = insertelement <4 x double> %a, double %x, i64 0
  ret <4 x double> %i
}

define <4 x double> @test_insertelement1(<4 x double> %a, double %x) #0 {
; CHECK-LABEL: test_insertelement1:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r1 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %i = insertelement <4 x double> %a, double %x, i64 1
  ret <4 x double> %i
}

define <4 x double> @test_insertelement2(<4 x double> %a, double %x) #0 {
; CHECK-LABEL: test_insertelement2:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r2 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %i = insertelement <4 x double> %a, double %x, i64 2
  ret <4 x double> %i
}

define <4 x double> @test_insertelement3(<4 x double> %a, double %x) #0 {
; CHECK-LABEL: test_insertelement3:
; CHECK:       # %bb.0:
; CHECK-NEXT:    copyd $r3 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
  %i = insertelement <4 x double> %a, double %x, i64 3
  ret <4 x double> %i
}


define <4 x double> @test_insertelement(<4 x double> %a, double %x, i64 %p) #0 {
; CV1-LABEL: test_insertelement:
; CV1:       # %bb.0:
; CV1-NEXT:    compd.eq $r6 = $r5, 3
; CV1-NEXT:    compd.eq $r7 = $r5, 2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    cmoved.odd $r7 ? $r2 = $r4
; CV1-NEXT:    cmoved.odd $r6 ? $r3 = $r4
; CV1-NEXT:    compd.eq $r5 = $r5, 0
; CV1-NEXT:    compd.eq $r6 = $r5, 1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    cmoved.odd $r5 ? $r0 = $r4
; CV1-NEXT:    cmoved.odd $r6 ? $r1 = $r4
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 2)
;
; CV2-LABEL: test_insertelement:
; CV2:       # %bb.0:
; CV2-NEXT:    compd.eq $r5 = $r5, 0
; CV2-NEXT:    compd.eq $r6 = $r5, 3
; CV2-NEXT:    compd.eq $r7 = $r5, 2
; CV2-NEXT:    compd.eq $r8 = $r5, 1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    cmoved.odd $r5 ? $r0 = $r4
; CV2-NEXT:    cmoved.odd $r8 ? $r1 = $r4
; CV2-NEXT:    cmoved.odd $r7 ? $r2 = $r4
; CV2-NEXT:    cmoved.odd $r6 ? $r3 = $r4
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 1)
  %i = insertelement <4 x double> %a, double %x, i64 %p
  ret <4 x double> %i
}

define <4 x i1> @fcmp_setoeq(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setoeq:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oeq $r2 = $r2, $r6
; CV1-NEXT:    fcompd.oeq $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oeq $r0 = $r0, $r4
; CV1-NEXT:    fcompd.oeq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setoeq:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.oeq $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.oeq $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.oeq $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.oeq $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp oeq <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setoeq_single(<4 x double> %a) #0 {
; CV1-LABEL: fcmp_setoeq_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oeq $r2 = $r2, $r2
; CV1-NEXT:    fcompd.oeq $r3 = $r3, $r3
; CV1-NEXT:    make $r4 = -1
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r4 = 0
; CV1-NEXT:    cmoved.even $r2 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oeq $r0 = $r0, $r0
; CV1-NEXT:    fcompd.oeq $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setoeq_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.oeq $r2 = $r2, $r2
; CV2-NEXT:    make $r3 = -1
; CV2-NEXT:    fcompd.oeq $r4 = $r3, $r3
; CV2-NEXT:    make $r5 = -1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.oeq $r0 = $r0, $r0
; CV2-NEXT:    fcompd.oeq $r1 = $r1, $r1
; CV2-NEXT:    make $r6 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    cmoved.even $r0 ? $r3 = 0
; CV2-NEXT:    cmoved.even $r4 ? $r5 = 0
; CV2-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r3 = $r7, 15, 8
; CV2-NEXT:    insf $r6 = $r5, 15, 8
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r3 = $r6, 31, 16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 5)
entry:
  %0 = fcmp oeq <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setogt(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setogt:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.olt $r2 = $r6, $r2
; CV1-NEXT:    fcompd.olt $r3 = $r7, $r3
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.olt $r0 = $r4, $r0
; CV1-NEXT:    fcompd.olt $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setogt:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.olt $r0 = $r4, $r0
; CV2-NEXT:    fcompnd.olt $r1 = $r5, $r1
; CV2-NEXT:    fcompnd.olt $r2 = $r6, $r2
; CV2-NEXT:    fcompnd.olt $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp ogt <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setogt_single(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setogt_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ogt <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setoge(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setoge:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oge $r2 = $r2, $r6
; CV1-NEXT:    fcompd.oge $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oge $r0 = $r0, $r4
; CV1-NEXT:    fcompd.oge $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setoge:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.oge $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.oge $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.oge $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp oge <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setoge_single(<4 x double> %a) #0 {
; CV1-LABEL: fcmp_setoge_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oeq $r2 = $r2, $r2
; CV1-NEXT:    fcompd.oeq $r3 = $r3, $r3
; CV1-NEXT:    make $r4 = -1
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r4 = 0
; CV1-NEXT:    cmoved.even $r2 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oeq $r0 = $r0, $r0
; CV1-NEXT:    fcompd.oeq $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setoge_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.oeq $r2 = $r2, $r2
; CV2-NEXT:    make $r3 = -1
; CV2-NEXT:    fcompd.oeq $r4 = $r3, $r3
; CV2-NEXT:    make $r5 = -1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.oeq $r0 = $r0, $r0
; CV2-NEXT:    fcompd.oeq $r1 = $r1, $r1
; CV2-NEXT:    make $r6 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    cmoved.even $r0 ? $r3 = 0
; CV2-NEXT:    cmoved.even $r4 ? $r5 = 0
; CV2-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r3 = $r7, 15, 8
; CV2-NEXT:    insf $r6 = $r5, 15, 8
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r3 = $r6, 31, 16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 5)
entry:
  %0 = fcmp oge <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setolt(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setolt:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.olt $r2 = $r2, $r6
; CV1-NEXT:    fcompd.olt $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.olt $r0 = $r0, $r4
; CV1-NEXT:    fcompd.olt $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setolt:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.olt $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.olt $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.olt $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.olt $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp olt <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setolt_single(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setolt_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp olt <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setole(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setole:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oge $r2 = $r6, $r2
; CV1-NEXT:    fcompd.oge $r3 = $r7, $r3
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oge $r0 = $r4, $r0
; CV1-NEXT:    fcompd.oge $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setole:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.oge $r0 = $r4, $r0
; CV2-NEXT:    fcompnd.oge $r1 = $r5, $r1
; CV2-NEXT:    fcompnd.oge $r2 = $r6, $r2
; CV2-NEXT:    fcompnd.oge $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp ole <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setole_single(<4 x double> %a) #0 {
; CV1-LABEL: fcmp_setole_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oeq $r2 = $r2, $r2
; CV1-NEXT:    fcompd.oeq $r3 = $r3, $r3
; CV1-NEXT:    make $r4 = -1
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r4 = 0
; CV1-NEXT:    cmoved.even $r2 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oeq $r0 = $r0, $r0
; CV1-NEXT:    fcompd.oeq $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setole_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.oeq $r2 = $r2, $r2
; CV2-NEXT:    make $r3 = -1
; CV2-NEXT:    fcompd.oeq $r4 = $r3, $r3
; CV2-NEXT:    make $r5 = -1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.oeq $r0 = $r0, $r0
; CV2-NEXT:    fcompd.oeq $r1 = $r1, $r1
; CV2-NEXT:    make $r6 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    cmoved.even $r0 ? $r3 = 0
; CV2-NEXT:    cmoved.even $r4 ? $r5 = 0
; CV2-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r3 = $r7, 15, 8
; CV2-NEXT:    insf $r6 = $r5, 15, 8
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r3 = $r6, 31, 16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 5)
entry:
  %0 = fcmp ole <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setone(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setone:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.one $r2 = $r2, $r6
; CV1-NEXT:    fcompd.one $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.one $r0 = $r0, $r4
; CV1-NEXT:    fcompd.one $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setone:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.one $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.one $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.one $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.one $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp one <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setone_single(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setone_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp one <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setord(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setord:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oge $r3 = $r3, $r7
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    fcompd.olt $r8 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompd.oge $r1 = $r1, $r5
; CV1-NEXT:    iorw $r3 = $r3, $r8
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    fcompd.olt $r8 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    iorw $r1 = $r1, $r8
; CV1-NEXT:    fcompd.olt $r3 = $r2, $r6
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    fcompd.oge $r6 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fcompd.oge $r0 = $r0, $r4
; CV1-NEXT:    iorw $r3 = $r6, $r3
; CV1-NEXT:    fcompd.olt $r6 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    iorw $r0 = $r0, $r6
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 9)
;
; CV2-LABEL: fcmp_setord:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.oge $r3 = $r3, $r7
; CV2-NEXT:    fcompd.oge $r6 = $r2, $r6
; CV2-NEXT:    fcompd.olt $r7 = $r2, $r6
; CV2-NEXT:    fcompd.olt $r8 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompd.olt $r5 = $r0, $r4
; CV2-NEXT:    iorw $r6 = $r6, $r7
; CV2-NEXT:    fcompd.olt $r7 = $r1, $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fcompd.oge $r0 = $r0, $r4
; CV2-NEXT:    make $r2 = -1
; CV2-NEXT:    iorw $r3 = $r3, $r8
; CV2-NEXT:    make $r8 = -1
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    iorw $r0 = $r0, $r5
; CV2-NEXT:    iorw $r1 = $r1, $r7
; CV2-NEXT:    make $r4 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV2-NEXT:    cmoved.even $r6 ? $r4 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    cmoved.even $r3 ? $r8 = 0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    insf $r2 = $r7, 15, 8
; CV2-NEXT:    insf $r4 = $r8, 15, 8
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    insf $r2 = $r4, 31, 16
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    copyd $r0 = $r2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 7)
entry:
  %0 = fcmp ord <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setord_single(<4 x double> %a) #0 {
; CV1-LABEL: fcmp_setord_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oeq $r2 = $r2, $r2
; CV1-NEXT:    fcompd.oeq $r3 = $r3, $r3
; CV1-NEXT:    make $r4 = -1
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r4 = 0
; CV1-NEXT:    cmoved.even $r2 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oeq $r0 = $r0, $r0
; CV1-NEXT:    fcompd.oeq $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setord_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.oeq $r2 = $r2, $r2
; CV2-NEXT:    make $r3 = -1
; CV2-NEXT:    fcompd.oeq $r4 = $r3, $r3
; CV2-NEXT:    make $r5 = -1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.oeq $r0 = $r0, $r0
; CV2-NEXT:    fcompd.oeq $r1 = $r1, $r1
; CV2-NEXT:    make $r6 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    cmoved.even $r0 ? $r3 = 0
; CV2-NEXT:    cmoved.even $r4 ? $r5 = 0
; CV2-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r3 = $r7, 15, 8
; CV2-NEXT:    insf $r6 = $r5, 15, 8
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r3 = $r6, 31, 16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 5)
entry:
  %0 = fcmp ord <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setuno(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setuno:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.uge $r3 = $r3, $r7
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    fcompd.ult $r8 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompd.uge $r1 = $r1, $r5
; CV1-NEXT:    andw $r3 = $r3, $r8
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    fcompd.ult $r8 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andw $r1 = $r1, $r8
; CV1-NEXT:    fcompd.ult $r3 = $r2, $r6
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    fcompd.uge $r6 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fcompd.uge $r0 = $r0, $r4
; CV1-NEXT:    andw $r3 = $r6, $r3
; CV1-NEXT:    fcompd.ult $r6 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    andw $r0 = $r0, $r6
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 9)
;
; CV2-LABEL: fcmp_setuno:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.uge $r3 = $r3, $r7
; CV2-NEXT:    fcompd.uge $r6 = $r2, $r6
; CV2-NEXT:    fcompd.ult $r7 = $r2, $r6
; CV2-NEXT:    fcompd.ult $r8 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.uge $r1 = $r1, $r5
; CV2-NEXT:    fcompd.ult $r5 = $r0, $r4
; CV2-NEXT:    andw $r6 = $r6, $r7
; CV2-NEXT:    fcompd.ult $r7 = $r1, $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fcompd.uge $r0 = $r0, $r4
; CV2-NEXT:    make $r2 = -1
; CV2-NEXT:    andw $r3 = $r3, $r8
; CV2-NEXT:    make $r8 = -1
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    andw $r0 = $r0, $r5
; CV2-NEXT:    andw $r1 = $r1, $r7
; CV2-NEXT:    make $r4 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV2-NEXT:    cmoved.even $r6 ? $r4 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    cmoved.even $r3 ? $r8 = 0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    insf $r2 = $r7, 15, 8
; CV2-NEXT:    insf $r4 = $r8, 15, 8
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    insf $r2 = $r4, 31, 16
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    copyd $r0 = $r2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 7)
entry:
  %0 = fcmp uno <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setuno_single(<4 x double> %a) #0 {
; CV1-LABEL: fcmp_setuno_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.une $r2 = $r2, $r2
; CV1-NEXT:    fcompd.une $r3 = $r3, $r3
; CV1-NEXT:    make $r4 = -1
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r4 = 0
; CV1-NEXT:    cmoved.even $r2 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.une $r0 = $r0, $r0
; CV1-NEXT:    fcompd.une $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setuno_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.une $r2 = $r2, $r2
; CV2-NEXT:    make $r3 = -1
; CV2-NEXT:    fcompd.une $r4 = $r3, $r3
; CV2-NEXT:    make $r5 = -1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.une $r0 = $r0, $r0
; CV2-NEXT:    fcompd.une $r1 = $r1, $r1
; CV2-NEXT:    make $r6 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    cmoved.even $r0 ? $r3 = 0
; CV2-NEXT:    cmoved.even $r4 ? $r5 = 0
; CV2-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r3 = $r7, 15, 8
; CV2-NEXT:    insf $r6 = $r5, 15, 8
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r3 = $r6, 31, 16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 5)
entry:
  %0 = fcmp uno <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setueq(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setueq:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.ueq $r2 = $r2, $r6
; CV1-NEXT:    fcompd.ueq $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.ueq $r0 = $r0, $r4
; CV1-NEXT:    fcompd.ueq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setueq:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.ueq $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.ueq $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.ueq $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.ueq $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp ueq <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setueq_single(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setueq_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ueq <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setugt(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setugt:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.ult $r2 = $r6, $r2
; CV1-NEXT:    fcompd.ult $r3 = $r7, $r3
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.ult $r0 = $r4, $r0
; CV1-NEXT:    fcompd.ult $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setugt:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.ult $r0 = $r4, $r0
; CV2-NEXT:    fcompnd.ult $r1 = $r5, $r1
; CV2-NEXT:    fcompnd.ult $r2 = $r6, $r2
; CV2-NEXT:    fcompnd.ult $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp ugt <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setugt_single(<4 x double> %a) #0 {
; CV1-LABEL: fcmp_setugt_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.une $r2 = $r2, $r2
; CV1-NEXT:    fcompd.une $r3 = $r3, $r3
; CV1-NEXT:    make $r4 = -1
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r4 = 0
; CV1-NEXT:    cmoved.even $r2 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.une $r0 = $r0, $r0
; CV1-NEXT:    fcompd.une $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setugt_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.une $r2 = $r2, $r2
; CV2-NEXT:    make $r3 = -1
; CV2-NEXT:    fcompd.une $r4 = $r3, $r3
; CV2-NEXT:    make $r5 = -1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.une $r0 = $r0, $r0
; CV2-NEXT:    fcompd.une $r1 = $r1, $r1
; CV2-NEXT:    make $r6 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    cmoved.even $r0 ? $r3 = 0
; CV2-NEXT:    cmoved.even $r4 ? $r5 = 0
; CV2-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r3 = $r7, 15, 8
; CV2-NEXT:    insf $r6 = $r5, 15, 8
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r3 = $r6, 31, 16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 5)
entry:
  %0 = fcmp ugt <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setuge(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setuge:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.uge $r2 = $r2, $r6
; CV1-NEXT:    fcompd.uge $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.uge $r0 = $r0, $r4
; CV1-NEXT:    fcompd.uge $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setuge:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.uge $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.uge $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.uge $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.uge $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp uge <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setuge_single(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setuge_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp uge <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setult(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setult:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.ult $r2 = $r2, $r6
; CV1-NEXT:    fcompd.ult $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.ult $r0 = $r0, $r4
; CV1-NEXT:    fcompd.ult $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setult:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.ult $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.ult $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.ult $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.ult $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp ult <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setult_single(<4 x double> %a) #0 {
; CV1-LABEL: fcmp_setult_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.une $r2 = $r2, $r2
; CV1-NEXT:    fcompd.une $r3 = $r3, $r3
; CV1-NEXT:    make $r4 = -1
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r4 = 0
; CV1-NEXT:    cmoved.even $r2 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.une $r0 = $r0, $r0
; CV1-NEXT:    fcompd.une $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setult_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.une $r2 = $r2, $r2
; CV2-NEXT:    make $r3 = -1
; CV2-NEXT:    fcompd.une $r4 = $r3, $r3
; CV2-NEXT:    make $r5 = -1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.une $r0 = $r0, $r0
; CV2-NEXT:    fcompd.une $r1 = $r1, $r1
; CV2-NEXT:    make $r6 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    cmoved.even $r0 ? $r3 = 0
; CV2-NEXT:    cmoved.even $r4 ? $r5 = 0
; CV2-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r3 = $r7, 15, 8
; CV2-NEXT:    insf $r6 = $r5, 15, 8
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r3 = $r6, 31, 16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 5)
entry:
  %0 = fcmp ult <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setule(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setule:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.uge $r2 = $r6, $r2
; CV1-NEXT:    fcompd.uge $r3 = $r7, $r3
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.uge $r0 = $r4, $r0
; CV1-NEXT:    fcompd.uge $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setule:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.uge $r0 = $r4, $r0
; CV2-NEXT:    fcompnd.uge $r1 = $r5, $r1
; CV2-NEXT:    fcompnd.uge $r2 = $r6, $r2
; CV2-NEXT:    fcompnd.uge $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp ule <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setule_single(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setule_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ule <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setune(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setune:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.une $r2 = $r2, $r6
; CV1-NEXT:    fcompd.une $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.une $r0 = $r0, $r4
; CV1-NEXT:    fcompd.une $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setune:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.une $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.une $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.une $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.une $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp une <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setune_single(<4 x double> %a) #0 {
; CV1-LABEL: fcmp_setune_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.une $r2 = $r2, $r2
; CV1-NEXT:    fcompd.une $r3 = $r3, $r3
; CV1-NEXT:    make $r4 = -1
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r4 = 0
; CV1-NEXT:    cmoved.even $r2 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.une $r0 = $r0, $r0
; CV1-NEXT:    fcompd.une $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setune_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.une $r2 = $r2, $r2
; CV2-NEXT:    make $r3 = -1
; CV2-NEXT:    fcompd.une $r4 = $r3, $r3
; CV2-NEXT:    make $r5 = -1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.une $r0 = $r0, $r0
; CV2-NEXT:    fcompd.une $r1 = $r1, $r1
; CV2-NEXT:    make $r6 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    cmoved.even $r0 ? $r3 = 0
; CV2-NEXT:    cmoved.even $r4 ? $r5 = 0
; CV2-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r3 = $r7, 15, 8
; CV2-NEXT:    insf $r6 = $r5, 15, 8
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r3 = $r6, 31, 16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 5)
entry:
  %0 = fcmp une <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setoeq_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setoeq_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oeq $r2 = $r2, $r6
; CV1-NEXT:    fcompd.oeq $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oeq $r0 = $r0, $r4
; CV1-NEXT:    fcompd.oeq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setoeq_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.oeq $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.oeq $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.oeq $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.oeq $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast oeq <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setoeq_single_fast(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setoeq_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast oeq <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setogt_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setogt_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.olt $r2 = $r6, $r2
; CV1-NEXT:    fcompd.olt $r3 = $r7, $r3
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.olt $r0 = $r4, $r0
; CV1-NEXT:    fcompd.olt $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setogt_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.olt $r0 = $r4, $r0
; CV2-NEXT:    fcompnd.olt $r1 = $r5, $r1
; CV2-NEXT:    fcompnd.olt $r2 = $r6, $r2
; CV2-NEXT:    fcompnd.olt $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast ogt <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setogt_single_fast(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setogt_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ogt <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setoge_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setoge_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oge $r2 = $r2, $r6
; CV1-NEXT:    fcompd.oge $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oge $r0 = $r0, $r4
; CV1-NEXT:    fcompd.oge $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setoge_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.oge $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.oge $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.oge $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast oge <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setoge_single_fast(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setoge_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast oge <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setolt_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setolt_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.olt $r2 = $r2, $r6
; CV1-NEXT:    fcompd.olt $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.olt $r0 = $r0, $r4
; CV1-NEXT:    fcompd.olt $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setolt_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.olt $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.olt $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.olt $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.olt $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast olt <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setolt_single_fast(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setolt_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast olt <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setole_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setole_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oge $r2 = $r6, $r2
; CV1-NEXT:    fcompd.oge $r3 = $r7, $r3
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oge $r0 = $r4, $r0
; CV1-NEXT:    fcompd.oge $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setole_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.oge $r0 = $r4, $r0
; CV2-NEXT:    fcompnd.oge $r1 = $r5, $r1
; CV2-NEXT:    fcompnd.oge $r2 = $r6, $r2
; CV2-NEXT:    fcompnd.oge $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast ole <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setole_single_fast(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setole_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ole <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setone_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setone_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.one $r2 = $r2, $r6
; CV1-NEXT:    fcompd.one $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.one $r0 = $r0, $r4
; CV1-NEXT:    fcompd.one $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setone_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.one $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.one $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.one $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.one $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast one <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setone_single_fast(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setone_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast one <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setord_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setord_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oge $r3 = $r3, $r7
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    fcompd.olt $r8 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompd.oge $r1 = $r1, $r5
; CV1-NEXT:    iorw $r3 = $r3, $r8
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    fcompd.olt $r8 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    iorw $r1 = $r1, $r8
; CV1-NEXT:    fcompd.olt $r3 = $r2, $r6
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    fcompd.oge $r6 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fcompd.oge $r0 = $r0, $r4
; CV1-NEXT:    iorw $r3 = $r6, $r3
; CV1-NEXT:    fcompd.olt $r6 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    iorw $r0 = $r0, $r6
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 9)
;
; CV2-LABEL: fcmp_setord_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.oge $r3 = $r3, $r7
; CV2-NEXT:    fcompd.oge $r6 = $r2, $r6
; CV2-NEXT:    fcompd.olt $r7 = $r2, $r6
; CV2-NEXT:    fcompd.olt $r8 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompd.olt $r5 = $r0, $r4
; CV2-NEXT:    iorw $r6 = $r6, $r7
; CV2-NEXT:    fcompd.olt $r7 = $r1, $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fcompd.oge $r0 = $r0, $r4
; CV2-NEXT:    make $r2 = -1
; CV2-NEXT:    iorw $r3 = $r3, $r8
; CV2-NEXT:    make $r8 = -1
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    iorw $r0 = $r0, $r5
; CV2-NEXT:    iorw $r1 = $r1, $r7
; CV2-NEXT:    make $r4 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV2-NEXT:    cmoved.even $r6 ? $r4 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    cmoved.even $r3 ? $r8 = 0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    insf $r2 = $r7, 15, 8
; CV2-NEXT:    insf $r4 = $r8, 15, 8
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    insf $r2 = $r4, 31, 16
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    copyd $r0 = $r2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 7)
entry:
  %0 = fcmp fast ord <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setord_single_fast(<4 x double> %a) #0 {
; CV1-LABEL: fcmp_setord_single_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oeq $r2 = $r2, $r2
; CV1-NEXT:    fcompd.oeq $r3 = $r3, $r3
; CV1-NEXT:    make $r4 = -1
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r4 = 0
; CV1-NEXT:    cmoved.even $r2 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oeq $r0 = $r0, $r0
; CV1-NEXT:    fcompd.oeq $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setord_single_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.oeq $r2 = $r2, $r2
; CV2-NEXT:    make $r3 = -1
; CV2-NEXT:    fcompd.oeq $r4 = $r3, $r3
; CV2-NEXT:    make $r5 = -1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.oeq $r0 = $r0, $r0
; CV2-NEXT:    fcompd.oeq $r1 = $r1, $r1
; CV2-NEXT:    make $r6 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    cmoved.even $r0 ? $r3 = 0
; CV2-NEXT:    cmoved.even $r4 ? $r5 = 0
; CV2-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r3 = $r7, 15, 8
; CV2-NEXT:    insf $r6 = $r5, 15, 8
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r3 = $r6, 31, 16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 5)
entry:
  %0 = fcmp fast ord <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setuno_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setuno_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.uge $r3 = $r3, $r7
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    fcompd.ult $r8 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompd.uge $r1 = $r1, $r5
; CV1-NEXT:    andw $r3 = $r3, $r8
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    fcompd.ult $r8 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andw $r1 = $r1, $r8
; CV1-NEXT:    fcompd.ult $r3 = $r2, $r6
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    fcompd.uge $r6 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fcompd.uge $r0 = $r0, $r4
; CV1-NEXT:    andw $r3 = $r6, $r3
; CV1-NEXT:    fcompd.ult $r6 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    andw $r0 = $r0, $r6
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 9)
;
; CV2-LABEL: fcmp_setuno_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.uge $r3 = $r3, $r7
; CV2-NEXT:    fcompd.uge $r6 = $r2, $r6
; CV2-NEXT:    fcompd.ult $r7 = $r2, $r6
; CV2-NEXT:    fcompd.ult $r8 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.uge $r1 = $r1, $r5
; CV2-NEXT:    fcompd.ult $r5 = $r0, $r4
; CV2-NEXT:    andw $r6 = $r6, $r7
; CV2-NEXT:    fcompd.ult $r7 = $r1, $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fcompd.uge $r0 = $r0, $r4
; CV2-NEXT:    make $r2 = -1
; CV2-NEXT:    andw $r3 = $r3, $r8
; CV2-NEXT:    make $r8 = -1
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    andw $r0 = $r0, $r5
; CV2-NEXT:    andw $r1 = $r1, $r7
; CV2-NEXT:    make $r4 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV2-NEXT:    cmoved.even $r6 ? $r4 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    cmoved.even $r3 ? $r8 = 0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    insf $r2 = $r7, 15, 8
; CV2-NEXT:    insf $r4 = $r8, 15, 8
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    insf $r2 = $r4, 31, 16
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    copyd $r0 = $r2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 7)
entry:
  %0 = fcmp fast uno <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setuno_single_fast(<4 x double> %a) #0 {
; CV1-LABEL: fcmp_setuno_single_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.une $r2 = $r2, $r2
; CV1-NEXT:    fcompd.une $r3 = $r3, $r3
; CV1-NEXT:    make $r4 = -1
; CV1-NEXT:    make $r5 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r3 ? $r4 = 0
; CV1-NEXT:    cmoved.even $r2 ? $r5 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.une $r0 = $r0, $r0
; CV1-NEXT:    fcompd.une $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setuno_single_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompd.une $r2 = $r2, $r2
; CV2-NEXT:    make $r3 = -1
; CV2-NEXT:    fcompd.une $r4 = $r3, $r3
; CV2-NEXT:    make $r5 = -1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompd.une $r0 = $r0, $r0
; CV2-NEXT:    fcompd.une $r1 = $r1, $r1
; CV2-NEXT:    make $r6 = -1
; CV2-NEXT:    make $r7 = -1
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    cmoved.even $r0 ? $r3 = 0
; CV2-NEXT:    cmoved.even $r4 ? $r5 = 0
; CV2-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV2-NEXT:    cmoved.even $r1 ? $r7 = 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r3 = $r7, 15, 8
; CV2-NEXT:    insf $r6 = $r5, 15, 8
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r3 = $r6, 31, 16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 5)
entry:
  %0 = fcmp fast uno <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setueq_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setueq_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oeq $r2 = $r2, $r6
; CV1-NEXT:    fcompd.oeq $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oeq $r0 = $r0, $r4
; CV1-NEXT:    fcompd.oeq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setueq_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.oeq $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.oeq $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.oeq $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.oeq $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast ueq <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setueq_single_fast(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setueq_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ueq <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setugt_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setugt_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.olt $r2 = $r6, $r2
; CV1-NEXT:    fcompd.olt $r3 = $r7, $r3
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.olt $r0 = $r4, $r0
; CV1-NEXT:    fcompd.olt $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setugt_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.olt $r0 = $r4, $r0
; CV2-NEXT:    fcompnd.olt $r1 = $r5, $r1
; CV2-NEXT:    fcompnd.olt $r2 = $r6, $r2
; CV2-NEXT:    fcompnd.olt $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast ugt <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setugt_single_fast(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setugt_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ugt <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setuge_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setuge_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oge $r2 = $r2, $r6
; CV1-NEXT:    fcompd.oge $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oge $r0 = $r0, $r4
; CV1-NEXT:    fcompd.oge $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setuge_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.oge $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.oge $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.oge $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast uge <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setuge_single_fast(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setuge_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast uge <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setult_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setult_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.olt $r2 = $r2, $r6
; CV1-NEXT:    fcompd.olt $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.olt $r0 = $r0, $r4
; CV1-NEXT:    fcompd.olt $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setult_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.olt $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.olt $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.olt $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.olt $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast ult <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setult_single_fast(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setult_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ult <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setule_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setule_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.oge $r2 = $r6, $r2
; CV1-NEXT:    fcompd.oge $r3 = $r7, $r3
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.oge $r0 = $r4, $r0
; CV1-NEXT:    fcompd.oge $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setule_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.oge $r0 = $r4, $r0
; CV2-NEXT:    fcompnd.oge $r1 = $r5, $r1
; CV2-NEXT:    fcompnd.oge $r2 = $r6, $r2
; CV2-NEXT:    fcompnd.oge $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast ule <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setule_single_fast(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setule_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = -1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ule <4 x double> %a, %a
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setune_fast(<4 x double> %a, <4 x double> %b) #0 {
; CV1-LABEL: fcmp_setune_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompd.one $r2 = $r2, $r6
; CV1-NEXT:    fcompd.one $r3 = $r3, $r7
; CV1-NEXT:    make $r6 = -1
; CV1-NEXT:    make $r7 = -1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    make $r2 = -1
; CV1-NEXT:    make $r3 = -1
; CV1-NEXT:    cmoved.even $r2 ? $r6 = 0
; CV1-NEXT:    cmoved.even $r3 ? $r7 = 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fcompd.one $r0 = $r0, $r4
; CV1-NEXT:    fcompd.one $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.even $r0 ? $r2 = 0
; CV1-NEXT:    cmoved.even $r1 ? $r3 = 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r2 = $r3, 15, 8
; CV1-NEXT:    insf $r6 = $r7, 15, 8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r2 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r0 = $r2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: fcmp_setune_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnd.one $r0 = $r0, $r4
; CV2-NEXT:    fcompnd.one $r1 = $r1, $r5
; CV2-NEXT:    fcompnd.one $r2 = $r2, $r6
; CV2-NEXT:    fcompnd.one $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r1, 15, 8
; CV2-NEXT:    insf $r2 = $r3, 15, 8
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r2, 31, 16
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast une <4 x double> %a, %b
  ret <4 x i1> %0
}

define <4 x i1> @fcmp_setune_single_fast(<4 x double> %a) #0 {
; CHECK-LABEL: fcmp_setune_single_fast:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r0 = 0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast une <4 x double> %a, %a
  ret <4 x i1> %0
}

attributes #0 = { nounwind }

define void @subvec0fp(ptr %0) {
; CHECK-LABEL: subvec0fp:
; CHECK:       # %bb.0:
  br label %2

2:
  %3 = shufflevector <4 x double> zeroinitializer, <4 x double> undef, <2 x i32> <i32 0, i32 1>
  %4 = fadd <2 x double> zeroinitializer, %3
  %5 = shufflevector <2 x double> %4, <2 x double> poison, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %6 = shufflevector <4 x double> %5, <4 x double> zeroinitializer, <4 x i32> <i32 0, i32 1, i32 6, i32 7>
  store <4 x double> %6, ptr undef, align 16
  br label %2
}

define void @subvec2fp(ptr %0) {
; CHECK-LABEL: subvec2fp:
; CHECK:       # %bb.0:
  br label %2

2:
  %3 = shufflevector <4 x double> zeroinitializer, <4 x double> undef, <2 x i32> <i32 0, i32 1>
  %4 = fadd <2 x double> zeroinitializer, %3
  %5 = shufflevector <2 x double> %4, <2 x double> poison, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %6 = shufflevector <4 x double> %5, <4 x double> zeroinitializer, <4 x i32> <i32 6, i32 7, i32 2, i32 3>
  store <4 x double> %6, ptr undef, align 16
  br label %2
}

define <4 x double> @test_select_cmp(<4 x double> %a, <4 x double> %b, <4 x double> %c, <4 x double> %d) #0 {
; CV1-LABEL: test_select_cmp:
; CV1:       # %bb.0:
; CV1-NEXT:    ld $r15 = 8[$r12]
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    ld $r16 = 0[$r12]
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r17 = 16[$r12]
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fcompd.une $r9 = $r9, $r15
; CV1-NEXT:    make $r15 = -1
; CV1-NEXT:    ld $r32 = 24[$r12]
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fcompd.une $r8 = $r8, $r16
; CV1-NEXT:    cmoved.even $r9 ? $r15 = 0
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    fcompd.une $r9 = $r10, $r17
; CV1-NEXT:    cmoved.even $r8 ? $r15 = 0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fcompd.une $r8 = $r11, $r32
; CV1-NEXT:    cmoved.even $r9 ? $r15 = 0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    cmoved.even $r8 ? $r15 = 0
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    compd.eq $r8 = $r15, -1
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    cmoved.even $r8 ? $r2 = $r6
; CV1-NEXT:    cmoved.even $r8 ? $r3 = $r7
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    cmoved.even $r8 ? $r0 = $r4
; CV1-NEXT:    cmoved.even $r8 ? $r1 = $r5
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 10)
;
; CV2-LABEL: test_select_cmp:
; CV2:       # %bb.0:
; CV2-NEXT:    ld $r15 = 0[$r12]
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    ld $r16 = 8[$r12]
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r17 = 16[$r12]
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fcompd.une $r8 = $r8, $r15
; CV2-NEXT:    ld $r32 = 24[$r12]
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fcompnd.une $r9 = $r9, $r16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    fcompd.une $r8 = $r10, $r17
; CV2-NEXT:    cmoved.even $r8 ? $r9 = 0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fcompd.une $r8 = $r11, $r32
; CV2-NEXT:    cmoved.even $r8 ? $r9 = 0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    cmoved.even $r8 ? $r9 = 0
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    compd.eq $r8 = $r9, -1
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    cmoved.even $r8 ? $r0 = $r4
; CV2-NEXT:    cmoved.even $r8 ? $r1 = $r5
; CV2-NEXT:    cmoved.even $r8 ? $r2 = $r6
; CV2-NEXT:    cmoved.even $r8 ? $r3 = $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 9)
  %cc = fcmp une <4 x double> %c, %d
  %bc = bitcast <4 x i1> %cc to i4
  %cmp = icmp eq i4 %bc, -1
  %r = select i1 %cmp, <4 x double> %a, <4 x double> %b
  ret <4 x double> %r
}
