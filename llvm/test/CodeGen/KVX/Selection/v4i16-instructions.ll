; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O2 -o - %s | FileCheck --check-prefixes=ALL,V1 %s
; RUN: llc -mcpu=kv3-2 -O2 -o - %s | FileCheck --check-prefixes=ALL,V2 %s
; RUN: clang -O2 -c -o /dev/null %s
; RUN: clang -O2 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define <4 x i16> @test_ret_const() {
; ALL-LABEL: test_ret_const:
; ALL:       # %bb.0:
; ALL-NEXT:    make $r0 = 0x2000100020001
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  ret <4 x i16> <i16 1, i16 2, i16 1, i16 2>
}

define i16 @test_extract_0(<4 x i16> %a) {
; ALL-LABEL: test_extract_0:
; ALL:       # %bb.0:
; ALL-NEXT:    zxhd $r0 = $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %e = extractelement <4 x i16> %a, i16 0
  ret i16 %e
}

define i16 @test_extract_1(<4 x i16> %a) {
; ALL-LABEL: test_extract_1:
; ALL:       # %bb.0:
; ALL-NEXT:    srlw $r0 = $r0, 16
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %e = extractelement <4 x i16> %a, i16 1
  ret i16 %e
}

define i16 @test_extract_2(<4 x i16> %a) {
; ALL-LABEL: test_extract_2:
; ALL:       # %bb.0:
; ALL-NEXT:    extfz $r0 = $r0, 47, 32
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %e = extractelement <4 x i16> %a, i16 2
  ret i16 %e
}

define i16 @test_extract_3(<4 x i16> %a) {
; ALL-LABEL: test_extract_3:
; ALL:       # %bb.0:
; ALL-NEXT:    srld $r0 = $r0, 48
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %e = extractelement <4 x i16> %a, i16 3
  ret i16 %e
}

define <4 x i16> @test_fma(<4 x i16> %a, <4 x i16> %b, <4 x i16> %c) {
; ALL-LABEL: test_fma:
; ALL:       # %bb.0:
; ALL-NEXT:    maddhq $r0 = $r1, $r2
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %m = mul <4 x i16> %b, %c
  %ad = add <4 x i16> %a, %m
  ret <4 x i16> %ad
}

define <4 x i16> @test_fma_imm(<4 x i16> %a, <4 x i16> %b) {
; V1-LABEL: test_fma_imm:
; V1:       # %bb.0:
; V1-NEXT:    maddhq $r0 = $r1, 0x3000100020007
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 0)
;
; V2-LABEL: test_fma_imm:
; V2:       # %bb.0:
; V2-NEXT:    make $r2 = 0x3000100020007
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    maddhq $r0 = $r1, $r2
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %m = mul <4 x i16> <i16 7, i16 2, i16 1, i16 3>, %b
  %ad = add <4 x i16> %a, %m
  ret <4 x i16> %ad
}


define <4 x i16> @test_fma_imm_2(<4 x i16> %a, <4 x i16> %b) {
; V1-LABEL: test_fma_imm_2:
; V1:       # %bb.0:
; V1-NEXT:    maddhq $r0 = $r1, 0x2000100020001
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 0)
;
; V2-LABEL: test_fma_imm_2:
; V2:       # %bb.0:
; V2-NEXT:    make $r2 = 0x2000100020001
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    maddhq $r0 = $r1, $r2
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %m = mul <4 x i16> <i16 1, i16 2, i16 1, i16 2>, %b
  %ad = add <4 x i16> %a, %m
  ret <4 x i16> %ad
}

define i16 @test_extract_i(<4 x i16> %a, i64 %idx) #0 {
; ALL-LABEL: test_extract_i:
; ALL:       # %bb.0:
; ALL-NEXT:    sllw $r1 = $r1, 4
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    srld $r0 = $r0, $r1
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    zxhd $r0 = $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 2)
  %e = extractelement <4 x i16> %a, i64 %idx
  ret i16 %e
}

define <4 x i16> @test_add(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: test_add:
; ALL:       # %bb.0:
; ALL-NEXT:    addhq $r0 = $r0, $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = add <4 x i16> %a, %b
  ret <4 x i16> %r
}

define <4 x i16> @test_add_imm_0(<4 x i16> %a) {
; ALL-LABEL: test_add_imm_0:
; ALL:       # %bb.0:
; ALL-NEXT:    addhq $r0 = $r0, 0x20001.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = add <4 x i16> <i16 1, i16 2, i16 1, i16 2>, %a
  ret <4 x i16> %r
}

define <4 x i16> @test_add_imm_1(<4 x i16> %a) {
; ALL-LABEL: test_add_imm_1:
; ALL:       # %bb.0:
; ALL-NEXT:    addhq $r0 = $r0, 0x20001.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = add <4 x i16> %a, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %r
}

define <4 x i16> @test_sub(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: test_sub:
; ALL:       # %bb.0:
; ALL-NEXT:    sbfhq $r0 = $r1, $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = sub <4 x i16> %a, %b
  ret <4 x i16> %r
}

define <4 x i16> @test_sub_imm(<4 x i16> %a) {
; ALL-LABEL: test_sub_imm:
; ALL:       # %bb.0:
; ALL-NEXT:    addhq $r0 = $r0, 0xfffeffff.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = sub <4 x i16> %a, <i16 1, i16 2, i16 1, i16 2>
  ret <4 x i16> %r
}

define <4 x i16> @test_sub_fromimm(<4 x i16> %a) {
; ALL-LABEL: test_sub_fromimm:
; ALL:       # %bb.0:
; ALL-NEXT:    sbfhq $r0 = $r0, 0x20001.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = sub <4 x i16> <i16 1, i16 2, i16 1, i16 2>, %a
  ret <4 x i16> %r
}

define <4 x i16> @test_neg(<4 x i16> %a) {
; ALL-LABEL: test_neg:
; ALL:       # %bb.0:
; ALL-NEXT:    neghq $r0 = $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = sub <4 x i16> <i16 0, i16 0, i16 0, i16 0>, %a
  ret <4 x i16> %r
}

define <4 x i16> @test_mul(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: test_mul:
; ALL:       # %bb.0:
; ALL-NEXT:    mulhq $r0 = $r0, $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = mul <4 x i16> %a, %b
  ret <4 x i16> %r
}

define <4 x i16> @test_mul_2(<4 x i16> %a, <4 x i16> %b, <4 x i16> %c) {
; ALL-LABEL: test_mul_2:
; ALL:       # %bb.0:
; ALL-NEXT:    mulhq $r0 = $r0, $r1
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    mulhq $r0 = $r0, $r2
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 2)
  %r = mul <4 x i16> %a, %b
  %r1 = mul <4 x i16> %r, %c
  ret <4 x i16> %r1
}

define <4 x i16> @test_div(<4 x i16> %a, <4 x i16> %b) #0 {
; ALL-LABEL: test_div:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call __divv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = sdiv <4 x i16> %a, %b
  ret <4 x i16> %r
}

define <4 x i16> @test_rem(<4 x i16> %a, <4 x i16> %b) #0 {
; ALL-LABEL: test_rem:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call __modv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = srem <4 x i16> %a, %b
  ret <4 x i16> %r
}

define void @test_ldst_v4i16(ptr %a, ptr %b) {
; ALL-LABEL: test_ldst_v4i16:
; ALL:       # %bb.0:
; ALL-NEXT:    ld $r0 = 0[$r0]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 0[$r1] = $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 2)
  %t1 = load <4 x i16>, ptr %a
  store <4 x i16> %t1, ptr %b, align 16
  ret void
}

declare <4 x i16> @test_callee(<4 x i16> %a, <4 x i16> %b)

define <4 x i16> @test_call(<4 x i16> %a, <4 x i16> %b) #0 {
; ALL-LABEL: test_call:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call test_callee
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = call <4 x i16> @test_callee(<4 x i16> %a, <4 x i16> %b)
  ret <4 x i16> %r
}

define <4 x i16> @test_call_flipped(<4 x i16> %a, <4 x i16> %b) #0 {
; ALL-LABEL: test_call_flipped:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    copyd $r0 = $r1
; ALL-NEXT:    copyd $r1 = $r0
; ALL-NEXT:    call test_callee
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = call <4 x i16> @test_callee(<4 x i16> %b, <4 x i16> %a)
  ret <4 x i16> %r
}

; Can perform swap in a single bundle
define <4 x i16> @test_tailcall_flipped(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: test_tailcall_flipped:
; ALL:       # %bb.0:
; ALL-NEXT:    copyd $r0 = $r1
; ALL-NEXT:    copyd $r1 = $r0
; ALL-NEXT:    goto test_callee
; ALL-NEXT:    ;; # (end cycle 0)
  %r = tail call <4 x i16> @test_callee(<4 x i16> %b, <4 x i16> %a)
  ret <4 x i16> %r
}

define <4 x i16> @test_select(<4 x i16> %a, <4 x i16> %b, i1 zeroext %c) {
; ALL-LABEL: test_select:
; ALL:       # %bb.0:
; ALL-NEXT:    cmoved.even $r2 ? $r0 = $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = select i1 %c, <4 x i16> %a, <4 x i16> %b
  ret <4 x i16> %r
}

define <4 x i16> @test_select_cc(<4 x i16> %a, <4 x i16> %b, <4 x i16> %c, <4 x i16> %d) {
; ALL-LABEL: test_select_cc:
; ALL:       # %bb.0:
; ALL-NEXT:    compnhq.lt $r2 = $r2, $r3
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    cmovehq.even $r2 ? $r0 = $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 1)
  %cc = icmp slt <4 x i16> %c, %d
  %r = select <4 x i1> %cc, <4 x i16> %a, <4 x i16> %b
  ret <4 x i16> %r
}

define <4 x i64> @test_select_cc_f32_f32(<4 x i64> %a, <4 x i64> %b, <4 x i16> %c, <4 x i16> %d) {
; V1-LABEL: test_select_cc_f32_f32:
; V1:       # %bb.0:
; V1-NEXT:    compnhq.ltu $r8 = $r8, $r9
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    srlw $r8 = $r8, 16
; V1-NEXT:    srld $r9 = $r8, 48
; V1-NEXT:    extfz $r10 = $r8, 47, 32
; V1-NEXT:    zxhd $r11 = $r8
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sxhd $r9 = $r9
; V1-NEXT:    sxhd $r10 = $r10
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    sxhd $r8 = $r8
; V1-NEXT:    sxhd $r11 = $r11
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    cmoved.dnez $r11 ? $r4 = $r0
; V1-NEXT:    cmoved.dnez $r8 ? $r5 = $r1
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    copyd $r0 = $r4
; V1-NEXT:    copyd $r1 = $r5
; V1-NEXT:    cmoved.dnez $r10 ? $r6 = $r2
; V1-NEXT:    cmoved.dnez $r9 ? $r7 = $r3
; V1-NEXT:    ;; # (end cycle 5)
; V1-NEXT:    copyd $r2 = $r6
; V1-NEXT:    copyd $r3 = $r7
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 6)
;
; V2-LABEL: test_select_cc_f32_f32:
; V2:       # %bb.0:
; V2-NEXT:    compnhq.ltu $r8 = $r8, $r9
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    srlw $r8 = $r8, 16
; V2-NEXT:    srld $r9 = $r8, 48
; V2-NEXT:    extfz $r10 = $r8, 47, 32
; V2-NEXT:    zxhd $r11 = $r8
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    sxhd $r8 = $r8
; V2-NEXT:    sxhd $r9 = $r9
; V2-NEXT:    sxhd $r10 = $r10
; V2-NEXT:    sxhd $r11 = $r11
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    cmoved.dnez $r11 ? $r4 = $r0
; V2-NEXT:    cmoved.dnez $r8 ? $r5 = $r1
; V2-NEXT:    cmoved.dnez $r10 ? $r6 = $r2
; V2-NEXT:    cmoved.dnez $r9 ? $r7 = $r3
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    copyd $r0 = $r4
; V2-NEXT:    copyd $r1 = $r5
; V2-NEXT:    copyd $r2 = $r6
; V2-NEXT:    copyd $r3 = $r7
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 4)
  %cc = icmp ult <4 x i16> %c, %d
  %r = select <4 x i1> %cc, <4 x i64> %a, <4 x i64> %b
  ret <4 x i64> %r
}

define <4 x i1> @test_icmp_ule(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: test_icmp_ule:
; ALL:       # %bb.0:
; ALL-NEXT:    compnhq.leu $r0 = $r0, $r1
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 1)
  %r = icmp ule <4 x i16> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_icmp_slt(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: test_icmp_slt:
; ALL:       # %bb.0:
; ALL-NEXT:    compnhq.lt $r0 = $r0, $r1
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 1)
  %r = icmp slt <4 x i16> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_icmp_ugt(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: test_icmp_ugt:
; ALL:       # %bb.0:
; ALL-NEXT:    compnhq.gtu $r0 = $r0, $r1
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 1)
  %r = icmp ugt <4 x i16> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_icmp_uge(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: test_icmp_uge:
; ALL:       # %bb.0:
; ALL-NEXT:    compnhq.geu $r0 = $r0, $r1
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 1)
  %r = icmp uge <4 x i16> %a, %b
  ret <4 x i1> %r
}

define <4 x i1> @test_icmp_ult(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: test_icmp_ult:
; ALL:       # %bb.0:
; ALL-NEXT:    compnhq.ltu $r0 = $r0, $r1
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 1)
  %r = icmp ult <4 x i16> %a, %b
  ret <4 x i1> %r
}

define <4 x i8> @trunc_to_v4i8(<4 x i16> %a) {
; ALL-LABEL: trunc_to_v4i8:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = trunc <4 x i16> %a to <4 x i8>
  ret <4 x i8> %r
}

define <4 x i8> @trunc_to_v4i8_buildvector(i32 %arg1, i32 %arg2, i32 %arg3, i32 %arg4) {
; ALL-LABEL: trunc_to_v4i8_buildvector:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r0 = $r1, 15, 8
; ALL-NEXT:    insf $r2 = $r3, 15, 8
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    insf $r0 = $r2, 31, 16
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 1)
  %arg1b = trunc i32 %arg1 to i16
  %arg2b = trunc i32 %arg2 to i16
  %arg3b = trunc i32 %arg3 to i16
  %arg4b = trunc i32 %arg4 to i16
  %v0 = insertelement <4 x i16> undef, i16 %arg1b, i32 0
  %v1 = insertelement <4 x i16> %v0, i16 %arg2b, i32 1
  %v2 = insertelement <4 x i16> %v1, i16 %arg3b, i32 2
  %v3 = insertelement <4 x i16> %v2, i16 %arg4b, i32 3
  %conv = trunc <4 x i16> %v3 to <4 x i8>
  ret <4 x i8> %conv
}

define <4 x i16> @concat(<2 x i16> %a, <2 x i16> %b){
; ALL-LABEL: concat:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r0 = $r1, 63, 32
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %v = shufflevector <2 x i16> %a, <2 x i16> %b, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  ret <4 x i16> %v
}

define <4 x i64> @test_sext_2xi64(<4 x i16> %a) {
; V1-LABEL: test_sext_2xi64:
; V1:       # %bb.0:
; V1-NEXT:    zxhd $r1 = $r0
; V1-NEXT:    srlw $r2 = $r0, 16
; V1-NEXT:    extfz $r3 = $r0, 47, 32
; V1-NEXT:    srld $r4 = $r0, 48
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    sxhd $r0 = $r1
; V1-NEXT:    sxhd $r1 = $r2
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    sxhd $r2 = $r3
; V1-NEXT:    sxhd $r3 = $r4
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 2)
;
; V2-LABEL: test_sext_2xi64:
; V2:       # %bb.0:
; V2-NEXT:    zxhd $r1 = $r0
; V2-NEXT:    srlw $r2 = $r0, 16
; V2-NEXT:    extfz $r3 = $r0, 47, 32
; V2-NEXT:    srld $r4 = $r0, 48
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    sxhd $r0 = $r1
; V2-NEXT:    sxhd $r1 = $r2
; V2-NEXT:    sxhd $r2 = $r3
; V2-NEXT:    sxhd $r3 = $r4
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %r = sext <4 x i16> %a to <4 x i64>
  ret <4 x i64> %r
}

declare <4 x i16> @llvm.abs.v4i16(<4 x i16>, i1) #0

define <4 x i16> @test_abs(<4 x i16> %a) {
; ALL-LABEL: test_abs:
; ALL:       # %bb.0:
; ALL-NEXT:    abshq $r0 = $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = call <4 x i16> @llvm.abs.v4i16(<4 x i16> %a, i1 false)
  ret <4 x i16> %r
}

define <4 x i16> @test_insertelement0(<4 x i16> %a, i16 %x) {
; ALL-LABEL: test_insertelement0:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r0 = $r1, 15, 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <4 x i16> %a, i16 %x, i64 0
  ret <4 x i16> %i
}

define <4 x i16> @test_insertelement1(<4 x i16> %a, i16 %x) {
; ALL-LABEL: test_insertelement1:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r0 = $r1, 31, 16
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <4 x i16> %a, i16 %x, i64 1
  ret <4 x i16> %i
}

define <4 x i16> @test_insertelement2(<4 x i16> %a, i16 %x) {
; ALL-LABEL: test_insertelement2:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r0 = $r1, 47, 32
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <4 x i16> %a, i16 %x, i64 2
  ret <4 x i16> %i
}

define <4 x i16> @test_insertelement3(<4 x i16> %a, i16 %x) {
; ALL-LABEL: test_insertelement3:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r0 = $r1, 63, 48
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <4 x i16> %a, i16 %x, i64 3
  ret <4 x i16> %i
}

define <4 x i16> @test_insertelement(<4 x i16> %a, i16 %x, i64 %p) {
; ALL-LABEL: test_insertelement:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r1 = $r1, 0x2010201.@
; ALL-NEXT:    sbmm8 $r2 = $r2, 0x10001.@
; ALL-NEXT:    make $r3 = 0x3000200010000
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    compnhq.eq $r2 = $r3, $r2
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    cmovehq.nez $r2 ? $r0 = $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 2)
  %i = insertelement <4 x i16> %a, i16 %x, i64 %p
  ret <4 x i16> %i
}

define <4 x i16> @mulsub(<4 x i16> %a, <4 x i16> %b, <4 x i16> %c) {
; ALL-LABEL: mulsub:
; ALL:       # %bb.0:
; ALL-NEXT:    msbfhq $r0 = $r1, $r2
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %mul = mul <4 x i16> %b, %c
  %sub = sub <4 x i16> %a, %mul
  ret <4 x i16> %sub
}

define <4 x i16> @vnot(<4 x i16> %a) {
; ALL-LABEL: vnot:
; ALL:       # %bb.0:
; ALL-NEXT:    notd $r0 = $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %vnot = xor <4 x i16> %a, <i16 -1, i16 -1, i16 -1, i16 -1>
  ret <4 x i16> %vnot
}

define <4 x i16> @lnand(<4 x i16> %0, <4 x i16> %1) {
; V1-LABEL: lnand:
; V1:       # %bb.0:
; V1-NEXT:    lnandhq $r0 = $r1, $r0
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 0)
;
; V2-LABEL: lnand:
; V2:       # %bb.0:
; V2-NEXT:    compnhq.eq $r0 = $r0, 0
; V2-NEXT:    compnhq.eq $r1 = $r1, 0
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    iord $r0 = $r1, $r0
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    andd $r0 = $r0, 0x10001.@
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 2)
  %3 = icmp eq <4 x i16> %0, zeroinitializer
  %4 = icmp eq <4 x i16> %1, zeroinitializer
  %5 = or <4 x i1> %4, %3
  %6 = zext <4 x i1> %5 to <4 x i16>
  ret <4 x i16> %6
}

define <4 x i16> @lnandn(<4 x i16> %0, <4 x i16> %1) {
; V1-LABEL: lnandn:
; V1:       # %bb.0:
; V1-NEXT:    lnandhq $r0 = $r1, $r0
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    neghq $r0 = $r0
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 1)
;
; V2-LABEL: lnandn:
; V2:       # %bb.0:
; V2-NEXT:    compnhq.eq $r0 = $r0, 0
; V2-NEXT:    compnhq.eq $r1 = $r1, 0
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    iord $r0 = $r1, $r0
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %3 = icmp eq <4 x i16> %0, zeroinitializer
  %4 = icmp eq <4 x i16> %1, zeroinitializer
  %5 = or <4 x i1> %4, %3
  %6 = sext <4 x i1> %5 to <4 x i16>
  ret <4 x i16> %6
}

define <4 x i16> @lor(<4 x i16> %0, <4 x i16> %1) {
; V1-LABEL: lor:
; V1:       # %bb.0:
; V1-NEXT:    liorhq $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 0)
;
; V2-LABEL: lor:
; V2:       # %bb.0:
; V2-NEXT:    iord $r0 = $r1, $r0
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    compnhq.ne $r0 = $r0, 0
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    andd $r0 = $r0, 0x10001.@
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 2)
  %3 = or <4 x i16> %1, %0
  %4 = icmp ne <4 x i16> %3, zeroinitializer
  %5 = zext <4 x i1> %4 to <4 x i16>
  ret <4 x i16> %5
}

; Not sure this is better than a (compnhq.ne (ord), (make 0))
define <4 x i16> @lorneg(<4 x i16> %0, <4 x i16> %1) {
; V1-LABEL: lorneg:
; V1:       # %bb.0:
; V1-NEXT:    liorhq $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    neghq $r0 = $r0
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 1)
;
; V2-LABEL: lorneg:
; V2:       # %bb.0:
; V2-NEXT:    iord $r0 = $r1, $r0
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    compnhq.ne $r0 = $r0, 0
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %3 = or <4 x i16> %1, %0
  %4 = icmp ne <4 x i16> %3, zeroinitializer
  %5 = sext <4 x i1> %4 to <4 x i16>
  ret <4 x i16> %5
}

define <4 x i16> @lnor(<4 x i16> %0, <4 x i16> %1) {
; V1-LABEL: lnor:
; V1:       # %bb.0:
; V1-NEXT:    lniorhq $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 0)
;
; V2-LABEL: lnor:
; V2:       # %bb.0:
; V2-NEXT:    iord $r0 = $r1, $r0
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    compnhq.eq $r0 = $r0, 0
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    andd $r0 = $r0, 0x10001.@
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 2)
  %3 = or <4 x i16> %1, %0
  %4 = icmp eq <4 x i16> %3, zeroinitializer
  %5 = zext <4 x i1> %4 to <4 x i16>
  ret <4 x i16> %5
}

; Not sure this is better than a (compnhq.eq (ord), (make 0))
define <4 x i16> @lnorneg(<4 x i16> %0, <4 x i16> %1) {
; V1-LABEL: lnorneg:
; V1:       # %bb.0:
; V1-NEXT:    lniorhq $r0 = $r0, $r1
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    neghq $r0 = $r0
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 1)
;
; V2-LABEL: lnorneg:
; V2:       # %bb.0:
; V2-NEXT:    iord $r0 = $r1, $r0
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    compnhq.eq $r0 = $r0, 0
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 1)
  %3 = or <4 x i16> %1, %0
  %4 = icmp eq <4 x i16> %3, zeroinitializer
  %5 = sext <4 x i1> %4 to <4 x i16>
  ret <4 x i16> %5
}


define <4 x i16> @abdhq_rr(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: abdhq_rr:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    abdhq $r0 = $r1, $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %sub = sub nsw <4 x i16> %a, %b
  %0 = tail call <4 x i16> @llvm.abs.v4i16(<4 x i16> %sub, i1 true)
  ret <4 x i16> %0
}

define <4 x i16> @abdhq_not_ri(<4 x i16> %0) {
; ALL-LABEL: abdhq_not_ri:
; ALL:       # %bb.0:
; ALL-NEXT:    make $r1 = 0x10000f00100012
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    abdhq $r0 = $r1, $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 1)
  %2 = sub nsw <4 x i16> <i16 18, i16 16, i16 15, i16 16>, %0
  %3 = tail call <4 x i16> @llvm.abs.v4i16(<4 x i16> %2, i1 true)
  ret <4 x i16> %3
}

define <4 x i16> @abdhq_ri_(<4 x i16> %0) {
; ALL-LABEL: abdhq_ri_:
; ALL:       # %bb.0:
; ALL-NEXT:    abdhq $r0 = $r0, 0x10000f
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = sub nsw <4 x i16> <i16 15, i16 16, i16 0, i16 0>, %0
  %3 = tail call <4 x i16> @llvm.abs.v4i16(<4 x i16> %2, i1 true)
  ret <4 x i16> %3
}

define <4 x i16> @abdhq_ri_at(<4 x i16> %0) {
; ALL-LABEL: abdhq_ri_at:
; ALL:       # %bb.0:
; ALL-NEXT:    abdhq $r0 = $r0, 0x10000f.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = sub nsw <4 x i16> <i16 15, i16 16, i16 15, i16 16>, %0
  %3 = tail call <4 x i16> @llvm.abs.v4i16(<4 x i16> %2, i1 true)
  ret <4 x i16> %3
}

define <4 x i16> @nandd_v4i16_rr(<4 x i16> %0, <4 x i16> %1) {
; ALL-LABEL: nandd_v4i16_rr:
; ALL:       # %bb.0:
; ALL-NEXT:    nandd $r0 = $r1, $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %3 = and <4 x i16> %1, %0
  %4 = xor <4 x i16> %3, <i16 -1, i16 -1, i16 -1, i16 -1>
  ret <4 x i16> %4
}

define <4 x i16> @nandd_v4i16_ri10(<4 x i16> %0) {
; ALL-LABEL: nandd_v4i16_ri10:
; ALL:       # %bb.0:
; ALL-NEXT:    nandd $r0 = $r0, 1023
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = and <4 x i16> %0, <i16 1023, i16 0, i16 0, i16 0>
  %3 = xor <4 x i16> %2, <i16 -1, i16 -1, i16 -1, i16 -1>
  ret <4 x i16> %3
}

define <4 x i16> @nandd_v4i16_ri37_0(<4 x i16> %0) {
; ALL-LABEL: nandd_v4i16_ri37_0:
; ALL:       # %bb.0:
; ALL-NEXT:    nandd $r0 = $r0, 0xfffd0400
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = and <4 x i16> %0, <i16 1024, i16 -3, i16 0, i16 0>
  %3 = xor <4 x i16> %2, <i16 -1, i16 -1, i16 -1, i16 -1>
  ret <4 x i16> %3
}

define <4 x i16> @nandd_v4i16_ri37_1(<4 x i16> %0) {
; ALL-LABEL: nandd_v4i16_ri37_1:
; ALL:       # %bb.0:
; ALL-NEXT:    nandd $r0 = $r0, 0xfffd0400
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = and <4 x i16> %0, <i16 1024, i16 -3, i16 0, i16 0>
  %3 = xor <4 x i16> %2, <i16 -1, i16 -1, i16 -1, i16 -1>
  ret <4 x i16> %3
}

define <4 x i16> @nandd_v4i16_ri37_2(<4 x i16> %0) {
; ALL-LABEL: nandd_v4i16_ri37_2:
; ALL:       # %bb.0:
; ALL-NEXT:    nandd $r0 = $r0, 0x1ffffd0400
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = and <4 x i16> %0, <i16 1024, i16 -3, i16 31, i16 0>
  %3 = xor <4 x i16> %2, <i16 -1, i16 -1, i16 -1, i16 -1>
  ret <4 x i16> %3
}

define <4 x i16> @nandd_v4i16_ri64_0(<4 x i16> %0) {
; ALL-LABEL: nandd_v4i16_ri64_0:
; ALL:       # %bb.0:
; ALL-NEXT:    nandd $r0 = $r0, 0x20fffd0400
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = and <4 x i16> %0, <i16 1024, i16 -3, i16 32, i16 0>
  %3 = xor <4 x i16> %2, <i16 -1, i16 -1, i16 -1, i16 -1>
  ret <4 x i16> %3
}

define <4 x i16> @nandd_v4i16_ri64_1(<4 x i16> %0) {
; ALL-LABEL: nandd_v4i16_ri64_1:
; ALL:       # %bb.0:
; ALL-NEXT:    nandd $r0 = $r0, 0xfffffffd0400
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = and <4 x i16> %0, <i16 1024, i16 -3, i16 -1, i16 0>
  %3 = xor <4 x i16> %2, <i16 -1, i16 -1, i16 -1, i16 -1>
  ret <4 x i16> %3
}

define <4 x i16> @nandd_v4i16_ri64_2(<4 x i16> %0) {
; ALL-LABEL: nandd_v4i16_ri64_2:
; ALL:       # %bb.0:
; ALL-NEXT:    nandd $r0 = $r0, 0x1001ffffd0400
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = and <4 x i16> %0, <i16 1024, i16 -3, i16 31, i16 1>
  %3 = xor <4 x i16> %2, <i16 -1, i16 -1, i16 -1, i16 -1>
  ret <4 x i16> %3
}

define <4 x i16> @splat(i32 %0) {
; ALL-LABEL: splat:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x2010201.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = trunc i32 %0 to i16
  %3 = insertelement <4 x i16> undef, i16 %2, i32 0
  %4 = shufflevector <4 x i16> %3, <4 x i16> undef, <4 x i32> zeroinitializer
  ret <4 x i16> %4
}

define <4 x i16> @splat_0(<4 x i16> %0) {
; ALL-LABEL: splat_0:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x2010201.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = shufflevector <4 x i16> %0, <4 x i16> undef, <4 x i32> zeroinitializer
  ret <4 x i16> %2
}

define <4 x i16> @splat_1(<4 x i16> %0) {
; ALL-LABEL: splat_1:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x8040804.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = shufflevector <4 x i16> %0, <4 x i16> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  ret <4 x i16> %2
}

define <4 x i16> @splat_1_32(i32 %0) {
; ALL-LABEL: splat_1_32:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x8040804.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = lshr i32 %0, 16
  %3 = trunc i32 %2 to i16
  %4 = insertelement <4 x i16> undef, i16 %3, i32 0
  %5 = shufflevector <4 x i16> %4, <4 x i16> undef, <4 x i32> zeroinitializer
  ret <4 x i16> %5
}

define <4 x i16> @splat_1_64(i64 %0) {
; ALL-LABEL: splat_1_64:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x8040804.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = lshr i64 %0, 16
  %3 = trunc i64 %2 to i16
  %4 = insertelement <4 x i16> undef, i16 %3, i32 0
  %5 = shufflevector <4 x i16> %4, <4 x i16> undef, <4 x i32> zeroinitializer
  ret <4 x i16> %5
}

define <4 x i16> @splat_2(<4 x i16> %0) {
; ALL-LABEL: splat_2:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x20102010.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = shufflevector <4 x i16> %0, <4 x i16> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  ret <4 x i16> %2
}

define <4 x i16> @splat_2_64(i64 %0) {
; ALL-LABEL: splat_2_64:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x20102010.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = lshr i64 %0, 32
  %3 = trunc i64 %2 to i16
  %4 = insertelement <4 x i16> undef, i16 %3, i32 0
  %5 = shufflevector <4 x i16> %4, <4 x i16> undef, <4 x i32> zeroinitializer
  ret <4 x i16> %5
}

define <4 x i16> @splat_3(<4 x i16> %0) {
; ALL-LABEL: splat_3:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x80408040.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = shufflevector <4 x i16> %0, <4 x i16> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  ret <4 x i16> %2
}

define <4 x i16> @splat_3_64(i64 %0) {
; ALL-LABEL: splat_3_64:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x80408040.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %2 = lshr i64 %0, 48
  %3 = trunc i64 %2 to i16
  %4 = insertelement <4 x i16> undef, i16 %3, i32 0
  %5 = shufflevector <4 x i16> %4, <4 x i16> undef, <4 x i32> zeroinitializer
  ret <4 x i16> %5
}

define  <4 x i16> @v4_maxhq_rr_i16(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: v4_maxhq_rr_i16:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    maxhq $r0 = $r0, $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = call <4 x i16> @llvm.smax.v4i16(<4 x i16> %a, <4 x i16> %b)
  ret <4 x i16> %0
}

define  <4 x i16> @v4_minhq_rr_i16(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: v4_minhq_rr_i16:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    minhq $r0 = $r0, $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = call <4 x i16> @llvm.smin.v4i16(<4 x i16> %a, <4 x i16> %b)
  ret <4 x i16> %0
}

define  <4 x i16> @v4_umaxhq_rr_i16(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: v4_umaxhq_rr_i16:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    maxuhq $r0 = $r0, $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = call <4 x i16> @llvm.umax.v4i16(<4 x i16> %a, <4 x i16> %b)
  ret <4 x i16> %0
}

define  <4 x i16> @v4_uminhq_rr_i16(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: v4_uminhq_rr_i16:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    minuhq $r0 = $r0, $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = call <4 x i16> @llvm.umin.v4i16(<4 x i16> %a, <4 x i16> %b)
  ret <4 x i16> %0
}

declare <4 x i16> @llvm.smax.v4i16(<4 x i16> %a, <4 x i16> %b)
declare <4 x i16> @llvm.smin.v4i16(<4 x i16> %a, <4 x i16> %b)
declare <4 x i16> @llvm.umax.v4i16(<4 x i16> %a, <4 x i16> %b)
declare <4 x i16> @llvm.umin.v4i16(<4 x i16> %a, <4 x i16> %b)

define <4 x i16> @add_splat_const_op1(<4 x i16> %vx) #0 {
; ALL-LABEL: add_splat_const_op1:
; ALL:       # %bb.0:
; ALL-NEXT:    addhq $r0 = $r0, 0x2a002a.@
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sbmm8 $r0 = $r0, 0x2010201.@
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 1)
  %splatx = shufflevector <4 x i16> %vx, <4 x i16> undef, <4 x i32> zeroinitializer
  %r = add <4 x i16> %splatx, <i16 42, i16 42, i16 42, i16 42>
  ret <4 x i16> %r
}
attributes #0 = { nounwind }

define <4 x i16> @test_div_4(<4 x i16> %a, <4 x i16> %b) #0 {
; ALL-LABEL: test_div_4:
; ALL:       # %bb.0:
; ALL-NEXT:    srshqs $r0 = $r0, 2
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = sdiv <4 x i16> %a, <i16 4, i16 4, i16 4, i16 4>
  ret <4 x i16> %r
}

define <4 x i16> @test_div_32(<4 x i16> %a, <4 x i16> %b) #0 {
; ALL-LABEL: test_div_32:
; ALL:       # %bb.0:
; ALL-NEXT:    srshqs $r0 = $r0, 5
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %r = sdiv <4 x i16> %a, <i16 32, i16 32, i16 32, i16 32>
  ret <4 x i16> %r
}

define <4 x i16> @test_select_cmp(<4 x i16> %a, <4 x i16> %b, <4 x i16> %c, <4 x i16> %d) #0 {
; ALL-LABEL: test_select_cmp:
; ALL:       # %bb.0:
; ALL-NEXT:    compnhq.ne $r2 = $r2, $r3
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    compd.eq $r2 = $r2, -1
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    cmoved.even $r2 ? $r0 = $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 2)
  %cc = icmp ne <4 x i16> %c, %d
  %bc = bitcast <4 x i1> %cc to i4
  %cmp = icmp eq i4 %bc, -1
  %r = select i1 %cmp, <4 x i16> %a, <4 x i16> %b
  ret <4 x i16> %r
}

define <4 x i16> @fshl_rr(<4 x i16> %a, <4 x i16> %b, i16 %c) {
; V1-LABEL: fshl_rr:
; V1:       # %bb.0:
; V1-NEXT:    srlhqs $r1 = $r1, 1
; V1-NEXT:    sbmm8 $r2 = $r2, 0x2010201.@
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    andd $r2 = $r2, 0xf000f.@
; V1-NEXT:    andnd $r3 = $r2, 0xf000f.@
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    srlhqs $r4 = $r1, $r3
; V1-NEXT:    extfz $r5 = $r3, 19, 16
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    extfz $r3 = $r3, 51, 48
; V1-NEXT:    extfz $r6 = $r3, 35, 32
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    srlhqs $r5 = $r1, $r5
; V1-NEXT:    srlhqs $r6 = $r1, $r6
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    srlhqs $r1 = $r1, $r3
; V1-NEXT:    extfz $r3 = $r2, 19, 16
; V1-NEXT:    ;; # (end cycle 5)
; V1-NEXT:    sllhqs $r4 = $r0, $r2
; V1-NEXT:    insf $r5 = $r4, 15, 0
; V1-NEXT:    ;; # (end cycle 6)
; V1-NEXT:    sllhqs $r3 = $r0, $r3
; V1-NEXT:    insf $r6 = $r5, 31, 0
; V1-NEXT:    ;; # (end cycle 7)
; V1-NEXT:    insf $r3 = $r4, 15, 0
; V1-NEXT:    extfz $r4 = $r2, 35, 32
; V1-NEXT:    ;; # (end cycle 8)
; V1-NEXT:    extfz $r2 = $r2, 51, 48
; V1-NEXT:    sllhqs $r4 = $r0, $r4
; V1-NEXT:    ;; # (end cycle 9)
; V1-NEXT:    sllhqs $r0 = $r0, $r2
; V1-NEXT:    insf $r4 = $r3, 31, 0
; V1-NEXT:    ;; # (end cycle 10)
; V1-NEXT:    insf $r0 = $r4, 47, 0
; V1-NEXT:    insf $r1 = $r6, 47, 0
; V1-NEXT:    ;; # (end cycle 11)
; V1-NEXT:    iord $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 12)
;
; V2-LABEL: fshl_rr:
; V2:       # %bb.0:
; V2-NEXT:    srlhqs $r1 = $r1, 1
; V2-NEXT:    sbmm8 $r2 = $r2, 0x2010201.@
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    andd $r2 = $r2, 0xf000f.@
; V2-NEXT:    andnd $r3 = $r2, 0xf000f.@
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    extfz $r4 = $r3, 19, 16
; V2-NEXT:    extfz $r5 = $r2, 19, 16
; V2-NEXT:    srlhqs $r6 = $r1, $r3
; V2-NEXT:    sllhqs $r7 = $r0, $r2
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    srlhqs $r4 = $r1, $r4
; V2-NEXT:    sllhqs $r5 = $r0, $r5
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    insf $r4 = $r6, 15, 0
; V2-NEXT:    insf $r5 = $r7, 15, 0
; V2-NEXT:    extfz $r6 = $r3, 35, 32
; V2-NEXT:    extfz $r7 = $r2, 35, 32
; V2-NEXT:    ;; # (end cycle 4)
; V2-NEXT:    extfz $r2 = $r2, 51, 48
; V2-NEXT:    extfz $r3 = $r3, 51, 48
; V2-NEXT:    srlhqs $r6 = $r1, $r6
; V2-NEXT:    sllhqs $r7 = $r0, $r7
; V2-NEXT:    ;; # (end cycle 5)
; V2-NEXT:    sllhqs $r0 = $r0, $r2
; V2-NEXT:    srlhqs $r1 = $r1, $r3
; V2-NEXT:    insf $r6 = $r4, 31, 0
; V2-NEXT:    insf $r7 = $r5, 31, 0
; V2-NEXT:    ;; # (end cycle 6)
; V2-NEXT:    insf $r0 = $r7, 47, 0
; V2-NEXT:    insf $r1 = $r6, 47, 0
; V2-NEXT:    ;; # (end cycle 7)
; V2-NEXT:    iord $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 8)
  %i = insertelement <4 x i16> undef, i16 %c, i16 0
  %s = shufflevector <4 x i16> %i, <4 x i16> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 0>
  %r = call <4 x i16> @llvm.fshl.v4i16(<4 x i16> %a, <4 x i16> %b, <4 x i16> %s)
  ret <4 x i16> %r
}

define <4 x i16> @fshl_ri(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: fshl_ri:
; ALL:       # %bb.0:
; ALL-NEXT:    sllhqs $r0 = $r0, 3
; ALL-NEXT:    srlhqs $r1 = $r1, 1
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    srlhqs $r1 = $r1, 12
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    iord $r0 = $r0, $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 2)
  %r = call <4 x i16> @llvm.fshl.v4i16(<4 x i16> %a, <4 x i16> %b, <4 x i16> <i16 3, i16 3, i16 3, i16 3>)
  ret <4 x i16> %r
}

define <4 x i16> @fshl_vec(<4 x i16> %a, <4 x i16> %b, <4 x i16> %c) {
; V1-LABEL: fshl_vec:
; V1:       # %bb.0:
; V1-NEXT:    srlhqs $r1 = $r1, 1
; V1-NEXT:    andd $r2 = $r2, 0xf000f.@
; V1-NEXT:    andnd $r3 = $r2, 0xf000f.@
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    extfz $r4 = $r3, 19, 16
; V1-NEXT:    srlhqs $r5 = $r1, $r3
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    srlhqs $r4 = $r1, $r4
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    insf $r4 = $r5, 15, 0
; V1-NEXT:    extfz $r5 = $r3, 35, 32
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    extfz $r3 = $r3, 51, 48
; V1-NEXT:    srlhqs $r5 = $r1, $r5
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    srlhqs $r1 = $r1, $r3
; V1-NEXT:    extfz $r3 = $r2, 19, 16
; V1-NEXT:    ;; # (end cycle 5)
; V1-NEXT:    sllhqs $r4 = $r0, $r2
; V1-NEXT:    insf $r5 = $r4, 31, 0
; V1-NEXT:    ;; # (end cycle 6)
; V1-NEXT:    insf $r1 = $r5, 47, 0
; V1-NEXT:    sllhqs $r3 = $r0, $r3
; V1-NEXT:    ;; # (end cycle 7)
; V1-NEXT:    insf $r3 = $r4, 15, 0
; V1-NEXT:    extfz $r4 = $r2, 35, 32
; V1-NEXT:    ;; # (end cycle 8)
; V1-NEXT:    extfz $r2 = $r2, 51, 48
; V1-NEXT:    sllhqs $r4 = $r0, $r4
; V1-NEXT:    ;; # (end cycle 9)
; V1-NEXT:    sllhqs $r0 = $r0, $r2
; V1-NEXT:    insf $r4 = $r3, 31, 0
; V1-NEXT:    ;; # (end cycle 10)
; V1-NEXT:    insf $r0 = $r4, 47, 0
; V1-NEXT:    ;; # (end cycle 11)
; V1-NEXT:    iord $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 12)
;
; V2-LABEL: fshl_vec:
; V2:       # %bb.0:
; V2-NEXT:    srlhqs $r1 = $r1, 1
; V2-NEXT:    andd $r2 = $r2, 0xf000f.@
; V2-NEXT:    andnd $r3 = $r2, 0xf000f.@
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    extfz $r4 = $r3, 19, 16
; V2-NEXT:    extfz $r5 = $r2, 19, 16
; V2-NEXT:    srlhqs $r6 = $r1, $r3
; V2-NEXT:    sllhqs $r7 = $r0, $r2
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    srlhqs $r4 = $r1, $r4
; V2-NEXT:    sllhqs $r5 = $r0, $r5
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    insf $r4 = $r6, 15, 0
; V2-NEXT:    insf $r5 = $r7, 15, 0
; V2-NEXT:    extfz $r6 = $r3, 35, 32
; V2-NEXT:    extfz $r7 = $r2, 35, 32
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    extfz $r2 = $r2, 51, 48
; V2-NEXT:    extfz $r3 = $r3, 51, 48
; V2-NEXT:    srlhqs $r6 = $r1, $r6
; V2-NEXT:    sllhqs $r7 = $r0, $r7
; V2-NEXT:    ;; # (end cycle 4)
; V2-NEXT:    sllhqs $r0 = $r0, $r2
; V2-NEXT:    srlhqs $r1 = $r1, $r3
; V2-NEXT:    insf $r6 = $r4, 31, 0
; V2-NEXT:    insf $r7 = $r5, 31, 0
; V2-NEXT:    ;; # (end cycle 5)
; V2-NEXT:    insf $r0 = $r7, 47, 0
; V2-NEXT:    insf $r1 = $r6, 47, 0
; V2-NEXT:    ;; # (end cycle 6)
; V2-NEXT:    iord $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 7)
  %r = call <4 x i16> @llvm.fshl.v4i16(<4 x i16> %a, <4 x i16> %b, <4 x i16> %c)
  ret <4 x i16> %r
}
define <4 x i16> @fshr_rr(<4 x i16> %a, <4 x i16> %b, i16 %c) {
; V1-LABEL: fshr_rr:
; V1:       # %bb.0:
; V1-NEXT:    sllhqs $r0 = $r0, 1
; V1-NEXT:    sbmm8 $r2 = $r2, 0x2010201.@
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    andnd $r2 = $r2, 0xf000f.@
; V1-NEXT:    andd $r3 = $r2, 0xf000f.@
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    srlhqs $r4 = $r1, $r3
; V1-NEXT:    extfz $r5 = $r3, 19, 16
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    extfz $r3 = $r3, 51, 48
; V1-NEXT:    extfz $r6 = $r3, 35, 32
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    srlhqs $r5 = $r1, $r5
; V1-NEXT:    srlhqs $r6 = $r1, $r6
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    srlhqs $r1 = $r1, $r3
; V1-NEXT:    extfz $r3 = $r2, 19, 16
; V1-NEXT:    ;; # (end cycle 5)
; V1-NEXT:    sllhqs $r4 = $r0, $r2
; V1-NEXT:    insf $r5 = $r4, 15, 0
; V1-NEXT:    ;; # (end cycle 6)
; V1-NEXT:    sllhqs $r3 = $r0, $r3
; V1-NEXT:    insf $r6 = $r5, 31, 0
; V1-NEXT:    ;; # (end cycle 7)
; V1-NEXT:    insf $r3 = $r4, 15, 0
; V1-NEXT:    extfz $r4 = $r2, 35, 32
; V1-NEXT:    ;; # (end cycle 8)
; V1-NEXT:    extfz $r2 = $r2, 51, 48
; V1-NEXT:    sllhqs $r4 = $r0, $r4
; V1-NEXT:    ;; # (end cycle 9)
; V1-NEXT:    sllhqs $r0 = $r0, $r2
; V1-NEXT:    insf $r4 = $r3, 31, 0
; V1-NEXT:    ;; # (end cycle 10)
; V1-NEXT:    insf $r0 = $r4, 47, 0
; V1-NEXT:    insf $r1 = $r6, 47, 0
; V1-NEXT:    ;; # (end cycle 11)
; V1-NEXT:    iord $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 12)
;
; V2-LABEL: fshr_rr:
; V2:       # %bb.0:
; V2-NEXT:    sllhqs $r0 = $r0, 1
; V2-NEXT:    sbmm8 $r2 = $r2, 0x2010201.@
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    andnd $r2 = $r2, 0xf000f.@
; V2-NEXT:    andd $r3 = $r2, 0xf000f.@
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    extfz $r4 = $r3, 19, 16
; V2-NEXT:    extfz $r5 = $r2, 19, 16
; V2-NEXT:    srlhqs $r6 = $r1, $r3
; V2-NEXT:    sllhqs $r7 = $r0, $r2
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    srlhqs $r4 = $r1, $r4
; V2-NEXT:    sllhqs $r5 = $r0, $r5
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    insf $r4 = $r6, 15, 0
; V2-NEXT:    insf $r5 = $r7, 15, 0
; V2-NEXT:    extfz $r6 = $r3, 35, 32
; V2-NEXT:    extfz $r7 = $r2, 35, 32
; V2-NEXT:    ;; # (end cycle 4)
; V2-NEXT:    extfz $r2 = $r2, 51, 48
; V2-NEXT:    extfz $r3 = $r3, 51, 48
; V2-NEXT:    srlhqs $r6 = $r1, $r6
; V2-NEXT:    sllhqs $r7 = $r0, $r7
; V2-NEXT:    ;; # (end cycle 5)
; V2-NEXT:    sllhqs $r0 = $r0, $r2
; V2-NEXT:    srlhqs $r1 = $r1, $r3
; V2-NEXT:    insf $r6 = $r4, 31, 0
; V2-NEXT:    insf $r7 = $r5, 31, 0
; V2-NEXT:    ;; # (end cycle 6)
; V2-NEXT:    insf $r0 = $r7, 47, 0
; V2-NEXT:    insf $r1 = $r6, 47, 0
; V2-NEXT:    ;; # (end cycle 7)
; V2-NEXT:    iord $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 8)
  %i = insertelement <4 x i16> undef, i16 %c, i16 0
  %s = shufflevector <4 x i16> %i, <4 x i16> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 0>
  %r = call <4 x i16> @llvm.fshr.v4i16(<4 x i16> %a, <4 x i16> %b, <4 x i16> %s)
  ret <4 x i16> %r
}

define <4 x i16> @fshr_ri(<4 x i16> %a, <4 x i16> %b, i16 %c) {
; ALL-LABEL: fshr_ri:
; ALL:       # %bb.0:
; ALL-NEXT:    sllhqs $r0 = $r0, 1
; ALL-NEXT:    srlhqs $r1 = $r1, 3
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sllhqs $r0 = $r0, 12
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    iord $r0 = $r0, $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 2)
  %r = call <4 x i16> @llvm.fshr.v4i16(<4 x i16> %a, <4 x i16> %b, <4 x i16> <i16 3, i16 3, i16 3, i16 3>)
  ret <4 x i16> %r
}

define <4 x i16> @fshr_vec(<4 x i16> %a, <4 x i16> %b, <4 x i16> %c) {
; V1-LABEL: fshr_vec:
; V1:       # %bb.0:
; V1-NEXT:    sllhqs $r0 = $r0, 1
; V1-NEXT:    andnd $r2 = $r2, 0xf000f.@
; V1-NEXT:    andd $r3 = $r2, 0xf000f.@
; V1-NEXT:    ;; # (end cycle 0)
; V1-NEXT:    srlhqs $r4 = $r1, $r3
; V1-NEXT:    extfz $r5 = $r3, 19, 16
; V1-NEXT:    ;; # (end cycle 1)
; V1-NEXT:    extfz $r3 = $r3, 51, 48
; V1-NEXT:    extfz $r6 = $r3, 35, 32
; V1-NEXT:    ;; # (end cycle 2)
; V1-NEXT:    srlhqs $r5 = $r1, $r5
; V1-NEXT:    srlhqs $r6 = $r1, $r6
; V1-NEXT:    ;; # (end cycle 3)
; V1-NEXT:    srlhqs $r1 = $r1, $r3
; V1-NEXT:    extfz $r3 = $r2, 19, 16
; V1-NEXT:    ;; # (end cycle 4)
; V1-NEXT:    sllhqs $r4 = $r0, $r2
; V1-NEXT:    insf $r5 = $r4, 15, 0
; V1-NEXT:    ;; # (end cycle 5)
; V1-NEXT:    sllhqs $r3 = $r0, $r3
; V1-NEXT:    insf $r6 = $r5, 31, 0
; V1-NEXT:    ;; # (end cycle 6)
; V1-NEXT:    insf $r3 = $r4, 15, 0
; V1-NEXT:    extfz $r4 = $r2, 35, 32
; V1-NEXT:    ;; # (end cycle 7)
; V1-NEXT:    extfz $r2 = $r2, 51, 48
; V1-NEXT:    sllhqs $r4 = $r0, $r4
; V1-NEXT:    ;; # (end cycle 8)
; V1-NEXT:    sllhqs $r0 = $r0, $r2
; V1-NEXT:    insf $r4 = $r3, 31, 0
; V1-NEXT:    ;; # (end cycle 9)
; V1-NEXT:    insf $r0 = $r4, 47, 0
; V1-NEXT:    insf $r1 = $r6, 47, 0
; V1-NEXT:    ;; # (end cycle 10)
; V1-NEXT:    iord $r0 = $r0, $r1
; V1-NEXT:    ret
; V1-NEXT:    ;; # (end cycle 11)
;
; V2-LABEL: fshr_vec:
; V2:       # %bb.0:
; V2-NEXT:    sllhqs $r0 = $r0, 1
; V2-NEXT:    andnd $r2 = $r2, 0xf000f.@
; V2-NEXT:    andd $r3 = $r2, 0xf000f.@
; V2-NEXT:    ;; # (end cycle 0)
; V2-NEXT:    extfz $r4 = $r3, 19, 16
; V2-NEXT:    extfz $r5 = $r2, 19, 16
; V2-NEXT:    srlhqs $r6 = $r1, $r3
; V2-NEXT:    sllhqs $r7 = $r0, $r2
; V2-NEXT:    ;; # (end cycle 1)
; V2-NEXT:    srlhqs $r4 = $r1, $r4
; V2-NEXT:    sllhqs $r5 = $r0, $r5
; V2-NEXT:    ;; # (end cycle 2)
; V2-NEXT:    insf $r4 = $r6, 15, 0
; V2-NEXT:    insf $r5 = $r7, 15, 0
; V2-NEXT:    extfz $r6 = $r3, 35, 32
; V2-NEXT:    extfz $r7 = $r2, 35, 32
; V2-NEXT:    ;; # (end cycle 3)
; V2-NEXT:    extfz $r2 = $r2, 51, 48
; V2-NEXT:    extfz $r3 = $r3, 51, 48
; V2-NEXT:    srlhqs $r6 = $r1, $r6
; V2-NEXT:    sllhqs $r7 = $r0, $r7
; V2-NEXT:    ;; # (end cycle 4)
; V2-NEXT:    sllhqs $r0 = $r0, $r2
; V2-NEXT:    srlhqs $r1 = $r1, $r3
; V2-NEXT:    insf $r6 = $r4, 31, 0
; V2-NEXT:    insf $r7 = $r5, 31, 0
; V2-NEXT:    ;; # (end cycle 5)
; V2-NEXT:    insf $r0 = $r7, 47, 0
; V2-NEXT:    insf $r1 = $r6, 47, 0
; V2-NEXT:    ;; # (end cycle 6)
; V2-NEXT:    iord $r0 = $r0, $r1
; V2-NEXT:    ret
; V2-NEXT:    ;; # (end cycle 7)
  %r = call <4 x i16> @llvm.fshr.v4i16(<4 x i16> %a, <4 x i16> %b, <4 x i16> %c)
  ret <4 x i16> %r
}

declare <4 x i16> @llvm.fshr.v4i16(<4 x i16>, <4 x i16>, <4 x i16>)
declare <4 x i16> @llvm.fshl.v4i16(<4 x i16>, <4 x i16>, <4 x i16>)

define <4 x i16> @sdiv(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: sdiv:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call __divv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = sdiv <4 x i16> %a, %b
  ret <4 x i16> %r
}

define <4 x i16> @sdiv_vs(<4 x i16> %a, i16 %b) {
; ALL-LABEL: sdiv_vs:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r1 = $r1, 0x2010201.@
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call __divv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %v0 = insertelement <4 x i16> undef, i16 %b, i32 0
  %splat = shufflevector <4 x i16> %v0, <4 x i16> undef, <4 x i32> zeroinitializer
  %div = sdiv <4 x i16> %a, %splat
  ret <4 x i16> %div
}

define <4 x i16> @sdiv_sv(<4 x i16> %a, i16 %b) {
; ALL-LABEL: sdiv_sv:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    sbmm8 $r0 = $r1, 0x2010201.@
; ALL-NEXT:    copyd $r2 = $r0
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    copyd $r1 = $r2
; ALL-NEXT:    call __divv4hi3
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %v0 = insertelement <4 x i16> undef, i16 %b, i32 0
  %splat = shufflevector <4 x i16> %v0, <4 x i16> undef, <4 x i32> zeroinitializer
  %div = sdiv <4 x i16> %splat, %a
  ret <4 x i16> %div
}

define <4 x i16> @sdiv_ss(i16 %a, i16 %b) {
; ALL-LABEL: sdiv_ss:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r2 = $r1, 0x2010201.@
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    copyd $r0 = $r2
; ALL-NEXT:    sbmm8 $r1 = $r0, 0x2010201.@
; ALL-NEXT:    call __divv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %va = insertelement <4 x i16> undef, i16 %b, i32 0
  %vb = insertelement <4 x i16> undef, i16 %a, i32 0
  %splata = shufflevector <4 x i16> %va, <4 x i16> undef, <4 x i32> zeroinitializer
  %splatb = shufflevector <4 x i16> %vb, <4 x i16> undef, <4 x i32> zeroinitializer
  %div = sdiv <4 x i16> %splata, %splatb
  ret <4 x i16> %div
}

define <4 x i16> @srem(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: srem:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call __modv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = srem <4 x i16> %a, %b
  ret <4 x i16> %r
}

define <4 x i16> @srem_vs(<4 x i16> %a, i16 %b) {
; ALL-LABEL: srem_vs:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r1 = $r1, 0x2010201.@
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call __modv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %v0 = insertelement <4 x i16> undef, i16 %b, i32 0
  %splat = shufflevector <4 x i16> %v0, <4 x i16> undef, <4 x i32> zeroinitializer
  %div = srem <4 x i16> %a, %splat
  ret <4 x i16> %div
}

define <4 x i16> @srem_sv(<4 x i16> %a, i16 %b) {
; ALL-LABEL: srem_sv:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    sbmm8 $r0 = $r1, 0x2010201.@
; ALL-NEXT:    copyd $r2 = $r0
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    copyd $r1 = $r2
; ALL-NEXT:    call __modv4hi3
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %v0 = insertelement <4 x i16> undef, i16 %b, i32 0
  %splat = shufflevector <4 x i16> %v0, <4 x i16> undef, <4 x i32> zeroinitializer
  %div = srem <4 x i16> %splat, %a
  ret <4 x i16> %div
}

define <4 x i16> @srem_ss(i16 %a, i16 %b) {
; ALL-LABEL: srem_ss:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r2 = $r1, 0x2010201.@
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    copyd $r0 = $r2
; ALL-NEXT:    sbmm8 $r1 = $r0, 0x2010201.@
; ALL-NEXT:    call __modv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %va = insertelement <4 x i16> undef, i16 %b, i32 0
  %vb = insertelement <4 x i16> undef, i16 %a, i32 0
  %splata = shufflevector <4 x i16> %va, <4 x i16> undef, <4 x i32> zeroinitializer
  %splatb = shufflevector <4 x i16> %vb, <4 x i16> undef, <4 x i32> zeroinitializer
  %div = srem <4 x i16> %splata, %splatb
  ret <4 x i16> %div
}

define <4 x i16> @udiv(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: udiv:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call __udivv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = udiv <4 x i16> %a, %b
  ret <4 x i16> %r
}

define <4 x i16> @udiv_vs(<4 x i16> %a, i16 %b) {
; ALL-LABEL: udiv_vs:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r1 = $r1, 0x2010201.@
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call __udivv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %v0 = insertelement <4 x i16> undef, i16 %b, i32 0
  %splat = shufflevector <4 x i16> %v0, <4 x i16> undef, <4 x i32> zeroinitializer
  %div = udiv <4 x i16> %a, %splat
  ret <4 x i16> %div
}

define <4 x i16> @udiv_sv(<4 x i16> %a, i16 %b) {
; ALL-LABEL: udiv_sv:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    sbmm8 $r0 = $r1, 0x2010201.@
; ALL-NEXT:    copyd $r2 = $r0
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    copyd $r1 = $r2
; ALL-NEXT:    call __udivv4hi3
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %v0 = insertelement <4 x i16> undef, i16 %b, i32 0
  %splat = shufflevector <4 x i16> %v0, <4 x i16> undef, <4 x i32> zeroinitializer
  %div = udiv <4 x i16> %splat, %a
  ret <4 x i16> %div
}

define <4 x i16> @udiv_ss(i16 %a, i16 %b) {
; ALL-LABEL: udiv_ss:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r2 = $r1, 0x2010201.@
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    copyd $r0 = $r2
; ALL-NEXT:    sbmm8 $r1 = $r0, 0x2010201.@
; ALL-NEXT:    call __udivv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %va = insertelement <4 x i16> undef, i16 %b, i32 0
  %vb = insertelement <4 x i16> undef, i16 %a, i32 0
  %splata = shufflevector <4 x i16> %va, <4 x i16> undef, <4 x i32> zeroinitializer
  %splatb = shufflevector <4 x i16> %vb, <4 x i16> undef, <4 x i32> zeroinitializer
  %div = udiv <4 x i16> %splata, %splatb
  ret <4 x i16> %div
}

define <4 x i16> @urem(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: urem:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call __umodv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = urem <4 x i16> %a, %b
  ret <4 x i16> %r
}

define <4 x i16> @urem_vs(<4 x i16> %a, i16 %b) {
; ALL-LABEL: urem_vs:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r1 = $r1, 0x2010201.@
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call __umodv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %v0 = insertelement <4 x i16> undef, i16 %b, i32 0
  %splat = shufflevector <4 x i16> %v0, <4 x i16> undef, <4 x i32> zeroinitializer
  %div = urem <4 x i16> %a, %splat
  ret <4 x i16> %div
}

define <4 x i16> @urem_sv(<4 x i16> %a, i16 %b) {
; ALL-LABEL: urem_sv:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    sbmm8 $r0 = $r1, 0x2010201.@
; ALL-NEXT:    copyd $r2 = $r0
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    copyd $r1 = $r2
; ALL-NEXT:    call __umodv4hi3
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %v0 = insertelement <4 x i16> undef, i16 %b, i32 0
  %splat = shufflevector <4 x i16> %v0, <4 x i16> undef, <4 x i32> zeroinitializer
  %div = urem <4 x i16> %splat, %a
  ret <4 x i16> %div
}

define <4 x i16> @urem_ss(i16 %a, i16 %b) {
; ALL-LABEL: urem_ss:
; ALL:       # %bb.0:
; ALL-NEXT:    sbmm8 $r2 = $r1, 0x2010201.@
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    copyd $r0 = $r2
; ALL-NEXT:    sbmm8 $r1 = $r0, 0x2010201.@
; ALL-NEXT:    call __umodv4hi3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %va = insertelement <4 x i16> undef, i16 %b, i32 0
  %vb = insertelement <4 x i16> undef, i16 %a, i32 0
  %splata = shufflevector <4 x i16> %va, <4 x i16> undef, <4 x i32> zeroinitializer
  %splatb = shufflevector <4 x i16> %vb, <4 x i16> undef, <4 x i32> zeroinitializer
  %div = urem <4 x i16> %splata, %splatb
  ret <4 x i16> %div
}

define <4 x i16> @sdivrem(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: sdivrem:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    sq 8[$r12] = $r18r19
; ALL-NEXT:    copyd $r18 = $r1
; ALL-NEXT:    copyd $r19 = $r0
; ALL-NEXT:    call __divv4hi3
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    msbfhq $r19 = $r0, $r18
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    lq $r18r19 = 8[$r12]
; ALL-NEXT:    addhq $r0 = $r0, $r19
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 3)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 8)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %q = sdiv <4 x i16> %a, %b
  %r = srem <4 x i16> %a, %b
  %res = add <4 x i16> %q, %r
  ret <4 x i16> %res
}

define <4 x i16> @udivrem(<4 x i16> %a, <4 x i16> %b) {
; ALL-LABEL: udivrem:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    sq 8[$r12] = $r18r19
; ALL-NEXT:    copyd $r18 = $r1
; ALL-NEXT:    copyd $r19 = $r0
; ALL-NEXT:    call __udivv4hi3
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    msbfhq $r19 = $r0, $r18
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    lq $r18r19 = 8[$r12]
; ALL-NEXT:    addhq $r0 = $r0, $r19
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 3)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 8)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %q = udiv <4 x i16> %a, %b
  %r = urem <4 x i16> %a, %b
  %res = add <4 x i16> %q, %r
  ret <4 x i16> %res
}
