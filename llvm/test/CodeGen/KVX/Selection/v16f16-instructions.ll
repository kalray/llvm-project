; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mcpu=kv3-1 -O2 -o - %s | FileCheck %s --check-prefixes=ALL,CV1
; RUN: llc -mcpu=kv3-2 -O2 -o - %s | FileCheck %s --check-prefixes=ALL,CV2
; RUN: clang -O2 -march=kv3-1 -c -o /dev/null %s
; RUN: clang -O2 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define <16 x half> @test_ret_const() #0 {
; ALL-LABEL: test_ret_const:
; ALL:       # %bb.0:
; ALL-NEXT:    make $r0 = 0x4400420040003c00
; ALL-NEXT:    make $r1 = 0x4400420040003c00
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    make $r2 = 0x4400420040003c00
; ALL-NEXT:    make $r3 = 0x4400420040003c00
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 1)
  ret <16 x half> <half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0>
}

define half @test_extract_0(<16 x half> %a) #0 {
; ALL-LABEL: test_extract_0:
; ALL:       # %bb.0:
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %e = extractelement <16 x half> %a, i32 0
  ret half %e
}

define half @test_extract_1(<16 x half> %a) #0 {
; ALL-LABEL: test_extract_1:
; ALL:       # %bb.0:
; ALL-NEXT:    srlw $r0 = $r0, 16
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %e = extractelement <16 x half> %a, i32 1
  ret half %e
}

define half @test_extract_2(<16 x half> %a) #0 {
; ALL-LABEL: test_extract_2:
; ALL:       # %bb.0:
; ALL-NEXT:    srld $r0 = $r0, 32
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %e = extractelement <16 x half> %a, i32 2
  ret half %e
}

define half @test_extract_3(<16 x half> %a) #0 {
; ALL-LABEL: test_extract_3:
; ALL:       # %bb.0:
; ALL-NEXT:    srld $r0 = $r0, 48
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %e = extractelement <16 x half> %a, i32 3
  ret half %e
}

define half @test_extract_4(<16 x half> %a) #0 {
; ALL-LABEL: test_extract_4:
; ALL:       # %bb.0:
; ALL-NEXT:    copyd $r0 = $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %e = extractelement <16 x half> %a, i32 4
  ret half %e
}

define half @test_extract_5(<16 x half> %a) #0 {
; ALL-LABEL: test_extract_5:
; ALL:       # %bb.0:
; ALL-NEXT:    srlw $r0 = $r1, 16
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %e = extractelement <16 x half> %a, i32 5
  ret half %e
}

define half @test_extract_6(<16 x half> %a) #0 {
; ALL-LABEL: test_extract_6:
; ALL:       # %bb.0:
; ALL-NEXT:    srld $r0 = $r1, 32
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %e = extractelement <16 x half> %a, i32 6
  ret half %e
}

define half @test_extract_i(<16 x half> %a, i64 %idx) #0 {
; ALL-LABEL: test_extract_i:
; ALL:       # %bb.0:
; ALL-NEXT:    andw $r4 = $r4, 15
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sq 16[$r12] = $r2r3
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    sq 0[$r12] = $r0r1
; ALL-NEXT:    addd $r0 = $r12, 0
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    lhz.xs $r0 = $r4[$r0]
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 3)
  %e = extractelement <16 x half> %a, i64 %idx
  ret half %e
}

define <16 x half> @test_fadd(<16 x half> %a, <16 x half> %b) #0 {
; ALL-LABEL: test_fadd:
; ALL:       # %bb.0:
; ALL-NEXT:    faddhq $r0 = $r0, $r4
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    faddhq $r1 = $r1, $r5
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    faddhq $r2 = $r2, $r6
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    faddhq $r3 = $r3, $r7
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 3)
  %r = fadd <16 x half> %a, %b
  ret <16 x half> %r
}

define <16 x half> @test_fadd_imm_0(<16 x half> %a) #0 {
; CV1-LABEL: test_fadd_imm_0:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0x4400420040003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0x4400420040003c00
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    faddhq $r2 = $r2, 0x4400420040003c00
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    faddhq $r3 = $r3, 0x4400420040003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_fadd_imm_0:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r5 = 0x4400420040003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r4 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fadd <16 x half> <half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0>, %a
  ret <16 x half> %r
}

define <16 x half> @test_fadd_imm_1(<16 x half> %a) #0 {
; CV1-LABEL: test_fadd_imm_1:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0x4400420040003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0x4400420040003c00
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    faddhq $r2 = $r2, 0x4400420040003c00
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    faddhq $r3 = $r3, 0x4400420040003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_fadd_imm_1:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r5 = 0x4400420040003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r4 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fadd <16 x half> %a, <half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0>
  ret <16 x half> %r
}

define <16 x half> @test_fadd_imm_2(<16 x half> %a) #0 {
; CV1-LABEL: test_fadd_imm_2:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0x40003c0040003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0x40003c0040003c00
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    faddhq $r2 = $r2, 0x40003c0040003c00
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    faddhq $r3 = $r3, 0x40003c0040003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_fadd_imm_2:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r5 = 0x40003c0040003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r4 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fadd <16 x half> %a, <half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0>
  ret <16 x half> %r
}

define <16 x half> @test_fadd_imm_3(<16 x half> %a) #0 {
; CV1-LABEL: test_fadd_imm_3:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0x40003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0x40003c00
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    faddhq $r2 = $r2, 0x40003c00
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    faddhq $r3 = $r3, 0x40003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_fadd_imm_3:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r5 = 0x40003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r4 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fadd <16 x half> %a, <half 1.0, half 2.0, half 0.0, half 0.0, half 1.0, half 2.0, half 0.0, half 0.0, half 1.0, half 2.0, half 0.0, half 0.0, half 1.0, half 2.0, half 0.0, half 0.0>
  ret <16 x half> %r
}

define <16 x half> @test_fsub(<16 x half> %a, <16 x half> %b) #0 {
; ALL-LABEL: test_fsub:
; ALL:       # %bb.0:
; ALL-NEXT:    fsbfhq $r0 = $r4, $r0
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    fsbfhq $r1 = $r5, $r1
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    fsbfhq $r2 = $r6, $r2
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    fsbfhq $r3 = $r7, $r3
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 3)
  %r = fsub <16 x half> %a, %b
  ret <16 x half> %r
}

define <16 x half> @test_fsub_imm_1(<16 x half> %a) #0 {
; CV1-LABEL: test_fsub_imm_1:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0xc400c200c000bc00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0xc400c200c000bc00
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    faddhq $r2 = $r2, 0xc400c200c000bc00
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    faddhq $r3 = $r3, 0xc400c200c000bc00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_fsub_imm_1:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r5 = 0xc400c200c000bc00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r4 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fsub <16 x half> %a, <half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0>
  ret <16 x half> %r
}

define <16 x half> @test_fsub_imm_2(<16 x half> %a) #0 {
; CV1-LABEL: test_fsub_imm_2:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0x80008000c000bc00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0x80008000c000bc00
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    faddhq $r2 = $r2, 0x80008000c000bc00
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    faddhq $r3 = $r3, 0x80008000c000bc00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_fsub_imm_2:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r5 = 0x80008000c000bc00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r4 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fsub <16 x half> %a, <half 1.0, half 2.0, half 0.0, half 0.0, half 1.0, half 2.0, half 0.0, half 0.0, half 1.0, half 2.0, half 0.0, half 0.0, half 1.0, half 2.0, half 0.0, half 0.0>
  ret <16 x half> %r
}

define <16 x half> @test_fsub_imm_3(<16 x half> %a) #0 {
; CV1-LABEL: test_fsub_imm_3:
; CV1:       # %bb.0:
; CV1-NEXT:    faddhq $r0 = $r0, 0xc000bc00c000bc00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    faddhq $r1 = $r1, 0xc000bc00c000bc00
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    faddhq $r2 = $r2, 0xc000bc00c000bc00
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    faddhq $r3 = $r3, 0xc000bc00c000bc00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_fsub_imm_3:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r5 = 0xc000bc00c000bc00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r4 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    faddho $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    faddho $r0r1 = $r0r1, $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fsub <16 x half> %a, <half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0>
  ret <16 x half> %r
}

define <16 x half> @test_fsub_fromimm1(<16 x half> %a) #0 {
; CV1-LABEL: test_fsub_fromimm1:
; CV1:       # %bb.0:
; CV1-NEXT:    fsbfhq $r0 = $r0, 0x4400420040003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fsbfhq $r1 = $r1, 0x4400420040003c00
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fsbfhq $r2 = $r2, 0x4400420040003c00
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fsbfhq $r3 = $r3, 0x4400420040003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_fsub_fromimm1:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r5 = 0x4400420040003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r4 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fsbfho $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fsbfho $r0r1 = $r0r1, $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fsub <16 x half> <half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0, half 1.0, half 2.0, half 3.0, half 4.0>, %a
  ret <16 x half> %r
}

define <16 x half> @test_fsub_fromimm2(<16 x half> %a) #0 {
; CV1-LABEL: test_fsub_fromimm2:
; CV1:       # %bb.0:
; CV1-NEXT:    fsbfhq $r0 = $r0, 0x40003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fsbfhq $r1 = $r1, 0x40003c00
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fsbfhq $r2 = $r2, 0x40003c00
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fsbfhq $r3 = $r3, 0x40003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_fsub_fromimm2:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r5 = 0x40003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r4 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fsbfho $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fsbfho $r0r1 = $r0r1, $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fsub <16 x half> <half 1.0, half 2.0, half 0.0, half 0.0, half 1.0, half 2.0, half 0.0, half 0.0, half 1.0, half 2.0, half 0.0, half 0.0, half 1.0, half 2.0, half 0.0, half 0.0>, %a
  ret <16 x half> %r
}

define <16 x half> @test_fsub_fromimm3(<16 x half> %a) #0 {
; CV1-LABEL: test_fsub_fromimm3:
; CV1:       # %bb.0:
; CV1-NEXT:    fsbfhq $r0 = $r0, 0x40003c0040003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fsbfhq $r1 = $r1, 0x40003c0040003c00
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fsbfhq $r2 = $r2, 0x40003c0040003c00
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fsbfhq $r3 = $r3, 0x40003c0040003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_fsub_fromimm3:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r5 = 0x40003c0040003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r4 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fsbfho $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fsbfho $r0r1 = $r0r1, $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fsub <16 x half> <half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0>, %a
  ret <16 x half> %r
}

define <16 x half> @test_fneg(<16 x half> %a) #0 {
; CV1-LABEL: test_fneg:
; CV1:       # %bb.0:
; CV1-NEXT:    fneghq $r0 = $r0
; CV1-NEXT:    fneghq $r1 = $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fneghq $r2 = $r2
; CV1-NEXT:    fneghq $r3 = $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fneg:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r5 = 0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r4 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fsbfho $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fsbfho $r0r1 = $r0r1, $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fsub <16 x half> <half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0, half 0.0>, %a
  ret <16 x half> %r
}

define <16 x half> @test_fmul(<16 x half> %a, <16 x half> %b) #0 {
; ALL-LABEL: test_fmul:
; ALL:       # %bb.0:
; ALL-NEXT:    fmulhq $r0 = $r0, $r4
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    fmulhq $r1 = $r1, $r5
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    fmulhq $r2 = $r2, $r6
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    fmulhq $r3 = $r3, $r7
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 3)
  %r = fmul <16 x half> %a, %b
  ret <16 x half> %r
}

define <16 x half> @test_fmul_imm(<16 x half> %a) {
; CV1-LABEL: test_fmul_imm:
; CV1:       # %bb.0:
; CV1-NEXT:    fmulhq $r0 = $r0, 0x40003c0040003c00
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fmulhq $r1 = $r1, 0x40003c0040003c00
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fmulhq $r2 = $r2, 0x40003c0040003c00
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fmulhq $r3 = $r3, 0x40003c0040003c00
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 3)
;
; CV2-LABEL: test_fmul_imm:
; CV2:       # %bb.0:
; CV2-NEXT:    make $r5 = 0x40003c0040003c00
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    copyd $r4 = $r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fmulho $r2r3 = $r2r3, $r4r5
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fmulho $r0r1 = $r0r1, $r4r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %r = fmul <16 x half> %a, <half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0, half 1.0, half 2.0>
  ret <16 x half> %r
}

define <16 x half> @test_fdiv(<16 x half> %a, <16 x half> %b) #0 {
; ALL-LABEL: test_fdiv:
; ALL:       # %bb.0:
; ALL-NEXT:    fwidenlhwp $r4 = $r4
; ALL-NEXT:    fwidenmhwp $r9 = $r4
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    frecw $r8 = $r9
; ALL-NEXT:    srld $r9 = $r9, 32
; ALL-NEXT:    fwidenlhwp $r32 = $r5
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    fwidenmhwp $r9 = $r0
; ALL-NEXT:    frecw $r10 = $r9
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    srld $r4 = $r4, 32
; ALL-NEXT:    frecw $r11 = $r4
; ALL-NEXT:    fwidenmhwp $r17 = $r5
; ALL-NEXT:    ;; # (end cycle 3)
; ALL-NEXT:    frecw $r4 = $r4
; ALL-NEXT:    fwidenmhwp $r5 = $r1
; ALL-NEXT:    srld $r15 = $r17, 32
; ALL-NEXT:    ;; # (end cycle 4)
; ALL-NEXT:    frecw $r16 = $r17
; ALL-NEXT:    srld $r17 = $r32, 32
; ALL-NEXT:    fwidenmhwp $r33 = $r6
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    fwidenlhwp $r6 = $r6
; ALL-NEXT:    frecw $r32 = $r32
; ALL-NEXT:    srld $r34 = $r33, 32
; ALL-NEXT:    ;; # (end cycle 6)
; ALL-NEXT:    frecw $r17 = $r17
; ALL-NEXT:    fwidenmhwp $r35 = $r2
; ALL-NEXT:    srld $r36 = $r6, 32
; ALL-NEXT:    ;; # (end cycle 7)
; ALL-NEXT:    fwidenmhwp $r37 = $r7
; ALL-NEXT:    fwidenlhwp $r38 = $r7
; ALL-NEXT:    ;; # (end cycle 8)
; ALL-NEXT:    fwidenlhwp $r0 = $r0
; ALL-NEXT:    frecw $r6 = $r6
; ALL-NEXT:    ;; # (end cycle 9)
; ALL-NEXT:    frecw $r36 = $r36
; ALL-NEXT:    ;; # (end cycle 10)
; ALL-NEXT:    frecw $r7 = $r37
; ALL-NEXT:    srld $r37 = $r37, 32
; ALL-NEXT:    ;; # (end cycle 11)
; ALL-NEXT:    srld $r38 = $r38, 32
; ALL-NEXT:    frecw $r39 = $r38
; ALL-NEXT:    ;; # (end cycle 12)
; ALL-NEXT:    frecw $r15 = $r15
; ALL-NEXT:    ;; # (end cycle 13)
; ALL-NEXT:    frecw $r33 = $r33
; ALL-NEXT:    ;; # (end cycle 14)
; ALL-NEXT:    frecw $r34 = $r34
; ALL-NEXT:    ;; # (end cycle 15)
; ALL-NEXT:    frecw $r37 = $r37
; ALL-NEXT:    ;; # (end cycle 16)
; ALL-NEXT:    insf $r8 = $r10, 63, 32
; ALL-NEXT:    frecw $r38 = $r38
; ALL-NEXT:    ;; # (end cycle 17)
; ALL-NEXT:    fmulwp $r9 = $r9, $r8
; ALL-NEXT:    ;; # (end cycle 18)
; ALL-NEXT:    insf $r11 = $r4, 63, 32
; ALL-NEXT:    ;; # (end cycle 19)
; ALL-NEXT:    fwidenlhwp $r0 = $r1
; ALL-NEXT:    fwidenmhwp $r1 = $r3
; ALL-NEXT:    fmulwp $r8 = $r0, $r11
; ALL-NEXT:    ;; # (end cycle 20)
; ALL-NEXT:    insf $r32 = $r17, 63, 32
; ALL-NEXT:    ;; # (end cycle 22)
; ALL-NEXT:    fwidenlhwp $r0 = $r2
; ALL-NEXT:    fmulwp $r4 = $r0, $r32
; ALL-NEXT:    ;; # (end cycle 23)
; ALL-NEXT:    insf $r6 = $r36, 63, 32
; ALL-NEXT:    ;; # (end cycle 25)
; ALL-NEXT:    fwidenlhwp $r0 = $r3
; ALL-NEXT:    fmulwp $r10 = $r0, $r6
; ALL-NEXT:    ;; # (end cycle 26)
; ALL-NEXT:    insf $r16 = $r15, 63, 32
; ALL-NEXT:    ;; # (end cycle 28)
; ALL-NEXT:    fmulwp $r5 = $r5, $r16
; ALL-NEXT:    ;; # (end cycle 29)
; ALL-NEXT:    insf $r33 = $r34, 63, 32
; ALL-NEXT:    ;; # (end cycle 30)
; ALL-NEXT:    insf $r7 = $r37, 63, 32
; ALL-NEXT:    fmulwp $r11 = $r35, $r33
; ALL-NEXT:    ;; # (end cycle 31)
; ALL-NEXT:    fmulwp $r7 = $r1, $r7
; ALL-NEXT:    insf $r39 = $r38, 63, 32
; ALL-NEXT:    ;; # (end cycle 32)
; ALL-NEXT:    fnarrowwhq $r0 = $r8r9
; ALL-NEXT:    fnarrowwhq $r1 = $r4r5
; ALL-NEXT:    fmulwp $r6 = $r0, $r39
; ALL-NEXT:    ;; # (end cycle 33)
; ALL-NEXT:    fnarrowwhq $r2 = $r10r11
; ALL-NEXT:    ;; # (end cycle 35)
; ALL-NEXT:    fnarrowwhq $r3 = $r6r7
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 37)
  %r = fdiv <16 x half> %a, %b
  ret <16 x half> %r
}

define <16 x half> @test_frem(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_frem:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r21 = $r7
; CV1-NEXT:    copyd $r22 = $r5
; CV1-NEXT:    copyd $r23 = $r6
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r19 = $r4
; CV1-NEXT:    copyd $r24 = $r3
; CV1-NEXT:    copyd $r25 = $r2
; CV1-NEXT:    copyd $r26 = $r1
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenmhw $r0 = $r24
; CV1-NEXT:    fwidenmhw $r1 = $r21
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r21
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenlhw $r0 = $r24
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r24, 48
; CV1-NEXT:    srld $r1 = $r21, 48
; CV1-NEXT:    fnarrowwh $r18 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    srld $r1 = $r21, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r24, 32
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenmhw $r0 = $r25
; CV1-NEXT:    fnarrowwh $r24 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r1 = $r23
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    fwidenlhw $r0 = $r25
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r25, 48
; CV1-NEXT:    srld $r1 = $r23, 48
; CV1-NEXT:    fnarrowwh $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r25, 32
; CV1-NEXT:    srld $r1 = $r23, 32
; CV1-NEXT:    fnarrowwh $r30 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenmhw $r0 = $r26
; CV1-NEXT:    fnarrowwh $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r1 = $r22
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r26
; CV1-NEXT:    fnarrowwh $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r1 = $r22
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r26, 48
; CV1-NEXT:    srld $r1 = $r22, 48
; CV1-NEXT:    fnarrowwh $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r26, 32
; CV1-NEXT:    srld $r1 = $r22, 32
; CV1-NEXT:    fnarrowwh $r27 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r1 = $r19
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    fnarrowwh $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r1 = $r19
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    srld $r1 = $r19, 48
; CV1-NEXT:    fnarrowwh $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    srld $r1 = $r19, 32
; CV1-NEXT:    fnarrowwh $r29 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call fmodf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r22 = $r28, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r29, 31, 16
; CV1-NEXT:    insf $r26 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r22 = $r0, 63, 32
; CV1-NEXT:    insf $r23 = $r31, 31, 16
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r23 = $r26, 63, 32
; CV1-NEXT:    insf $r25 = $r30, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    ld $r0 = 24[$r12]
; CV1-NEXT:    insf $r21 = $r0, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    insf $r21 = $r25, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r0 = 32[$r12]
; CV1-NEXT:    insf $r24 = $r0, 31, 16
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    copyd $r0 = $r22
; CV1-NEXT:    copyd $r1 = $r23
; CV1-NEXT:    copyd $r2 = $r21
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    insf $r18 = $r24, 63, 32
; CV1-NEXT:    ;; # (end cycle 12)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 17)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 22)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_frem:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r21 = $r7
; CV2-NEXT:    copyd $r22 = $r5
; CV2-NEXT:    copyd $r23 = $r6
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r19 = $r4
; CV2-NEXT:    copyd $r24 = $r3
; CV2-NEXT:    copyd $r25 = $r2
; CV2-NEXT:    copyd $r26 = $r1
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenmhw $r0 = $r24
; CV2-NEXT:    fwidenmhw $r1 = $r21
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r21
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenlhw $r0 = $r24
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r24, 48
; CV2-NEXT:    srld $r1 = $r21, 48
; CV2-NEXT:    fnarrowwh $r18 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    srld $r1 = $r21, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r24, 32
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenmhw $r0 = $r25
; CV2-NEXT:    fnarrowwh $r24 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r1 = $r23
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    fwidenlhw $r0 = $r25
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r25, 48
; CV2-NEXT:    srld $r1 = $r23, 48
; CV2-NEXT:    fnarrowwh $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r25, 32
; CV2-NEXT:    srld $r1 = $r23, 32
; CV2-NEXT:    fnarrowwh $r30 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenmhw $r0 = $r26
; CV2-NEXT:    fnarrowwh $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r1 = $r22
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r26
; CV2-NEXT:    fnarrowwh $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r1 = $r22
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r26, 48
; CV2-NEXT:    srld $r1 = $r22, 48
; CV2-NEXT:    fnarrowwh $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r26, 32
; CV2-NEXT:    srld $r1 = $r22, 32
; CV2-NEXT:    fnarrowwh $r27 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r1 = $r19
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    fnarrowwh $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r1 = $r19
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    srld $r1 = $r19, 48
; CV2-NEXT:    fnarrowwh $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    srld $r1 = $r19, 32
; CV2-NEXT:    fnarrowwh $r29 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call fmodf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r22 = $r28, 31, 16
; CV2-NEXT:    insf $r26 = $r27, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r29, 31, 16
; CV2-NEXT:    insf $r23 = $r31, 31, 16
; CV2-NEXT:    insf $r25 = $r30, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r22 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r26, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    insf $r21 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r21 = $r25, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r22
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    insf $r24 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    copyd $r1 = $r23
; CV2-NEXT:    copyd $r2 = $r21
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    insf $r18 = $r24, 63, 32
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 13)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 15)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 20)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = frem <16 x half> %a, %b
  ret <16 x half> %r
}

define void @test_ldst_v8f16(ptr %a, ptr %b) {
; ALL-LABEL: test_ldst_v8f16:
; ALL:       # %bb.0:
; ALL-NEXT:    lo $r4r5r6r7 = 0[$r0]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    so 0[$r1] = $r4r5r6r7
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 2)
  %t1 = load <16 x half>, ptr %a
  store <16 x half> %t1, ptr %b, align 16
  ret void
}

declare <16 x half> @test_callee(<16 x half> %a, <16 x half> %b) #0

define <16 x half> @test_call(<16 x half> %a, <16 x half> %b) #0 {
; ALL-LABEL: test_call:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    call test_callee
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = call <16 x half> @test_callee(<16 x half> %a, <16 x half> %b)
  ret <16 x half> %r
}

define <16 x half> @test_call_flipped(<16 x half> %a, <16 x half> %b) #0 {
; ALL-LABEL: test_call_flipped:
; ALL:       # %bb.0:
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    get $r16 = $ra
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sd 24[$r12] = $r16
; ALL-NEXT:    copyd $r0 = $r4
; ALL-NEXT:    copyd $r4 = $r0
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    copyd $r1 = $r5
; ALL-NEXT:    copyd $r2 = $r6
; ALL-NEXT:    copyd $r5 = $r1
; ALL-NEXT:    copyd $r6 = $r2
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    copyd $r3 = $r7
; ALL-NEXT:    copyd $r7 = $r3
; ALL-NEXT:    call test_callee
; ALL-NEXT:    ;; # (end cycle 3)
; ALL-NEXT:    ld $r16 = 24[$r12]
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    set $ra = $r16
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = call <16 x half> @test_callee(<16 x half> %b, <16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_tailcall_flipped(<16 x half> %a, <16 x half> %b) #0 {
; ALL-LABEL: test_tailcall_flipped:
; ALL:       # %bb.0:
; ALL-NEXT:    copyd $r0 = $r4
; ALL-NEXT:    copyd $r1 = $r5
; ALL-NEXT:    copyd $r4 = $r0
; ALL-NEXT:    copyd $r5 = $r1
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    copyd $r2 = $r6
; ALL-NEXT:    copyd $r3 = $r7
; ALL-NEXT:    copyd $r6 = $r2
; ALL-NEXT:    copyd $r7 = $r3
; ALL-NEXT:    goto test_callee
; ALL-NEXT:    ;; # (end cycle 1)
  %r = tail call <16 x half> @test_callee(<16 x half> %b, <16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_select(<16 x half> %a, <16 x half> %b, i1 zeroext %c) #0 {
; CV1-LABEL: test_select:
; CV1:       # %bb.0:
; CV1-NEXT:    cmoved.even $r8 ? $r2 = $r6
; CV1-NEXT:    cmoved.even $r8 ? $r3 = $r7
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    cmoved.even $r8 ? $r0 = $r4
; CV1-NEXT:    cmoved.even $r8 ? $r1 = $r5
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_select:
; CV2:       # %bb.0:
; CV2-NEXT:    cmoved.even $r8 ? $r0 = $r4
; CV2-NEXT:    cmoved.even $r8 ? $r1 = $r5
; CV2-NEXT:    cmoved.even $r8 ? $r2 = $r6
; CV2-NEXT:    cmoved.even $r8 ? $r3 = $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = select i1 %c, <16 x half> %a, <16 x half> %b
  ret <16 x half> %r
}

define <16 x half> @test_select_cc(<16 x half> %a, <16 x half> %b, <16 x half> %c, <16 x half> %d) #0 {
; CV1-LABEL: test_select_cc:
; CV1:       # %bb.0:
; CV1-NEXT:    ld $r15 = 0[$r12]
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    ld $r16 = 16[$r12]
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r17 = 24[$r12]
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fcompnhq.une $r8 = $r8, $r15
; CV1-NEXT:    ld $r32 = 8[$r12]
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    cmovehq.even $r8 ? $r0 = $r4
; CV1-NEXT:    fcompnhq.une $r10 = $r10, $r16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    cmovehq.even $r10 ? $r2 = $r6
; CV1-NEXT:    fcompnhq.une $r11 = $r11, $r17
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    cmovehq.even $r11 ? $r3 = $r7
; CV1-NEXT:    fcompnhq.une $r9 = $r9, $r32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    cmovehq.even $r9 ? $r1 = $r5
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 7)
;
; CV2-LABEL: test_select_cc:
; CV2:       # %bb.0:
; CV2-NEXT:    ld $r15 = 0[$r12]
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    ld $r16 = 8[$r12]
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r17 = 16[$r12]
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fcompnhq.une $r8 = $r8, $r15
; CV2-NEXT:    ld $r32 = 24[$r12]
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    cmovehq.even $r8 ? $r0 = $r4
; CV2-NEXT:    fcompnhq.une $r9 = $r9, $r16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    cmovehq.even $r9 ? $r1 = $r5
; CV2-NEXT:    fcompnhq.une $r10 = $r10, $r17
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    cmovehq.even $r10 ? $r2 = $r6
; CV2-NEXT:    fcompnhq.une $r11 = $r11, $r32
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    cmovehq.even $r11 ? $r3 = $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 7)
  %cc = fcmp une <16 x half> %c, %d
  %r = select <16 x i1> %cc, <16 x half> %a, <16 x half> %b
  ret <16 x half> %r
}

define <16 x half> @test_select_cc_f16_f32(<16 x half> %a, <16 x half> %b, <16 x float> %c, <16 x float> %d) #0 {
; CV1-LABEL: test_select_cc_f16_f32:
; CV1:       # %bb.0:
; CV1-NEXT:    ld $r16 = 0[$r12]
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    ld $r17 = 8[$r12]
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r32 = 16[$r12]
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    ld $r33 = 24[$r12]
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    ld $r34 = 80[$r12]
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r35 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    ld $r36 = 64[$r12]
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fcompnwp.une $r32 = $r32, $r34
; CV1-NEXT:    ld $r37 = 72[$r12]
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    sbmm8 $r32 = $r32, 0x20100201
; CV1-NEXT:    fcompnwp.une $r33 = $r33, $r35
; CV1-NEXT:    ld $r34 = 48[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    sbmm8 $r15 = $r33, 0x20100201
; CV1-NEXT:    fcompnwp.une $r16 = $r16, $r36
; CV1-NEXT:    ld $r33 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    sbmm8 $r16 = $r16, 0x20100201
; CV1-NEXT:    fcompnwp.une $r17 = $r17, $r37
; CV1-NEXT:    ld $r36 = 32[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    fcompnwp.une $r10 = $r10, $r34
; CV1-NEXT:    sbmm8 $r17 = $r17, 0x20100201
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    fcompnwp.une $r11 = $r11, $r33
; CV1-NEXT:    insf $r16 = $r17, 63, 32
; CV1-NEXT:    ld $r17 = 40[$r12]
; CV1-NEXT:    ;; # (end cycle 12)
; CV1-NEXT:    fcompnwp.une $r8 = $r8, $r36
; CV1-NEXT:    sbmm8 $r11 = $r11, 0x20100201
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    sbmm8 $r8 = $r8, 0x20100201
; CV1-NEXT:    sbmm8 $r10 = $r10, 0x20100201
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    fcompnwp.une $r9 = $r9, $r17
; CV1-NEXT:    insf $r32 = $r15, 63, 32
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    sbmm8 $r9 = $r9, 0x20100201
; CV1-NEXT:    insf $r10 = $r11, 63, 32
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    cmovehq.even $r10 ? $r1 = $r5
; CV1-NEXT:    insf $r8 = $r9, 63, 32
; CV1-NEXT:    ;; # (end cycle 17)
; CV1-NEXT:    cmovehq.even $r8 ? $r0 = $r4
; CV1-NEXT:    cmovehq.even $r16 ? $r2 = $r6
; CV1-NEXT:    ;; # (end cycle 18)
; CV1-NEXT:    cmovehq.even $r32 ? $r3 = $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 19)
;
; CV2-LABEL: test_select_cc_f16_f32:
; CV2:       # %bb.0:
; CV2-NEXT:    ld $r16 = 32[$r12]
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    ld $r17 = 40[$r12]
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r32 = 0[$r12]
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fcompnwp.une $r8 = $r8, $r16
; CV2-NEXT:    ld $r33 = 8[$r12]
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    sbmm8 $r8 = $r8, 0x20100201
; CV2-NEXT:    fcompnwp.une $r9 = $r9, $r17
; CV2-NEXT:    ld $r34 = 64[$r12]
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sbmm8 $r9 = $r9, 0x20100201
; CV2-NEXT:    ld $r35 = 72[$r12]
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    insf $r8 = $r9, 63, 32
; CV2-NEXT:    ld $r36 = 16[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    cmovehq.even $r8 ? $r0 = $r4
; CV2-NEXT:    fcompnwp.une $r32 = $r32, $r34
; CV2-NEXT:    ld $r37 = 24[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    sbmm8 $r32 = $r32, 0x20100201
; CV2-NEXT:    fcompnwp.une $r33 = $r33, $r35
; CV2-NEXT:    ld $r38 = 80[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    sbmm8 $r33 = $r33, 0x20100201
; CV2-NEXT:    ld $r39 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    insf $r32 = $r33, 63, 32
; CV2-NEXT:    ld $r40 = 48[$r12]
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    cmovehq.even $r32 ? $r2 = $r6
; CV2-NEXT:    fcompnwp.une $r36 = $r36, $r38
; CV2-NEXT:    ld $r41 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    sbmm8 $r34 = $r36, 0x20100201
; CV2-NEXT:    fcompnwp.une $r37 = $r37, $r39
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    fcompnwp.une $r10 = $r10, $r40
; CV2-NEXT:    sbmm8 $r15 = $r37, 0x20100201
; CV2-NEXT:    ;; # (end cycle 13)
; CV2-NEXT:    sbmm8 $r10 = $r10, 0x20100201
; CV2-NEXT:    fcompnwp.une $r11 = $r11, $r41
; CV2-NEXT:    insf $r34 = $r15, 63, 32
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    cmovehq.even $r34 ? $r3 = $r7
; CV2-NEXT:    sbmm8 $r11 = $r11, 0x20100201
; CV2-NEXT:    ;; # (end cycle 15)
; CV2-NEXT:    insf $r10 = $r11, 63, 32
; CV2-NEXT:    ;; # (end cycle 16)
; CV2-NEXT:    cmovehq.even $r10 ? $r1 = $r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 17)
  %cc = fcmp une <16 x float> %c, %d
  %r = select <16 x i1> %cc, <16 x half> %a, <16 x half> %b
  ret <16 x half> %r
}

define <16 x i1> @test_fcmp_une(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_une:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.une $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.une $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.une $r1 = $r3, $r7
; CV1-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    fcompnhq.une $r2 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_une:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.une $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.une $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.une $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.une $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp une <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_ueq(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_ueq:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.ueq $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.ueq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.ueq $r1 = $r3, $r7
; CV1-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    fcompnhq.ueq $r2 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_ueq:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.ueq $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.ueq $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.ueq $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.ueq $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp ueq <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_ugt(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_ugt:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.ult $r0 = $r4, $r0
; CV1-NEXT:    fcompnhq.ult $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.ult $r1 = $r7, $r3
; CV1-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    fcompnhq.ult $r2 = $r6, $r2
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_ugt:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.ult $r0 = $r4, $r0
; CV2-NEXT:    fcompnhq.ult $r1 = $r5, $r1
; CV2-NEXT:    fcompnhq.ult $r2 = $r6, $r2
; CV2-NEXT:    fcompnhq.ult $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp ugt <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_uge(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_uge:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.uge $r1 = $r3, $r7
; CV1-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    fcompnhq.uge $r2 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_uge:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.uge $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.uge $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp uge <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_ult(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_ult:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.ult $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.ult $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.ult $r1 = $r3, $r7
; CV1-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    fcompnhq.ult $r2 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_ult:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.ult $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.ult $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.ult $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.ult $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp ult <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_ule(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_ule:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.uge $r0 = $r4, $r0
; CV1-NEXT:    fcompnhq.uge $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.uge $r1 = $r7, $r3
; CV1-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    fcompnhq.uge $r2 = $r6, $r2
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_ule:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.uge $r0 = $r4, $r0
; CV2-NEXT:    fcompnhq.uge $r1 = $r5, $r1
; CV2-NEXT:    fcompnhq.uge $r2 = $r6, $r2
; CV2-NEXT:    fcompnhq.uge $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp ule <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_uno(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_uno:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r5
; CV1-NEXT:    fcompnhq.ult $r8 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r4
; CV1-NEXT:    andd $r1 = $r1, $r8
; CV1-NEXT:    fcompnhq.ult $r5 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r0 = $r0, $r5
; CV1-NEXT:    fcompnhq.uge $r3 = $r3, $r7
; CV1-NEXT:    fcompnhq.ult $r4 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fcompnhq.uge $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.ult $r5 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    andd $r1 = $r3, $r4
; CV1-NEXT:    andd $r2 = $r2, $r5
; CV1-NEXT:    sbmm8 $r6 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    insf $r0 = $r6, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_uno:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.ult $r5 = $r0, $r4
; CV2-NEXT:    fcompnhq.ult $r8 = $r1, $r5
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompnhq.uge $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.uge $r3 = $r3, $r7
; CV2-NEXT:    fcompnhq.ult $r4 = $r3, $r7
; CV2-NEXT:    fcompnhq.ult $r7 = $r2, $r6
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    andd $r0 = $r0, $r5
; CV2-NEXT:    andd $r1 = $r1, $r8
; CV2-NEXT:    andd $r2 = $r2, $r7
; CV2-NEXT:    andd $r3 = $r3, $r4
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 4)
  %r = fcmp uno <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_one(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_one:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.one $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.one $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.one $r1 = $r3, $r7
; CV1-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    fcompnhq.one $r2 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_one:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.one $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.one $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.one $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.one $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp one <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_oeq(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_oeq:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.oeq $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.oeq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oeq $r1 = $r3, $r7
; CV1-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    fcompnhq.oeq $r2 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_oeq:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.oeq $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.oeq $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.oeq $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.oeq $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp oeq <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_ogt(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_ogt:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.olt $r0 = $r4, $r0
; CV1-NEXT:    fcompnhq.olt $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.olt $r1 = $r7, $r3
; CV1-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    fcompnhq.olt $r2 = $r6, $r2
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_ogt:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.olt $r0 = $r4, $r0
; CV2-NEXT:    fcompnhq.olt $r1 = $r5, $r1
; CV2-NEXT:    fcompnhq.olt $r2 = $r6, $r2
; CV2-NEXT:    fcompnhq.olt $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp ogt <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_oge(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_oge:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oge $r1 = $r3, $r7
; CV1-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_oge:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp oge <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_olt(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_olt:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.olt $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.olt $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.olt $r1 = $r3, $r7
; CV1-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    fcompnhq.olt $r2 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_olt:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.olt $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.olt $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.olt $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.olt $r3 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp olt <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_ole(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_ole:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.oge $r0 = $r4, $r0
; CV1-NEXT:    fcompnhq.oge $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oge $r1 = $r7, $r3
; CV1-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    fcompnhq.oge $r2 = $r6, $r2
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_fcmp_ole:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.oge $r0 = $r4, $r0
; CV2-NEXT:    fcompnhq.oge $r1 = $r5, $r1
; CV2-NEXT:    fcompnhq.oge $r2 = $r6, $r2
; CV2-NEXT:    fcompnhq.oge $r3 = $r7, $r3
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
  %r = fcmp ole <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i1> @test_fcmp_ord(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_fcmp_ord:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV1-NEXT:    fcompnhq.olt $r8 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV1-NEXT:    iord $r1 = $r1, $r8
; CV1-NEXT:    fcompnhq.olt $r5 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    iord $r0 = $r0, $r5
; CV1-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV1-NEXT:    fcompnhq.olt $r4 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.olt $r5 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    iord $r1 = $r3, $r4
; CV1-NEXT:    iord $r2 = $r2, $r5
; CV1-NEXT:    sbmm8 $r6 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV1-NEXT:    sbmm8 $r3 = $r1, 0x40100401
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    insf $r0 = $r6, 63, 32
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: test_fcmp_ord:
; CV2:       # %bb.0:
; CV2-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.olt $r5 = $r0, $r4
; CV2-NEXT:    fcompnhq.olt $r8 = $r1, $r5
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV2-NEXT:    fcompnhq.olt $r4 = $r3, $r7
; CV2-NEXT:    fcompnhq.olt $r7 = $r2, $r6
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    iord $r0 = $r0, $r5
; CV2-NEXT:    iord $r1 = $r1, $r8
; CV2-NEXT:    iord $r2 = $r2, $r7
; CV2-NEXT:    iord $r3 = $r3, $r4
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV2-NEXT:    sbmm8 $r1 = $r2, 0x40100401
; CV2-NEXT:    sbmm8 $r3 = $r3, 0x40100401
; CV2-NEXT:    sbmm8 $r4 = $r1, 0x40100401
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    insf $r1 = $r3, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 4)
  %r = fcmp ord <16 x half> %a, %b
  ret <16 x i1> %r
}

define <16 x i16> @test_fptosi_i16(<16 x half> %a) #0 {
; CV1-LABEL: test_fptosi_i16:
; CV1:       # %bb.0:
; CV1-NEXT:    fwidenlhwp $r0 = $r0
; CV1-NEXT:    fwidenmhwp $r4 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhwp $r1 = $r1
; CV1-NEXT:    fwidenmhwp $r4 = $r1
; CV1-NEXT:    fixedwp.rz $r5 = $r4, 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenmhwp $r4 = $r2
; CV1-NEXT:    fixedwp.rz $r7 = $r4, 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhwp $r1 = $r2
; CV1-NEXT:    fwidenmhwp $r2 = $r3
; CV1-NEXT:    fixedwp.rz $r6 = $r1, 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fixedwp.rz $r0 = $r0, 0
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    fixedwp.rz $r9 = $r4, 0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fwidenlhwp $r1 = $r3
; CV1-NEXT:    fixedwp.rz $r4 = $r1, 0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    sbmm8 $r2 = $r5, 0x20100201
; CV1-NEXT:    fixedwp.rz $r3 = $r2, 0
; CV1-NEXT:    sbmm8 $r5 = $r7, 0x20100201
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x20100201
; CV1-NEXT:    sbmm8 $r1 = $r6, 0x20100201
; CV1-NEXT:    fixedwp.rz $r8 = $r1, 0
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    insf $r0 = $r2, 63, 32
; CV1-NEXT:    insf $r1 = $r5, 63, 32
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    sbmm8 $r2 = $r4, 0x20100201
; CV1-NEXT:    sbmm8 $r5 = $r9, 0x20100201
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    insf $r2 = $r5, 63, 32
; CV1-NEXT:    sbmm8 $r4 = $r3, 0x20100201
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    sbmm8 $r3 = $r8, 0x20100201
; CV1-NEXT:    ;; # (end cycle 12)
; CV1-NEXT:    insf $r3 = $r4, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 13)
;
; CV2-LABEL: test_fptosi_i16:
; CV2:       # %bb.0:
; CV2-NEXT:    fwidenlhwp $r0 = $r0
; CV2-NEXT:    fwidenmhwp $r4 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhwp $r1 = $r1
; CV2-NEXT:    fwidenmhwp $r4 = $r1
; CV2-NEXT:    fixedwp.rz $r5 = $r4, 0
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenmhwp $r4 = $r2
; CV2-NEXT:    fixedwp.rz $r7 = $r4, 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhwp $r1 = $r2
; CV2-NEXT:    fwidenmhwp $r2 = $r3
; CV2-NEXT:    fixedwp.rz $r6 = $r1, 0
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fixedwp.rz $r9 = $r4, 0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    fwidenlhwp $r1 = $r3
; CV2-NEXT:    fixedwp.rz $r4 = $r1, 0
; CV2-NEXT:    sbmm8 $r5 = $r5, 0x20100201
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fixedwp.rz $r0 = $r0, 0
; CV2-NEXT:    sbmm8 $r7 = $r7, 0x20100201
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fixedwp.rz $r3 = $r2, 0
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    sbmm8 $r1 = $r6, 0x20100201
; CV2-NEXT:    sbmm8 $r6 = $r9, 0x20100201
; CV2-NEXT:    fixedwp.rz $r8 = $r1, 0
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    insf $r1 = $r7, 63, 32
; CV2-NEXT:    sbmm8 $r2 = $r4, 0x20100201
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    sbmm8 $r0 = $r0, 0x20100201
; CV2-NEXT:    insf $r2 = $r6, 63, 32
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    insf $r0 = $r5, 63, 32
; CV2-NEXT:    sbmm8 $r4 = $r3, 0x20100201
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    sbmm8 $r3 = $r8, 0x20100201
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    insf $r3 = $r4, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 13)
  %r = fptosi <16 x half> %a to <16 x i16>
  ret <16 x i16> %r
}

define <16 x half> @test_uitofp_8xi16(<16 x i16> %a) #0 {
; CV1-LABEL: test_uitofp_8xi16:
; CV1:       # %bb.0:
; CV1-NEXT:    sbmm8 $r1 = $r1, 0x804000002010
; CV1-NEXT:    sbmm8 $r6 = $r1, 0x80400000201
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sbmm8 $r4 = $r0, 0x80400000201
; CV1-NEXT:    sbmm8 $r5 = $r0, 0x804000002010
; CV1-NEXT:    floatuwp.rn $r7 = $r1, 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    sbmm8 $r0 = $r2, 0x80400000201
; CV1-NEXT:    sbmm8 $r1 = $r2, 0x804000002010
; CV1-NEXT:    floatuwp.rn $r4 = $r4, 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    sbmm8 $r0 = $r3, 0x80400000201
; CV1-NEXT:    floatuwp.rn $r8 = $r0, 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    sbmm8 $r1 = $r3, 0x804000002010
; CV1-NEXT:    floatuwp.rn $r9 = $r1, 0
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    floatuwp.rn $r6 = $r6, 0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    floatuwp.rn $r5 = $r5, 0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    floatuwp.rn $r10 = $r0, 0
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwhq.rn $r2 = $r8r9
; CV1-NEXT:    floatuwp.rn $r11 = $r1, 0
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwhq.rn $r1 = $r6r7
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    fnarrowwhq.rn $r0 = $r4r5
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    fnarrowwhq.rn $r3 = $r10r11
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 12)
;
; CV2-LABEL: test_uitofp_8xi16:
; CV2:       # %bb.0:
; CV2-NEXT:    zxmhwp $r1 = $r1
; CV2-NEXT:    zxlhwp $r4 = $r0
; CV2-NEXT:    zxmhwp $r5 = $r0
; CV2-NEXT:    zxlhwp $r6 = $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    zxlhwp $r0 = $r2
; CV2-NEXT:    zxmhwp $r1 = $r2
; CV2-NEXT:    floatuwp.rn $r7 = $r1, 0
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    zxlhwp $r0 = $r3
; CV2-NEXT:    floatuwp.rn $r8 = $r0, 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    zxmhwp $r1 = $r3
; CV2-NEXT:    floatuwp.rn $r9 = $r1, 0
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    floatuwp.rn $r4 = $r4, 0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    floatuwp.rn $r6 = $r6, 0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    floatuwp.rn $r5 = $r5, 0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwhq.rn $r2 = $r8r9
; CV2-NEXT:    floatuwp.rn $r10 = $r0, 0
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    floatuwp.rn $r11 = $r1, 0
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwhq.rn $r1 = $r6r7
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    fnarrowwhq.rn $r0 = $r4r5
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    fnarrowwhq.rn $r3 = $r10r11
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 12)
  %r = uitofp <16 x i16> %a to <16 x half>
  ret <16 x half> %r
}

define <16 x half> @test_uitofp_8xi32(<16 x i32> %a) #0 {
; ALL-LABEL: test_uitofp_8xi32:
; ALL:       # %bb.0:
; ALL-NEXT:    floatuwp.rn $r0 = $r0, 0
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    floatuwp.rn $r1 = $r1, 0
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    floatuwp.rn $r2 = $r2, 0
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    floatuwp.rn $r3 = $r3, 0
; ALL-NEXT:    ;; # (end cycle 3)
; ALL-NEXT:    floatuwp.rn $r4 = $r4, 0
; ALL-NEXT:    ;; # (end cycle 4)
; ALL-NEXT:    fnarrowwhq.rn $r0 = $r0r1
; ALL-NEXT:    floatuwp.rn $r5 = $r5, 0
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    floatuwp.rn $r6 = $r6, 0
; ALL-NEXT:    ;; # (end cycle 6)
; ALL-NEXT:    fnarrowwhq.rn $r1 = $r2r3
; ALL-NEXT:    floatuwp.rn $r7 = $r7, 0
; ALL-NEXT:    ;; # (end cycle 7)
; ALL-NEXT:    fnarrowwhq.rn $r2 = $r4r5
; ALL-NEXT:    ;; # (end cycle 9)
; ALL-NEXT:    fnarrowwhq.rn $r3 = $r6r7
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 11)
  %r = uitofp <16 x i32> %a to <16 x half>
  ret <16 x half> %r
}

define <16 x half> @test_sitofp_8xi32(<16 x i32> %a) #0 {
; ALL-LABEL: test_sitofp_8xi32:
; ALL:       # %bb.0:
; ALL-NEXT:    floatwp.rn $r0 = $r0, 0
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    floatwp.rn $r1 = $r1, 0
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    floatwp.rn $r2 = $r2, 0
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    floatwp.rn $r3 = $r3, 0
; ALL-NEXT:    ;; # (end cycle 3)
; ALL-NEXT:    floatwp.rn $r4 = $r4, 0
; ALL-NEXT:    ;; # (end cycle 4)
; ALL-NEXT:    fnarrowwhq.rn $r0 = $r0r1
; ALL-NEXT:    floatwp.rn $r5 = $r5, 0
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    floatwp.rn $r6 = $r6, 0
; ALL-NEXT:    ;; # (end cycle 6)
; ALL-NEXT:    fnarrowwhq.rn $r1 = $r2r3
; ALL-NEXT:    floatwp.rn $r7 = $r7, 0
; ALL-NEXT:    ;; # (end cycle 7)
; ALL-NEXT:    fnarrowwhq.rn $r2 = $r4r5
; ALL-NEXT:    ;; # (end cycle 9)
; ALL-NEXT:    fnarrowwhq.rn $r3 = $r6r7
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 11)
  %r = sitofp <16 x i32> %a to <16 x half>
  ret <16 x half> %r
}

define <16 x half> @test_uitofp_8xi32_fadd(<16 x i32> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_uitofp_8xi32_fadd:
; CV1:       # %bb.0:
; CV1-NEXT:    floatuwp.rn $r6 = $r6, 0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    floatuwp.rn $r4 = $r4, 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    floatuwp.rn $r2 = $r2, 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    floatuwp.rn $r0 = $r0, 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    floatuwp.rn $r1 = $r1, 0
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    floatuwp.rn $r3 = $r3, 0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    floatuwp.rn $r5 = $r5, 0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    floatuwp.rn $r7 = $r7, 0
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwhq.rn $r0 = $r0r1
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    faddhq $r0 = $r8, $r0
; CV1-NEXT:    fnarrowwhq.rn $r1 = $r2r3
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    faddhq $r1 = $r9, $r1
; CV1-NEXT:    fnarrowwhq.rn $r2 = $r4r5
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    faddhq $r2 = $r10, $r2
; CV1-NEXT:    fnarrowwhq.rn $r3 = $r6r7
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    faddhq $r3 = $r11, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 12)
;
; CV2-LABEL: test_uitofp_8xi32_fadd:
; CV2:       # %bb.0:
; CV2-NEXT:    floatuwp.rn $r2 = $r2, 0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    floatuwp.rn $r3 = $r3, 0
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    floatuwp.rn $r0 = $r0, 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    floatuwp.rn $r6 = $r6, 0
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    floatuwp.rn $r7 = $r7, 0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    floatuwp.rn $r4 = $r4, 0
; CV2-NEXT:    fnarrowwhq.rn $r17 = $r2r3
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    floatuwp.rn $r5 = $r5, 0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    floatuwp.rn $r1 = $r1, 0
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwhq.rn $r7 = $r6r7
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwhq.rn $r6 = $r4r5
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    faddho $r2r3 = $r10r11, $r6r7
; CV2-NEXT:    fnarrowwhq.rn $r16 = $r0r1
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    faddho $r0r1 = $r8r9, $r16r17
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 12)
  %c = uitofp <16 x i32> %a to <16 x half>
  %r = fadd <16 x half> %b, %c
  ret <16 x half> %r
}

define <16 x half> @test_sitofp_8xi32_fadd(<16 x i32> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_sitofp_8xi32_fadd:
; CV1:       # %bb.0:
; CV1-NEXT:    floatwp.rn $r6 = $r6, 0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    floatwp.rn $r4 = $r4, 0
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    floatwp.rn $r2 = $r2, 0
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    floatwp.rn $r0 = $r0, 0
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    floatwp.rn $r1 = $r1, 0
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    floatwp.rn $r3 = $r3, 0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    floatwp.rn $r5 = $r5, 0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    floatwp.rn $r7 = $r7, 0
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwhq.rn $r0 = $r0r1
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    faddhq $r0 = $r8, $r0
; CV1-NEXT:    fnarrowwhq.rn $r1 = $r2r3
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    faddhq $r1 = $r9, $r1
; CV1-NEXT:    fnarrowwhq.rn $r2 = $r4r5
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    faddhq $r2 = $r10, $r2
; CV1-NEXT:    fnarrowwhq.rn $r3 = $r6r7
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    faddhq $r3 = $r11, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 12)
;
; CV2-LABEL: test_sitofp_8xi32_fadd:
; CV2:       # %bb.0:
; CV2-NEXT:    floatwp.rn $r2 = $r2, 0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    floatwp.rn $r3 = $r3, 0
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    floatwp.rn $r0 = $r0, 0
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    floatwp.rn $r6 = $r6, 0
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    floatwp.rn $r7 = $r7, 0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    floatwp.rn $r4 = $r4, 0
; CV2-NEXT:    fnarrowwhq.rn $r17 = $r2r3
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    floatwp.rn $r5 = $r5, 0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    floatwp.rn $r1 = $r1, 0
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwhq.rn $r7 = $r6r7
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwhq.rn $r6 = $r4r5
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    faddho $r2r3 = $r10r11, $r6r7
; CV2-NEXT:    fnarrowwhq.rn $r16 = $r0r1
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    faddho $r0r1 = $r8r9, $r16r17
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 12)
  %c = sitofp <16 x i32> %a to <16 x half>
  %r = fadd <16 x half> %b, %c
  ret <16 x half> %r
}

define <16 x half> @test_fptrunc_8xfloat(<16 x float> %a) #0 {
; ALL-LABEL: test_fptrunc_8xfloat:
; ALL:       # %bb.0:
; ALL-NEXT:    fnarrowwhq $r0 = $r0r1
; ALL-NEXT:    fnarrowwhq $r1 = $r2r3
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    fnarrowwhq $r2 = $r4r5
; ALL-NEXT:    fnarrowwhq $r3 = $r6r7
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 1)
  %r = fptrunc <16 x float> %a to <16 x half>
  ret <16 x half> %r
}

define <16 x i16> @test_bitcast_8xhalf_to_8xi16(<16 x half> %a) #0 {
; ALL-LABEL: test_bitcast_8xhalf_to_8xi16:
; ALL:       # %bb.0:
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = bitcast <16 x half> %a to <16 x i16>
  ret <16 x i16> %r
}

define <16 x half> @test_bitcast_8xi16_to_8xhalf(<16 x i16> %a) #0 {
; ALL-LABEL: test_bitcast_8xi16_to_8xhalf:
; ALL:       # %bb.0:
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %r = bitcast <16 x i16> %a to <16 x half>
  ret <16 x half> %r
}

declare <16 x half> @llvm.sqrt.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.powi.v8f16(<16 x half> %a, i32 %b) #0
declare <16 x half> @llvm.sin.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.cos.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.pow.v8f16(<16 x half> %a, <16 x half> %b) #0
declare <16 x half> @llvm.exp.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.exp2.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.log.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.log10.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.log2.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.fma.v8f16(<16 x half> %a, <16 x half> %b, <16 x half> %c) #0
declare <16 x half> @llvm.fabs.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.minnum.v8f16(<16 x half> %a, <16 x half> %b) #0
declare <16 x half> @llvm.maxnum.v8f16(<16 x half> %a, <16 x half> %b) #0
declare <16 x half> @llvm.copysign.v8f16(<16 x half> %a, <16 x half> %b) #0
declare <16 x half> @llvm.floor.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.ceil.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.trunc.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.rint.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.nearbyint.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.round.v8f16(<16 x half> %a) #0
declare <16 x half> @llvm.fmuladd.v8f16(<16 x half> %a, <16 x half> %b, <16 x half> %c) #0

define <16 x half> @test_sqrt(<16 x half> %a) #0 {
; CV1-LABEL: test_sqrt:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call sqrtf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_sqrt:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call sqrtf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.sqrt.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_powi(<16 x half> %a, i32 %b) #0 {
; CV1-LABEL: test_powi:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r19 = $r4
; CV1-NEXT:    copyd $r21 = $r3
; CV1-NEXT:    copyd $r22 = $r2
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    copyd $r23 = $r1
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    fnarrowwh $r18 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenmhw $r0 = $r22
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    fwidenlhw $r0 = $r22
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r22, 48
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    fnarrowwh $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r22, 32
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    fnarrowwh $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenmhw $r0 = $r23
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    fnarrowwh $r29 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r23
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    fnarrowwh $r30 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r23, 48
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    fnarrowwh $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r23, 32
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    fnarrowwh $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    fnarrowwh $r24 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    fnarrowwh $r25 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    fnarrowwh $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    copyd $r1 = $r19
; CV1-NEXT:    fnarrowwh $r27 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call __powisf2
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r23 = $r25, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r27, 31, 16
; CV1-NEXT:    insf $r24 = $r31, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r22 = $r30, 31, 16
; CV1-NEXT:    insf $r23 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r22 = $r24, 63, 32
; CV1-NEXT:    insf $r29 = $r28, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    ld $r0 = 24[$r12]
; CV1-NEXT:    insf $r21 = $r0, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    insf $r21 = $r29, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r0 = 32[$r12]
; CV1-NEXT:    insf $r26 = $r0, 31, 16
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    copyd $r0 = $r23
; CV1-NEXT:    copyd $r1 = $r22
; CV1-NEXT:    copyd $r2 = $r21
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    insf $r18 = $r26, 63, 32
; CV1-NEXT:    ;; # (end cycle 12)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 17)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 22)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_powi:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r19 = $r4
; CV2-NEXT:    copyd $r21 = $r3
; CV2-NEXT:    copyd $r22 = $r2
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    copyd $r23 = $r1
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    fnarrowwh $r18 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenmhw $r0 = $r22
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    fwidenlhw $r0 = $r22
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r22, 48
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    fnarrowwh $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r22, 32
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    fnarrowwh $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenmhw $r0 = $r23
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    fnarrowwh $r29 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r23
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    fnarrowwh $r30 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r23, 48
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    fnarrowwh $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r23, 32
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    fnarrowwh $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    fnarrowwh $r24 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    fnarrowwh $r25 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    fnarrowwh $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    copyd $r1 = $r19
; CV2-NEXT:    fnarrowwh $r27 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call __powisf2
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r23 = $r25, 31, 16
; CV2-NEXT:    insf $r24 = $r31, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r27, 31, 16
; CV2-NEXT:    insf $r22 = $r30, 31, 16
; CV2-NEXT:    insf $r29 = $r28, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r22 = $r24, 63, 32
; CV2-NEXT:    insf $r23 = $r0, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    insf $r21 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r21 = $r29, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r23
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    insf $r26 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    copyd $r1 = $r22
; CV2-NEXT:    copyd $r2 = $r21
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    insf $r18 = $r26, 63, 32
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 13)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 15)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 20)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.powi.v8f16(<16 x half> %a, i32 %b)
  ret <16 x half> %r
}

define <16 x half> @test_sin(<16 x half> %a) #0 {
; CV1-LABEL: test_sin:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call sinf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_sin:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call sinf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.sin.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_cos(<16 x half> %a) #0 {
; CV1-LABEL: test_cos:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call cosf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_cos:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call cosf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.cos.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_pow(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_pow:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r21 = $r7
; CV1-NEXT:    copyd $r22 = $r5
; CV1-NEXT:    copyd $r23 = $r6
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r19 = $r4
; CV1-NEXT:    copyd $r24 = $r3
; CV1-NEXT:    copyd $r25 = $r2
; CV1-NEXT:    copyd $r26 = $r1
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fwidenmhw $r0 = $r24
; CV1-NEXT:    fwidenmhw $r1 = $r21
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r21
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenlhw $r0 = $r24
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r24, 48
; CV1-NEXT:    srld $r1 = $r21, 48
; CV1-NEXT:    fnarrowwh $r18 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    srld $r1 = $r21, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r24, 32
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenmhw $r0 = $r25
; CV1-NEXT:    fnarrowwh $r24 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r1 = $r23
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    fwidenlhw $r0 = $r25
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r25, 48
; CV1-NEXT:    srld $r1 = $r23, 48
; CV1-NEXT:    fnarrowwh $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r25, 32
; CV1-NEXT:    srld $r1 = $r23, 32
; CV1-NEXT:    fnarrowwh $r30 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenmhw $r0 = $r26
; CV1-NEXT:    fnarrowwh $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r1 = $r22
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r26
; CV1-NEXT:    fnarrowwh $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r1 = $r22
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r26, 48
; CV1-NEXT:    srld $r1 = $r22, 48
; CV1-NEXT:    fnarrowwh $r23 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r26, 32
; CV1-NEXT:    srld $r1 = $r22, 32
; CV1-NEXT:    fnarrowwh $r27 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    fnarrowwh $r26 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r1 = $r19
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    fnarrowwh $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r1 = $r19
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    srld $r1 = $r19, 48
; CV1-NEXT:    fnarrowwh $r22 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    srld $r1 = $r19, 32
; CV1-NEXT:    fnarrowwh $r29 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fwidenlhw $r1 = $r1
; CV1-NEXT:    call powf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r22 = $r28, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r29, 31, 16
; CV1-NEXT:    insf $r26 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r22 = $r0, 63, 32
; CV1-NEXT:    insf $r23 = $r31, 31, 16
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r23 = $r26, 63, 32
; CV1-NEXT:    insf $r25 = $r30, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    ld $r0 = 24[$r12]
; CV1-NEXT:    insf $r21 = $r0, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    insf $r21 = $r25, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    ld $r0 = 32[$r12]
; CV1-NEXT:    insf $r24 = $r0, 31, 16
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    copyd $r0 = $r22
; CV1-NEXT:    copyd $r1 = $r23
; CV1-NEXT:    copyd $r2 = $r21
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    insf $r18 = $r24, 63, 32
; CV1-NEXT:    ;; # (end cycle 12)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 17)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 22)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_pow:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r21 = $r7
; CV2-NEXT:    copyd $r22 = $r5
; CV2-NEXT:    copyd $r23 = $r6
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r19 = $r4
; CV2-NEXT:    copyd $r24 = $r3
; CV2-NEXT:    copyd $r25 = $r2
; CV2-NEXT:    copyd $r26 = $r1
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fwidenmhw $r0 = $r24
; CV2-NEXT:    fwidenmhw $r1 = $r21
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r21
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenlhw $r0 = $r24
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r24, 48
; CV2-NEXT:    srld $r1 = $r21, 48
; CV2-NEXT:    fnarrowwh $r18 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    srld $r1 = $r21, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r24, 32
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenmhw $r0 = $r25
; CV2-NEXT:    fnarrowwh $r24 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r1 = $r23
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    fwidenlhw $r0 = $r25
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r25, 48
; CV2-NEXT:    srld $r1 = $r23, 48
; CV2-NEXT:    fnarrowwh $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r25, 32
; CV2-NEXT:    srld $r1 = $r23, 32
; CV2-NEXT:    fnarrowwh $r30 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenmhw $r0 = $r26
; CV2-NEXT:    fnarrowwh $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r1 = $r22
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r26
; CV2-NEXT:    fnarrowwh $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r1 = $r22
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r26, 48
; CV2-NEXT:    srld $r1 = $r22, 48
; CV2-NEXT:    fnarrowwh $r23 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r26, 32
; CV2-NEXT:    srld $r1 = $r22, 32
; CV2-NEXT:    fnarrowwh $r27 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    fnarrowwh $r26 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r1 = $r19
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    fnarrowwh $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r1 = $r19
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    srld $r1 = $r19, 48
; CV2-NEXT:    fnarrowwh $r22 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    srld $r1 = $r19, 32
; CV2-NEXT:    fnarrowwh $r29 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fwidenlhw $r1 = $r1
; CV2-NEXT:    call powf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r22 = $r28, 31, 16
; CV2-NEXT:    insf $r26 = $r27, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r29, 31, 16
; CV2-NEXT:    insf $r23 = $r31, 31, 16
; CV2-NEXT:    insf $r25 = $r30, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r22 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r26, 63, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    insf $r21 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r21 = $r25, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    copyd $r0 = $r22
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    insf $r24 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    copyd $r1 = $r23
; CV2-NEXT:    copyd $r2 = $r21
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    insf $r18 = $r24, 63, 32
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 13)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 15)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 20)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.pow.v8f16(<16 x half> %a, <16 x half> %b)
  ret <16 x half> %r
}

define <16 x half> @test_exp(<16 x half> %a) #0 {
; CV1-LABEL: test_exp:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call expf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_exp:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call expf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.exp.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_exp2(<16 x half> %a) #0 {
; CV1-LABEL: test_exp2:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call exp2f
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_exp2:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call exp2f
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.exp2.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_log(<16 x half> %a) #0 {
; CV1-LABEL: test_log:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call logf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_log:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call logf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.log.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_log10(<16 x half> %a) #0 {
; CV1-LABEL: test_log10:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call log10f
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_log10:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call log10f
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.log10.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_log2(<16 x half> %a) #0 {
; CV1-LABEL: test_log2:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call log2f
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_log2:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call log2f
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.log2.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_fma(<16 x half> %a, <16 x half> %b, <16 x half> %c) #0 {
; CV1-LABEL: test_fma:
; CV1:       # %bb.0:
; CV1-NEXT:    ffmahq $r8 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    ffmahq $r9 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ffmahq $r10 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    ffmahq $r11 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    copyd $r0 = $r8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r1 = $r9
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r10
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    copyd $r3 = $r11
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 7)
;
; CV2-LABEL: test_fma:
; CV2:       # %bb.0:
; CV2-NEXT:    ffmaho $r10r11 = $r2r3, $r6r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    ffmaho $r8r9 = $r0r1, $r4r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    copyd $r0 = $r8
; CV2-NEXT:    copyd $r1 = $r9
; CV2-NEXT:    copyd $r2 = $r10
; CV2-NEXT:    copyd $r3 = $r11
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 5)
  %r = call <16 x half> @llvm.fma.v8f16(<16 x half> %a, <16 x half> %b, <16 x half> %c)
  ret <16 x half> %r
}

define <16 x half> @test_fabs(<16 x half> %a) #0 {
; CV1-LABEL: test_fabs:
; CV1:       # %bb.0:
; CV1-NEXT:    fabshq $r0 = $r0
; CV1-NEXT:    fabshq $r1 = $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fabshq $r2 = $r2
; CV1-NEXT:    fabshq $r3 = $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_fabs:
; CV2:       # %bb.0:
; CV2-NEXT:    fabshq $r0 = $r0
; CV2-NEXT:    fabshq $r1 = $r1
; CV2-NEXT:    fabshq $r2 = $r2
; CV2-NEXT:    fabshq $r3 = $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = call <16 x half> @llvm.fabs.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_minnum(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_minnum:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.olt $r8 = $r4, $r0
; CV1-NEXT:    fcompnhq.une $r9 = $r0, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    iord $r8 = $r8, $r9
; CV1-NEXT:    fcompnhq.olt $r10 = $r5, $r1
; CV1-NEXT:    fcompnhq.une $r11 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    iord $r9 = $r10, $r11
; CV1-NEXT:    fcompnhq.olt $r15 = $r6, $r2
; CV1-NEXT:    fcompnhq.une $r16 = $r2, $r2
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fcompnhq.olt $r10 = $r7, $r3
; CV1-NEXT:    fcompnhq.une $r11 = $r3, $r3
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    cmovehq.odd $r8 ? $r0 = $r4
; CV1-NEXT:    cmovehq.odd $r9 ? $r1 = $r5
; CV1-NEXT:    iord $r4 = $r15, $r16
; CV1-NEXT:    iord $r5 = $r10, $r11
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    cmovehq.odd $r4 ? $r2 = $r6
; CV1-NEXT:    cmovehq.odd $r5 ? $r3 = $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 5)
;
; CV2-LABEL: test_minnum:
; CV2:       # %bb.0:
; CV2-NEXT:    fminhq $r0 = $r0, $r4
; CV2-NEXT:    fminhq $r1 = $r1, $r5
; CV2-NEXT:    fminhq $r2 = $r2, $r6
; CV2-NEXT:    fminhq $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = call <16 x half> @llvm.minnum.v8f16(<16 x half> %a, <16 x half> %b)
  ret <16 x half> %r
}

define <16 x half> @test_minnum_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_minnum_fast:
; CV1:       # %bb.0:
; CV1-NEXT:    fminhq $r0 = $r0, $r4
; CV1-NEXT:    fminhq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fminhq $r2 = $r2, $r6
; CV1-NEXT:    fminhq $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_minnum_fast:
; CV2:       # %bb.0:
; CV2-NEXT:    fminhq $r0 = $r0, $r4
; CV2-NEXT:    fminhq $r1 = $r1, $r5
; CV2-NEXT:    fminhq $r2 = $r2, $r6
; CV2-NEXT:    fminhq $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = call fast <16 x half> @llvm.minnum.v8f16(<16 x half> %a, <16 x half> %b)
  ret <16 x half> %r
}

define <16 x half> @test_maxnum(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_maxnum:
; CV1:       # %bb.0:
; CV1-NEXT:    fcompnhq.olt $r8 = $r0, $r4
; CV1-NEXT:    fcompnhq.une $r9 = $r4, $r4
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    iord $r8 = $r8, $r9
; CV1-NEXT:    fcompnhq.olt $r10 = $r1, $r5
; CV1-NEXT:    fcompnhq.une $r11 = $r5, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    iord $r9 = $r10, $r11
; CV1-NEXT:    fcompnhq.olt $r15 = $r2, $r6
; CV1-NEXT:    fcompnhq.une $r16 = $r6, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fcompnhq.olt $r10 = $r3, $r7
; CV1-NEXT:    fcompnhq.une $r11 = $r7, $r7
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    cmovehq.odd $r8 ? $r0 = $r4
; CV1-NEXT:    cmovehq.odd $r9 ? $r1 = $r5
; CV1-NEXT:    iord $r4 = $r15, $r16
; CV1-NEXT:    iord $r5 = $r10, $r11
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    cmovehq.odd $r4 ? $r2 = $r6
; CV1-NEXT:    cmovehq.odd $r5 ? $r3 = $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 5)
;
; CV2-LABEL: test_maxnum:
; CV2:       # %bb.0:
; CV2-NEXT:    fmaxhq $r0 = $r0, $r4
; CV2-NEXT:    fmaxhq $r1 = $r1, $r5
; CV2-NEXT:    fmaxhq $r2 = $r2, $r6
; CV2-NEXT:    fmaxhq $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = call <16 x half> @llvm.maxnum.v8f16(<16 x half> %a, <16 x half> %b)
  ret <16 x half> %r
}

define <16 x half> @test_maxnum_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: test_maxnum_fast:
; CV1:       # %bb.0:
; CV1-NEXT:    fmaxhq $r0 = $r0, $r4
; CV1-NEXT:    fmaxhq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fmaxhq $r2 = $r2, $r6
; CV1-NEXT:    fmaxhq $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: test_maxnum_fast:
; CV2:       # %bb.0:
; CV2-NEXT:    fmaxhq $r0 = $r0, $r4
; CV2-NEXT:    fmaxhq $r1 = $r1, $r5
; CV2-NEXT:    fmaxhq $r2 = $r2, $r6
; CV2-NEXT:    fmaxhq $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
  %r = call fast <16 x half> @llvm.maxnum.v8f16(<16 x half> %a, <16 x half> %b)
  ret <16 x half> %r
}

define <16 x half> @test_copysign(<16 x half> %a, <16 x half> %b) #0 {
; ALL-LABEL: test_copysign:
; ALL:       # %bb.0:
; ALL-NEXT:    fabshq $r0 = $r0
; ALL-NEXT:    fabshq $r1 = $r1
; ALL-NEXT:    andd $r4 = $r4, 0x80008000.@
; ALL-NEXT:    andd $r5 = $r5, 0x80008000.@
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    fabshq $r2 = $r2
; ALL-NEXT:    fabshq $r3 = $r3
; ALL-NEXT:    andd $r6 = $r6, 0x80008000.@
; ALL-NEXT:    andd $r7 = $r7, 0x80008000.@
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    iord $r0 = $r0, $r4
; ALL-NEXT:    iord $r1 = $r1, $r5
; ALL-NEXT:    iord $r2 = $r2, $r6
; ALL-NEXT:    iord $r3 = $r3, $r7
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 2)
  %r = call <16 x half> @llvm.copysign.v8f16(<16 x half> %a, <16 x half> %b)
  ret <16 x half> %r
}

define <16 x half> @test_copysign_v4f32(<16 x half> %a, <16 x float> %b) #0 {
; CV1-LABEL: test_copysign_v4f32:
; CV1:       # %bb.0:
; CV1-NEXT:    fnarrowwhq $r8 = $r8r9
; CV1-NEXT:    fnarrowwhq $r10 = $r10r11
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwhq $r4 = $r4r5
; CV1-NEXT:    fnarrowwhq $r6 = $r6r7
; CV1-NEXT:    andd $r7 = $r10, 0x80008000.@
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fabshq $r0 = $r0
; CV1-NEXT:    fabshq $r1 = $r1
; CV1-NEXT:    andd $r4 = $r4, 0x80008000.@
; CV1-NEXT:    andd $r5 = $r6, 0x80008000.@
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    iord $r0 = $r0, $r4
; CV1-NEXT:    fabshq $r2 = $r2
; CV1-NEXT:    fabshq $r3 = $r3
; CV1-NEXT:    andd $r6 = $r8, 0x80008000.@
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    iord $r1 = $r1, $r5
; CV1-NEXT:    iord $r2 = $r2, $r6
; CV1-NEXT:    iord $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: test_copysign_v4f32:
; CV2:       # %bb.0:
; CV2-NEXT:    fabshq $r0 = $r0
; CV2-NEXT:    fabshq $r1 = $r1
; CV2-NEXT:    fnarrowwhq $r8 = $r8r9
; CV2-NEXT:    fnarrowwhq $r10 = $r10r11
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fabshq $r2 = $r2
; CV2-NEXT:    fnarrowwhq $r4 = $r4r5
; CV2-NEXT:    fnarrowwhq $r6 = $r6r7
; CV2-NEXT:    andd $r7 = $r10, 0x80008000.@
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fabshq $r3 = $r3
; CV2-NEXT:    andd $r4 = $r4, 0x80008000.@
; CV2-NEXT:    andd $r5 = $r6, 0x80008000.@
; CV2-NEXT:    andd $r6 = $r8, 0x80008000.@
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    iord $r0 = $r0, $r4
; CV2-NEXT:    iord $r1 = $r1, $r5
; CV2-NEXT:    iord $r2 = $r2, $r6
; CV2-NEXT:    iord $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 3)
  %tb = fptrunc <16 x float> %b to <16 x half>
  %r = call <16 x half> @llvm.copysign.v8f16(<16 x half> %a, <16 x half> %tb)
  ret <16 x half> %r
}

define <16 x half> @test_floor(<16 x half> %a) #0 {
; CV1-LABEL: test_floor:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call floorf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_floor:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call floorf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.floor.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_ceil(<16 x half> %a) #0 {
; CV1-LABEL: test_ceil:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call ceilf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_ceil:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call ceilf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.ceil.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_trunc(<16 x half> %a) #0 {
; CV1-LABEL: test_trunc:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call truncf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_trunc:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call truncf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.trunc.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_rint(<16 x half> %a) #0 {
; CV1-LABEL: test_rint:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call rintf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_rint:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call rintf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.rint.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_nearbyint(<16 x half> %a) #0 {
; CV1-LABEL: test_nearbyint:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call nearbyintf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_nearbyint:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call nearbyintf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.nearbyint.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_round(<16 x half> %a) #0 {
; CV1-LABEL: test_round:
; CV1:       # %bb.0:
; CV1-NEXT:    addd $r12 = $r12, -160
; CV1-NEXT:    get $r16 = $ra
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 152[$r12] = $r16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    so 120[$r12] = $r28r29r30r31
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    so 88[$r12] = $r24r25r26r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    so 56[$r12] = $r20r21r22r23
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    sq 40[$r12] = $r18r19
; CV1-NEXT:    copyd $r18 = $r3
; CV1-NEXT:    copyd $r19 = $r2
; CV1-NEXT:    copyd $r20 = $r1
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r21 = $r0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    srld $r0 = $r21, 48
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fwidenlhw $r0 = $r21
; CV1-NEXT:    copyd $r24 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 32[$r12] = $r0
; CV1-NEXT:    fwidenmhw $r0 = $r21
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 24[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r20, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r20, 48
; CV1-NEXT:    copyd $r25 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r20
; CV1-NEXT:    copyd $r26 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r20
; CV1-NEXT:    copyd $r27 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r19, 32
; CV1-NEXT:    copyd $r20 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r19, 48
; CV1-NEXT:    copyd $r28 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r19
; CV1-NEXT:    copyd $r29 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r19
; CV1-NEXT:    copyd $r30 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r0 = $r18, 32
; CV1-NEXT:    copyd $r19 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r18, 48
; CV1-NEXT:    copyd $r31 = $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    fwidenlhw $r0 = $r18
; CV1-NEXT:    copyd $r22 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fwidenmhw $r0 = $r18
; CV1-NEXT:    copyd $r23 = $r0
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    fnarrowwh $r18 = $r23
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    sd 16[$r12] = $r0
; CV1-NEXT:    srld $r0 = $r21, 32
; CV1-NEXT:    fnarrowwh $r23 = $r31
; CV1-NEXT:    fnarrowwh $r31 = $r19
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r1 = 24[$r12]
; CV1-NEXT:    fnarrowwh $r19 = $r30
; CV1-NEXT:    fnarrowwh $r30 = $r20
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fwidenlhw $r0 = $r0
; CV1-NEXT:    fnarrowwh $r20 = $r27
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fnarrowwh $r22 = $r22
; CV1-NEXT:    fnarrowwh $r29 = $r29
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    ld $r1 = 32[$r12]
; CV1-NEXT:    fnarrowwh $r27 = $r1
; CV1-NEXT:    fnarrowwh $r28 = $r28
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    fnarrowwh $r25 = $r25
; CV1-NEXT:    fnarrowwh $r26 = $r26
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    fnarrowwh $r24 = $r24
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    fnarrowwh $r21 = $r1
; CV1-NEXT:    call roundf
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    fnarrowwh $r0 = $r0
; CV1-NEXT:    insf $r21 = $r27, 31, 16
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r24, 31, 16
; CV1-NEXT:    insf $r25 = $r26, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r0 = 16[$r12]
; CV1-NEXT:    insf $r20 = $r30, 31, 16
; CV1-NEXT:    insf $r21 = $r0, 63, 32
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r19 = $r31, 31, 16
; CV1-NEXT:    insf $r28 = $r29, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r20 = $r25, 63, 32
; CV1-NEXT:    insf $r23 = $r22, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r0 = $r21
; CV1-NEXT:    copyd $r1 = $r20
; CV1-NEXT:    insf $r18 = $r0, 31, 16
; CV1-NEXT:    insf $r19 = $r28, 63, 32
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r19
; CV1-NEXT:    insf $r18 = $r23, 63, 32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    lq $r18r19 = 40[$r12]
; CV1-NEXT:    copyd $r3 = $r18
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    ld $r16 = 152[$r12]
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    set $ra = $r16
; CV1-NEXT:    addd $r12 = $r12, 160
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: test_round:
; CV2:       # %bb.0:
; CV2-NEXT:    addd $r12 = $r12, -160
; CV2-NEXT:    get $r16 = $ra
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 152[$r12] = $r16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    so 120[$r12] = $r28r29r30r31
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    so 88[$r12] = $r24r25r26r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    so 56[$r12] = $r20r21r22r23
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    sq 40[$r12] = $r18r19
; CV2-NEXT:    copyd $r18 = $r3
; CV2-NEXT:    copyd $r19 = $r2
; CV2-NEXT:    copyd $r20 = $r1
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r21 = $r0
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    srld $r0 = $r21, 48
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fwidenlhw $r0 = $r21
; CV2-NEXT:    copyd $r24 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 32[$r12] = $r0
; CV2-NEXT:    fwidenmhw $r0 = $r21
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 24[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r20, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r20, 48
; CV2-NEXT:    copyd $r25 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r20
; CV2-NEXT:    copyd $r26 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r20
; CV2-NEXT:    copyd $r27 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r19, 32
; CV2-NEXT:    copyd $r20 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r19, 48
; CV2-NEXT:    copyd $r28 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r19
; CV2-NEXT:    copyd $r29 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r19
; CV2-NEXT:    copyd $r30 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r0 = $r18, 32
; CV2-NEXT:    copyd $r19 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r0 = $r18, 48
; CV2-NEXT:    copyd $r31 = $r0
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    fwidenlhw $r0 = $r18
; CV2-NEXT:    copyd $r22 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fwidenmhw $r0 = $r18
; CV2-NEXT:    copyd $r23 = $r0
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    fnarrowwh $r18 = $r23
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    sd 16[$r12] = $r0
; CV2-NEXT:    srld $r0 = $r21, 32
; CV2-NEXT:    fnarrowwh $r23 = $r31
; CV2-NEXT:    fnarrowwh $r31 = $r19
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r1 = 24[$r12]
; CV2-NEXT:    fnarrowwh $r19 = $r30
; CV2-NEXT:    fnarrowwh $r30 = $r20
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fwidenlhw $r0 = $r0
; CV2-NEXT:    fnarrowwh $r20 = $r27
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fnarrowwh $r22 = $r22
; CV2-NEXT:    fnarrowwh $r29 = $r29
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    ld $r1 = 32[$r12]
; CV2-NEXT:    fnarrowwh $r27 = $r1
; CV2-NEXT:    fnarrowwh $r28 = $r28
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    fnarrowwh $r25 = $r25
; CV2-NEXT:    fnarrowwh $r26 = $r26
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    fnarrowwh $r24 = $r24
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    fnarrowwh $r21 = $r1
; CV2-NEXT:    call roundf
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    fnarrowwh $r0 = $r0
; CV2-NEXT:    ld $r1 = 16[$r12]
; CV2-NEXT:    insf $r21 = $r27, 31, 16
; CV2-NEXT:    insf $r25 = $r26, 31, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r24, 31, 16
; CV2-NEXT:    insf $r19 = $r31, 31, 16
; CV2-NEXT:    insf $r20 = $r30, 31, 16
; CV2-NEXT:    insf $r28 = $r29, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r19 = $r28, 63, 32
; CV2-NEXT:    insf $r20 = $r25, 63, 32
; CV2-NEXT:    insf $r21 = $r0, 63, 32
; CV2-NEXT:    insf $r23 = $r22, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r21
; CV2-NEXT:    copyd $r1 = $r20
; CV2-NEXT:    copyd $r2 = $r19
; CV2-NEXT:    insf $r18 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r18 = $r23, 63, 32
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    lq $r18r19 = 40[$r12]
; CV2-NEXT:    copyd $r3 = $r18
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    lo $r20r21r22r23 = 56[$r12]
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    lo $r24r25r26r27 = 88[$r12]
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    lo $r28r29r30r31 = 120[$r12]
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    ld $r16 = 152[$r12]
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    set $ra = $r16
; CV2-NEXT:    addd $r12 = $r12, 160
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %r = call <16 x half> @llvm.round.v8f16(<16 x half> %a)
  ret <16 x half> %r
}

define <16 x half> @test_fmuladd(<16 x half> %a, <16 x half> %b, <16 x half> %c) #0 {
; CV1-LABEL: test_fmuladd:
; CV1:       # %bb.0:
; CV1-NEXT:    ffmahq $r8 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    ffmahq $r9 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ffmahq $r10 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    ffmahq $r11 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    copyd $r0 = $r8
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    copyd $r1 = $r9
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    copyd $r2 = $r10
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    copyd $r3 = $r11
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 7)
;
; CV2-LABEL: test_fmuladd:
; CV2:       # %bb.0:
; CV2-NEXT:    ffmaho $r10r11 = $r2r3, $r6r7
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    ffmaho $r8r9 = $r0r1, $r4r5
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    copyd $r0 = $r8
; CV2-NEXT:    copyd $r1 = $r9
; CV2-NEXT:    copyd $r2 = $r10
; CV2-NEXT:    copyd $r3 = $r11
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 5)
  %r = call <16 x half> @llvm.fmuladd.v8f16(<16 x half> %a, <16 x half> %b, <16 x half> %c)
  ret <16 x half> %r
}

define <16 x half> @test_shufflevector(<16 x half> %a) #0 {
; CV1-LABEL: test_shufflevector:
; CV1:       # %bb.0:
; CV1-NEXT:    srld $r4 = $r1, 48
; CV1-NEXT:    srlw $r5 = $r1, 16
; CV1-NEXT:    srld $r6 = $r1, 32
; CV1-NEXT:    srld $r7 = $r2, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srlw $r1 = $r0, 16
; CV1-NEXT:    insf $r4 = $r6, 31, 16
; CV1-NEXT:    insf $r5 = $r1, 31, 16
; CV1-NEXT:    srld $r6 = $r0, 32
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srld $r0 = $r3, 48
; CV1-NEXT:    insf $r1 = $r0, 31, 16
; CV1-NEXT:    insf $r4 = $r5, 63, 32
; CV1-NEXT:    srld $r5 = $r0, 48
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r5 = $r6, 31, 16
; CV1-NEXT:    srlw $r6 = $r3, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    srld $r1 = $r3, 32
; CV1-NEXT:    srlw $r3 = $r2, 16
; CV1-NEXT:    insf $r5 = $r1, 63, 32
; CV1-NEXT:    insf $r6 = $r3, 31, 16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r0 = $r1, 31, 16
; CV1-NEXT:    srld $r1 = $r2, 48
; CV1-NEXT:    copyd $r2 = $r4
; CV1-NEXT:    insf $r3 = $r2, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    insf $r0 = $r6, 63, 32
; CV1-NEXT:    insf $r1 = $r7, 31, 16
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    insf $r1 = $r3, 63, 32
; CV1-NEXT:    copyd $r3 = $r5
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 7)
;
; CV2-LABEL: test_shufflevector:
; CV2:       # %bb.0:
; CV2-NEXT:    srld $r4 = $r1, 48
; CV2-NEXT:    srld $r5 = $r1, 32
; CV2-NEXT:    srlw $r6 = $r1, 16
; CV2-NEXT:    srlw $r7 = $r0, 16
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    srld $r1 = $r0, 32
; CV2-NEXT:    insf $r4 = $r5, 31, 16
; CV2-NEXT:    srld $r5 = $r0, 48
; CV2-NEXT:    insf $r6 = $r1, 31, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r5 = $r1, 31, 16
; CV2-NEXT:    insf $r7 = $r0, 31, 16
; CV2-NEXT:    srlw $r8 = $r3, 16
; CV2-NEXT:    srld $r9 = $r3, 32
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    srld $r0 = $r3, 48
; CV2-NEXT:    srld $r1 = $r2, 48
; CV2-NEXT:    srlw $r10 = $r2, 16
; CV2-NEXT:    srld $r11 = $r2, 32
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r0 = $r9, 31, 16
; CV2-NEXT:    insf $r1 = $r11, 31, 16
; CV2-NEXT:    insf $r8 = $r3, 31, 16
; CV2-NEXT:    insf $r10 = $r2, 31, 16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    insf $r0 = $r8, 63, 32
; CV2-NEXT:    insf $r1 = $r10, 63, 32
; CV2-NEXT:    insf $r4 = $r6, 63, 32
; CV2-NEXT:    insf $r5 = $r7, 63, 32
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    copyd $r2 = $r4
; CV2-NEXT:    copyd $r3 = $r5
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 6)
  %s = shufflevector <16 x half> %a, <16 x half> undef, <16 x i32> <i32 15, i32 14, i32 13, i32 12, i32 11, i32 10, i32 9, i32 8, i32 7, i32 6, i32 5, i32 4, i32 3, i32 2, i32 1, i32 0>
  ret <16 x half> %s
}

define <16 x half> @test_shufflevector2(<16 x half> %a) #0 {
; CV1-LABEL: test_shufflevector2:
; CV1:       # %bb.0:
; CV1-NEXT:    srld $r2 = $r2, 16
; CV1-NEXT:    srld $r4 = $r3, 48
; CV1-NEXT:    srlw $r5 = $r3, 16
; CV1-NEXT:    srld $r6 = $r0, 48
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r2 = $r3, 63, 48
; CV1-NEXT:    srld $r3 = $r0, 32
; CV1-NEXT:    srld $r4 = $r1, 32
; CV1-NEXT:    insf $r5 = $r4, 31, 16
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    insf $r1 = $r4, 31, 16
; CV1-NEXT:    srlw $r3 = $r0, 16
; CV1-NEXT:    insf $r6 = $r3, 31, 16
; CV1-NEXT:    srld $r7 = $r1, 48
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    insf $r0 = $r3, 31, 16
; CV1-NEXT:    insf $r7 = $r7, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r0 = $r6, 63, 32
; CV1-NEXT:    sbmm8 $r3 = $r5, 0x804080408040201
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r1 = $r7, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 5)
;
; CV2-LABEL: test_shufflevector2:
; CV2:       # %bb.0:
; CV2-NEXT:    srld $r4 = $r3, 48
; CV2-NEXT:    srlw $r5 = $r3, 16
; CV2-NEXT:    srld $r6 = $r0, 32
; CV2-NEXT:    srld $r7 = $r1, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r1 = $r7, 31, 16
; CV2-NEXT:    srld $r4 = $r0, 48
; CV2-NEXT:    insf $r5 = $r4, 31, 16
; CV2-NEXT:    srld $r8 = $r1, 48
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    srld $r2 = $r2, 16
; CV2-NEXT:    insf $r4 = $r6, 31, 16
; CV2-NEXT:    srlw $r6 = $r0, 16
; CV2-NEXT:    insf $r8 = $r8, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    insf $r0 = $r6, 31, 16
; CV2-NEXT:    insf $r1 = $r8, 63, 32
; CV2-NEXT:    insf $r2 = $r3, 63, 48
; CV2-NEXT:    sbmm8 $r3 = $r5, 0x804080408040201
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r0 = $r4, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 4)
  %s = shufflevector <16 x half> %a, <16 x half> undef, <16 x i32> <i32 0, i32 1, i32 3, i32 2, i32 4, i32 6, i32 7, i32 7, i32 9, i32 10, i32 11, i32 12, i32 13, i32 15, i32 15, i32 15>
  ret <16 x half> %s
}

define <16 x half> @test_insertelement0(<16 x half> %a, half %x) #0 {
; ALL-LABEL: test_insertelement0:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r0 = $r4, 15, 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <16 x half> %a, half %x, i64 0
  ret <16 x half> %i
}

define <16 x half> @test_insertelement1(<16 x half> %a, half %x) #0 {
; ALL-LABEL: test_insertelement1:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r0 = $r4, 31, 16
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <16 x half> %a, half %x, i64 1
  ret <16 x half> %i
}

define <16 x half> @test_insertelement2(<16 x half> %a, half %x) #0 {
; ALL-LABEL: test_insertelement2:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r0 = $r4, 47, 32
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <16 x half> %a, half %x, i64 2
  ret <16 x half> %i
}

define <16 x half> @test_insertelement3(<16 x half> %a, half %x) #0 {
; ALL-LABEL: test_insertelement3:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r0 = $r4, 63, 48
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <16 x half> %a, half %x, i64 3
  ret <16 x half> %i
}

define <16 x half> @test_insertelement4(<16 x half> %a, half %x) #0 {
; ALL-LABEL: test_insertelement4:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r1 = $r4, 15, 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <16 x half> %a, half %x, i64 4
  ret <16 x half> %i
}

define <16 x half> @test_insertelement5(<16 x half> %a, half %x) #0 {
; ALL-LABEL: test_insertelement5:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r1 = $r4, 31, 16
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <16 x half> %a, half %x, i64 5
  ret <16 x half> %i
}

define <16 x half> @test_insertelement6(<16 x half> %a, half %x) #0 {
; ALL-LABEL: test_insertelement6:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r1 = $r4, 47, 32
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <16 x half> %a, half %x, i64 6
  ret <16 x half> %i
}

define <16 x half> @test_insertelement7(<16 x half> %a, half %x) #0 {
; ALL-LABEL: test_insertelement7:
; ALL:       # %bb.0:
; ALL-NEXT:    insf $r1 = $r4, 63, 48
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
  %i = insertelement <16 x half> %a, half %x, i64 7
  ret <16 x half> %i
}

define <16 x half> @test_insertelement(<16 x half> %a, half %x, i64 %p) #0 {
; ALL-LABEL: test_insertelement:
; ALL:       # %bb.0:
; ALL-NEXT:    andw $r5 = $r5, 15
; ALL-NEXT:    addd $r12 = $r12, -32
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    sq 16[$r12] = $r2r3
; ALL-NEXT:    addd $r2 = $r12, 0
; ALL-NEXT:    muluwd $r5 = $r5, 2
; ALL-NEXT:    ;; # (end cycle 1)
; ALL-NEXT:    sq 0[$r12] = $r0r1
; ALL-NEXT:    ;; # (end cycle 2)
; ALL-NEXT:    sh $r5[$r2] = $r4
; ALL-NEXT:    ;; # (end cycle 3)
; ALL-NEXT:    lq $r2r3 = 16[$r12]
; ALL-NEXT:    ;; # (end cycle 4)
; ALL-NEXT:    lq $r0r1 = 0[$r12]
; ALL-NEXT:    addd $r12 = $r12, 32
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 5)
  %i = insertelement <16 x half> %a, half %x, i64 %p
  ret <16 x half> %i
}

define <16 x i16> @fcmp_setoeq(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setoeq:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oeq $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.oeq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oeq $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.oeq $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setoeq:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oeq $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.oeq $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.oeq $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.oeq $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp oeq <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setoeq_single(<16 x half> %a) #0 {
; CV1-LABEL: fcmp_setoeq_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oeq $r2 = $r2, $r2
; CV1-NEXT:    fcompnhq.oeq $r3 = $r3, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setoeq_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.oeq $r2 = $r2, $r2
; CV2-NEXT:    fcompnhq.oeq $r3 = $r3, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp oeq <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setogt(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setogt:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.olt $r0 = $r4, $r0
; CV1-NEXT:    fcompnhq.olt $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.olt $r2 = $r6, $r2
; CV1-NEXT:    fcompnhq.olt $r3 = $r7, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setogt:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.olt $r0 = $r4, $r0
; CV2-NEXT:    fcompnhq.olt $r1 = $r5, $r1
; CV2-NEXT:    fcompnhq.olt $r2 = $r6, $r2
; CV2-NEXT:    fcompnhq.olt $r3 = $r7, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ogt <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setogt_single(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setogt_single:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = 0
; ALL-NEXT:    make $r1 = 0
; ALL-NEXT:    make $r2 = 0
; ALL-NEXT:    make $r3 = 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ogt <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setoge(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setoge:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setoge:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp oge <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setoge_single(<16 x half> %a) #0 {
; CV1-LABEL: fcmp_setoge_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oeq $r2 = $r2, $r2
; CV1-NEXT:    fcompnhq.oeq $r3 = $r3, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setoge_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.oeq $r2 = $r2, $r2
; CV2-NEXT:    fcompnhq.oeq $r3 = $r3, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp oge <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setolt(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setolt:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.olt $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.olt $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.olt $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.olt $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setolt:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.olt $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.olt $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.olt $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.olt $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp olt <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setolt_single(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setolt_single:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = 0
; ALL-NEXT:    make $r1 = 0
; ALL-NEXT:    make $r2 = 0
; ALL-NEXT:    make $r3 = 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp olt <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setole(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setole:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oge $r0 = $r4, $r0
; CV1-NEXT:    fcompnhq.oge $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oge $r2 = $r6, $r2
; CV1-NEXT:    fcompnhq.oge $r3 = $r7, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setole:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oge $r0 = $r4, $r0
; CV2-NEXT:    fcompnhq.oge $r1 = $r5, $r1
; CV2-NEXT:    fcompnhq.oge $r2 = $r6, $r2
; CV2-NEXT:    fcompnhq.oge $r3 = $r7, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ole <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setole_single(<16 x half> %a) #0 {
; CV1-LABEL: fcmp_setole_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oeq $r2 = $r2, $r2
; CV1-NEXT:    fcompnhq.oeq $r3 = $r3, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setole_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.oeq $r2 = $r2, $r2
; CV2-NEXT:    fcompnhq.oeq $r3 = $r3, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ole <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setone(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setone:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.one $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.one $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.one $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.one $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setone:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.one $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.one $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.one $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.one $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp one <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setone_single(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setone_single:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = 0
; ALL-NEXT:    make $r1 = 0
; ALL-NEXT:    make $r2 = 0
; ALL-NEXT:    make $r3 = 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp one <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setord(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setord:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.olt $r8 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    iord $r0 = $r0, $r8
; CV1-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV1-NEXT:    fcompnhq.olt $r4 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    iord $r1 = $r1, $r4
; CV1-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.olt $r5 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    iord $r2 = $r2, $r5
; CV1-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV1-NEXT:    fcompnhq.olt $r6 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    iord $r3 = $r3, $r6
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: fcmp_setord:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.olt $r4 = $r1, $r5
; CV2-NEXT:    fcompnhq.olt $r8 = $r0, $r4
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV2-NEXT:    fcompnhq.olt $r5 = $r2, $r6
; CV2-NEXT:    fcompnhq.olt $r6 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    iord $r0 = $r0, $r8
; CV2-NEXT:    iord $r1 = $r1, $r4
; CV2-NEXT:    iord $r2 = $r2, $r5
; CV2-NEXT:    iord $r3 = $r3, $r6
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp ord <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setord_single(<16 x half> %a) #0 {
; CV1-LABEL: fcmp_setord_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oeq $r2 = $r2, $r2
; CV1-NEXT:    fcompnhq.oeq $r3 = $r3, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setord_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.oeq $r2 = $r2, $r2
; CV2-NEXT:    fcompnhq.oeq $r3 = $r3, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ord <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setuno(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setuno:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.ult $r8 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r8
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r5
; CV1-NEXT:    fcompnhq.ult $r4 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r4
; CV1-NEXT:    fcompnhq.uge $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.ult $r5 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    andd $r2 = $r2, $r5
; CV1-NEXT:    fcompnhq.uge $r3 = $r3, $r7
; CV1-NEXT:    fcompnhq.ult $r6 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    andd $r3 = $r3, $r6
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: fcmp_setuno:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.ult $r4 = $r1, $r5
; CV2-NEXT:    fcompnhq.ult $r8 = $r0, $r4
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompnhq.uge $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.uge $r3 = $r3, $r7
; CV2-NEXT:    fcompnhq.ult $r5 = $r2, $r6
; CV2-NEXT:    fcompnhq.ult $r6 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    andd $r0 = $r0, $r8
; CV2-NEXT:    andd $r1 = $r1, $r4
; CV2-NEXT:    andd $r2 = $r2, $r5
; CV2-NEXT:    andd $r3 = $r3, $r6
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp uno <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setuno_single(<16 x half> %a) #0 {
; CV1-LABEL: fcmp_setuno_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.ult $r4 = $r0, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV1-NEXT:    fcompnhq.ult $r5 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r5
; CV1-NEXT:    fcompnhq.uge $r2 = $r2, $r2
; CV1-NEXT:    fcompnhq.ult $r6 = $r2, $r2
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    andd $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.uge $r3 = $r3, $r3
; CV1-NEXT:    fcompnhq.ult $r7 = $r3, $r3
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    andd $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: fcmp_setuno_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.ult $r4 = $r0, $r0
; CV2-NEXT:    fcompnhq.ult $r5 = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompnhq.uge $r2 = $r2, $r2
; CV2-NEXT:    fcompnhq.uge $r3 = $r3, $r3
; CV2-NEXT:    fcompnhq.ult $r6 = $r2, $r2
; CV2-NEXT:    fcompnhq.ult $r7 = $r3, $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    andd $r0 = $r0, $r4
; CV2-NEXT:    andd $r1 = $r1, $r5
; CV2-NEXT:    andd $r2 = $r2, $r6
; CV2-NEXT:    andd $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp uno <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setueq(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setueq:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.ueq $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.ueq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.ueq $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.ueq $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setueq:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.ueq $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.ueq $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.ueq $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.ueq $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ueq <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setueq_single(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setueq_single:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = -1
; ALL-NEXT:    make $r1 = -1
; ALL-NEXT:    make $r2 = -1
; ALL-NEXT:    make $r3 = -1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ueq <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setugt(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setugt:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.ult $r0 = $r4, $r0
; CV1-NEXT:    fcompnhq.ult $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.ult $r2 = $r6, $r2
; CV1-NEXT:    fcompnhq.ult $r3 = $r7, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setugt:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.ult $r0 = $r4, $r0
; CV2-NEXT:    fcompnhq.ult $r1 = $r5, $r1
; CV2-NEXT:    fcompnhq.ult $r2 = $r6, $r2
; CV2-NEXT:    fcompnhq.ult $r3 = $r7, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ugt <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setugt_single(<16 x half> %a) #0 {
; CV1-LABEL: fcmp_setugt_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.ult $r4 = $r0, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV1-NEXT:    fcompnhq.ult $r5 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r5
; CV1-NEXT:    fcompnhq.uge $r2 = $r2, $r2
; CV1-NEXT:    fcompnhq.ult $r6 = $r2, $r2
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    andd $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.uge $r3 = $r3, $r3
; CV1-NEXT:    fcompnhq.ult $r7 = $r3, $r3
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    andd $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: fcmp_setugt_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.ult $r4 = $r0, $r0
; CV2-NEXT:    fcompnhq.ult $r5 = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompnhq.uge $r2 = $r2, $r2
; CV2-NEXT:    fcompnhq.uge $r3 = $r3, $r3
; CV2-NEXT:    fcompnhq.ult $r6 = $r2, $r2
; CV2-NEXT:    fcompnhq.ult $r7 = $r3, $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    andd $r0 = $r0, $r4
; CV2-NEXT:    andd $r1 = $r1, $r5
; CV2-NEXT:    andd $r2 = $r2, $r6
; CV2-NEXT:    andd $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp ugt <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setuge(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setuge:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.uge $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.uge $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setuge:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.uge $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.uge $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp uge <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setuge_single(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setuge_single:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = -1
; ALL-NEXT:    make $r1 = -1
; ALL-NEXT:    make $r2 = -1
; ALL-NEXT:    make $r3 = -1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp uge <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setult(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setult:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.ult $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.ult $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.ult $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.ult $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setult:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.ult $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.ult $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.ult $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.ult $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ult <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setult_single(<16 x half> %a) #0 {
; CV1-LABEL: fcmp_setult_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.ult $r4 = $r0, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV1-NEXT:    fcompnhq.ult $r5 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r5
; CV1-NEXT:    fcompnhq.uge $r2 = $r2, $r2
; CV1-NEXT:    fcompnhq.ult $r6 = $r2, $r2
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    andd $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.uge $r3 = $r3, $r3
; CV1-NEXT:    fcompnhq.ult $r7 = $r3, $r3
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    andd $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: fcmp_setult_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.ult $r4 = $r0, $r0
; CV2-NEXT:    fcompnhq.ult $r5 = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompnhq.uge $r2 = $r2, $r2
; CV2-NEXT:    fcompnhq.uge $r3 = $r3, $r3
; CV2-NEXT:    fcompnhq.ult $r6 = $r2, $r2
; CV2-NEXT:    fcompnhq.ult $r7 = $r3, $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    andd $r0 = $r0, $r4
; CV2-NEXT:    andd $r1 = $r1, $r5
; CV2-NEXT:    andd $r2 = $r2, $r6
; CV2-NEXT:    andd $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp ult <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setule(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setule:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r4, $r0
; CV1-NEXT:    fcompnhq.uge $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.uge $r2 = $r6, $r2
; CV1-NEXT:    fcompnhq.uge $r3 = $r7, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setule:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r4, $r0
; CV2-NEXT:    fcompnhq.uge $r1 = $r5, $r1
; CV2-NEXT:    fcompnhq.uge $r2 = $r6, $r2
; CV2-NEXT:    fcompnhq.uge $r3 = $r7, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ule <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setule_single(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setule_single:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = -1
; ALL-NEXT:    make $r1 = -1
; ALL-NEXT:    make $r2 = -1
; ALL-NEXT:    make $r3 = -1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp ule <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setune(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setune:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.une $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.une $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.une $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.une $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setune:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.une $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.une $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.une $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.une $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp une <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setune_single(<16 x half> %a) #0 {
; CV1-LABEL: fcmp_setune_single:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.ult $r4 = $r0, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV1-NEXT:    fcompnhq.ult $r5 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r5
; CV1-NEXT:    fcompnhq.uge $r2 = $r2, $r2
; CV1-NEXT:    fcompnhq.ult $r6 = $r2, $r2
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    andd $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.uge $r3 = $r3, $r3
; CV1-NEXT:    fcompnhq.ult $r7 = $r3, $r3
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    andd $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: fcmp_setune_single:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.ult $r4 = $r0, $r0
; CV2-NEXT:    fcompnhq.ult $r5 = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompnhq.uge $r2 = $r2, $r2
; CV2-NEXT:    fcompnhq.uge $r3 = $r3, $r3
; CV2-NEXT:    fcompnhq.ult $r6 = $r2, $r2
; CV2-NEXT:    fcompnhq.ult $r7 = $r3, $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    andd $r0 = $r0, $r4
; CV2-NEXT:    andd $r1 = $r1, $r5
; CV2-NEXT:    andd $r2 = $r2, $r6
; CV2-NEXT:    andd $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp une <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setoeq_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setoeq_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oeq $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.oeq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oeq $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.oeq $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setoeq_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oeq $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.oeq $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.oeq $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.oeq $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast oeq <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setoeq_single_fast(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setoeq_single_fast:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = -1
; ALL-NEXT:    make $r1 = -1
; ALL-NEXT:    make $r2 = -1
; ALL-NEXT:    make $r3 = -1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast oeq <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setogt_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setogt_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.olt $r0 = $r4, $r0
; CV1-NEXT:    fcompnhq.olt $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.olt $r2 = $r6, $r2
; CV1-NEXT:    fcompnhq.olt $r3 = $r7, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setogt_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.olt $r0 = $r4, $r0
; CV2-NEXT:    fcompnhq.olt $r1 = $r5, $r1
; CV2-NEXT:    fcompnhq.olt $r2 = $r6, $r2
; CV2-NEXT:    fcompnhq.olt $r3 = $r7, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ogt <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setogt_single_fast(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setogt_single_fast:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = 0
; ALL-NEXT:    make $r1 = 0
; ALL-NEXT:    make $r2 = 0
; ALL-NEXT:    make $r3 = 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ogt <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setoge_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setoge_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setoge_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast oge <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setoge_single_fast(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setoge_single_fast:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = -1
; ALL-NEXT:    make $r1 = -1
; ALL-NEXT:    make $r2 = -1
; ALL-NEXT:    make $r3 = -1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast oge <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setolt_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setolt_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.olt $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.olt $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.olt $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.olt $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setolt_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.olt $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.olt $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.olt $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.olt $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast olt <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setolt_single_fast(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setolt_single_fast:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = 0
; ALL-NEXT:    make $r1 = 0
; ALL-NEXT:    make $r2 = 0
; ALL-NEXT:    make $r3 = 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast olt <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setole_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setole_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oge $r0 = $r4, $r0
; CV1-NEXT:    fcompnhq.oge $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oge $r2 = $r6, $r2
; CV1-NEXT:    fcompnhq.oge $r3 = $r7, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setole_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oge $r0 = $r4, $r0
; CV2-NEXT:    fcompnhq.oge $r1 = $r5, $r1
; CV2-NEXT:    fcompnhq.oge $r2 = $r6, $r2
; CV2-NEXT:    fcompnhq.oge $r3 = $r7, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ole <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setole_single_fast(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setole_single_fast:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = -1
; ALL-NEXT:    make $r1 = -1
; ALL-NEXT:    make $r2 = -1
; ALL-NEXT:    make $r3 = -1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ole <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setone_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setone_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.one $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.one $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.one $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.one $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setone_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.one $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.one $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.one $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.one $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast one <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setone_single_fast(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setone_single_fast:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = 0
; ALL-NEXT:    make $r1 = 0
; ALL-NEXT:    make $r2 = 0
; ALL-NEXT:    make $r3 = 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast one <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setord_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setord_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.olt $r8 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    iord $r0 = $r0, $r8
; CV1-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV1-NEXT:    fcompnhq.olt $r4 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    iord $r1 = $r1, $r4
; CV1-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.olt $r5 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    iord $r2 = $r2, $r5
; CV1-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV1-NEXT:    fcompnhq.olt $r6 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    iord $r3 = $r3, $r6
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: fcmp_setord_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.olt $r4 = $r1, $r5
; CV2-NEXT:    fcompnhq.olt $r8 = $r0, $r4
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV2-NEXT:    fcompnhq.olt $r5 = $r2, $r6
; CV2-NEXT:    fcompnhq.olt $r6 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    iord $r0 = $r0, $r8
; CV2-NEXT:    iord $r1 = $r1, $r4
; CV2-NEXT:    iord $r2 = $r2, $r5
; CV2-NEXT:    iord $r3 = $r3, $r6
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast ord <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setord_single_fast(<16 x half> %a) #0 {
; CV1-LABEL: fcmp_setord_single_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oeq $r2 = $r2, $r2
; CV1-NEXT:    fcompnhq.oeq $r3 = $r3, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setord_single_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oeq $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.oeq $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.oeq $r2 = $r2, $r2
; CV2-NEXT:    fcompnhq.oeq $r3 = $r3, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ord <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setuno_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setuno_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.ult $r8 = $r0, $r4
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r8
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r5
; CV1-NEXT:    fcompnhq.ult $r4 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r4
; CV1-NEXT:    fcompnhq.uge $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.ult $r5 = $r2, $r6
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    andd $r2 = $r2, $r5
; CV1-NEXT:    fcompnhq.uge $r3 = $r3, $r7
; CV1-NEXT:    fcompnhq.ult $r6 = $r3, $r7
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    andd $r3 = $r3, $r6
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: fcmp_setuno_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.ult $r4 = $r1, $r5
; CV2-NEXT:    fcompnhq.ult $r8 = $r0, $r4
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompnhq.uge $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.uge $r3 = $r3, $r7
; CV2-NEXT:    fcompnhq.ult $r5 = $r2, $r6
; CV2-NEXT:    fcompnhq.ult $r6 = $r3, $r7
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    andd $r0 = $r0, $r8
; CV2-NEXT:    andd $r1 = $r1, $r4
; CV2-NEXT:    andd $r2 = $r2, $r5
; CV2-NEXT:    andd $r3 = $r3, $r6
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast uno <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setuno_single_fast(<16 x half> %a) #0 {
; CV1-LABEL: fcmp_setuno_single_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV1-NEXT:    fcompnhq.ult $r4 = $r0, $r0
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    andd $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV1-NEXT:    fcompnhq.ult $r5 = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andd $r1 = $r1, $r5
; CV1-NEXT:    fcompnhq.uge $r2 = $r2, $r2
; CV1-NEXT:    fcompnhq.ult $r6 = $r2, $r2
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    andd $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.uge $r3 = $r3, $r3
; CV1-NEXT:    fcompnhq.ult $r7 = $r3, $r3
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    andd $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 4)
;
; CV2-LABEL: fcmp_setuno_single_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.uge $r0 = $r0, $r0
; CV2-NEXT:    fcompnhq.uge $r1 = $r1, $r1
; CV2-NEXT:    fcompnhq.ult $r4 = $r0, $r0
; CV2-NEXT:    fcompnhq.ult $r5 = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompnhq.uge $r2 = $r2, $r2
; CV2-NEXT:    fcompnhq.uge $r3 = $r3, $r3
; CV2-NEXT:    fcompnhq.ult $r6 = $r2, $r2
; CV2-NEXT:    fcompnhq.ult $r7 = $r3, $r3
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    andd $r0 = $r0, $r4
; CV2-NEXT:    andd $r1 = $r1, $r5
; CV2-NEXT:    andd $r2 = $r2, $r6
; CV2-NEXT:    andd $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 2)
entry:
  %0 = fcmp fast uno <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setueq_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setueq_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oeq $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.oeq $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oeq $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.oeq $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setueq_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oeq $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.oeq $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.oeq $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.oeq $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ueq <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setueq_single_fast(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setueq_single_fast:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = -1
; ALL-NEXT:    make $r1 = -1
; ALL-NEXT:    make $r2 = -1
; ALL-NEXT:    make $r3 = -1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ueq <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setugt_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setugt_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.olt $r0 = $r4, $r0
; CV1-NEXT:    fcompnhq.olt $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.olt $r2 = $r6, $r2
; CV1-NEXT:    fcompnhq.olt $r3 = $r7, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setugt_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.olt $r0 = $r4, $r0
; CV2-NEXT:    fcompnhq.olt $r1 = $r5, $r1
; CV2-NEXT:    fcompnhq.olt $r2 = $r6, $r2
; CV2-NEXT:    fcompnhq.olt $r3 = $r7, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ugt <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setugt_single_fast(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setugt_single_fast:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = 0
; ALL-NEXT:    make $r1 = 0
; ALL-NEXT:    make $r2 = 0
; ALL-NEXT:    make $r3 = 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ugt <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setuge_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setuge_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setuge_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oge $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.oge $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.oge $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.oge $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast uge <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setuge_single_fast(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setuge_single_fast:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = -1
; ALL-NEXT:    make $r1 = -1
; ALL-NEXT:    make $r2 = -1
; ALL-NEXT:    make $r3 = -1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast uge <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setult_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setult_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.olt $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.olt $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.olt $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.olt $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setult_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.olt $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.olt $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.olt $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.olt $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ult <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setult_single_fast(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setult_single_fast:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = 0
; ALL-NEXT:    make $r1 = 0
; ALL-NEXT:    make $r2 = 0
; ALL-NEXT:    make $r3 = 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ult <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setule_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setule_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.oge $r0 = $r4, $r0
; CV1-NEXT:    fcompnhq.oge $r1 = $r5, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.oge $r2 = $r6, $r2
; CV1-NEXT:    fcompnhq.oge $r3 = $r7, $r3
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setule_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.oge $r0 = $r4, $r0
; CV2-NEXT:    fcompnhq.oge $r1 = $r5, $r1
; CV2-NEXT:    fcompnhq.oge $r2 = $r6, $r2
; CV2-NEXT:    fcompnhq.oge $r3 = $r7, $r3
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ule <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setule_single_fast(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setule_single_fast:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = -1
; ALL-NEXT:    make $r1 = -1
; ALL-NEXT:    make $r2 = -1
; ALL-NEXT:    make $r3 = -1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast ule <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setune_fast(<16 x half> %a, <16 x half> %b) #0 {
; CV1-LABEL: fcmp_setune_fast:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.one $r0 = $r0, $r4
; CV1-NEXT:    fcompnhq.one $r1 = $r1, $r5
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    fcompnhq.one $r2 = $r2, $r6
; CV1-NEXT:    fcompnhq.one $r3 = $r3, $r7
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 1)
;
; CV2-LABEL: fcmp_setune_fast:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    fcompnhq.one $r0 = $r0, $r4
; CV2-NEXT:    fcompnhq.one $r1 = $r1, $r5
; CV2-NEXT:    fcompnhq.one $r2 = $r2, $r6
; CV2-NEXT:    fcompnhq.one $r3 = $r3, $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast une <16 x half> %a, %b
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define <16 x i16> @fcmp_setune_single_fast(<16 x half> %a) #0 {
; ALL-LABEL: fcmp_setune_single_fast:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    make $r0 = 0
; ALL-NEXT:    make $r1 = 0
; ALL-NEXT:    make $r2 = 0
; ALL-NEXT:    make $r3 = 0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %0 = fcmp fast une <16 x half> %a, %a
  %1 = sext <16 x i1> %0 to <16 x i16>
  ret <16 x i16> %1
}

define float @fwidenmhw(<16 x half> %v) #0 {
; ALL-LABEL: fwidenmhw:
; ALL:       # %bb.0: # %entry
; ALL-NEXT:    fwidenmhw $r0 = $r0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 0)
entry:
  %vecext = extractelement <16 x half> %v, i32 1
  %conv = fpext half %vecext to float
  ret float %conv
}

define <16 x half> @concat (<8 x half> %a, <8 x half> %b) #0 {
; ALL-LABEL: concat:
; ALL:       # %bb.0:
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %v = shufflevector <8 x half> %a, <8 x half> %b, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  ret <16 x half> %v
}

attributes #0 = { nounwind }

define <16 x half> @select_shufflehx_2(<16 x half> %0, half %1, i32 %2) {
; CV1-LABEL: select_shufflehx_2:
; CV1:       # %bb.0:
; CV1-NEXT:    cb.weqz $r5 ? .LBB150_2
; CV1-NEXT:    ;;
; CV1-NEXT:  # %bb.1:
; CV1-NEXT:    extfz $r0 = $r0, 47, 32
; CV1-NEXT:    srld $r5 = $r0, 48
; CV1-NEXT:    extfz $r6 = $r1, 47, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    insf $r0 = $r5, 31, 16
; CV1-NEXT:    insf $r4 = $r0, 31, 16
; CV1-NEXT:    srld $r5 = $r1, 48
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    srlw $r0 = $r1, 16
; CV1-NEXT:    insf $r4 = $r0, 63, 32
; CV1-NEXT:    insf $r6 = $r5, 31, 16
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    copyd $r0 = $r4
; CV1-NEXT:    insf $r1 = $r0, 31, 16
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    insf $r1 = $r6, 63, 32
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:  .LBB150_2:
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: select_shufflehx_2:
; CV2:       # %bb.0:
; CV2-NEXT:    cb.weqz $r5 ? .LBB150_2
; CV2-NEXT:    ;;
; CV2-NEXT:  # %bb.1:
; CV2-NEXT:    extfz $r0 = $r0, 47, 32
; CV2-NEXT:    insf $r4 = $r0, 31, 16
; CV2-NEXT:    srld $r5 = $r0, 48
; CV2-NEXT:    extfz $r6 = $r1, 47, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    insf $r0 = $r5, 31, 16
; CV2-NEXT:    srld $r5 = $r1, 48
; CV2-NEXT:    srlw $r7 = $r1, 16
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    insf $r1 = $r7, 31, 16
; CV2-NEXT:    insf $r4 = $r0, 63, 32
; CV2-NEXT:    insf $r6 = $r5, 31, 16
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    copyd $r0 = $r4
; CV2-NEXT:    insf $r1 = $r6, 63, 32
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:  .LBB150_2:
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %4 = icmp eq i32 %2, 0
  br i1 %4, label %8, label %5

5:
  %6 = insertelement <16 x half> undef, half %1, i64 0
  %7 = shufflevector <16 x half> %6, <16 x half> %0, <16 x i32> <i32 0, i32 1, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30, i32 31>
  br label %8

8:
  %9 = phi <16 x half> [ %7, %5 ], [ %0, %3 ]
  ret <16 x half> %9
}

define <16 x half> @test_select_cmp(<16 x half> %a, <16 x half> %b, <16 x half> %c, <16 x half> %d) #0 {
; CV1-LABEL: test_select_cmp:
; CV1:       # %bb.0:
; CV1-NEXT:    ld $r15 = 0[$r12]
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    ld $r16 = 8[$r12]
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    ld $r17 = 16[$r12]
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    fcompnhq.une $r8 = $r8, $r15
; CV1-NEXT:    ld $r32 = 24[$r12]
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    fcompnhq.une $r9 = $r9, $r16
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    andd $r8 = $r8, $r9
; CV1-NEXT:    fcompnhq.une $r10 = $r10, $r17
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    andd $r8 = $r8, $r10
; CV1-NEXT:    fcompnhq.une $r9 = $r11, $r32
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    andd $r8 = $r8, $r9
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    compd.eq $r8 = $r8, -1
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    cmoved.even $r8 ? $r2 = $r6
; CV1-NEXT:    cmoved.even $r8 ? $r3 = $r7
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    cmoved.even $r8 ? $r0 = $r4
; CV1-NEXT:    cmoved.even $r8 ? $r1 = $r5
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 10)
;
; CV2-LABEL: test_select_cmp:
; CV2:       # %bb.0:
; CV2-NEXT:    ld $r15 = 0[$r12]
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    ld $r16 = 8[$r12]
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    ld $r17 = 16[$r12]
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    fcompnhq.une $r8 = $r8, $r15
; CV2-NEXT:    ld $r32 = 24[$r12]
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    fcompnhq.une $r9 = $r9, $r16
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    andd $r8 = $r8, $r9
; CV2-NEXT:    fcompnhq.une $r10 = $r10, $r17
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    andd $r8 = $r8, $r10
; CV2-NEXT:    fcompnhq.une $r9 = $r11, $r32
; CV2-NEXT:    ;; # (end cycle 6)
; CV2-NEXT:    andd $r8 = $r8, $r9
; CV2-NEXT:    ;; # (end cycle 7)
; CV2-NEXT:    compd.eq $r8 = $r8, -1
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    cmoved.even $r8 ? $r0 = $r4
; CV2-NEXT:    cmoved.even $r8 ? $r1 = $r5
; CV2-NEXT:    cmoved.even $r8 ? $r2 = $r6
; CV2-NEXT:    cmoved.even $r8 ? $r3 = $r7
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 9)
  %cc = fcmp une <16 x half> %c, %d
  %bc = bitcast <16 x i1> %cc to i16
  %cmp = icmp eq i16 %bc, -1
  %r = select i1 %cmp, <16 x half> %a, <16 x half> %b
  ret <16 x half> %r
}
