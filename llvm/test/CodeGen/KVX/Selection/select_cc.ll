; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O2 -mcpu=kv3-1 -o - %s | FileCheck --check-prefixes=CHECK,CV1 %s
; RUN: llc -O2 -mcpu=kv3-2 -o - %s | FileCheck --check-prefixes=CHECK,CV2 %s
; RUN: clang -O2 -c -o /dev/null %s
; RUN: clang -O2 -march=kv3-2 -c -o /dev/null %s

; Assembly broken, cf T19977

target triple = "kvx-kalray-cos"

define i32 @f(i32 %a){
; CHECK-LABEL: f:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    make $r1 = 7
; CHECK-NEXT:    make $r2 = 5
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    cmoved.wgtz $r0 ? $r1 = $r2
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
entry:
  %cmp = icmp sgt i32 %a, 0
  %cond = select i1 %cmp, i32 5, i32 7
  ret i32 %cond
}

define i32 @f_select_cc_i32(i32 %c, i32 %c2, i32 %a, i32 %b){
; CHECK-LABEL: f_select_cc_i32:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    compw.gt $r0 = $r0, $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    cmoved.wnez $r0 ? $r3 = $r2
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    copyd $r0 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
entry:
  %cmp = icmp sgt i32 %c, %c2
  %cond = select i1 %cmp, i32 %a, i32 %b
  ret i32 %cond
}

define i32 @f_select_cc_i64(i64 %c, i64 %c2, i32 %a, i32 %b){
; CHECK-LABEL: f_select_cc_i64:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    compd.gt $r0 = $r0, $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    cmoved.wnez $r0 ? $r3 = $r2
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    copyd $r0 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
entry:
  %cmp = icmp sgt i64 %c, %c2
  %cond = select i1 %cmp, i32 %a, i32 %b
  ret i32 %cond
}

define <4 x half> @f_Select32PAT(<4 x half> %x, <4 x half> %y){
; CV1-LABEL: f_Select32PAT:
; CV1:       # %bb.0: # %entry
; CV1-NEXT:    fcompnhq.olt $r2 = $r0, $r1
; CV1-NEXT:    srlw $r3 = $r0, 16
; CV1-NEXT:    srlw $r4 = $r1, 16
; CV1-NEXT:    srld $r5 = $r0, 32
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    srld $r6 = $r0, 48
; CV1-NEXT:    fcompnhq.olt $r7 = $r3, $r4
; CV1-NEXT:    srld $r8 = $r1, 32
; CV1-NEXT:    srld $r9 = $r1, 48
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    andw $r2 = $r2, 1
; CV1-NEXT:    andw $r7 = $r7, 1
; CV1-NEXT:    fcompnhq.olt $r10 = $r5, $r8
; CV1-NEXT:    fcompnhq.olt $r11 = $r6, $r9
; CV1-NEXT:    ;; # (end cycle 2)
; CV1-NEXT:    cmoved.wnez $r2 ? $r0 = $r1
; CV1-NEXT:    andw $r1 = $r10, 1
; CV1-NEXT:    andw $r2 = $r11, 1
; CV1-NEXT:    cmoved.wnez $r7 ? $r3 = $r4
; CV1-NEXT:    ;; # (end cycle 3)
; CV1-NEXT:    cmoved.wnez $r1 ? $r5 = $r8
; CV1-NEXT:    cmoved.wnez $r2 ? $r6 = $r9
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    insf $r0 = $r3, 31, 16
; CV1-NEXT:    insf $r5 = $r6, 31, 16
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    insf $r0 = $r5, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 6)
;
; CV2-LABEL: f_Select32PAT:
; CV2:       # %bb.0: # %entry
; CV2-NEXT:    srlw $r3 = $r0, 16
; CV2-NEXT:    srlw $r4 = $r1, 16
; CV2-NEXT:    srld $r5 = $r0, 32
; CV2-NEXT:    srld $r6 = $r1, 32
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    fcompnhq.olt $r2 = $r0, $r1
; CV2-NEXT:    srld $r7 = $r0, 48
; CV2-NEXT:    srld $r8 = $r1, 48
; CV2-NEXT:    fcompnhq.olt $r9 = $r3, $r4
; CV2-NEXT:    ;; # (end cycle 1)
; CV2-NEXT:    andw $r2 = $r2, 1
; CV2-NEXT:    andw $r9 = $r9, 1
; CV2-NEXT:    fcompnhq.olt $r10 = $r5, $r6
; CV2-NEXT:    fcompnhq.olt $r11 = $r7, $r8
; CV2-NEXT:    ;; # (end cycle 2)
; CV2-NEXT:    cmoved.wnez $r2 ? $r0 = $r1
; CV2-NEXT:    cmoved.wnez $r9 ? $r3 = $r4
; CV2-NEXT:    andw $r10 = $r10, 1
; CV2-NEXT:    andw $r11 = $r11, 1
; CV2-NEXT:    ;; # (end cycle 3)
; CV2-NEXT:    insf $r0 = $r3, 31, 16
; CV2-NEXT:    cmoved.wnez $r10 ? $r5 = $r6
; CV2-NEXT:    cmoved.wnez $r11 ? $r7 = $r8
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    insf $r5 = $r7, 31, 16
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    insf $r0 = $r5, 63, 32
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 6)
entry:
  %vecext = extractelement <4 x half> %x, i32 0
  %vecext1 = extractelement <4 x half> %y, i32 0
  %cmp = fcmp olt half %vecext, %vecext1
  %cond = select i1 %cmp, half %vecext1, half %vecext
  %vecins = insertelement <4 x half> undef, half %cond, i32 0
  %vecext4 = extractelement <4 x half> %x, i32 1
  %vecext5 = extractelement <4 x half> %y, i32 1
  %cmp6 = fcmp olt half %vecext4, %vecext5
  %cond12 = select i1 %cmp6, half %vecext5, half %vecext4
  %vecins13 = insertelement <4 x half> %vecins, half %cond12, i32 1
  %vecext14 = extractelement <4 x half> %x, i32 2
  %vecext15 = extractelement <4 x half> %y, i32 2
  %cmp16 = fcmp olt half %vecext14, %vecext15
  %cond22 = select i1 %cmp16, half %vecext15, half %vecext14
  %vecins23 = insertelement <4 x half> %vecins13, half %cond22, i32 2
  %vecext24 = extractelement <4 x half> %x, i32 3
  %vecext25 = extractelement <4 x half> %y, i32 3
  %cmp26 = fcmp olt half %vecext24, %vecext25
  %cond32 = select i1 %cmp26, half %vecext25, half %vecext24
  %vecins33 = insertelement <4 x half> %vecins23, half %cond32, i32 3
  ret <4 x half> %vecins33
}

define half @f_Select64PAT(i64 %c, half %a, half %b){
; CHECK-LABEL: f_Select64PAT:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    cmoved.deqz $r0 ? $r2 = $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
entry:
  %cmp = icmp eq i64 %c, 0
  %cond = select i1 %cmp, half %a, half %b
  ret half %cond
}

define <2 x float> @f_select_cc_v2f32(i32 %c, i32 %c2, <2 x float> %a, <2 x float> %b){
; CHECK-LABEL: f_select_cc_v2f32:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    compw.gt $r0 = $r0, $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    cmoved.even $r0 ? $r2 = $r3
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 2)
entry:
  %cmp = icmp sgt i32 %c, %c2
  %cond = select i1 %cmp, <2 x float> %a, <2 x float> %b
  ret <2 x float> %cond
}

; Fixme: Do select for tca v2
; define void @test_select_vector_reg(ptr %V, i1 %cc){
;   %v0 = load volatile <256 x i1>, ptr %V, align 32
;   %v1 = load volatile <256 x i1>, ptr %V, align 32
;   %v3 = select i1 %cc, <256 x i1> %v0, <256 x i1> %v1
;   store volatile <256 x i1> %v3, ptr %V, align 32
;   ret void
; }

; define void @test_select_wide_reg(ptr %V, i1 %cc){
;   %v0 = load volatile <512 x i1>, ptr %V, align 32
;   %v1 = load volatile <512 x i1>, ptr %V, align 32
;   %v3 = select i1 %cc, <512 x i1> %v0, <512 x i1> %v1
;   store volatile <512 x i1> %v3, ptr %V, align 32
;   ret void
; }

; define void @test_select_matrix_reg(ptr %V, i1 %cc){
;   %v0 = load volatile <1024 x i1>, ptr %V, align 32
;   %v1 = load volatile <1024 x i1>, ptr %V, align 32
;   %v3 = select i1 %cc, <1024 x i1> %v0, <1024 x i1> %v1
;   store volatile <1024 x i1> %v3, ptr %V, align 32
;   ret void
; }
