; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mcpu=kv3-1 -O2 -o - %s | FileCheck %s --check-prefixes=ALL,CV1
; RUN: llc -mcpu=kv3-2 -O2 -o - %s | FileCheck %s --check-prefixes=ALL,CV2
; RUN: clang -O2 -c -o /dev/null %s
; RUN: clang -O2 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define <2 x i8> @srs_v2i8(<2 x i8> %0) {
; CV1-LABEL: srs_v2i8:
; CV1:       # %bb.0:
; CV1-NEXT:    sxlbhq $r0 = $r0
; CV1-NEXT:    extfz $r1 = $r0, 15, 8
; CV1-NEXT:    zxbd $r2 = $r0
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r1 = $r1, 14, 11
; CV1-NEXT:    extfz $r2 = $r2, 14, 11
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r2 = $r1, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxlbhq $r1 = $r2
; CV1-NEXT:    ;;
; CV1-NEXT:    addhq $r0 = $r0, $r1
; CV1-NEXT:    ;;
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x401
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    extfz $r1 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r0 = $r0
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r0 = $r0, 4
; CV1-NEXT:    sraw $r1 = $r1, 4
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r1, 15, 8
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: srs_v2i8:
; CV2:       # %bb.0:
; CV2-NEXT:    srsbos $r0 = $r0, 4
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %2 = sdiv <2 x i8> %0, <i8 16, i8 16>
  ret <2 x i8> %2
}

define <4 x i8> @srs_v4i8(<4 x i8> %0) {
; CV1-LABEL: srs_v4i8:
; CV1:       # %bb.0:
; CV1-NEXT:    srlw $r1 = $r0, 24
; CV1-NEXT:    extfz $r2 = $r0, 23, 16
; CV1-NEXT:    extfz $r3 = $r0, 15, 8
; CV1-NEXT:    zxbd $r4 = $r0
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r1 = $r1, 14, 11
; CV1-NEXT:    extfz $r2 = $r2, 14, 11
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r3 = $r3, 14, 11
; CV1-NEXT:    extfz $r4 = $r4, 14, 11
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r2 = $r1, 15, 8
; CV1-NEXT:    insf $r4 = $r3, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxlbhq $r0 = $r0
; CV1-NEXT:    insf $r4 = $r2, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    sxlbhq $r1 = $r4
; CV1-NEXT:    ;;
; CV1-NEXT:    addhq $r0 = $r0, $r1
; CV1-NEXT:    ;;
; CV1-NEXT:    sbmm8 $r0 = $r0, 0x40100401
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    srlw $r1 = $r0, 24
; CV1-NEXT:    extfz $r2 = $r0, 23, 16
; CV1-NEXT:    extfz $r3 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r0 = $r0
; CV1-NEXT:    sraw $r1 = $r1, 4
; CV1-NEXT:    sraw $r2 = $r2, 4
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r0 = $r0, 4
; CV1-NEXT:    insf $r2 = $r1, 15, 8
; CV1-NEXT:    sraw $r3 = $r3, 4
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r3, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r2, 31, 16
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: srs_v4i8:
; CV2:       # %bb.0:
; CV2-NEXT:    srsbos $r0 = $r0, 4
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %2 = sdiv <4 x i8> %0, <i8 16, i8 16, i8 16, i8 16>
  ret <4 x i8> %2
}

define <8 x i8> @srs_v8i8(<8 x i8> %0) {
; CV1-LABEL: srs_v8i8:
; CV1:       # %bb.0:
; CV1-NEXT:    srld $r1 = $r0, 56
; CV1-NEXT:    extfz $r2 = $r0, 55, 48
; CV1-NEXT:    extfz $r3 = $r0, 47, 40
; CV1-NEXT:    zxbd $r5 = $r0
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    extfz $r4 = $r0, 39, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r1 = $r1, 7
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r2 = $r2, 7
; CV1-NEXT:    sraw $r3 = $r3, 7
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    extfz $r6 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r1 = $r0, 24
; CV1-NEXT:    insf $r2 = $r1, 15, 8
; CV1-NEXT:    sraw $r4 = $r4, 7
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r3 = $r0, 23, 16
; CV1-NEXT:    insf $r4 = $r3, 15, 8
; CV1-NEXT:    sraw $r6 = $r6, 7
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r1 = $r1, 7
; CV1-NEXT:    sraw $r3 = $r3, 7
; CV1-NEXT:    insf $r4 = $r2, 31, 16
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    ;;
; CV1-NEXT:    make $r2 = 4
; CV1-NEXT:    insf $r3 = $r1, 15, 8
; CV1-NEXT:    sraw $r5 = $r5, 7
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r5 = $r6, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r5 = $r3, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r5 = $r4, 63, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r1 = $r5, 0xff00ff00ff00ff
; CV1-NEXT:    andd $r3 = $r5, 0xff00ff00ff00ff00
; CV1-NEXT:    ;;
; CV1-NEXT:    srld $r1 = $r1, $r2
; CV1-NEXT:    srld $r2 = $r3, $r2
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r1 = $r1, 0xff00ff00ff00ff
; CV1-NEXT:    andd $r2 = $r2, 0xff00ff00ff00ff00
; CV1-NEXT:    ;;
; CV1-NEXT:    ord $r1 = $r2, $r1
; CV1-NEXT:    andd $r2 = $r0, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    ;;
; CV1-NEXT:    xord $r0 = $r0, $r1
; CV1-NEXT:    andd $r3 = $r1, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CV1-NEXT:    addd $r1 = $r2, $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    xord $r0 = $r1, $r0
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r1 = $r0, 55, 48
; CV1-NEXT:    srld $r2 = $r0, 56
; CV1-NEXT:    extfz $r3 = $r0, 47, 40
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    extfz $r4 = $r0, 39, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    sraw $r2 = $r2, 4
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r1 = $r1, 4
; CV1-NEXT:    sraw $r3 = $r3, 4
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    extfz $r5 = $r0, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r1 = $r2, 15, 8
; CV1-NEXT:    srlw $r2 = $r0, 24
; CV1-NEXT:    sraw $r4 = $r4, 4
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    extfz $r3 = $r0, 15, 8
; CV1-NEXT:    insf $r4 = $r3, 15, 8
; CV1-NEXT:    sraw $r5 = $r5, 4
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r0 = $r0
; CV1-NEXT:    sraw $r2 = $r2, 4
; CV1-NEXT:    sraw $r3 = $r3, 4
; CV1-NEXT:    insf $r4 = $r1, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r0 = $r0, 4
; CV1-NEXT:    insf $r5 = $r2, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r3, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r5, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r4, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: srs_v8i8:
; CV2:       # %bb.0:
; CV2-NEXT:    srsbos $r0 = $r0, 4
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %2 = sdiv <8 x i8> %0, <i8 16, i8 16, i8 16, i8 16, i8 16, i8 16, i8 16, i8 16>
  ret <8 x i8> %2
}

define <2 x i16> @srs_v2i16(<2 x i16> %0) {
; ALL-LABEL: srs_v2i16:
; ALL:       # %bb.0:
; ALL-NEXT:    srshqs $r0 = $r0, 4
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %2 = sdiv <2 x i16> %0, <i16 16, i16 16>
  ret <2 x i16> %2
}

define <4 x i16> @srs_v4i16(<4 x i16> %0) {
; ALL-LABEL: srs_v4i16:
; ALL:       # %bb.0:
; ALL-NEXT:    srshqs $r0 = $r0, 4
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %2 = sdiv <4 x i16> %0, <i16 16, i16 16, i16 16, i16 16>
  ret <4 x i16> %2
}

define <2 x i32> @srs_v2i32(<2 x i32> %0) {
; ALL-LABEL: srs_v2i32:
; ALL:       # %bb.0:
; ALL-NEXT:    srswps $r0 = $r0, 4
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %2 = sdiv <2 x i32> %0, <i32 16, i32 16>
  ret <2 x i32> %2
}

define i32 @srs_i32(i32 %0) {
; ALL-LABEL: srs_i32:
; ALL:       # %bb.0:
; ALL-NEXT:    srsw $r0 = $r0, 4
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %2 = sdiv i32 %0, 16
  ret i32 %2
}

define i64 @srs_i64(i64 %0) {
; ALL-LABEL: srs_i64:
; ALL:       # %bb.0:
; ALL-NEXT:    srsd $r0 = $r0, 4
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %2 = sdiv i64 %0, 16
  ret i64 %2
}

define <16 x i8> @srs_v16i8(<16 x i8> %0) {
; CV1-LABEL: srs_v16i8:
; CV1:       # %bb.0:
; CV1-NEXT:    srld $r2 = $r0, 56
; CV1-NEXT:    extfz $r3 = $r0, 55, 48
; CV1-NEXT:    extfz $r4 = $r0, 47, 40
; CV1-NEXT:    zxbd $r7 = $r0
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    extfz $r5 = $r0, 39, 32
; CV1-NEXT:    zxbd $r9 = $r1
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r2 = $r2, 7
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r3 = $r3, 7
; CV1-NEXT:    sraw $r4 = $r4, 7
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    extfz $r6 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r2 = $r0, 24
; CV1-NEXT:    insf $r3 = $r2, 15, 8
; CV1-NEXT:    sraw $r5 = $r5, 7
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r4 = $r0, 23, 16
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    sraw $r6 = $r6, 7
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r2 = $r2, 7
; CV1-NEXT:    sraw $r4 = $r4, 7
; CV1-NEXT:    insf $r5 = $r3, 31, 16
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    ;;
; CV1-NEXT:    make $r3 = 4
; CV1-NEXT:    insf $r4 = $r2, 15, 8
; CV1-NEXT:    sraw $r7 = $r7, 7
; CV1-NEXT:    extfz $r8 = $r1, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r6 = $r1, 55, 48
; CV1-NEXT:    insf $r7 = $r6, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r7 = $r4, 31, 16
; CV1-NEXT:    sxbd $r8 = $r8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r7 = $r5, 63, 32
; CV1-NEXT:    sraw $r8 = $r8, 7
; CV1-NEXT:    sxbd $r9 = $r9
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r2 = $r7, 0xff00ff00ff00ff
; CV1-NEXT:    andd $r4 = $r7, 0xff00ff00ff00ff00
; CV1-NEXT:    extfz $r7 = $r1, 39, 32
; CV1-NEXT:    sraw $r9 = $r9, 7
; CV1-NEXT:    ;;
; CV1-NEXT:    srld $r2 = $r2, $r3
; CV1-NEXT:    srld $r4 = $r4, $r3
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    insf $r9 = $r8, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r2 = $r2, 0xff00ff00ff00ff
; CV1-NEXT:    andd $r4 = $r4, 0xff00ff00ff00ff00
; CV1-NEXT:    sraw $r7 = $r7, 7
; CV1-NEXT:    ;;
; CV1-NEXT:    ord $r2 = $r4, $r2
; CV1-NEXT:    andd $r4 = $r0, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    ;;
; CV1-NEXT:    xord $r0 = $r0, $r2
; CV1-NEXT:    srld $r2 = $r1, 56
; CV1-NEXT:    andd $r5 = $r2, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    addd $r4 = $r4, $r5
; CV1-NEXT:    sxbd $r5 = $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    xord $r0 = $r4, $r0
; CV1-NEXT:    sraw $r2 = $r2, 7
; CV1-NEXT:    sraw $r4 = $r5, 7
; CV1-NEXT:    extfz $r6 = $r1, 47, 40
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r2 = $r0, 55, 48
; CV1-NEXT:    insf $r4 = $r2, 15, 8
; CV1-NEXT:    srld $r5 = $r0, 56
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r2 = $r2, 4
; CV1-NEXT:    sraw $r5 = $r5, 4
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    extfz $r8 = $r0, 39, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r2 = $r5, 15, 8
; CV1-NEXT:    srlw $r5 = $r1, 24
; CV1-NEXT:    sraw $r6 = $r6, 7
; CV1-NEXT:    sxbd $r8 = $r8
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r6 = $r1, 23, 16
; CV1-NEXT:    insf $r7 = $r6, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r5 = $r5, 7
; CV1-NEXT:    sraw $r6 = $r6, 7
; CV1-NEXT:    insf $r7 = $r4, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r5 = $r0, 47, 40
; CV1-NEXT:    insf $r6 = $r5, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    insf $r9 = $r6, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r4 = $r5, 4
; CV1-NEXT:    sraw $r5 = $r8, 4
; CV1-NEXT:    extfz $r7 = $r0, 23, 16
; CV1-NEXT:    insf $r9 = $r7, 63, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r4 = $r0, 24
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    andd $r6 = $r9, 0xff00ff00ff00ff00
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r2 = $r9, 0xff00ff00ff00ff
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    insf $r5 = $r2, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    srld $r2 = $r2, $r3
; CV1-NEXT:    srld $r3 = $r6, $r3
; CV1-NEXT:    sxbd $r6 = $r7
; CV1-NEXT:    extfz $r7 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    andd $r2 = $r2, 0xff00ff00ff00ff
; CV1-NEXT:    andd $r3 = $r3, 0xff00ff00ff00ff00
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r0 = $r0
; CV1-NEXT:    ord $r2 = $r3, $r2
; CV1-NEXT:    sraw $r4 = $r4, 4
; CV1-NEXT:    sraw $r6 = $r6, 4
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r1 = $r1, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    xord $r2 = $r1, $r2
; CV1-NEXT:    andd $r3 = $r2, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    sraw $r7 = $r7, 4
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r0 = $r0, 4
; CV1-NEXT:    addd $r1 = $r1, $r3
; CV1-NEXT:    andd $r2 = $r2, 0x8080808080808080
; CV1-NEXT:    insf $r6 = $r4, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r7, 15, 8
; CV1-NEXT:    xord $r1 = $r1, $r2
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r6, 31, 16
; CV1-NEXT:    srld $r2 = $r1, 56
; CV1-NEXT:    extfz $r3 = $r1, 55, 48
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r4 = $r1, 47, 40
; CV1-NEXT:    extfz $r6 = $r1, 39, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r2 = $r2, 4
; CV1-NEXT:    sraw $r3 = $r3, 4
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r2 = $r1, 24
; CV1-NEXT:    insf $r3 = $r2, 15, 8
; CV1-NEXT:    sraw $r4 = $r4, 4
; CV1-NEXT:    sraw $r6 = $r6, 4
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r4 = $r1, 23, 16
; CV1-NEXT:    insf $r6 = $r4, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r1 = $r1
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    extfz $r7 = $r1, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r2 = $r2, 4
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    sraw $r4 = $r4, 4
; CV1-NEXT:    insf $r6 = $r3, 31, 16
; CV1-NEXT:    sraw $r7 = $r7, 4
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r5, 63, 32
; CV1-NEXT:    sraw $r1 = $r1, 4
; CV1-NEXT:    insf $r4 = $r2, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r1 = $r7, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r1 = $r4, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r1 = $r6, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: srs_v16i8:
; CV2:       # %bb.0:
; CV2-NEXT:    srabos $r2 = $r0, 7
; CV2-NEXT:    srabos $r3 = $r1, 7
; CV2-NEXT:    ;;
; CV2-NEXT:    srlbos $r2 = $r2, 4
; CV2-NEXT:    srlbos $r3 = $r3, 4
; CV2-NEXT:    ;;
; CV2-NEXT:    addbo $r0 = $r0, $r2
; CV2-NEXT:    addbo $r1 = $r1, $r3
; CV2-NEXT:    ;;
; CV2-NEXT:    srabos $r0 = $r0, 4
; CV2-NEXT:    srabos $r1 = $r1, 4
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %2 = sdiv <16 x i8> %0, <i8 16, i8 16, i8 16, i8 16, i8 16, i8 16, i8 16, i8 16, i8 16, i8 16, i8 16, i8 16, i8 16, i8 16, i8 16, i8 16>
  ret <16 x i8> %2
}

define <32 x i8> @srs_v32i8(<32 x i8> %0) {
; CV1-LABEL: srs_v32i8:
; CV1:       # %bb.0:
; CV1-NEXT:    srld $r4 = $r0, 56
; CV1-NEXT:    extfz $r5 = $r0, 55, 48
; CV1-NEXT:    extfz $r6 = $r0, 47, 40
; CV1-NEXT:    zxbd $r9 = $r0
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    extfz $r7 = $r0, 39, 32
; CV1-NEXT:    zxbd $r15 = $r1
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r4 = $r4, 7
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r5 = $r5, 7
; CV1-NEXT:    sraw $r6 = $r6, 7
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    extfz $r8 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r4 = $r0, 24
; CV1-NEXT:    insf $r5 = $r4, 15, 8
; CV1-NEXT:    sraw $r7 = $r7, 7
; CV1-NEXT:    sxbd $r8 = $r8
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r6 = $r0, 23, 16
; CV1-NEXT:    insf $r7 = $r6, 15, 8
; CV1-NEXT:    sraw $r8 = $r8, 7
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r4 = $r4, 7
; CV1-NEXT:    sraw $r6 = $r6, 7
; CV1-NEXT:    insf $r7 = $r5, 31, 16
; CV1-NEXT:    sxbd $r9 = $r9
; CV1-NEXT:    ;;
; CV1-NEXT:    make $r4 = 3
; CV1-NEXT:    insf $r6 = $r4, 15, 8
; CV1-NEXT:    sraw $r9 = $r9, 7
; CV1-NEXT:    extfz $r11 = $r1, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r9 = $r8, 15, 8
; CV1-NEXT:    sxbd $r11 = $r11
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r9 = $r6, 31, 16
; CV1-NEXT:    sraw $r11 = $r11, 7
; CV1-NEXT:    sxbd $r15 = $r15
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r7 = $r0, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    insf $r9 = $r7, 63, 32
; CV1-NEXT:    sraw $r15 = $r15, 7
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r5 = $r9, 0xff00ff00ff00ff
; CV1-NEXT:    andd $r6 = $r9, 0xff00ff00ff00ff00
; CV1-NEXT:    extfz $r9 = $r1, 39, 32
; CV1-NEXT:    insf $r15 = $r11, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    srld $r5 = $r5, $r4
; CV1-NEXT:    srld $r6 = $r6, $r4
; CV1-NEXT:    sxbd $r9 = $r9
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r5 = $r5, 0xff00ff00ff00ff
; CV1-NEXT:    andd $r6 = $r6, 0xff00ff00ff00ff00
; CV1-NEXT:    sraw $r9 = $r9, 7
; CV1-NEXT:    ;;
; CV1-NEXT:    ord $r5 = $r6, $r5
; CV1-NEXT:    ;;
; CV1-NEXT:    xord $r0 = $r0, $r5
; CV1-NEXT:    srld $r5 = $r1, 56
; CV1-NEXT:    andd $r6 = $r5, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r0 = $r0, 0x8080808080808080
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    addd $r6 = $r7, $r6
; CV1-NEXT:    extfz $r7 = $r1, 55, 48
; CV1-NEXT:    ;;
; CV1-NEXT:    xord $r0 = $r6, $r0
; CV1-NEXT:    sraw $r5 = $r5, 7
; CV1-NEXT:    sxbd $r6 = $r7
; CV1-NEXT:    extfz $r7 = $r1, 47, 40
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r6 = $r6, 7
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    srld $r8 = $r0, 56
; CV1-NEXT:    extfz $r10 = $r0, 55, 48
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r5 = $r1, 24
; CV1-NEXT:    insf $r6 = $r5, 15, 8
; CV1-NEXT:    sraw $r7 = $r7, 7
; CV1-NEXT:    extfz $r11 = $r0, 39, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r7 = $r1, 23, 16
; CV1-NEXT:    insf $r9 = $r7, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r5 = $r5, 7
; CV1-NEXT:    sraw $r7 = $r7, 7
; CV1-NEXT:    sxbd $r8 = $r8
; CV1-NEXT:    sxbd $r10 = $r10
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r5 = $r0, 47, 40
; CV1-NEXT:    insf $r7 = $r5, 15, 8
; CV1-NEXT:    sraw $r8 = $r8, 5
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    sxbd $r11 = $r11
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r5 = $r5, 5
; CV1-NEXT:    sraw $r6 = $r10, 5
; CV1-NEXT:    insf $r9 = $r6, 31, 16
; CV1-NEXT:    insf $r15 = $r7, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r6 = $r8, 15, 8
; CV1-NEXT:    sraw $r7 = $r11, 5
; CV1-NEXT:    srlw $r9 = $r0, 24
; CV1-NEXT:    insf $r15 = $r9, 63, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r5 = $r15, 0xff00ff00ff00ff
; CV1-NEXT:    insf $r7 = $r5, 15, 8
; CV1-NEXT:    andd $r8 = $r15, 0xff00ff00ff00ff00
; CV1-NEXT:    extfz $r10 = $r0, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r0 = $r0
; CV1-NEXT:    srld $r5 = $r5, $r4
; CV1-NEXT:    srld $r8 = $r8, $r4
; CV1-NEXT:    extfz $r11 = $r0, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r0 = $r0
; CV1-NEXT:    andd $r5 = $r5, 0xff00ff00ff00ff
; CV1-NEXT:    andd $r8 = $r8, 0xff00ff00ff00ff00
; CV1-NEXT:    sxbd $r9 = $r9
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r0 = $r0, 5
; CV1-NEXT:    ord $r5 = $r8, $r5
; CV1-NEXT:    sxbd $r10 = $r10
; CV1-NEXT:    andd $r15 = $r1, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    ;;
; CV1-NEXT:    xord $r1 = $r1, $r5
; CV1-NEXT:    sxbd $r5 = $r11
; CV1-NEXT:    andd $r8 = $r5, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    sraw $r9 = $r9, 5
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r1 = $r1, 0x8080808080808080
; CV1-NEXT:    sraw $r5 = $r5, 5
; CV1-NEXT:    addd $r8 = $r15, $r8
; CV1-NEXT:    sraw $r10 = $r10, 5
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r5, 15, 8
; CV1-NEXT:    xord $r1 = $r8, $r1
; CV1-NEXT:    insf $r10 = $r9, 15, 8
; CV1-NEXT:    zxbd $r15 = $r2
; CV1-NEXT:    ;;
; CV1-NEXT:    srld $r5 = $r1, 56
; CV1-NEXT:    insf $r7 = $r6, 31, 16
; CV1-NEXT:    extfz $r8 = $r1, 55, 48
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    sxbd $r8 = $r8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r10, 31, 16
; CV1-NEXT:    sraw $r5 = $r5, 5
; CV1-NEXT:    sraw $r6 = $r8, 5
; CV1-NEXT:    extfz $r8 = $r2, 55, 48
; CV1-NEXT:    ;;
; CV1-NEXT:    srld $r5 = $r2, 56
; CV1-NEXT:    insf $r6 = $r5, 15, 8
; CV1-NEXT:    extfz $r9 = $r2, 47, 40
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    extfz $r10 = $r2, 39, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r5 = $r5, 7
; CV1-NEXT:    sxbd $r8 = $r8
; CV1-NEXT:    sxbd $r9 = $r9
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r8 = $r8, 7
; CV1-NEXT:    sraw $r9 = $r9, 7
; CV1-NEXT:    sxbd $r10 = $r10
; CV1-NEXT:    extfz $r11 = $r2, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r5 = $r2, 24
; CV1-NEXT:    insf $r8 = $r5, 15, 8
; CV1-NEXT:    sraw $r10 = $r10, 7
; CV1-NEXT:    sxbd $r11 = $r11
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r9 = $r2, 23, 16
; CV1-NEXT:    insf $r10 = $r9, 15, 8
; CV1-NEXT:    sraw $r11 = $r11, 7
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    sxbd $r9 = $r9
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r5 = $r5, 7
; CV1-NEXT:    sraw $r9 = $r9, 7
; CV1-NEXT:    insf $r10 = $r8, 31, 16
; CV1-NEXT:    sxbd $r15 = $r15
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r5 = $r1, 47, 40
; CV1-NEXT:    insf $r9 = $r5, 15, 8
; CV1-NEXT:    sraw $r15 = $r15, 7
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r11 = $r1, 39, 32
; CV1-NEXT:    insf $r15 = $r11, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    sxbd $r11 = $r11
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r5 = $r5, 5
; CV1-NEXT:    sraw $r8 = $r11, 5
; CV1-NEXT:    extfz $r11 = $r1, 15, 8
; CV1-NEXT:    insf $r15 = $r9, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r5 = $r1, 24
; CV1-NEXT:    insf $r8 = $r5, 15, 8
; CV1-NEXT:    insf $r15 = $r10, 63, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r6 = $r15, 0xff00ff00ff00ff
; CV1-NEXT:    insf $r8 = $r6, 31, 16
; CV1-NEXT:    andd $r9 = $r15, 0xff00ff00ff00ff00
; CV1-NEXT:    extfz $r10 = $r1, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    srld $r6 = $r6, $r4
; CV1-NEXT:    srld $r9 = $r9, $r4
; CV1-NEXT:    sxbd $r10 = $r10
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r1 = $r1
; CV1-NEXT:    sraw $r5 = $r5, 5
; CV1-NEXT:    andd $r6 = $r6, 0xff00ff00ff00ff
; CV1-NEXT:    andd $r9 = $r9, 0xff00ff00ff00ff00
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r1 = $r1
; CV1-NEXT:    ord $r6 = $r9, $r6
; CV1-NEXT:    sraw $r10 = $r10, 5
; CV1-NEXT:    sxbd $r11 = $r11
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r2 = $r2, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    xord $r6 = $r2, $r6
; CV1-NEXT:    andd $r9 = $r6, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    sraw $r11 = $r11, 5
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r1 = $r1, 5
; CV1-NEXT:    addd $r2 = $r2, $r9
; CV1-NEXT:    andd $r6 = $r6, 0x8080808080808080
; CV1-NEXT:    insf $r10 = $r5, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r0 = $r7, 63, 32
; CV1-NEXT:    insf $r1 = $r11, 15, 8
; CV1-NEXT:    xord $r2 = $r2, $r6
; CV1-NEXT:    zxbd $r11 = $r3
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r1 = $r10, 31, 16
; CV1-NEXT:    srld $r5 = $r2, 56
; CV1-NEXT:    extfz $r6 = $r2, 55, 48
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r1 = $r8, 63, 32
; CV1-NEXT:    sraw $r5 = $r5, 5
; CV1-NEXT:    sraw $r6 = $r6, 5
; CV1-NEXT:    extfz $r7 = $r3, 55, 48
; CV1-NEXT:    ;;
; CV1-NEXT:    srld $r5 = $r3, 56
; CV1-NEXT:    insf $r6 = $r5, 15, 8
; CV1-NEXT:    extfz $r8 = $r3, 47, 40
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    extfz $r9 = $r3, 39, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r5 = $r5, 7
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    sxbd $r8 = $r8
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r7 = $r7, 7
; CV1-NEXT:    sraw $r8 = $r8, 7
; CV1-NEXT:    sxbd $r9 = $r9
; CV1-NEXT:    extfz $r10 = $r3, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r5 = $r3, 24
; CV1-NEXT:    insf $r7 = $r5, 15, 8
; CV1-NEXT:    sraw $r9 = $r9, 7
; CV1-NEXT:    sxbd $r10 = $r10
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r8 = $r3, 23, 16
; CV1-NEXT:    insf $r9 = $r8, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    sxbd $r8 = $r8
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r5 = $r5, 7
; CV1-NEXT:    sraw $r8 = $r8, 7
; CV1-NEXT:    insf $r9 = $r7, 31, 16
; CV1-NEXT:    sxbd $r11 = $r11
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r5 = $r10, 7
; CV1-NEXT:    sraw $r7 = $r11, 7
; CV1-NEXT:    insf $r8 = $r5, 15, 8
; CV1-NEXT:    extfz $r10 = $r2, 47, 40
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r5 = $r2, 39, 32
; CV1-NEXT:    insf $r7 = $r5, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r7 = $r8, 31, 16
; CV1-NEXT:    srlw $r8 = $r2, 24
; CV1-NEXT:    sxbd $r10 = $r10
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r5 = $r5
; CV1-NEXT:    insf $r7 = $r9, 63, 32
; CV1-NEXT:    sraw $r9 = $r10, 5
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r5 = $r5, 5
; CV1-NEXT:    sxbd $r8 = $r8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r5 = $r9, 15, 8
; CV1-NEXT:    andd $r7 = $r7, 0xff00ff00ff00ff00
; CV1-NEXT:    sraw $r8 = $r8, 5
; CV1-NEXT:    andd $r9 = $r7, 0xff00ff00ff00ff
; CV1-NEXT:    ;;
; CV1-NEXT:    srld $r4 = $r7, $r4
; CV1-NEXT:    insf $r5 = $r6, 31, 16
; CV1-NEXT:    srld $r6 = $r9, $r4
; CV1-NEXT:    extfz $r9 = $r2, 23, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    andd $r4 = $r4, 0xff00ff00ff00ff00
; CV1-NEXT:    andd $r6 = $r6, 0xff00ff00ff00ff
; CV1-NEXT:    sxbd $r7 = $r9
; CV1-NEXT:    extfz $r9 = $r2, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r2 = $r2
; CV1-NEXT:    ord $r4 = $r4, $r6
; CV1-NEXT:    sraw $r7 = $r7, 5
; CV1-NEXT:    sxbd $r9 = $r9
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r2 = $r2
; CV1-NEXT:    andd $r3 = $r3, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    xord $r4 = $r3, $r4
; CV1-NEXT:    andd $r6 = $r4, 0x7f7f7f7f7f7f7f7f
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r2 = $r2, 5
; CV1-NEXT:    addd $r3 = $r3, $r6
; CV1-NEXT:    andd $r4 = $r4, 0x8080808080808080
; CV1-NEXT:    sraw $r9 = $r9, 5
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r2 = $r9, 15, 8
; CV1-NEXT:    xord $r3 = $r3, $r4
; CV1-NEXT:    insf $r7 = $r8, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r2 = $r7, 31, 16
; CV1-NEXT:    srld $r4 = $r3, 56
; CV1-NEXT:    extfz $r6 = $r3, 55, 48
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r7 = $r3, 47, 40
; CV1-NEXT:    extfz $r8 = $r3, 39, 32
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    sxbd $r6 = $r6
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r4 = $r4, 5
; CV1-NEXT:    sraw $r6 = $r6, 5
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    sxbd $r8 = $r8
; CV1-NEXT:    ;;
; CV1-NEXT:    srlw $r4 = $r3, 24
; CV1-NEXT:    insf $r6 = $r4, 15, 8
; CV1-NEXT:    sraw $r7 = $r7, 5
; CV1-NEXT:    sraw $r8 = $r8, 5
; CV1-NEXT:    ;;
; CV1-NEXT:    extfz $r7 = $r3, 23, 16
; CV1-NEXT:    insf $r8 = $r7, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    zxbd $r3 = $r3
; CV1-NEXT:    sxbd $r4 = $r4
; CV1-NEXT:    extfz $r9 = $r3, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    sraw $r4 = $r4, 5
; CV1-NEXT:    sxbd $r7 = $r7
; CV1-NEXT:    sxbd $r9 = $r9
; CV1-NEXT:    ;;
; CV1-NEXT:    sxbd $r3 = $r3
; CV1-NEXT:    sraw $r7 = $r7, 5
; CV1-NEXT:    insf $r8 = $r6, 31, 16
; CV1-NEXT:    sraw $r9 = $r9, 5
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r2 = $r5, 63, 32
; CV1-NEXT:    sraw $r3 = $r3, 5
; CV1-NEXT:    insf $r7 = $r4, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r3 = $r9, 15, 8
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r3 = $r7, 31, 16
; CV1-NEXT:    ;;
; CV1-NEXT:    insf $r3 = $r8, 63, 32
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: srs_v32i8:
; CV2:       # %bb.0:
; CV2-NEXT:    srabos $r4 = $r0, 7
; CV2-NEXT:    srabos $r5 = $r1, 7
; CV2-NEXT:    srabos $r6 = $r2, 7
; CV2-NEXT:    srabos $r7 = $r3, 7
; CV2-NEXT:    ;;
; CV2-NEXT:    srlbos $r4 = $r4, 3
; CV2-NEXT:    srlbos $r5 = $r5, 3
; CV2-NEXT:    srlbos $r6 = $r6, 3
; CV2-NEXT:    srlbos $r7 = $r7, 3
; CV2-NEXT:    ;;
; CV2-NEXT:    addbo $r0 = $r0, $r4
; CV2-NEXT:    addbo $r1 = $r1, $r5
; CV2-NEXT:    addbo $r2 = $r2, $r6
; CV2-NEXT:    addbo $r3 = $r3, $r7
; CV2-NEXT:    ;;
; CV2-NEXT:    srabos $r0 = $r0, 5
; CV2-NEXT:    srabos $r1 = $r1, 5
; CV2-NEXT:    srabos $r2 = $r2, 5
; CV2-NEXT:    srabos $r3 = $r3, 5
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %2 = sdiv <32 x i8> %0, <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32>
  ret <32 x i8> %2
}

define <8 x i16> @srs_v8i16(<8 x i16> %0) {
; ALL-LABEL: srs_v8i16:
; ALL:       # %bb.0:
; ALL-NEXT:    srahqs $r2 = $r0, 15
; ALL-NEXT:    srahqs $r3 = $r1, 15
; ALL-NEXT:    ;;
; ALL-NEXT:    srlhqs $r2 = $r2, 12
; ALL-NEXT:    srlhqs $r3 = $r3, 12
; ALL-NEXT:    ;;
; ALL-NEXT:    addhq $r0 = $r0, $r2
; ALL-NEXT:    addhq $r1 = $r1, $r3
; ALL-NEXT:    ;;
; ALL-NEXT:    srahqs $r0 = $r0, 4
; ALL-NEXT:    srahqs $r1 = $r1, 4
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %2 = sdiv <8 x i16> %0, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  ret <8 x i16> %2
}

define <16 x i16> @srs_v16i16(<16 x i16> %0) {
; CV1-LABEL: srs_v16i16:
; CV1:       # %bb.0:
; CV1-NEXT:    srahqs $r4 = $r0, 15
; CV1-NEXT:    srahqs $r5 = $r1, 15
; CV1-NEXT:    ;;
; CV1-NEXT:    srlhqs $r4 = $r4, 12
; CV1-NEXT:    srlhqs $r5 = $r5, 12
; CV1-NEXT:    ;;
; CV1-NEXT:    addhq $r0 = $r0, $r4
; CV1-NEXT:    addhq $r1 = $r1, $r5
; CV1-NEXT:    srahqs $r6 = $r2, 15
; CV1-NEXT:    srahqs $r7 = $r3, 15
; CV1-NEXT:    ;;
; CV1-NEXT:    srlhqs $r4 = $r6, 12
; CV1-NEXT:    srlhqs $r5 = $r7, 12
; CV1-NEXT:    ;;
; CV1-NEXT:    srahqs $r0 = $r0, 4
; CV1-NEXT:    srahqs $r1 = $r1, 4
; CV1-NEXT:    addhq $r2 = $r2, $r4
; CV1-NEXT:    addhq $r3 = $r3, $r5
; CV1-NEXT:    ;;
; CV1-NEXT:    srahqs $r2 = $r2, 4
; CV1-NEXT:    srahqs $r3 = $r3, 4
; CV1-NEXT:    ret
; CV1-NEXT:    ;;
;
; CV2-LABEL: srs_v16i16:
; CV2:       # %bb.0:
; CV2-NEXT:    srahqs $r4 = $r0, 15
; CV2-NEXT:    srahqs $r5 = $r1, 15
; CV2-NEXT:    srahqs $r6 = $r2, 15
; CV2-NEXT:    srahqs $r7 = $r3, 15
; CV2-NEXT:    ;;
; CV2-NEXT:    srlhqs $r4 = $r4, 12
; CV2-NEXT:    srlhqs $r5 = $r5, 12
; CV2-NEXT:    srlhqs $r6 = $r6, 12
; CV2-NEXT:    srlhqs $r7 = $r7, 12
; CV2-NEXT:    ;;
; CV2-NEXT:    addhq $r0 = $r0, $r4
; CV2-NEXT:    addhq $r1 = $r1, $r5
; CV2-NEXT:    addhq $r2 = $r2, $r6
; CV2-NEXT:    addhq $r3 = $r3, $r7
; CV2-NEXT:    ;;
; CV2-NEXT:    srahqs $r0 = $r0, 4
; CV2-NEXT:    srahqs $r1 = $r1, 4
; CV2-NEXT:    srahqs $r2 = $r2, 4
; CV2-NEXT:    srahqs $r3 = $r3, 4
; CV2-NEXT:    ret
; CV2-NEXT:    ;;
  %2 = sdiv <16 x i16> %0, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  ret <16 x i16> %2
}

define i32 @srs_i322(i32 %0) {
; ALL-LABEL: srs_i322:
; ALL:       # %bb.0:
; ALL-NEXT:    mulwd $r1 = $r0, 0xe070381d
; ALL-NEXT:    ;;
; ALL-NEXT:    srad $r1 = $r1, 32
; ALL-NEXT:    ;;
; ALL-NEXT:    addw $r0 = $r1, $r0
; ALL-NEXT:    ;;
; ALL-NEXT:    sraw $r0 = $r0, 6
; ALL-NEXT:    srlw $r1 = $r0, 31
; ALL-NEXT:    ;;
; ALL-NEXT:    addw $r0 = $r0, $r1
; ALL-NEXT:    ret
; ALL-NEXT:    ;;
  %2 = sdiv i32 %0, 73
  ret i32 %2
}
