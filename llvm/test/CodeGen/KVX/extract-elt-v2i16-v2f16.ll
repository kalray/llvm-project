; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O2 < %s | FileCheck %s
target triple = "kvx-kalray-cos-O2"

define i64 @ext_v2i16_0(<2 x i16> %x, i64 %y){
; CHECK-LABEL: ext_v2i16_0:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    sw 0[$r12] = $r0
; CHECK-NEXT:    sxhd $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 8[$r12] = $r1
; CHECK-NEXT:    addd $r0 = $r0, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 16[$r12] = $r0
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %x.addr = alloca <2 x i16>, align 4
  %y.addr = alloca i64, align 8
  %z = alloca i64, align 8
  store <2 x i16> %x, <2 x i16>* %x.addr, align 4
  store i64 %y, i64* %y.addr, align 8
  %0 = load <2 x i16>, <2 x i16>* %x.addr, align 4
  %vecext = extractelement <2 x i16> %0, i32 0
  %conv = sext i16 %vecext to i64
  %1 = load i64, i64* %y.addr, align 8
  %add = add nsw i64 %conv, %1
  store i64 %add, i64* %z, align 8
  %2 = load i64, i64* %z, align 8
  ret i64 %2
}

define i64 @ext_v2i16_1(<2 x i16> %x, i64 %y){
; CHECK-LABEL: ext_v2i16_1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    sw 0[$r12] = $r0
; CHECK-NEXT:    extfs $r0 = $r0, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 8[$r12] = $r1
; CHECK-NEXT:    addd $r0 = $r0, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 16[$r12] = $r0
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %x.addr = alloca <2 x i16>, align 4
  %y.addr = alloca i64, align 8
  %z = alloca i64, align 8
  store <2 x i16> %x, <2 x i16>* %x.addr, align 4
  store i64 %y, i64* %y.addr, align 8
  %0 = load <2 x i16>, <2 x i16>* %x.addr, align 4
  %vecext = extractelement <2 x i16> %0, i32 1
  %conv = sext i16 %vecext to i64
  %1 = load i64, i64* %y.addr, align 8
  %add = add nsw i64 %conv, %1
  store i64 %add, i64* %z, align 8
  %2 = load i64, i64* %z, align 8
  ret i64 %2
}

define i16 @ext_v2i16_s_0(<2 x i16> %x){
; CHECK-LABEL: ext_v2i16_s_0:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    zxhd $r1 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    sw 0[$r12] = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %x.addr = alloca <2 x i16>, align 4
  store <2 x i16> %x, <2 x i16>* %x.addr, align 4
  %0 = load <2 x i16>, <2 x i16>* %x.addr, align 4
  %vecext = extractelement <2 x i16> %0, i32 0
  ret i16 %vecext
}

define i16 @ext_v2i16_s_1(<2 x i16> %x){
; CHECK-LABEL: ext_v2i16_s_1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    srlw $r1 = $r0, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    sw 0[$r12] = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %x.addr = alloca <2 x i16>, align 4
  store <2 x i16> %x, <2 x i16>* %x.addr, align 4
  %0 = load <2 x i16>, <2 x i16>* %x.addr, align 4
  %vecext = extractelement <2 x i16> %0, i32 1
  ret i16 %vecext
}

define i16 @ext_v2i16_us_0(<2 x i16> %x){
; CHECK-LABEL: ext_v2i16_us_0:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    zxhd $r1 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    sw 0[$r12] = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %x.addr = alloca <2 x i16>, align 4
  store <2 x i16> %x, <2 x i16>* %x.addr, align 4
  %0 = load <2 x i16>, <2 x i16>* %x.addr, align 4
  %vecext = extractelement <2 x i16> %0, i32 0
  ret i16 %vecext
}

define i16 @ext_v2i16_us_1(<2 x i16> %x){
; CHECK-LABEL: ext_v2i16_us_1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    srlw $r1 = $r0, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    sw 0[$r12] = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %x.addr = alloca <2 x i16>, align 4
  store <2 x i16> %x, <2 x i16>* %x.addr, align 4
  %0 = load <2 x i16>, <2 x i16>* %x.addr, align 4
  %vecext = extractelement <2 x i16> %0, i32 1
  ret i16 %vecext
}

define half @ext_v2f16_0(<2 x half> %x){
; CHECK-LABEL: ext_v2f16_0:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    zxhd $r1 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    sw 0[$r12] = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %x.addr = alloca <2 x half>, align 4
  store <2 x half> %x, <2 x half>* %x.addr, align 4
  %0 = load <2 x half>, <2 x half>* %x.addr, align 4
  %vecext = extractelement <2 x half> %0, i32 0
  ret half %vecext
}

define half @ext_v2f16_1(<2 x half> %x){
; CHECK-LABEL: ext_v2f16_1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    srld $r1 = $r0, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    sw 0[$r12] = $r0
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %x.addr = alloca <2 x half>, align 4
  store <2 x half> %x, <2 x half>* %x.addr, align 4
  %0 = load <2 x half>, <2 x half>* %x.addr, align 4
  %vecext = extractelement <2 x half> %0, i32 1
  ret half %vecext
}
