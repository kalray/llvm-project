; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc --frame-pointer=none < %s | FileCheck -check-prefix=FP-NONE %s
; RUN: llc --frame-pointer=all < %s | FileCheck -check-prefix=FP-ALL %s

target triple = "kvx-kalray-cos"

; int fn1(int a, int b, int c, int d, int e,
;         int f, int g, int h, int i, int j,
;         int k, int l, int m, int n, int o) {
;   fn3(a, c);
;   return a + b + c + d + e +
;          f + g + h + i + j +
;          k + l + m + n + o;
; }

define i32 @fn1(i32 %a, i32 %b, i32 %c, i32 %d, i32 %e, i32 %f, i32 %g, i32 %h, i32 %i, i32 %j, i32 %k, i32 %l, i32 %m, i32 %n, i32 %o) {
; FP-NONE-LABEL: fn1:
; FP-NONE:       # %bb.0: # %entry
; FP-NONE-NEXT:    addd $r12 = $r12, -160
; FP-NONE-NEXT:    get $r16 = $ra
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    .cfi_def_cfa_offset 160
; FP-NONE-NEXT:    sd 124[$r12] = $r16
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    .cfi_offset 67, -24
; FP-NONE-NEXT:    so 92[$r12] = $r28r29r30r31
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    .cfi_offset 31, -32
; FP-NONE-NEXT:    .cfi_offset 30, -40
; FP-NONE-NEXT:    .cfi_offset 29, -48
; FP-NONE-NEXT:    .cfi_offset 28, -56
; FP-NONE-NEXT:    so 60[$r12] = $r24r25r26r27
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    .cfi_offset 27, -64
; FP-NONE-NEXT:    .cfi_offset 26, -72
; FP-NONE-NEXT:    .cfi_offset 25, -80
; FP-NONE-NEXT:    .cfi_offset 24, -88
; FP-NONE-NEXT:    so 28[$r12] = $r20r21r22r23
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    .cfi_offset 23, -96
; FP-NONE-NEXT:    .cfi_offset 22, -104
; FP-NONE-NEXT:    .cfi_offset 21, -112
; FP-NONE-NEXT:    .cfi_offset 20, -120
; FP-NONE-NEXT:    sq 12[$r12] = $r18r19
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    .cfi_offset 19, -128
; FP-NONE-NEXT:    .cfi_offset 18, -136
; FP-NONE-NEXT:    sd 132[$r12] = $r11
; FP-NONE-NEXT:    copyd $r19 = $r10
; FP-NONE-NEXT:    copyd $r20 = $r9
; FP-NONE-NEXT:    copyd $r21 = $r8
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    copyd $r22 = $r7
; FP-NONE-NEXT:    copyd $r23 = $r6
; FP-NONE-NEXT:    copyd $r24 = $r5
; FP-NONE-NEXT:    copyd $r25 = $r4
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    copyd $r26 = $r3
; FP-NONE-NEXT:    copyd $r27 = $r2
; FP-NONE-NEXT:    copyd $r28 = $r1
; FP-NONE-NEXT:    copyd $r29 = $r0
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    lwz $r30 = 176[$r12]
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    lwz $r31 = 168[$r12]
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    lwz $r18 = 160[$r12]
; FP-NONE-NEXT:    copyd $r1 = $r27
; FP-NONE-NEXT:    call fn3
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r28, $r29
; FP-NONE-NEXT:    ld $r1 = 132[$r12]
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r27
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r26
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r25
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r24
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r23
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r22
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r21
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r20
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r19
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r1
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r18
; FP-NONE-NEXT:    lq $r18r19 = 12[$r12]
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r31
; FP-NONE-NEXT:    lo $r20r21r22r23 = 28[$r12]
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    addw $r0 = $r0, $r30
; FP-NONE-NEXT:    lo $r24r25r26r27 = 60[$r12]
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    lo $r28r29r30r31 = 92[$r12]
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    ld $r16 = 124[$r12]
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    set $ra = $r16
; FP-NONE-NEXT:    addd $r12 = $r12, 160
; FP-NONE-NEXT:    ;;
; FP-NONE-NEXT:    .cfi_def_cfa_offset 0
; FP-NONE-NEXT:    ret
; FP-NONE-NEXT:    ;;
;
; FP-ALL-LABEL: fn1:
; FP-ALL:       # %bb.0: # %entry
; FP-ALL-NEXT:    addd $r12 = $r12, -160
; FP-ALL-NEXT:    get $r16 = $ra
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    .cfi_def_cfa_offset 160
; FP-ALL-NEXT:    sd 124[$r12] = $r16
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    .cfi_offset 67, -24
; FP-ALL-NEXT:    so 92[$r12] = $r28r29r30r31
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    .cfi_offset 31, -32
; FP-ALL-NEXT:    .cfi_offset 30, -40
; FP-ALL-NEXT:    .cfi_offset 29, -48
; FP-ALL-NEXT:    .cfi_offset 28, -56
; FP-ALL-NEXT:    so 60[$r12] = $r24r25r26r27
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    .cfi_offset 27, -64
; FP-ALL-NEXT:    .cfi_offset 26, -72
; FP-ALL-NEXT:    .cfi_offset 25, -80
; FP-ALL-NEXT:    .cfi_offset 24, -88
; FP-ALL-NEXT:    so 28[$r12] = $r20r21r22r23
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    .cfi_offset 23, -96
; FP-ALL-NEXT:    .cfi_offset 22, -104
; FP-ALL-NEXT:    .cfi_offset 21, -112
; FP-ALL-NEXT:    .cfi_offset 20, -120
; FP-ALL-NEXT:    sq 12[$r12] = $r18r19
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    .cfi_offset 19, -128
; FP-ALL-NEXT:    .cfi_offset 18, -136
; FP-ALL-NEXT:    sd 132[$r12] = $r11
; FP-ALL-NEXT:    copyd $r19 = $r10
; FP-ALL-NEXT:    copyd $r20 = $r9
; FP-ALL-NEXT:    copyd $r21 = $r8
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    copyd $r22 = $r7
; FP-ALL-NEXT:    copyd $r23 = $r6
; FP-ALL-NEXT:    copyd $r24 = $r5
; FP-ALL-NEXT:    copyd $r25 = $r4
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    copyd $r26 = $r3
; FP-ALL-NEXT:    copyd $r27 = $r2
; FP-ALL-NEXT:    copyd $r28 = $r1
; FP-ALL-NEXT:    copyd $r29 = $r0
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    lwz $r30 = 176[$r12]
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    lwz $r31 = 168[$r12]
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    lwz $r18 = 160[$r12]
; FP-ALL-NEXT:    copyd $r1 = $r27
; FP-ALL-NEXT:    call fn3
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r28, $r29
; FP-ALL-NEXT:    ld $r1 = 132[$r12]
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r27
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r26
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r25
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r24
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r23
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r22
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r21
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r20
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r19
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r1
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r18
; FP-ALL-NEXT:    lq $r18r19 = 12[$r12]
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r31
; FP-ALL-NEXT:    lo $r20r21r22r23 = 28[$r12]
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    addw $r0 = $r0, $r30
; FP-ALL-NEXT:    lo $r24r25r26r27 = 60[$r12]
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    lo $r28r29r30r31 = 92[$r12]
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    ld $r16 = 124[$r12]
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    set $ra = $r16
; FP-ALL-NEXT:    addd $r12 = $r12, 160
; FP-ALL-NEXT:    ;;
; FP-ALL-NEXT:    .cfi_def_cfa_offset 0
; FP-ALL-NEXT:    ret
; FP-ALL-NEXT:    ;;
entry:
  %call = tail call i32 bitcast (i32 (...)* @fn3 to i32 (i32, i32)*)(i32 %a, i32 %c)
  %add = add nsw i32 %b, %a
  %add1 = add nsw i32 %add, %c
  %add2 = add nsw i32 %add1, %d
  %add3 = add nsw i32 %add2, %e
  %add4 = add nsw i32 %add3, %f
  %add5 = add nsw i32 %add4, %g
  %add6 = add nsw i32 %add5, %h
  %add7 = add nsw i32 %add6, %i
  %add8 = add nsw i32 %add7, %j
  %add9 = add nsw i32 %add8, %k
  %add10 = add nsw i32 %add9, %l
  %add11 = add nsw i32 %add10, %m
  %add12 = add nsw i32 %add11, %n
  %add13 = add nsw i32 %add12, %o
  ret i32 %add13
}

declare dso_local i32 @fn3(...)
