; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s | FileCheck %s
target triple = "kvx-kalray-cos"

define i64 @asm_clobber_single_none(<2 x i64> %v, i64 returned %A) {
; CHECK-LABEL: asm_clobber_single_none:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r3 = $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    movetq $r0r1 = $r0, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    copyd $r0 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %vecext = extractelement <2 x i64> %v, i32 0
  %vecext1 = extractelement <2 x i64> %v, i32 1
  %0 = tail call <2 x i64> asm sideeffect "movetq $0 = $1, $2", "=r,r,r,~{$r2}"(i64 %vecext, i64 %vecext1)
  ret i64 %A
}

define i64 @asm_clobber_single_single(i64 returned %A) {
; CHECK-LABEL: asm_clobber_single_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r1 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    movetq $r2r3 = $r1, $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    copyd $r0 = $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = tail call <2 x i64> asm sideeffect "movetq $0 = $1, $1", "=r,r,~{$r0}"(i64 %A)
  ret i64 %A
}

define i8* @asm_clobber_single_pair(i8* returned %A){
; CHECK-LABEL: asm_clobber_single_pair:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r2 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  tail call void asm sideeffect "", "r,~{$r0r1}"(i8* %A)
  ret i8* %A
}

define i8* @asm_clobber_single_quad(i8* nocapture readnone %A, i8* %B, i8* readnone returned %C){
; CHECK-LABEL: asm_clobber_single_quad:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r4 = $r2
; CHECK-NEXT:    copyd $r5 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    copyd $r0 = $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  tail call void asm sideeffect "copyd $$r0 = $0", "r,~{$r0r1r2r3}"(i8* %B)
  ret i8* %C
}

define <2 x i64> @asm_clobber_double_single(<2 x i64> returned %a) {
; CHECK-LABEL: asm_clobber_double_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r2 = $r0
; CHECK-NEXT:    copyd $r3 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    copyd $r1 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  tail call void asm sideeffect "", "r,~{$r1}"(<2 x i64> %a)
  ret <2 x i64> %a
}

define <2 x i64> @asm_clobber_double_double(<2 x i64> returned %a) {
; CHECK-LABEL: asm_clobber_double_double:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r2 = $r1
; CHECK-NEXT:    copyd $r3 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    copyd $r0 = $r3
; CHECK-NEXT:    copyd $r1 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  tail call void asm sideeffect "", "~{$r0r1}"()
  ret <2 x i64> %a
}

define <2 x i64> @asm_clobber_double_quad(<2 x i64> returned %a) {
; CHECK-LABEL: asm_clobber_double_quad:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r4 = $r1
; CHECK-NEXT:    copyd $r5 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    copyd $r0 = $r5
; CHECK-NEXT:    copyd $r1 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  tail call void asm sideeffect "", "~{$r0r1r2r3}"()
  ret <2 x i64> %a
}

define float @asm_clobber_multiple_quad(float %a, <2 x i64> %b, <4 x i64> %c){
; CHECK-LABEL: asm_clobber_multiple_quad:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r12 = $r12, -32
; CHECK-NEXT:    get $r16 = $ra
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 24[$r12] = $r16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sd 16[$r12] = $r18
; CHECK-NEXT:    copyd $r4 = $r3
; CHECK-NEXT:    copyd $r5 = $r2
; CHECK-NEXT:    copyd $r6 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r18 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    addd $r0 = $r6, $r5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    addd $r0 = $r0, $r4
; CHECK-NEXT:    call __floatdisf
; CHECK-NEXT:    ;;
; CHECK-NEXT:    faddw $r0 = $r0, $r18
; CHECK-NEXT:    ld $r18 = 16[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ld $r16 = 24[$r12]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    set $ra = $r16
; CHECK-NEXT:    addd $r12 = $r12, 32
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  tail call void asm sideeffect "", "~{$r0r1r2r3}"()
  %vecext = extractelement <2 x i64> %b, i32 0
  %vecext1 = extractelement <2 x i64> %b, i32 1
  %add = add nsw i64 %vecext, %vecext1
  %vecext2 = extractelement <4 x i64> %c, i32 0
  %add3 = add nsw i64 %add, %vecext2
  %conv = sitofp i64 %add3 to float
  %add4 = fadd float %conv, %a
  ret float %add4
}

define void @asm_clobber_quad_single(<4 x i64> %a){
; CHECK-LABEL: asm_clobber_quad_single:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    #APP
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  tail call void asm sideeffect "", "~{$r0}"()
  ret void
}

define <4 x i64> @asm_clobber_quad_double(<4 x i64> returned %a){
; CHECK-LABEL: asm_clobber_quad_double:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    #APP
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  tail call void asm sideeffect "", "r"(<4 x i64> %a)
  ret <4 x i64> %a
}

define <4 x i64> @asm_clobber_quad_quad(<4 x i64> returned %a){
; CHECK-LABEL: asm_clobber_quad_quad:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r4 = $r3
; CHECK-NEXT:    copyd $r5 = $r2
; CHECK-NEXT:    copyd $r6 = $r1
; CHECK-NEXT:    copyd $r7 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    copyd $r0 = $r7
; CHECK-NEXT:    copyd $r1 = $r6
; CHECK-NEXT:    copyd $r2 = $r5
; CHECK-NEXT:    copyd $r3 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  tail call void asm sideeffect "", "~{$r0r1r2r3}"()
  ret <4 x i64> %a
}

define <4 x i64> @asm_clobber_quad_quad_use(<4 x i64> returned %a){
; CHECK-LABEL: asm_clobber_quad_quad_use:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r4 = $r3
; CHECK-NEXT:    copyd $r5 = $r2
; CHECK-NEXT:    copyd $r6 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    copyd $r0 = $r6
; CHECK-NEXT:    copyd $r2 = $r5
; CHECK-NEXT:    copyd $r3 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  tail call void asm sideeffect "", "~{$r0},~{$r2r3}"()
  ret <4 x i64> %a
}

define i64 @local_regs(i32 %a, i64 %b, i64 %c, i64 %d, i64 %e, i64 %f, i64 %g){
; CHECK-LABEL: local_regs:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r1 = $r2
; CHECK-NEXT:    copyd $r2 = $r3
; CHECK-NEXT:    copyd $r7 = $r1
; CHECK-NEXT:    copyd $r8 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r7
; CHECK-NEXT:    copyd $r3 = $r4
; CHECK-NEXT:    copyd $r4 = $r5
; CHECK-NEXT:    copyd $r5 = $r6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    scall $r8
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = tail call i64 asm sideeffect "scall $6\0A\09;;", "={$r0},{$r1},{$r2},{$r3},{$r4},{$r5},ir,0,~{memory}"(i64 %c, i64 %d, i64 %e, i64 %f, i64 %g, i32 %a, i64 %b)
  ret i64 %0
}
