; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -o - %s -O2 -verify-machineinstrs | FileCheck %s --check-prefixes=CHECK
; RUN: llc -mcpu=kv3-2 -o - %s -O2 -verify-machineinstrs | FileCheck %s --check-prefixes=CHECK
; RUN: clang -O2 -c -o /dev/null %s
; RUN: clang -O2 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define i8 @loadcbc(i8 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadcbc:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lbz.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %conv = zext i8 %a to i64
  %0 = tail call i64 @llvm.kvx.loadc.u.i64.p0(i64 %conv, ptr %ptr, i32 8, i64 %cond, i32 0, i32 2, i32 -1)
  %conv1 = trunc i64 %0 to i8
  ret i8 %conv1
}

define i64 @loadcbl(i64 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadcbl:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lbz.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call i64 @llvm.kvx.loadc.u.i64.p0(i64 %a, ptr %ptr, i32 8, i64 %cond, i32 0, i32 2, i32 -1)
  ret i64 %0
}

define i16 @loadchs(i16 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadchs:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lhz.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %conv = zext i16 %a to i64
  %0 = tail call i64 @llvm.kvx.loadc.u.i64.p0(i64 %conv, ptr %ptr, i32 16, i64 %cond, i32 0, i32 2, i32 -1)
  %conv1 = trunc i64 %0 to i16
  ret i16 %conv1
}

define i64 @loadchl(i64 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadchl:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lhz.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call i64 @llvm.kvx.loadc.u.i64.p0(i64 %a, ptr %ptr, i32 16, i64 %cond, i32 0, i32 2, i32 -1)
  ret i64 %0
}

define i32 @loadcwi(i32 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadcwi:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %conv = zext i32 %a to i64
  %0 = tail call i64 @llvm.kvx.loadc.u.i64.p0(i64 %conv, ptr %ptr, i32 32, i64 %cond, i32 0, i32 2, i32 -1)
  %conv1 = trunc i64 %0 to i32
  ret i32 %conv1
}

define i64 @loadcwl(i64 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadcwl:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call i64 @llvm.kvx.loadc.u.i64.p0(i64 %a, ptr %ptr, i32 32, i64 %cond, i32 0, i32 2, i32 -1)
  ret i64 %0
}

define i64 @loadcdl(i64 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadcdl:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    ld.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call i64 @llvm.kvx.loadc.u.i64.p0(i64 %a, ptr %ptr, i32 64, i64 %cond, i32 0, i32 2, i32 -1)
  ret i64 %0
}

define i128 @loadcq(i128 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadcq:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lq.dltz $r3 ? $r0r1 = [$r2]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast i128 %a to <2 x i64>
  %1 = tail call <2 x i64> @llvm.kvx.loadc.u.v2i64.p0(<2 x i64> %0, ptr %ptr, i32 128, i64 %cond, i32 0, i32 2, i32 -1)
  %2 = bitcast <2 x i64> %1 to i128
  ret i128 %2
}

define half @loadchf(half %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadchf:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lhz.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call half @llvm.kvx.loadc.u.f16.p0(half %a, ptr %ptr, i32 16, i64 %cond, i32 0, i32 2, i32 -1)
  ret half %0
}

define float @loadcwf(float %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadcwf:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call float @llvm.kvx.loadc.u.f32.p0(float %a, ptr %ptr, i32 32, i64 %cond, i32 0, i32 2, i32 -1)
  ret float %0
}

define double @loadcdf(double %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadcdf:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    ld.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call double @llvm.kvx.loadc.u.f64.p0(double %a, ptr %ptr, i32 64, i64 %cond, i32 0, i32 2, i32 -1)
  ret double %0
}

define <2 x i32> @loadc64(<2 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc64:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    ld.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call <2 x i32> @llvm.kvx.loadc.u.v2i32.p0(<2 x i32> %a, ptr %ptr, i32 64, i64 %cond, i32 0, i32 2, i32 -1)
  ret <2 x i32> %0
}

define <4 x i32> @loadc128(<4 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc128:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lq.dltz $r3 ? $r0r1 = [$r2]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <4 x i32> %a to <2 x i64>
  %1 = tail call <2 x i64> @llvm.kvx.loadc.u.v2i64.p0(<2 x i64> %0, ptr %ptr, i32 128, i64 %cond, i32 0, i32 2, i32 -1)
  %2 = bitcast <2 x i64> %1 to <4 x i32>
  ret <4 x i32> %2
}

define i64 @loadcwls(i64 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadcwls:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz.s.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call i64 @llvm.kvx.loadc.u.i64.p0(i64 %a, ptr %ptr, i32 32, i64 %cond, i32 1, i32 2, i32 -1)
  ret i64 %0
}

define i64 @loadcwlu(i64 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadcwlu:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz.u.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call i64 @llvm.kvx.loadc.u.i64.p0(i64 %a, ptr %ptr, i32 32, i64 %cond, i32 2, i32 2, i32 -1)
  ret i64 %0
}

define i64 @loadcwlus(i64 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadcwlus:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz.us.dltz $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = tail call i64 @llvm.kvx.loadc.u.i64.p0(i64 %a, ptr %ptr, i32 32, i64 %cond, i32 3, i32 2, i32 -1)
  ret i64 %0
}

define <8 x i32> @loadc256_dltz(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_dltz:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.dltz $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 2, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_dnez(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_dnez:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.dnez $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 0, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_deqz(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_deqz:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.deqz $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 1, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_dgez(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_dgez:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.dgez $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 3, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_dlez(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_dlez:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.dlez $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 4, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_dgtz(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_dgtz:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.dgtz $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 5, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_odd(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_odd:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.odd $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 6, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_even(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_even:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.even $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 7, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_wnez(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_wnez:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.wnez $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 8, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_weqz(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_weqz:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.weqz $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 9, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_wltz(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_wltz:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.wltz $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 10, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_wgez(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_wgez:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.wgez $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 11, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_wlez(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_wlez:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.wlez $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 12, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define <8 x i32> @loadc256_wgtz(<8 x i32> %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_wgtz:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.wgtz $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64> %0, ptr %ptr, i32 256, i64 %cond, i32 0, i32 13, i32 -1)
  %2 = bitcast <4 x i64> %1 to <8 x i32>
  ret <8 x i32> %2
}

define i32 @loadc_vol(i32 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc_vol:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lwz.wgez $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
entry:
  %conv = sext i32 %a to i64
  %0 = tail call i64 @llvm.kvx.loadc.u.vol.i64.p0(i64 %conv, ptr %ptr, i32 32, i64 %cond, i32 0, i32 11, i32 -1)
  %conv3 = trunc i64 %0 to i32
  ret i32 %conv3
}

define i32 @loadc_novol(i32 %a, ptr %ptr, i64 %cond) {
; CHECK-LABEL: loadc_novol:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sxwd $r0 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lwz.wgez $r2 ? $r0 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
entry:
  %conv = sext i32 %a to i64
  %0 = tail call i64 @llvm.kvx.loadc.u.i64.p0(i64 %conv, ptr %ptr, i32 32, i64 %cond, i32 0, i32 11, i32 -1)
  %conv3 = trunc i64 %0 to i32
  ret i32 %conv3
}

declare i64 @llvm.kvx.loadc.u.i64.p0(i64, ptr, i32, i64, i32, i32, i32)

declare <2 x i64> @llvm.kvx.loadc.u.v2i64.p0(<2 x i64>, ptr, i32, i64, i32, i32, i32)

declare half @llvm.kvx.loadc.u.f16.p0(half, ptr, i32, i64, i32, i32, i32)

declare float @llvm.kvx.loadc.u.f32.p0(float, ptr, i32, i64, i32, i32, i32)

declare double @llvm.kvx.loadc.u.f64.p0(double, ptr, i32, i64, i32, i32, i32)

declare <2 x i32> @llvm.kvx.loadc.u.v2i32.p0(<2 x i32>, ptr, i32, i64, i32, i32, i32)

declare <4 x i64> @llvm.kvx.loadc.u.v4i64.p0(<4 x i64>, ptr, i32, i64, i32, i32, i32)

declare i64 @llvm.kvx.loadc.u.vol.i64.p0(i64, ptr, i32, i64, i32, i32, i32)

