; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mcpu=kv3-2 -o - %s -O2 -verify-machineinstrs | FileCheck %s --check-prefixes=CHECK
; RUN: clang -O2 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define <8 x i32> @loadc256_mt(<8 x i32> %a, i8* readonly %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_mt:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.mt $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = bitcast i8* %ptr to <4 x i64>*
  %2 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64> %0, <4 x i64>* %1, i32 256, i64 %cond, i32 0, i32 -1, i32 4)
  %3 = bitcast <4 x i64> %2 to <8 x i32>
  ret <8 x i32> %3
}

declare <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64>, <4 x i64>*, i32, i64, i32, i32, i32)

define <8 x i32> @loadc256_mf(<8 x i32> %a, i8* readonly %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_mf:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.mf $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = bitcast i8* %ptr to <4 x i64>*
  %2 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64> %0, <4 x i64>* %1, i32 256, i64 %cond, i32 0, i32 -1, i32 5)
  %3 = bitcast <4 x i64> %2 to <8 x i32>
  ret <8 x i32> %3
}

define <8 x i32> @loadc256_mtc(<8 x i32> %a, i8* readonly %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_mtc:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.mtc $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = bitcast i8* %ptr to <4 x i64>*
  %2 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64> %0, <4 x i64>* %1, i32 256, i64 %cond, i32 0, i32 -1, i32 6)
  %3 = bitcast <4 x i64> %2 to <8 x i32>
  ret <8 x i32> %3
}

define <8 x i32> @loadc256_mfc(<8 x i32> %a, i8* readonly %ptr, i64 %cond) {
; CHECK-LABEL: loadc256_mfc:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.mfc $r5 ? $r0r1r2r3 = [$r4]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = bitcast <8 x i32> %a to <4 x i64>
  %1 = bitcast i8* %ptr to <4 x i64>*
  %2 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64> %0, <4 x i64>* %1, i32 256, i64 %cond, i32 0, i32 -1, i32 7)
  %3 = bitcast <4 x i64> %2 to <8 x i32>
  ret <8 x i32> %3
}

define <4 x i32> @loadc128_mt(<4 x i32> %a, i8* %ptr, i64 %cond) {
; CHECK-LABEL: loadc128_mt:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.mt $r3 ? $r0r1r2r3 = [$r2]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = bitcast <4 x i32> %a to <2 x i64>
  %1 = shufflevector <2 x i64> %0, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %2 = bitcast i8* %ptr to <4 x i64>*
  %3 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64> %1, <4 x i64>* %2, i32 256, i64 %cond, i32 0, i32 -1, i32 4)
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %5 = bitcast <2 x i64> %4 to <4 x i32>
  ret <4 x i32> %5
}

define <4 x i32> @loadc128_mf(<4 x i32> %a, i8* %ptr, i64 %cond) {
; CHECK-LABEL: loadc128_mf:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.mf $r3 ? $r0r1r2r3 = [$r2]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = bitcast <4 x i32> %a to <2 x i64>
  %1 = shufflevector <2 x i64> %0, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %2 = bitcast i8* %ptr to <4 x i64>*
  %3 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64> %1, <4 x i64>* %2, i32 256, i64 %cond, i32 0, i32 -1, i32 5)
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %5 = bitcast <2 x i64> %4 to <4 x i32>
  ret <4 x i32> %5
}

define <4 x i32> @loadc128_mtc(<4 x i32> %a, i8* %ptr, i64 %cond) {
; CHECK-LABEL: loadc128_mtc:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.mtc $r3 ? $r0r1r2r3 = [$r2]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = bitcast <4 x i32> %a to <2 x i64>
  %1 = shufflevector <2 x i64> %0, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %2 = bitcast i8* %ptr to <4 x i64>*
  %3 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64> %1, <4 x i64>* %2, i32 256, i64 %cond, i32 0, i32 -1, i32 6)
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %5 = bitcast <2 x i64> %4 to <4 x i32>
  ret <4 x i32> %5
}

define <4 x i32> @loadc128_mfc(<4 x i32> %a, i8* %ptr, i64 %cond) {
; CHECK-LABEL: loadc128_mfc:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.mfc $r3 ? $r0r1r2r3 = [$r2]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = bitcast <4 x i32> %a to <2 x i64>
  %1 = shufflevector <2 x i64> %0, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %2 = bitcast i8* %ptr to <4 x i64>*
  %3 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64> %1, <4 x i64>* %2, i32 256, i64 %cond, i32 0, i32 -1, i32 7)
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %5 = bitcast <2 x i64> %4 to <4 x i32>
  ret <4 x i32> %5
}

define <2 x i32> @loadc64_mt(<2 x i32> %a, i8* %ptr, i64 %cond) {
; CHECK-LABEL: loadc64_mt:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.mt $r2 ? $r0r1r2r3 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = bitcast <2 x i32> %a to <1 x i64>
  %1 = shufflevector <1 x i64> %0, <1 x i64> undef, <4 x i32> <i32 0, i32 undef, i32 undef, i32 undef>
  %2 = bitcast i8* %ptr to <4 x i64>*
  %3 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64> %1, <4 x i64>* %2, i32 256, i64 %cond, i32 0, i32 -1, i32 4)
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <1 x i32> zeroinitializer
  %5 = bitcast <1 x i64> %4 to <2 x i32>
  ret <2 x i32> %5
}

define <2 x i32> @loadc64_mf(<2 x i32> %a, i8* %ptr, i64 %cond) {
; CHECK-LABEL: loadc64_mf:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.mf $r2 ? $r0r1r2r3 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = bitcast <2 x i32> %a to <1 x i64>
  %1 = shufflevector <1 x i64> %0, <1 x i64> undef, <4 x i32> <i32 0, i32 undef, i32 undef, i32 undef>
  %2 = bitcast i8* %ptr to <4 x i64>*
  %3 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64> %1, <4 x i64>* %2, i32 256, i64 %cond, i32 0, i32 -1, i32 5)
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <1 x i32> zeroinitializer
  %5 = bitcast <1 x i64> %4 to <2 x i32>
  ret <2 x i32> %5
}

define <2 x i32> @loadc64_mtc(<2 x i32> %a, i8* %ptr, i64 %cond) {
; CHECK-LABEL: loadc64_mtc:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.mtc $r2 ? $r0r1r2r3 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = bitcast <2 x i32> %a to <1 x i64>
  %1 = shufflevector <1 x i64> %0, <1 x i64> undef, <4 x i32> <i32 0, i32 undef, i32 undef, i32 undef>
  %2 = bitcast i8* %ptr to <4 x i64>*
  %3 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64> %1, <4 x i64>* %2, i32 256, i64 %cond, i32 0, i32 -1, i32 6)
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <1 x i32> zeroinitializer
  %5 = bitcast <1 x i64> %4 to <2 x i32>
  ret <2 x i32> %5
}

define <2 x i32> @loadc64_mfc(<2 x i32> %a, i8* %ptr, i64 %cond) {
; CHECK-LABEL: loadc64_mfc:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lo.mfc $r2 ? $r0r1r2r3 = [$r1]
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = bitcast <2 x i32> %a to <1 x i64>
  %1 = shufflevector <1 x i64> %0, <1 x i64> undef, <4 x i32> <i32 0, i32 undef, i32 undef, i32 undef>
  %2 = bitcast i8* %ptr to <4 x i64>*
  %3 = tail call <4 x i64> @llvm.kvx.loadc.u.v4i64(<4 x i64> %1, <4 x i64>* %2, i32 256, i64 %cond, i32 0, i32 -1, i32 7)
  %4 = shufflevector <4 x i64> %3, <4 x i64> undef, <1 x i32> zeroinitializer
  %5 = bitcast <1 x i64> %4 to <2 x i32>
  ret <2 x i32> %5
}

