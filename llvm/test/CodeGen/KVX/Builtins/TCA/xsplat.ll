; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O3 -o - %s -mcpu=kv3-1 | FileCheck %s --check-prefixes=ALL,CV1
; RUN: llc -O3 -o - %s -mcpu=kv3-2 | FileCheck %s --check-prefixes=ALL,CV2
; RUN: clang -O3 -march=kv3-1 -c -o /dev/null %s
; RUN: clang -O3 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define void @xsplat256rr(<256 x i1>* nocapture %0, i64 %1) {
; ALL-LABEL: xsplat256rr:
; ALL:       # %bb.0:
; ALL-NEXT:    xmovetq $a0.lo = $r1, $r1
; ALL-NEXT:    xmovetq $a0.hi = $r1, $r1
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    xso 0[$r0] = $a0
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 4)
  %3 = tail call <256 x i1> @llvm.kvx.xsplat.v256i1(i64 %1)
  store <256 x i1> %3, <256 x i1>* %0
  ret void
}

declare <256 x i1> @llvm.kvx.xsplat.v256i1(i64)

define void @xsplat256ri16(<256 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat256ri16:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x7fff
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 5)
;
; CV2-LABEL: xsplat256ri16:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x7fff
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 4)
  %3 = tail call <256 x i1> @llvm.kvx.xsplat.v256i1(i64 32767)
  store <256 x i1> %3, <256 x i1>* %0
  ret void
}

define void @xsplat256ri37(<256 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat256ri37:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x8000
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 5)
;
; CV2-LABEL: xsplat256ri37:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x8000
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 4)
  %3 = tail call <256 x i1> @llvm.kvx.xsplat.v256i1(i64 32768)
  store <256 x i1> %3, <256 x i1>* %0
  ret void
}

define void @xsplat256ri64(<256 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat256ri64:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x80000000000
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 5)
;
; CV2-LABEL: xsplat256ri64:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x80000000000
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 4)
  %3 = tail call <256 x i1> @llvm.kvx.xsplat.v256i1(i64 8796093022208)
  store <256 x i1> %3, <256 x i1>* %0
  ret void
}

define void @xsplat512rr(<512 x i1>* nocapture %0, i64 %1) {
; ALL-LABEL: xsplat512rr:
; ALL:       # %bb.0:
; ALL-NEXT:    xmovetq $a0.lo = $r1, $r1
; ALL-NEXT:    xmovetq $a0.hi = $r1, $r1
; ALL-NEXT:    ;; # (end cycle 0)
; ALL-NEXT:    xcopyo $a1 = $a0
; ALL-NEXT:    ;; # (end cycle 4)
; ALL-NEXT:    xso 0[$r0] = $a0
; ALL-NEXT:    ;; # (end cycle 5)
; ALL-NEXT:    xso 32[$r0] = $a1
; ALL-NEXT:    ret
; ALL-NEXT:    ;; # (end cycle 8)
  %3 = tail call <512 x i1> @llvm.kvx.xsplat.v512i1(i64 %1)
  store <512 x i1> %3, <512 x i1>* %0
  ret void
}

declare <512 x i1> @llvm.kvx.xsplat.v512i1(i64)

define void @xsplat512ri16(<512 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat512ri16:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x7fff
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 9)
;
; CV2-LABEL: xsplat512ri16:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x7fff
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xcopyo $a1 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 8)
  %3 = tail call <512 x i1> @llvm.kvx.xsplat.v512i1(i64 32767)
  store <512 x i1> %3, <512 x i1>* %0
  ret void
}

define void @xsplat512ri37(<512 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat512ri37:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x8000
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 9)
;
; CV2-LABEL: xsplat512ri37:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x8000
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xcopyo $a1 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 8)
  %3 = tail call <512 x i1> @llvm.kvx.xsplat.v512i1(i64 32768)
  store <512 x i1> %3, <512 x i1>* %0
  ret void
}

define void @xsplat512ri64(<512 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat512ri64:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x80000000000
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 9)
;
; CV2-LABEL: xsplat512ri64:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x80000000000
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xcopyo $a1 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ;; # (end cycle 5)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 8)
  %3 = tail call <512 x i1> @llvm.kvx.xsplat.v512i1(i64 8796093022208)
  store <512 x i1> %3, <512 x i1>* %0
  ret void
}

define void @xsplat1024rr(<1024 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat1024rr:
; CV1:       # %bb.0:
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xcopyo $a3 = $a0
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xso 96[$r0] = $a3
; CV1-NEXT:    ;; # (end cycle 8)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    xcopyo $a2 = $a0
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    xso 64[$r0] = $a2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 18)
;
; CV2-LABEL: xsplat1024rr:
; CV2:       # %bb.0:
; CV2-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV2-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xsplatov $a0a1a2a3 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    xso 96[$r0] = $a3
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    xso 64[$r0] = $a2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 11)
  %3 = tail call <1024 x i1> @llvm.kvx.xsplat.v1024i1(i64 %1)
  store <1024 x i1> %3, <1024 x i1>* %0
  ret void
}

declare <1024 x i1> @llvm.kvx.xsplat.v1024i1(i64)

define void @xsplat1024ri16(<1024 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat1024ri16:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x7fff
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xcopyo $a3 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xso 96[$r0] = $a3
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    xcopyo $a2 = $a0
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    xso 64[$r0] = $a2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 19)
;
; CV2-LABEL: xsplat1024ri16:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x7fff
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xsplatov $a0a1a2a3 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    xso 96[$r0] = $a3
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    xso 64[$r0] = $a2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 11)
  %3 = tail call <1024 x i1> @llvm.kvx.xsplat.v1024i1(i64 32767)
  store <1024 x i1> %3, <1024 x i1>* %0
  ret void
}

define void @xsplat1024ri37(<1024 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat1024ri37:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x8000
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xcopyo $a3 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xso 96[$r0] = $a3
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    xcopyo $a2 = $a0
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    xso 64[$r0] = $a2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 19)
;
; CV2-LABEL: xsplat1024ri37:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x8000
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xsplatov $a0a1a2a3 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    xso 96[$r0] = $a3
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    xso 64[$r0] = $a2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 11)
  %3 = tail call <1024 x i1> @llvm.kvx.xsplat.v1024i1(i64 32768)
  store <1024 x i1> %3, <1024 x i1>* %0
  ret void
}

define void @xsplat1024ri64(<1024 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat1024ri64:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x80000000000
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xcopyo $a3 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xso 96[$r0] = $a3
; CV1-NEXT:    ;; # (end cycle 9)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    xcopyo $a2 = $a0
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    xso 64[$r0] = $a2
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 19)
;
; CV2-LABEL: xsplat1024ri64:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x80000000000
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xsplatov $a0a1a2a3 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    xso 96[$r0] = $a3
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    xso 64[$r0] = $a2
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 11)
  %3 = tail call <1024 x i1> @llvm.kvx.xsplat.v1024i1(i64 8796093022208)
  store <1024 x i1> %3, <1024 x i1>* %0
  ret void
}

define void @xsplat2048rr(<2048 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat2048rr:
; CV1:       # %bb.0:
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    xcopyo $a2 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xcopyo $a3 = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    xmt44d $a4a5a6a7 = $a0a1a2a3
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    xso 96[$r0] = $a3
; CV1-NEXT:    ;; # (end cycle 12)
; CV1-NEXT:    xso 64[$r0] = $a2
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    xso 160[$r0] = $a5
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    xso 128[$r0] = $a4
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    xso 224[$r0] = $a7
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    xso 192[$r0] = $a6
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 17)
;
; CV2-LABEL: xsplat2048rr:
; CV2:       # %bb.0:
; CV2-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV2-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xsplatov $a0a1a2a3 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    xcopyv $a4a5a6a7 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    xso 96[$r0] = $a3
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    xso 64[$r0] = $a2
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    xso 160[$r0] = $a5
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    xso 128[$r0] = $a4
; CV2-NEXT:    ;; # (end cycle 13)
; CV2-NEXT:    xso 224[$r0] = $a7
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    xso 192[$r0] = $a6
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 15)
  %3 = tail call <2048 x i1> @llvm.kvx.xsplat.v2048i1(i64 %1)
  store <2048 x i1> %3, <2048 x i1>* %0
  ret void
}

declare <2048 x i1> @llvm.kvx.xsplat.v2048i1(i64)

define void @xsplat2048ri16(<2048 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat2048ri16:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x7fff
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xcopyo $a2 = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xcopyo $a3 = $a0
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    xmt44d $a4a5a6a7 = $a0a1a2a3
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 12)
; CV1-NEXT:    xso 96[$r0] = $a3
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    xso 64[$r0] = $a2
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    xso 160[$r0] = $a5
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    xso 128[$r0] = $a4
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    xso 224[$r0] = $a7
; CV1-NEXT:    ;; # (end cycle 17)
; CV1-NEXT:    xso 192[$r0] = $a6
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 18)
;
; CV2-LABEL: xsplat2048ri16:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x7fff
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xsplatov $a0a1a2a3 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    xcopyv $a4a5a6a7 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    xso 96[$r0] = $a3
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    xso 64[$r0] = $a2
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    xso 160[$r0] = $a5
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    xso 128[$r0] = $a4
; CV2-NEXT:    ;; # (end cycle 13)
; CV2-NEXT:    xso 224[$r0] = $a7
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    xso 192[$r0] = $a6
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 15)
  %3 = tail call <2048 x i1> @llvm.kvx.xsplat.v2048i1(i64 32767)
  store <2048 x i1> %3, <2048 x i1>* %0
  ret void
}

define void @xsplat2048ri37(<2048 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat2048ri37:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x8000
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xcopyo $a2 = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xcopyo $a3 = $a0
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    xmt44d $a4a5a6a7 = $a0a1a2a3
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 12)
; CV1-NEXT:    xso 96[$r0] = $a3
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    xso 64[$r0] = $a2
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    xso 160[$r0] = $a5
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    xso 128[$r0] = $a4
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    xso 224[$r0] = $a7
; CV1-NEXT:    ;; # (end cycle 17)
; CV1-NEXT:    xso 192[$r0] = $a6
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 18)
;
; CV2-LABEL: xsplat2048ri37:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x8000
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xsplatov $a0a1a2a3 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    xcopyv $a4a5a6a7 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    xso 96[$r0] = $a3
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    xso 64[$r0] = $a2
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    xso 160[$r0] = $a5
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    xso 128[$r0] = $a4
; CV2-NEXT:    ;; # (end cycle 13)
; CV2-NEXT:    xso 224[$r0] = $a7
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    xso 192[$r0] = $a6
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 15)
  %3 = tail call <2048 x i1> @llvm.kvx.xsplat.v2048i1(i64 32768)
  store <2048 x i1> %3, <2048 x i1>* %0
  ret void
}

define void @xsplat2048ri64(<2048 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat2048ri64:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x80000000000
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xcopyo $a2 = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xcopyo $a3 = $a0
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    xmt44d $a4a5a6a7 = $a0a1a2a3
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 12)
; CV1-NEXT:    xso 96[$r0] = $a3
; CV1-NEXT:    ;; # (end cycle 13)
; CV1-NEXT:    xso 64[$r0] = $a2
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    xso 160[$r0] = $a5
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    xso 128[$r0] = $a4
; CV1-NEXT:    ;; # (end cycle 16)
; CV1-NEXT:    xso 224[$r0] = $a7
; CV1-NEXT:    ;; # (end cycle 17)
; CV1-NEXT:    xso 192[$r0] = $a6
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 18)
;
; CV2-LABEL: xsplat2048ri64:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x80000000000
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xsplatov $a0a1a2a3 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    xcopyv $a4a5a6a7 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    xso 96[$r0] = $a3
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    xso 64[$r0] = $a2
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    xso 160[$r0] = $a5
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    xso 128[$r0] = $a4
; CV2-NEXT:    ;; # (end cycle 13)
; CV2-NEXT:    xso 224[$r0] = $a7
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    xso 192[$r0] = $a6
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 15)
  %3 = tail call <2048 x i1> @llvm.kvx.xsplat.v2048i1(i64 8796093022208)
  store <2048 x i1> %3, <2048 x i1>* %0
  ret void
}

define void @xsplat4096rr(<4096 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat4096rr:
; CV1:       # %bb.0:
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 4)
; CV1-NEXT:    xcopyo $a2 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xcopyo $a3 = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xmt44d $a4a5a6a7 = $a0a1a2a3
; CV1-NEXT:    ;; # (end cycle 10)
; CV1-NEXT:    xmt44d $a8a9a10a11 = $a4a5a6a7
; CV1-NEXT:    ;; # (end cycle 14)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    xmt44d $a12a13a14a15 = $a8a9a10a11
; CV1-NEXT:    ;; # (end cycle 18)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 19)
; CV1-NEXT:    xso 96[$r0] = $a3
; CV1-NEXT:    ;; # (end cycle 20)
; CV1-NEXT:    xso 64[$r0] = $a2
; CV1-NEXT:    ;; # (end cycle 21)
; CV1-NEXT:    xso 160[$r0] = $a5
; CV1-NEXT:    ;; # (end cycle 22)
; CV1-NEXT:    xso 128[$r0] = $a4
; CV1-NEXT:    ;; # (end cycle 23)
; CV1-NEXT:    xso 224[$r0] = $a7
; CV1-NEXT:    ;; # (end cycle 24)
; CV1-NEXT:    xso 192[$r0] = $a6
; CV1-NEXT:    ;; # (end cycle 25)
; CV1-NEXT:    xso 288[$r0] = $a9
; CV1-NEXT:    ;; # (end cycle 26)
; CV1-NEXT:    xso 256[$r0] = $a8
; CV1-NEXT:    ;; # (end cycle 27)
; CV1-NEXT:    xso 352[$r0] = $a11
; CV1-NEXT:    ;; # (end cycle 28)
; CV1-NEXT:    xso 320[$r0] = $a10
; CV1-NEXT:    ;; # (end cycle 29)
; CV1-NEXT:    xso 416[$r0] = $a13
; CV1-NEXT:    ;; # (end cycle 30)
; CV1-NEXT:    xso 384[$r0] = $a12
; CV1-NEXT:    ;; # (end cycle 31)
; CV1-NEXT:    xso 480[$r0] = $a15
; CV1-NEXT:    ;; # (end cycle 32)
; CV1-NEXT:    xso 448[$r0] = $a14
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 33)
;
; CV2-LABEL: xsplat4096rr:
; CV2:       # %bb.0:
; CV2-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV2-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xsplatov $a0a1a2a3 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    xcopyv $a8a9a10a11 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    xcopyv $a4a5a6a7 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    xso 96[$r0] = $a3
; CV2-NEXT:    xcopyv $a12a13a14a15 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    xso 64[$r0] = $a2
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    xso 288[$r0] = $a9
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    xso 256[$r0] = $a8
; CV2-NEXT:    ;; # (end cycle 13)
; CV2-NEXT:    xso 160[$r0] = $a5
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    xso 128[$r0] = $a4
; CV2-NEXT:    ;; # (end cycle 15)
; CV2-NEXT:    xso 224[$r0] = $a7
; CV2-NEXT:    ;; # (end cycle 16)
; CV2-NEXT:    xso 192[$r0] = $a6
; CV2-NEXT:    ;; # (end cycle 17)
; CV2-NEXT:    xso 352[$r0] = $a11
; CV2-NEXT:    ;; # (end cycle 18)
; CV2-NEXT:    xso 320[$r0] = $a10
; CV2-NEXT:    ;; # (end cycle 19)
; CV2-NEXT:    xso 416[$r0] = $a13
; CV2-NEXT:    ;; # (end cycle 20)
; CV2-NEXT:    xso 384[$r0] = $a12
; CV2-NEXT:    ;; # (end cycle 21)
; CV2-NEXT:    xso 480[$r0] = $a15
; CV2-NEXT:    ;; # (end cycle 22)
; CV2-NEXT:    xso 448[$r0] = $a14
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 23)
  %3 = tail call <4096 x i1> @llvm.kvx.xsplat.v4096i1(i64 %1)
  store <4096 x i1> %3, <4096 x i1>* %0
  ret void
}

declare <4096 x i1> @llvm.kvx.xsplat.v4096i1(i64)

define void @xsplat4096ri16(<4096 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat4096ri16:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x7fff
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xcopyo $a2 = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xcopyo $a3 = $a0
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    xmt44d $a4a5a6a7 = $a0a1a2a3
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    xmt44d $a8a9a10a11 = $a4a5a6a7
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    xmt44d $a12a13a14a15 = $a8a9a10a11
; CV1-NEXT:    ;; # (end cycle 19)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 20)
; CV1-NEXT:    xso 96[$r0] = $a3
; CV1-NEXT:    ;; # (end cycle 21)
; CV1-NEXT:    xso 64[$r0] = $a2
; CV1-NEXT:    ;; # (end cycle 22)
; CV1-NEXT:    xso 160[$r0] = $a5
; CV1-NEXT:    ;; # (end cycle 23)
; CV1-NEXT:    xso 128[$r0] = $a4
; CV1-NEXT:    ;; # (end cycle 24)
; CV1-NEXT:    xso 224[$r0] = $a7
; CV1-NEXT:    ;; # (end cycle 25)
; CV1-NEXT:    xso 192[$r0] = $a6
; CV1-NEXT:    ;; # (end cycle 26)
; CV1-NEXT:    xso 288[$r0] = $a9
; CV1-NEXT:    ;; # (end cycle 27)
; CV1-NEXT:    xso 256[$r0] = $a8
; CV1-NEXT:    ;; # (end cycle 28)
; CV1-NEXT:    xso 352[$r0] = $a11
; CV1-NEXT:    ;; # (end cycle 29)
; CV1-NEXT:    xso 320[$r0] = $a10
; CV1-NEXT:    ;; # (end cycle 30)
; CV1-NEXT:    xso 416[$r0] = $a13
; CV1-NEXT:    ;; # (end cycle 31)
; CV1-NEXT:    xso 384[$r0] = $a12
; CV1-NEXT:    ;; # (end cycle 32)
; CV1-NEXT:    xso 480[$r0] = $a15
; CV1-NEXT:    ;; # (end cycle 33)
; CV1-NEXT:    xso 448[$r0] = $a14
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 34)
;
; CV2-LABEL: xsplat4096ri16:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x7fff
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xsplatov $a0a1a2a3 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    xcopyv $a8a9a10a11 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    xcopyv $a4a5a6a7 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    xso 96[$r0] = $a3
; CV2-NEXT:    xcopyv $a12a13a14a15 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    xso 64[$r0] = $a2
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    xso 288[$r0] = $a9
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    xso 160[$r0] = $a5
; CV2-NEXT:    ;; # (end cycle 13)
; CV2-NEXT:    xso 128[$r0] = $a4
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    xso 224[$r0] = $a7
; CV2-NEXT:    ;; # (end cycle 15)
; CV2-NEXT:    xso 192[$r0] = $a6
; CV2-NEXT:    ;; # (end cycle 16)
; CV2-NEXT:    xso 256[$r0] = $a8
; CV2-NEXT:    ;; # (end cycle 17)
; CV2-NEXT:    xso 352[$r0] = $a11
; CV2-NEXT:    ;; # (end cycle 18)
; CV2-NEXT:    xso 320[$r0] = $a10
; CV2-NEXT:    ;; # (end cycle 19)
; CV2-NEXT:    xso 416[$r0] = $a13
; CV2-NEXT:    ;; # (end cycle 20)
; CV2-NEXT:    xso 384[$r0] = $a12
; CV2-NEXT:    ;; # (end cycle 21)
; CV2-NEXT:    xso 480[$r0] = $a15
; CV2-NEXT:    ;; # (end cycle 22)
; CV2-NEXT:    xso 448[$r0] = $a14
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 23)
  %3 = tail call <4096 x i1> @llvm.kvx.xsplat.v4096i1(i64 32767)
  store <4096 x i1> %3, <4096 x i1>* %0
  ret void
}

define void @xsplat4096ri37(<4096 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat4096ri37:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x8000
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xcopyo $a2 = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xcopyo $a3 = $a0
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    xmt44d $a4a5a6a7 = $a0a1a2a3
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    xmt44d $a8a9a10a11 = $a4a5a6a7
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    xmt44d $a12a13a14a15 = $a8a9a10a11
; CV1-NEXT:    ;; # (end cycle 19)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 20)
; CV1-NEXT:    xso 96[$r0] = $a3
; CV1-NEXT:    ;; # (end cycle 21)
; CV1-NEXT:    xso 64[$r0] = $a2
; CV1-NEXT:    ;; # (end cycle 22)
; CV1-NEXT:    xso 160[$r0] = $a5
; CV1-NEXT:    ;; # (end cycle 23)
; CV1-NEXT:    xso 128[$r0] = $a4
; CV1-NEXT:    ;; # (end cycle 24)
; CV1-NEXT:    xso 224[$r0] = $a7
; CV1-NEXT:    ;; # (end cycle 25)
; CV1-NEXT:    xso 192[$r0] = $a6
; CV1-NEXT:    ;; # (end cycle 26)
; CV1-NEXT:    xso 288[$r0] = $a9
; CV1-NEXT:    ;; # (end cycle 27)
; CV1-NEXT:    xso 256[$r0] = $a8
; CV1-NEXT:    ;; # (end cycle 28)
; CV1-NEXT:    xso 352[$r0] = $a11
; CV1-NEXT:    ;; # (end cycle 29)
; CV1-NEXT:    xso 320[$r0] = $a10
; CV1-NEXT:    ;; # (end cycle 30)
; CV1-NEXT:    xso 416[$r0] = $a13
; CV1-NEXT:    ;; # (end cycle 31)
; CV1-NEXT:    xso 384[$r0] = $a12
; CV1-NEXT:    ;; # (end cycle 32)
; CV1-NEXT:    xso 480[$r0] = $a15
; CV1-NEXT:    ;; # (end cycle 33)
; CV1-NEXT:    xso 448[$r0] = $a14
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 34)
;
; CV2-LABEL: xsplat4096ri37:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x8000
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xsplatov $a0a1a2a3 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    xcopyv $a8a9a10a11 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    xcopyv $a4a5a6a7 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    xso 96[$r0] = $a3
; CV2-NEXT:    xcopyv $a12a13a14a15 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    xso 64[$r0] = $a2
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    xso 288[$r0] = $a9
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    xso 160[$r0] = $a5
; CV2-NEXT:    ;; # (end cycle 13)
; CV2-NEXT:    xso 128[$r0] = $a4
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    xso 224[$r0] = $a7
; CV2-NEXT:    ;; # (end cycle 15)
; CV2-NEXT:    xso 192[$r0] = $a6
; CV2-NEXT:    ;; # (end cycle 16)
; CV2-NEXT:    xso 256[$r0] = $a8
; CV2-NEXT:    ;; # (end cycle 17)
; CV2-NEXT:    xso 352[$r0] = $a11
; CV2-NEXT:    ;; # (end cycle 18)
; CV2-NEXT:    xso 320[$r0] = $a10
; CV2-NEXT:    ;; # (end cycle 19)
; CV2-NEXT:    xso 416[$r0] = $a13
; CV2-NEXT:    ;; # (end cycle 20)
; CV2-NEXT:    xso 384[$r0] = $a12
; CV2-NEXT:    ;; # (end cycle 21)
; CV2-NEXT:    xso 480[$r0] = $a15
; CV2-NEXT:    ;; # (end cycle 22)
; CV2-NEXT:    xso 448[$r0] = $a14
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 23)
  %3 = tail call <4096 x i1> @llvm.kvx.xsplat.v4096i1(i64 32768)
  store <4096 x i1> %3, <4096 x i1>* %0
  ret void
}

define void @xsplat4096ri64(<4096 x i1>* nocapture %0, i64 %1) {
; CV1-LABEL: xsplat4096ri64:
; CV1:       # %bb.0:
; CV1-NEXT:    make $r1 = 0x80000000000
; CV1-NEXT:    ;; # (end cycle 0)
; CV1-NEXT:    xmovetq $a0.lo = $r1, $r1
; CV1-NEXT:    xmovetq $a0.hi = $r1, $r1
; CV1-NEXT:    ;; # (end cycle 1)
; CV1-NEXT:    xcopyo $a1 = $a0
; CV1-NEXT:    ;; # (end cycle 5)
; CV1-NEXT:    xcopyo $a2 = $a0
; CV1-NEXT:    ;; # (end cycle 6)
; CV1-NEXT:    xcopyo $a3 = $a0
; CV1-NEXT:    ;; # (end cycle 7)
; CV1-NEXT:    xmt44d $a4a5a6a7 = $a0a1a2a3
; CV1-NEXT:    ;; # (end cycle 11)
; CV1-NEXT:    xmt44d $a8a9a10a11 = $a4a5a6a7
; CV1-NEXT:    ;; # (end cycle 15)
; CV1-NEXT:    xso 32[$r0] = $a1
; CV1-NEXT:    xmt44d $a12a13a14a15 = $a8a9a10a11
; CV1-NEXT:    ;; # (end cycle 19)
; CV1-NEXT:    xso 0[$r0] = $a0
; CV1-NEXT:    ;; # (end cycle 20)
; CV1-NEXT:    xso 96[$r0] = $a3
; CV1-NEXT:    ;; # (end cycle 21)
; CV1-NEXT:    xso 64[$r0] = $a2
; CV1-NEXT:    ;; # (end cycle 22)
; CV1-NEXT:    xso 160[$r0] = $a5
; CV1-NEXT:    ;; # (end cycle 23)
; CV1-NEXT:    xso 128[$r0] = $a4
; CV1-NEXT:    ;; # (end cycle 24)
; CV1-NEXT:    xso 224[$r0] = $a7
; CV1-NEXT:    ;; # (end cycle 25)
; CV1-NEXT:    xso 192[$r0] = $a6
; CV1-NEXT:    ;; # (end cycle 26)
; CV1-NEXT:    xso 288[$r0] = $a9
; CV1-NEXT:    ;; # (end cycle 27)
; CV1-NEXT:    xso 256[$r0] = $a8
; CV1-NEXT:    ;; # (end cycle 28)
; CV1-NEXT:    xso 352[$r0] = $a11
; CV1-NEXT:    ;; # (end cycle 29)
; CV1-NEXT:    xso 320[$r0] = $a10
; CV1-NEXT:    ;; # (end cycle 30)
; CV1-NEXT:    xso 416[$r0] = $a13
; CV1-NEXT:    ;; # (end cycle 31)
; CV1-NEXT:    xso 384[$r0] = $a12
; CV1-NEXT:    ;; # (end cycle 32)
; CV1-NEXT:    xso 480[$r0] = $a15
; CV1-NEXT:    ;; # (end cycle 33)
; CV1-NEXT:    xso 448[$r0] = $a14
; CV1-NEXT:    ret
; CV1-NEXT:    ;; # (end cycle 34)
;
; CV2-LABEL: xsplat4096ri64:
; CV2:       # %bb.0:
; CV2-NEXT:    xsplatdo $a0 = 0x80000000000
; CV2-NEXT:    ;; # (end cycle 0)
; CV2-NEXT:    xsplatov $a0a1a2a3 = $a0
; CV2-NEXT:    ;; # (end cycle 4)
; CV2-NEXT:    xso 32[$r0] = $a1
; CV2-NEXT:    xcopyv $a8a9a10a11 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 8)
; CV2-NEXT:    xso 0[$r0] = $a0
; CV2-NEXT:    xcopyv $a4a5a6a7 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 9)
; CV2-NEXT:    xso 96[$r0] = $a3
; CV2-NEXT:    xcopyv $a12a13a14a15 = $a0a1a2a3
; CV2-NEXT:    ;; # (end cycle 10)
; CV2-NEXT:    xso 64[$r0] = $a2
; CV2-NEXT:    ;; # (end cycle 11)
; CV2-NEXT:    xso 288[$r0] = $a9
; CV2-NEXT:    ;; # (end cycle 12)
; CV2-NEXT:    xso 160[$r0] = $a5
; CV2-NEXT:    ;; # (end cycle 13)
; CV2-NEXT:    xso 128[$r0] = $a4
; CV2-NEXT:    ;; # (end cycle 14)
; CV2-NEXT:    xso 224[$r0] = $a7
; CV2-NEXT:    ;; # (end cycle 15)
; CV2-NEXT:    xso 192[$r0] = $a6
; CV2-NEXT:    ;; # (end cycle 16)
; CV2-NEXT:    xso 256[$r0] = $a8
; CV2-NEXT:    ;; # (end cycle 17)
; CV2-NEXT:    xso 352[$r0] = $a11
; CV2-NEXT:    ;; # (end cycle 18)
; CV2-NEXT:    xso 320[$r0] = $a10
; CV2-NEXT:    ;; # (end cycle 19)
; CV2-NEXT:    xso 416[$r0] = $a13
; CV2-NEXT:    ;; # (end cycle 20)
; CV2-NEXT:    xso 384[$r0] = $a12
; CV2-NEXT:    ;; # (end cycle 21)
; CV2-NEXT:    xso 480[$r0] = $a15
; CV2-NEXT:    ;; # (end cycle 22)
; CV2-NEXT:    xso 448[$r0] = $a14
; CV2-NEXT:    ret
; CV2-NEXT:    ;; # (end cycle 23)
  %3 = tail call <4096 x i1> @llvm.kvx.xsplat.v4096i1(i64 8796093022208)
  store <4096 x i1> %3, <4096 x i1>* %0
  ret void
}

