; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -o - %s -O2 -verify-machineinstrs | FileCheck %s --check-prefixes=CHECK
; RUN: llc -mcpu=kv3-2 -o - %s -O2 -verify-machineinstrs | FileCheck %s --check-prefixes=CHECK
; RUN: clang -O2 -c -o /dev/null %s
; RUN: clang -O2 -march=kv3-2 -c -o /dev/null %s

target triple = "kvx-kalray-cos"

define void @storebc(i8 %a, ptr %ptr) {
; CHECK-LABEL: storebc:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sb 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store i8 %a, ptr %ptr, align 1
  ret void
}

define i32 @storebc_r(i8 %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: storebc_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sb 0[$r1] = $r0
; CHECK-NEXT:    iord $r2 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  %conv1 = zext i8 %a to i64
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %conv1, ptr %ptr, i32 8, i32 %conv)
  ret i32 %conv
}

declare i64 @llvm.kvx.ready(...)

define void @storebl(i64 %a, ptr %ptr) {
; CHECK-LABEL: storebl:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sb 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = trunc i64 %a to i8
  store i8 %0, ptr %ptr, align 1
  ret void
}

define i32 @storebl_r(i64 %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: storebl_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sb 0[$r1] = $r0
; CHECK-NEXT:    iord $r2 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %a, ptr %ptr, i32 8, i32 %conv)
  ret i32 %conv
}

define void @storehs(i16 %a, ptr %ptr) {
; CHECK-LABEL: storehs:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sh 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store i16 %a, ptr %ptr, align 2
  ret void
}

define i32 @storehs_r(i16 %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: storehs_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sh 0[$r1] = $r0
; CHECK-NEXT:    iord $r2 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  %conv1 = zext i16 %a to i64
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %conv1, ptr %ptr, i32 16, i32 %conv)
  ret i32 %conv
}

define void @storehl(i64 %a, ptr %ptr) {
; CHECK-LABEL: storehl:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sh 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = trunc i64 %a to i16
  store i16 %0, ptr %ptr, align 2
  ret void
}

define i32 @storehl_r(i64 %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: storehl_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sh 0[$r1] = $r0
; CHECK-NEXT:    iord $r2 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %a, ptr %ptr, i32 16, i32 %conv)
  ret i32 %conv
}

define void @storewi(i32 %a, ptr %ptr) {
; CHECK-LABEL: storewi:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sw 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store i32 %a, ptr %ptr, align 4
  ret void
}

define i32 @storewi_r(i32 %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: storewi_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sw 0[$r1] = $r0
; CHECK-NEXT:    iord $r2 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  %conv1 = zext i32 %a to i64
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %conv1, ptr %ptr, i32 32, i32 %conv)
  ret i32 %conv
}

define void @storewl(i64 %a, ptr %ptr) {
; CHECK-LABEL: storewl:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sw 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  %0 = trunc i64 %a to i32
  store i32 %0, ptr %ptr, align 4
  ret void
}

define i32 @storewl_r(i64 %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: storewl_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sw 0[$r1] = $r0
; CHECK-NEXT:    iord $r2 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %a, ptr %ptr, i32 32, i32 %conv)
  ret i32 %conv
}

define void @storedl(i64 %a, ptr %ptr) {
; CHECK-LABEL: storedl:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sd 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store i64 %a, ptr %ptr, align 8
  ret void
}

define i32 @storedl_r(i64 %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: storedl_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 0[$r1] = $r0
; CHECK-NEXT:    iord $r2 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %a, ptr %ptr, i32 64, i32 %conv)
  ret i32 %conv
}

define void @storeq(i128 %a, ptr %ptr) {
; CHECK-LABEL: storeq:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sq 0[$r2] = $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store i128 %a, ptr %ptr, align 8
  ret void
}

define i32 @storeq_r(i128 %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: storeq_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r3 = 0[$r3]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sq 0[$r2] = $r0r1
; CHECK-NEXT:    iord $r3 = $r3, $r3
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  %2 = bitcast i128 %a to <2 x i64>
  tail call void @llvm.kvx.store.v2i64.p0.i32(<2 x i64> %2, ptr %ptr, i32 128, i32 %conv)
  ret i32 %conv
}

define void @storehf(half %a, ptr %ptr) {
; CHECK-LABEL: storehf:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sh 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store half %a, ptr %ptr, align 2
  ret void
}

define i32 @storehf_r(half %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: storehf_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sh 0[$r1] = $r0
; CHECK-NEXT:    iord $r2 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  tail call void @llvm.kvx.store.f16.p0.i32(half %a, ptr %ptr, i32 16, i32 %conv)
  ret i32 %conv
}

define void @storewf(float %a, ptr %ptr) {
; CHECK-LABEL: storewf:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sw 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store float %a, ptr %ptr, align 4
  ret void
}

define i32 @storewf_r(float %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: storewf_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sw 0[$r1] = $r0
; CHECK-NEXT:    iord $r2 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  tail call void @llvm.kvx.store.f32.p0.i32(float %a, ptr %ptr, i32 32, i32 %conv)
  ret i32 %conv
}

define void @storedf(double %a, ptr %ptr) {
; CHECK-LABEL: storedf:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sd 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store double %a, ptr %ptr, align 8
  ret void
}

define i32 @storedf_r(double %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: storedf_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 0[$r1] = $r0
; CHECK-NEXT:    iord $r2 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  tail call void @llvm.kvx.store.f64.p0.i32(double %a, ptr %ptr, i32 64, i32 %conv)
  ret i32 %conv
}

define void @store64(<2 x i32> %a, ptr %ptr) {
; CHECK-LABEL: store64:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sd 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store <2 x i32> %a, ptr %ptr, align 8
  ret void
}

define i32 @store64_r(<2 x i32> %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: store64_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 0[$r1] = $r0
; CHECK-NEXT:    iord $r2 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  %2 = bitcast <2 x i32> %a to i64
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %2, ptr %ptr, i32 64, i32 %conv)
  ret i32 %conv
}

define void @store64h(<4 x i16> %a, ptr %ptr) {
; CHECK-LABEL: store64h:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sd 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store <4 x i16> %a, ptr %ptr, align 8
  ret void
}

define i32 @store64h_r(<4 x i16> %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: store64h_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sd 0[$r1] = $r0
; CHECK-NEXT:    iord $r2 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  %2 = bitcast <4 x i16> %a to i64
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %2, ptr %ptr, i32 64, i32 %conv)
  ret i32 %conv
}

define void @store128(<4 x i32> %a, ptr %ptr) {
; CHECK-LABEL: store128:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sq 0[$r2] = $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store <4 x i32> %a, ptr %ptr, align 16
  ret void
}

define i32 @store128_r(<4 x i32> %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: store128_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r3 = 0[$r3]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sq 0[$r2] = $r0r1
; CHECK-NEXT:    iord $r3 = $r3, $r3
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  %2 = bitcast <4 x i32> %a to <2 x i64>
  tail call void @llvm.kvx.store.v2i64.p0.i32(<2 x i64> %2, ptr %ptr, i32 128, i32 %conv)
  ret i32 %conv
}

define void @store128h(<8 x i16> %a, ptr %ptr) {
; CHECK-LABEL: store128h:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sq 0[$r2] = $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store <8 x i16> %a, ptr %ptr, align 16
  ret void
}

define i32 @store128h_r(<8 x i16> %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: store128h_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r3 = 0[$r3]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sq 0[$r2] = $r0r1
; CHECK-NEXT:    iord $r3 = $r3, $r3
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  %2 = bitcast <8 x i16> %a to <2 x i64>
  tail call void @llvm.kvx.store.v2i64.p0.i32(<2 x i64> %2, ptr %ptr, i32 128, i32 %conv)
  ret i32 %conv
}

define void @store256(<8 x i32> %a, ptr %ptr) {
; CHECK-LABEL: store256:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    so 0[$r4] = $r0r1r2r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store <8 x i32> %a, ptr %ptr, align 32
  ret void
}

define i32 @store256_r(<8 x i32> %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: store256_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r5 = 0[$r5]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    so 0[$r4] = $r0r1r2r3
; CHECK-NEXT:    iord $r5 = $r5, $r5
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  %2 = bitcast <8 x i32> %a to <4 x i64>
  tail call void @llvm.kvx.store.v4i64.p0.i32(<4 x i64> %2, ptr %ptr, i32 256, i32 %conv)
  ret i32 %conv
}

define void @store256h(<16 x i16> %a, ptr %ptr) {
; CHECK-LABEL: store256h:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    so 0[$r4] = $r0r1r2r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store <16 x i16> %a, ptr %ptr, align 32
  ret void
}

define i32 @store256h_r(<16 x i16> %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: store256h_r:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r5 = 0[$r5]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    so 0[$r4] = $r0r1r2r3
; CHECK-NEXT:    iord $r5 = $r5, $r5
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    copyd $r0 = $r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  %2 = bitcast <16 x i16> %a to <4 x i64>
  tail call void @llvm.kvx.store.v4i64.p0.i32(<4 x i64> %2, ptr %ptr, i32 256, i32 %conv)
  ret i32 %conv
}

define void @store_vol(i32 %a, ptr %ptr) {
; CHECK-LABEL: store_vol:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sw 0[$r1] = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sw 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
entry:
  store volatile i32 %a, ptr %ptr, align 4
  store volatile i32 %a, ptr %ptr, align 4
  ret void
}

define void @store_novol(i32 %a, ptr %ptr) {
; CHECK-LABEL: store_novol:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sw 0[$r1] = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 0)
entry:
  store i32 %a, ptr %ptr, align 4
  ret void
}

define i32 @store_r_vol(i32 %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: store_r_vol:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    sxwd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sw 0[$r1] = $r3
; CHECK-NEXT:    iord $r0 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sw 0[$r1] = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  %conv1 = sext i32 %a to i64
  tail call void @llvm.kvx.store.vol.i64.p0.i32(i64 %conv1, ptr %ptr, i32 32, i32 %conv)
  tail call void @llvm.kvx.store.vol.i64.p0.i32(i64 %conv1, ptr %ptr, i32 32, i32 %conv)
  ret i32 %conv
}

define i32 @store_r_novol(i32 %a, ptr %ptr, ptr %load) {
; CHECK-LABEL: store_r_novol:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    sxwd $r3 = $r0
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sw 0[$r1] = $r3
; CHECK-NEXT:    iord $r0 = $r2, $r2
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sw 0[$r1] = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 4)
entry:
  %0 = load i32, ptr %load, align 4
  %1 = tail call i64 (...) @llvm.kvx.ready(i32 %0)
  %conv = trunc i64 %1 to i32
  %conv1 = sext i32 %a to i64
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %conv1, ptr %ptr, i32 32, i32 %conv)
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %conv1, ptr %ptr, i32 32, i32 %conv)
  ret i32 %conv
}

define void @ready_then_store(ptr %addr0, ptr %addr1, ptr %addr2, ptr %to0, ptr %to1, ptr %to2) {
; CHECK-LABEL: ready_then_store:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lws $r0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lws $r1 = 0[$r1]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lws $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sw 0[$r3] = $r0
; CHECK-NEXT:    iord $r6 = $r0, $r1
; CHECK-NEXT:    iord $r6 = $r2, $r0
; CHECK-NEXT:    ;; # (end cycle 5)
; CHECK-NEXT:    sw 0[$r4] = $r1
; CHECK-NEXT:    ;; # (end cycle 6)
; CHECK-NEXT:    sw 0[$r5] = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 7)
entry:
  %0 = load i32, ptr %addr0, align 4
  %1 = load i32, ptr %addr1, align 4
  %2 = load i32, ptr %addr2, align 4
  %3 = tail call i64 (...) @llvm.kvx.ready(i32 %0, i32 %1, i32 %2)
  %conv = trunc i64 %3 to i32
  %conv1 = sext i32 %0 to i64
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %conv1, ptr %to0, i32 32, i32 %conv)
  %conv2 = sext i32 %1 to i64
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %conv2, ptr %to1, i32 32, i32 %conv)
  %conv3 = sext i32 %2 to i64
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %conv3, ptr %to2, i32 32, i32 %conv)
  ret void
}

define void @load_then_store(ptr %addr0, ptr %addr1, ptr %addr2, ptr %to0, ptr %to1, ptr %to2) {
; CHECK-LABEL: load_then_store:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lwz $r0 = 0[$r0]
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    lwz $r1 = 0[$r1]
; CHECK-NEXT:    ;; # (end cycle 1)
; CHECK-NEXT:    lwz $r2 = 0[$r2]
; CHECK-NEXT:    ;; # (end cycle 2)
; CHECK-NEXT:    sw 0[$r3] = $r0
; CHECK-NEXT:    ;; # (end cycle 3)
; CHECK-NEXT:    sw 0[$r4] = $r1
; CHECK-NEXT:    ;; # (end cycle 4)
; CHECK-NEXT:    sw 0[$r5] = $r2
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 5)
entry:
  %0 = load i32, ptr %addr0, align 4
  %1 = load i32, ptr %addr1, align 4
  %2 = load i32, ptr %addr2, align 4
  store i32 %0, ptr %to0, align 4
  store i32 %1, ptr %to1, align 4
  store i32 %2, ptr %to2, align 4
  ret void
}

define void @store_imm(ptr %addr, i32 %sv, i32 %ready) {
; CHECK-LABEL: store_imm:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addd $r0 = $r0, 4
; CHECK-NEXT:    sxwd $r1 = $r1
; CHECK-NEXT:    ;; # (end cycle 0)
; CHECK-NEXT:    sw 0[$r0] = $r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;; # (end cycle 1)
entry:
  %conv = sext i32 %sv to i64
  %arrayidx = getelementptr inbounds i8, ptr %addr, i64 4
  tail call void @llvm.kvx.store.i64.p0.i32(i64 %conv, ptr nonnull %arrayidx, i32 32, i32 %ready)
  ret void
}

declare void @llvm.kvx.store.i64.p0.i32(i64, ptr, i32, i32)

declare void @llvm.kvx.store.v2i64.p0.i32(<2 x i64>, ptr, i32, i32)

declare void @llvm.kvx.store.f16.p0.i32(half, ptr, i32, i32)

declare void @llvm.kvx.store.f32.p0.i32(float, ptr, i32, i32)

declare void @llvm.kvx.store.f64.p0.i32(double, ptr, i32, i32)

declare void @llvm.kvx.store.v4i64.p0.i32(<4 x i64>, ptr, i32, i32)

declare void @llvm.kvx.store.vol.i64.p0.i32(i64, ptr, i32, i32)

